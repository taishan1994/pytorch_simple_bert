nohup: 忽略输入
/data02/gob/envs/python3.6/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:1641: FutureWarning: Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated and won't be possible anymore in v5. Use a model identifier or the path to a directory instead.
  FutureWarning,
input_ids: [101, 704, 1290, 1957, 2094, 2110, 7368, 8038, 3315, 4906, 2231, 3613, 788, 122, 683, 689, 2875, 4511, 4495, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
label: 3
input_ids: [101, 697, 1921, 817, 5381, 4991, 5520, 1400, 7028, 7028, 6837, 7443, 8038, 976, 702, 5381, 4991, 4955, 4994, 6206, 1914, 2208, 7178, 102, 0, 0, 0, 0, 0, 0, 0, 0]
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]
label: 4
input_ids: [101, 691, 126, 4384, 3862, 3478, 1062, 4852, 9111, 118, 9845, 2398, 123, 2233, 1114, 4385, 2791, 8327, 2835, 831, 2669, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
label: 1
input_ids: [101, 860, 7741, 9648, 2330, 2292, 953, 1921, 2248, 7987, 6381, 1282, 1920, 1158, 3173, 3519, 6229, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
label: 8
input_ids: [101, 8183, 2399, 7188, 3409, 2458, 5709, 2501, 4307, 849, 4373, 5101, 5708, 113, 5299, 1745, 114, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
label: 5
input_ids: [101, 1398, 3635, 143, 5500, 7674, 4899, 8038, 3949, 5500, 5367, 7030, 1726, 6444, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
label: 2
input_ids: [101, 6404, 3726, 7325, 6438, 3221, 1068, 7241, 8142, 2399, 5440, 4777, 3264, 3309, 5739, 6427, 1908, 739, 1059, 2900, 1298, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
label: 3
input_ids: [101, 704, 1744, 782, 3696, 1062, 2128, 1920, 2110, 8151, 2399, 4798, 1894, 4777, 4955, 4495, 4680, 2497, 1350, 741, 4680, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
label: 3
input_ids: [101, 3189, 3315, 1765, 7448, 8038, 7032, 1395, 1154, 1068, 3800, 1762, 3189, 2110, 2094, 5143, 1154, 2845, 6887, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
label: 3
{'token_ids': tensor([ 101,  704, 1290, 1957, 2094, 2110, 7368, 8038, 3315, 4906, 2231, 3613,
         788,  122,  683,  689, 2875, 4511, 4495,  102,    0,    0,    0,    0,
           0,    0,    0,    0,    0,    0,    0,    0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0]), 'attention_masks': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0]), 'labels': tensor(3)}
【train】 epoch：0 step:0/14065 loss：2.412215
【train】 epoch：0 step:1/14065 loss：2.353096
【train】 epoch：0 step:2/14065 loss：2.272873
【train】 epoch：0 step:3/14065 loss：2.255766
【train】 epoch：0 step:4/14065 loss：2.259874
【train】 epoch：0 step:5/14065 loss：2.158639
【train】 epoch：0 step:6/14065 loss：2.148731
【train】 epoch：0 step:7/14065 loss：2.221019
【train】 epoch：0 step:8/14065 loss：2.164906
【train】 epoch：0 step:9/14065 loss：2.103571
【train】 epoch：0 step:10/14065 loss：2.067668
【train】 epoch：0 step:11/14065 loss：2.054495
【train】 epoch：0 step:12/14065 loss：1.968975
【train】 epoch：0 step:13/14065 loss：1.841659
【train】 epoch：0 step:14/14065 loss：1.795961
【train】 epoch：0 step:15/14065 loss：1.835525
【train】 epoch：0 step:16/14065 loss：1.634886
【train】 epoch：0 step:17/14065 loss：1.621820
【train】 epoch：0 step:18/14065 loss：1.543494
【train】 epoch：0 step:19/14065 loss：1.416858
【train】 epoch：0 step:20/14065 loss：1.442211
【train】 epoch：0 step:21/14065 loss：1.230017
【train】 epoch：0 step:22/14065 loss：1.261969
【train】 epoch：0 step:23/14065 loss：1.231330
【train】 epoch：0 step:24/14065 loss：1.044800
【train】 epoch：0 step:25/14065 loss：1.075121
【train】 epoch：0 step:26/14065 loss：1.003639
【train】 epoch：0 step:27/14065 loss：1.069033
【train】 epoch：0 step:28/14065 loss：0.933528
【train】 epoch：0 step:29/14065 loss：1.009563
【train】 epoch：0 step:30/14065 loss：0.977729
【train】 epoch：0 step:31/14065 loss：0.845975
【train】 epoch：0 step:32/14065 loss：0.902854
【train】 epoch：0 step:33/14065 loss：0.798012
【train】 epoch：0 step:34/14065 loss：0.890043
【train】 epoch：0 step:35/14065 loss：0.742243
【train】 epoch：0 step:36/14065 loss：0.615827
【train】 epoch：0 step:37/14065 loss：0.978696
【train】 epoch：0 step:38/14065 loss：0.738457
【train】 epoch：0 step:39/14065 loss：0.539300
【train】 epoch：0 step:40/14065 loss：0.810101
【train】 epoch：0 step:41/14065 loss：0.552832
【train】 epoch：0 step:42/14065 loss：0.646816
【train】 epoch：0 step:43/14065 loss：0.542826
【train】 epoch：0 step:44/14065 loss：0.607349
【train】 epoch：0 step:45/14065 loss：0.682486
【train】 epoch：0 step:46/14065 loss：0.615565
【train】 epoch：0 step:47/14065 loss：0.568343
【train】 epoch：0 step:48/14065 loss：0.600130
【train】 epoch：0 step:49/14065 loss：0.486764
【train】 epoch：0 step:50/14065 loss：0.714471
【train】 epoch：0 step:51/14065 loss：0.590598
【train】 epoch：0 step:52/14065 loss：0.608760
【train】 epoch：0 step:53/14065 loss：0.438464
【train】 epoch：0 step:54/14065 loss：0.428712
【train】 epoch：0 step:55/14065 loss：0.665780
【train】 epoch：0 step:56/14065 loss：0.492599
【train】 epoch：0 step:57/14065 loss：0.609207
【train】 epoch：0 step:58/14065 loss：0.364668
【train】 epoch：0 step:59/14065 loss：0.604717
【train】 epoch：0 step:60/14065 loss：0.700268
【train】 epoch：0 step:61/14065 loss：0.599648
【train】 epoch：0 step:62/14065 loss：0.617937
【train】 epoch：0 step:63/14065 loss：0.627450
【train】 epoch：0 step:64/14065 loss：0.526132
【train】 epoch：0 step:65/14065 loss：0.324383
【train】 epoch：0 step:66/14065 loss：0.433347
【train】 epoch：0 step:67/14065 loss：0.333808
【train】 epoch：0 step:68/14065 loss：0.334093
【train】 epoch：0 step:69/14065 loss：0.391834
【train】 epoch：0 step:70/14065 loss：0.626733
【train】 epoch：0 step:71/14065 loss：0.518687
【train】 epoch：0 step:72/14065 loss：0.435205
【train】 epoch：0 step:73/14065 loss：0.429311
【train】 epoch：0 step:74/14065 loss：0.503760
【train】 epoch：0 step:75/14065 loss：0.495004
【train】 epoch：0 step:76/14065 loss：0.415608
【train】 epoch：0 step:77/14065 loss：0.380370
【train】 epoch：0 step:78/14065 loss：0.512474
【train】 epoch：0 step:79/14065 loss：0.674819
【train】 epoch：0 step:80/14065 loss：0.309836
【train】 epoch：0 step:81/14065 loss：0.340387
【train】 epoch：0 step:82/14065 loss：0.404173
【train】 epoch：0 step:83/14065 loss：0.235934
【train】 epoch：0 step:84/14065 loss：0.398896
【train】 epoch：0 step:85/14065 loss：0.284611
【train】 epoch：0 step:86/14065 loss：0.427769
【train】 epoch：0 step:87/14065 loss：0.432410
【train】 epoch：0 step:88/14065 loss：0.446560
【train】 epoch：0 step:89/14065 loss：0.495184
【train】 epoch：0 step:90/14065 loss：0.386628
【train】 epoch：0 step:91/14065 loss：0.382016
【train】 epoch：0 step:92/14065 loss：0.724275
【train】 epoch：0 step:93/14065 loss：0.281986
【train】 epoch：0 step:94/14065 loss：0.221161
【train】 epoch：0 step:95/14065 loss：0.402732
【train】 epoch：0 step:96/14065 loss：0.373743
【train】 epoch：0 step:97/14065 loss：0.322975
【train】 epoch：0 step:98/14065 loss：0.265730
【train】 epoch：0 step:99/14065 loss：0.310036
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：992.354712 accuracy：0.9083 precision：0.9083 recall：0.9083 f1：0.9083
------------>保存当前最好的模型
【train】 epoch：0 step:100/14065 loss：0.459296
【train】 epoch：0 step:101/14065 loss：0.270136
【train】 epoch：0 step:102/14065 loss：0.357022
【train】 epoch：0 step:103/14065 loss：0.306388
【train】 epoch：0 step:104/14065 loss：0.520022
【train】 epoch：0 step:105/14065 loss：0.714274
【train】 epoch：0 step:106/14065 loss：0.479566
【train】 epoch：0 step:107/14065 loss：0.411353
【train】 epoch：0 step:108/14065 loss：0.524072
【train】 epoch：0 step:109/14065 loss：0.414397
【train】 epoch：0 step:110/14065 loss：0.409584
【train】 epoch：0 step:111/14065 loss：0.228404
【train】 epoch：0 step:112/14065 loss：0.387846
【train】 epoch：0 step:113/14065 loss：0.371326
【train】 epoch：0 step:114/14065 loss：0.260765
【train】 epoch：0 step:115/14065 loss：0.212106
【train】 epoch：0 step:116/14065 loss：0.304883
【train】 epoch：0 step:117/14065 loss：0.306532
【train】 epoch：0 step:118/14065 loss：0.473359
【train】 epoch：0 step:119/14065 loss：0.404294
【train】 epoch：0 step:120/14065 loss：0.375868
【train】 epoch：0 step:121/14065 loss：0.481416
【train】 epoch：0 step:122/14065 loss：0.212104
【train】 epoch：0 step:123/14065 loss：0.338568
【train】 epoch：0 step:124/14065 loss：0.309685
【train】 epoch：0 step:125/14065 loss：0.342871
【train】 epoch：0 step:126/14065 loss：0.256259
【train】 epoch：0 step:127/14065 loss：0.411809
【train】 epoch：0 step:128/14065 loss：0.414247
【train】 epoch：0 step:129/14065 loss：0.525264
【train】 epoch：0 step:130/14065 loss：0.283038
【train】 epoch：0 step:131/14065 loss：0.616510
【train】 epoch：0 step:132/14065 loss：0.355246
【train】 epoch：0 step:133/14065 loss：0.179773
【train】 epoch：0 step:134/14065 loss：0.449270
【train】 epoch：0 step:135/14065 loss：0.510925
【train】 epoch：0 step:136/14065 loss：0.288242
【train】 epoch：0 step:137/14065 loss：0.355721
【train】 epoch：0 step:138/14065 loss：0.336808
【train】 epoch：0 step:139/14065 loss：0.310255
【train】 epoch：0 step:140/14065 loss：0.213858
【train】 epoch：0 step:141/14065 loss：0.524352
【train】 epoch：0 step:142/14065 loss：0.236567
【train】 epoch：0 step:143/14065 loss：0.391716
【train】 epoch：0 step:144/14065 loss：0.326503
【train】 epoch：0 step:145/14065 loss：0.382322
【train】 epoch：0 step:146/14065 loss：0.217066
【train】 epoch：0 step:147/14065 loss：0.215501
【train】 epoch：0 step:148/14065 loss：0.472736
【train】 epoch：0 step:149/14065 loss：0.411989
【train】 epoch：0 step:150/14065 loss：0.354245
【train】 epoch：0 step:151/14065 loss：0.366844
【train】 epoch：0 step:152/14065 loss：0.569124
【train】 epoch：0 step:153/14065 loss：0.420616
【train】 epoch：0 step:154/14065 loss：0.283566
【train】 epoch：0 step:155/14065 loss：0.207005
【train】 epoch：0 step:156/14065 loss：0.397551
【train】 epoch：0 step:157/14065 loss：0.301494
【train】 epoch：0 step:158/14065 loss：0.183114
【train】 epoch：0 step:159/14065 loss：0.193008
【train】 epoch：0 step:160/14065 loss：0.274043
【train】 epoch：0 step:161/14065 loss：0.537636
【train】 epoch：0 step:162/14065 loss：0.453836
【train】 epoch：0 step:163/14065 loss：0.435264
【train】 epoch：0 step:164/14065 loss：0.231842
【train】 epoch：0 step:165/14065 loss：0.156661
【train】 epoch：0 step:166/14065 loss：0.288925
【train】 epoch：0 step:167/14065 loss：0.354061
【train】 epoch：0 step:168/14065 loss：0.299667
【train】 epoch：0 step:169/14065 loss：0.329349
【train】 epoch：0 step:170/14065 loss：0.312403
【train】 epoch：0 step:171/14065 loss：0.234431
【train】 epoch：0 step:172/14065 loss：0.340566
【train】 epoch：0 step:173/14065 loss：0.291988
【train】 epoch：0 step:174/14065 loss：0.388161
【train】 epoch：0 step:175/14065 loss：0.507583
【train】 epoch：0 step:176/14065 loss：0.414111
【train】 epoch：0 step:177/14065 loss：0.102716
【train】 epoch：0 step:178/14065 loss：0.284838
【train】 epoch：0 step:179/14065 loss：0.253896
【train】 epoch：0 step:180/14065 loss：0.250738
【train】 epoch：0 step:181/14065 loss：0.430997
【train】 epoch：0 step:182/14065 loss：0.283052
【train】 epoch：0 step:183/14065 loss：0.426459
【train】 epoch：0 step:184/14065 loss：0.281734
【train】 epoch：0 step:185/14065 loss：0.497389
【train】 epoch：0 step:186/14065 loss：0.311166
【train】 epoch：0 step:187/14065 loss：0.273866
【train】 epoch：0 step:188/14065 loss：0.239475
【train】 epoch：0 step:189/14065 loss：0.291042
【train】 epoch：0 step:190/14065 loss：0.316022
【train】 epoch：0 step:191/14065 loss：0.426415
【train】 epoch：0 step:192/14065 loss：0.216363
【train】 epoch：0 step:193/14065 loss：0.339357
【train】 epoch：0 step:194/14065 loss：0.495682
【train】 epoch：0 step:195/14065 loss：0.300490
【train】 epoch：0 step:196/14065 loss：0.240281
【train】 epoch：0 step:197/14065 loss：0.234919
【train】 epoch：0 step:198/14065 loss：0.171447
【train】 epoch：0 step:199/14065 loss：0.317753
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：796.792930 accuracy：0.9188 precision：0.9188 recall：0.9188 f1：0.9188
------------>保存当前最好的模型
【train】 epoch：0 step:200/14065 loss：0.269957
【train】 epoch：0 step:201/14065 loss：0.246577
【train】 epoch：0 step:202/14065 loss：0.212046
【train】 epoch：0 step:203/14065 loss：0.280329
【train】 epoch：0 step:204/14065 loss：0.453765
【train】 epoch：0 step:205/14065 loss：0.293014
【train】 epoch：0 step:206/14065 loss：0.504910
【train】 epoch：0 step:207/14065 loss：0.313900
【train】 epoch：0 step:208/14065 loss：0.385203
【train】 epoch：0 step:209/14065 loss：0.282265
【train】 epoch：0 step:210/14065 loss：0.293875
【train】 epoch：0 step:211/14065 loss：0.191504
【train】 epoch：0 step:212/14065 loss：0.519099
【train】 epoch：0 step:213/14065 loss：0.440356
【train】 epoch：0 step:214/14065 loss：0.363523
【train】 epoch：0 step:215/14065 loss：0.129655
【train】 epoch：0 step:216/14065 loss：0.278885
【train】 epoch：0 step:217/14065 loss：0.299742
【train】 epoch：0 step:218/14065 loss：0.187493
【train】 epoch：0 step:219/14065 loss：0.334411
【train】 epoch：0 step:220/14065 loss：0.422343
【train】 epoch：0 step:221/14065 loss：0.204964
【train】 epoch：0 step:222/14065 loss：0.232782
【train】 epoch：0 step:223/14065 loss：0.269915
【train】 epoch：0 step:224/14065 loss：0.184054
【train】 epoch：0 step:225/14065 loss：0.256348
【train】 epoch：0 step:226/14065 loss：0.431318
【train】 epoch：0 step:227/14065 loss：0.362198
【train】 epoch：0 step:228/14065 loss：0.501152
【train】 epoch：0 step:229/14065 loss：0.278745
【train】 epoch：0 step:230/14065 loss：0.365916
【train】 epoch：0 step:231/14065 loss：0.245946
【train】 epoch：0 step:232/14065 loss：0.235500
【train】 epoch：0 step:233/14065 loss：0.224920
【train】 epoch：0 step:234/14065 loss：0.275072
【train】 epoch：0 step:235/14065 loss：0.191555
【train】 epoch：0 step:236/14065 loss：0.369767
【train】 epoch：0 step:237/14065 loss：0.324567
【train】 epoch：0 step:238/14065 loss：0.256613
【train】 epoch：0 step:239/14065 loss：0.259686
【train】 epoch：0 step:240/14065 loss：0.313061
【train】 epoch：0 step:241/14065 loss：0.140764
【train】 epoch：0 step:242/14065 loss：0.352236
【train】 epoch：0 step:243/14065 loss：0.561566
【train】 epoch：0 step:244/14065 loss：0.186296
【train】 epoch：0 step:245/14065 loss：0.132549
【train】 epoch：0 step:246/14065 loss：0.309388
【train】 epoch：0 step:247/14065 loss：0.505709
【train】 epoch：0 step:248/14065 loss：0.369357
【train】 epoch：0 step:249/14065 loss：0.354686
【train】 epoch：0 step:250/14065 loss：0.285009
【train】 epoch：0 step:251/14065 loss：0.161475
【train】 epoch：0 step:252/14065 loss：0.166168
【train】 epoch：0 step:253/14065 loss：0.372717
【train】 epoch：0 step:254/14065 loss：0.416939
【train】 epoch：0 step:255/14065 loss：0.226172
【train】 epoch：0 step:256/14065 loss：0.394954
【train】 epoch：0 step:257/14065 loss：0.208546
【train】 epoch：0 step:258/14065 loss：0.350302
【train】 epoch：0 step:259/14065 loss：0.289962
【train】 epoch：0 step:260/14065 loss：0.227676
【train】 epoch：0 step:261/14065 loss：0.410902
【train】 epoch：0 step:262/14065 loss：0.274797
【train】 epoch：0 step:263/14065 loss：0.293150
【train】 epoch：0 step:264/14065 loss：0.434422
【train】 epoch：0 step:265/14065 loss：0.199170
【train】 epoch：0 step:266/14065 loss：0.314586
【train】 epoch：0 step:267/14065 loss：0.451910
【train】 epoch：0 step:268/14065 loss：0.133978
【train】 epoch：0 step:269/14065 loss：0.165204
【train】 epoch：0 step:270/14065 loss：0.244345
【train】 epoch：0 step:271/14065 loss：0.250526
【train】 epoch：0 step:272/14065 loss：0.364982
【train】 epoch：0 step:273/14065 loss：0.200363
【train】 epoch：0 step:274/14065 loss：0.294266
【train】 epoch：0 step:275/14065 loss：0.268426
【train】 epoch：0 step:276/14065 loss：0.188099
【train】 epoch：0 step:277/14065 loss：0.288500
【train】 epoch：0 step:278/14065 loss：0.253329
【train】 epoch：0 step:279/14065 loss：0.394051
【train】 epoch：0 step:280/14065 loss：0.330687
【train】 epoch：0 step:281/14065 loss：0.347204
【train】 epoch：0 step:282/14065 loss：0.219060
【train】 epoch：0 step:283/14065 loss：0.361951
【train】 epoch：0 step:284/14065 loss：0.368593
【train】 epoch：0 step:285/14065 loss：0.338913
【train】 epoch：0 step:286/14065 loss：0.386164
【train】 epoch：0 step:287/14065 loss：0.320577
【train】 epoch：0 step:288/14065 loss：0.433350
【train】 epoch：0 step:289/14065 loss：0.294221
【train】 epoch：0 step:290/14065 loss：0.378373
【train】 epoch：0 step:291/14065 loss：0.350402
【train】 epoch：0 step:292/14065 loss：0.280973
【train】 epoch：0 step:293/14065 loss：0.219503
【train】 epoch：0 step:294/14065 loss：0.091555
【train】 epoch：0 step:295/14065 loss：0.337844
【train】 epoch：0 step:296/14065 loss：0.397729
【train】 epoch：0 step:297/14065 loss：0.270569
【train】 epoch：0 step:298/14065 loss：0.194855
【train】 epoch：0 step:299/14065 loss：0.362855
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：711.410351 accuracy：0.9269 precision：0.9269 recall：0.9269 f1：0.9269
------------>保存当前最好的模型
【train】 epoch：0 step:300/14065 loss：0.273264
【train】 epoch：0 step:301/14065 loss：0.141031
【train】 epoch：0 step:302/14065 loss：0.364273
【train】 epoch：0 step:303/14065 loss：0.377698
【train】 epoch：0 step:304/14065 loss：0.266851
【train】 epoch：0 step:305/14065 loss：0.235549
【train】 epoch：0 step:306/14065 loss：0.217614
【train】 epoch：0 step:307/14065 loss：0.156866
【train】 epoch：0 step:308/14065 loss：0.254546
【train】 epoch：0 step:309/14065 loss：0.332220
【train】 epoch：0 step:310/14065 loss：0.275309
【train】 epoch：0 step:311/14065 loss：0.292007
【train】 epoch：0 step:312/14065 loss：0.122187
【train】 epoch：0 step:313/14065 loss：0.305157
【train】 epoch：0 step:314/14065 loss：0.258585
【train】 epoch：0 step:315/14065 loss：0.257500
【train】 epoch：0 step:316/14065 loss：0.521854
【train】 epoch：0 step:317/14065 loss：0.251023
【train】 epoch：0 step:318/14065 loss：0.341543
【train】 epoch：0 step:319/14065 loss：0.314415
【train】 epoch：0 step:320/14065 loss：0.308722
【train】 epoch：0 step:321/14065 loss：0.336162
【train】 epoch：0 step:322/14065 loss：0.213349
【train】 epoch：0 step:323/14065 loss：0.290382
【train】 epoch：0 step:324/14065 loss：0.195103
【train】 epoch：0 step:325/14065 loss：0.313005
【train】 epoch：0 step:326/14065 loss：0.279635
【train】 epoch：0 step:327/14065 loss：0.236211
【train】 epoch：0 step:328/14065 loss：0.211264
【train】 epoch：0 step:329/14065 loss：0.342180
【train】 epoch：0 step:330/14065 loss：0.400204
【train】 epoch：0 step:331/14065 loss：0.477328
【train】 epoch：0 step:332/14065 loss：0.263449
【train】 epoch：0 step:333/14065 loss：0.204410
【train】 epoch：0 step:334/14065 loss：0.279833
【train】 epoch：0 step:335/14065 loss：0.421848
【train】 epoch：0 step:336/14065 loss：0.333930
【train】 epoch：0 step:337/14065 loss：0.241032
【train】 epoch：0 step:338/14065 loss：0.193980
【train】 epoch：0 step:339/14065 loss：0.344606
【train】 epoch：0 step:340/14065 loss：0.199423
【train】 epoch：0 step:341/14065 loss：0.293591
【train】 epoch：0 step:342/14065 loss：0.381971
【train】 epoch：0 step:343/14065 loss：0.245233
【train】 epoch：0 step:344/14065 loss：0.232846
【train】 epoch：0 step:345/14065 loss：0.167264
【train】 epoch：0 step:346/14065 loss：0.197962
【train】 epoch：0 step:347/14065 loss：0.279620
【train】 epoch：0 step:348/14065 loss：0.145693
【train】 epoch：0 step:349/14065 loss：0.217457
【train】 epoch：0 step:350/14065 loss：0.303681
【train】 epoch：0 step:351/14065 loss：0.222974
【train】 epoch：0 step:352/14065 loss：0.173732
【train】 epoch：0 step:353/14065 loss：0.411031
【train】 epoch：0 step:354/14065 loss：0.325662
【train】 epoch：0 step:355/14065 loss：0.394458
【train】 epoch：0 step:356/14065 loss：0.337961
【train】 epoch：0 step:357/14065 loss：0.269093
【train】 epoch：0 step:358/14065 loss：0.235693
【train】 epoch：0 step:359/14065 loss：0.143225
【train】 epoch：0 step:360/14065 loss：0.140686
【train】 epoch：0 step:361/14065 loss：0.260818
【train】 epoch：0 step:362/14065 loss：0.283748
【train】 epoch：0 step:363/14065 loss：0.128881
【train】 epoch：0 step:364/14065 loss：0.242759
【train】 epoch：0 step:365/14065 loss：0.277607
【train】 epoch：0 step:366/14065 loss：0.220374
【train】 epoch：0 step:367/14065 loss：0.308945
【train】 epoch：0 step:368/14065 loss：0.420884
【train】 epoch：0 step:369/14065 loss：0.333473
【train】 epoch：0 step:370/14065 loss：0.175692
【train】 epoch：0 step:371/14065 loss：0.230782
【train】 epoch：0 step:372/14065 loss：0.431421
【train】 epoch：0 step:373/14065 loss：0.358294
【train】 epoch：0 step:374/14065 loss：0.350515
【train】 epoch：0 step:375/14065 loss：0.264228
【train】 epoch：0 step:376/14065 loss：0.308346
【train】 epoch：0 step:377/14065 loss：0.193109
【train】 epoch：0 step:378/14065 loss：0.266320
【train】 epoch：0 step:379/14065 loss：0.264754
【train】 epoch：0 step:380/14065 loss：0.262848
【train】 epoch：0 step:381/14065 loss：0.274443
【train】 epoch：0 step:382/14065 loss：0.316466
【train】 epoch：0 step:383/14065 loss：0.250349
【train】 epoch：0 step:384/14065 loss：0.145340
【train】 epoch：0 step:385/14065 loss：0.183301
【train】 epoch：0 step:386/14065 loss：0.211666
【train】 epoch：0 step:387/14065 loss：0.188198
【train】 epoch：0 step:388/14065 loss：0.122366
【train】 epoch：0 step:389/14065 loss：0.235000
【train】 epoch：0 step:390/14065 loss：0.379283
【train】 epoch：0 step:391/14065 loss：0.512720
【train】 epoch：0 step:392/14065 loss：0.241723
【train】 epoch：0 step:393/14065 loss：0.218257
【train】 epoch：0 step:394/14065 loss：0.330494
【train】 epoch：0 step:395/14065 loss：0.180815
【train】 epoch：0 step:396/14065 loss：0.381934
【train】 epoch：0 step:397/14065 loss：0.369674
【train】 epoch：0 step:398/14065 loss：0.119357
【train】 epoch：0 step:399/14065 loss：0.153995
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：702.761921 accuracy：0.9254 precision：0.9254 recall：0.9254 f1：0.9254
【train】 epoch：0 step:400/14065 loss：0.216532
【train】 epoch：0 step:401/14065 loss：0.413040
【train】 epoch：0 step:402/14065 loss：0.137549
【train】 epoch：0 step:403/14065 loss：0.273432
【train】 epoch：0 step:404/14065 loss：0.279412
【train】 epoch：0 step:405/14065 loss：0.343396
【train】 epoch：0 step:406/14065 loss：0.356603
【train】 epoch：0 step:407/14065 loss：0.152379
【train】 epoch：0 step:408/14065 loss：0.209759
【train】 epoch：0 step:409/14065 loss：0.307856
【train】 epoch：0 step:410/14065 loss：0.330015
【train】 epoch：0 step:411/14065 loss：0.420179
【train】 epoch：0 step:412/14065 loss：0.336640
【train】 epoch：0 step:413/14065 loss：0.267511
【train】 epoch：0 step:414/14065 loss：0.340853
【train】 epoch：0 step:415/14065 loss：0.340954
【train】 epoch：0 step:416/14065 loss：0.254066
【train】 epoch：0 step:417/14065 loss：0.668089
【train】 epoch：0 step:418/14065 loss：0.301722
【train】 epoch：0 step:419/14065 loss：0.445972
【train】 epoch：0 step:420/14065 loss：0.222307
【train】 epoch：0 step:421/14065 loss：0.382438
【train】 epoch：0 step:422/14065 loss：0.216218
【train】 epoch：0 step:423/14065 loss：0.227514
【train】 epoch：0 step:424/14065 loss：0.483619
【train】 epoch：0 step:425/14065 loss：0.263897
【train】 epoch：0 step:426/14065 loss：0.269618
【train】 epoch：0 step:427/14065 loss：0.250514
【train】 epoch：0 step:428/14065 loss：0.280543
【train】 epoch：0 step:429/14065 loss：0.157551
【train】 epoch：0 step:430/14065 loss：0.125511
【train】 epoch：0 step:431/14065 loss：0.160018
【train】 epoch：0 step:432/14065 loss：0.212466
【train】 epoch：0 step:433/14065 loss：0.372565
【train】 epoch：0 step:434/14065 loss：0.241204
【train】 epoch：0 step:435/14065 loss：0.236120
【train】 epoch：0 step:436/14065 loss：0.461435
【train】 epoch：0 step:437/14065 loss：0.122282
【train】 epoch：0 step:438/14065 loss：0.387446
【train】 epoch：0 step:439/14065 loss：0.153879
【train】 epoch：0 step:440/14065 loss：0.630558
【train】 epoch：0 step:441/14065 loss：0.269612
【train】 epoch：0 step:442/14065 loss：0.249192
【train】 epoch：0 step:443/14065 loss：0.230593
【train】 epoch：0 step:444/14065 loss：0.152138
【train】 epoch：0 step:445/14065 loss：0.263929
【train】 epoch：0 step:446/14065 loss：0.135617
【train】 epoch：0 step:447/14065 loss：0.282879
【train】 epoch：0 step:448/14065 loss：0.233539
【train】 epoch：0 step:449/14065 loss：0.239888
【train】 epoch：0 step:450/14065 loss：0.226213
【train】 epoch：0 step:451/14065 loss：0.141133
【train】 epoch：0 step:452/14065 loss：0.204221
【train】 epoch：0 step:453/14065 loss：0.150821
【train】 epoch：0 step:454/14065 loss：0.386903
【train】 epoch：0 step:455/14065 loss：0.209592
【train】 epoch：0 step:456/14065 loss：0.344298
【train】 epoch：0 step:457/14065 loss：0.337382
【train】 epoch：0 step:458/14065 loss：0.456254
【train】 epoch：0 step:459/14065 loss：0.149470
【train】 epoch：0 step:460/14065 loss：0.194543
【train】 epoch：0 step:461/14065 loss：0.224358
【train】 epoch：0 step:462/14065 loss：0.428756
【train】 epoch：0 step:463/14065 loss：0.176107
【train】 epoch：0 step:464/14065 loss：0.244898
【train】 epoch：0 step:465/14065 loss：0.353925
【train】 epoch：0 step:466/14065 loss：0.069161
【train】 epoch：0 step:467/14065 loss：0.228512
【train】 epoch：0 step:468/14065 loss：0.531286
【train】 epoch：0 step:469/14065 loss：0.191232
【train】 epoch：0 step:470/14065 loss：0.396157
【train】 epoch：0 step:471/14065 loss：0.233895
【train】 epoch：0 step:472/14065 loss：0.303439
【train】 epoch：0 step:473/14065 loss：0.108845
【train】 epoch：0 step:474/14065 loss：0.220374
【train】 epoch：0 step:475/14065 loss：0.156828
【train】 epoch：0 step:476/14065 loss：0.149450
【train】 epoch：0 step:477/14065 loss：0.126673
【train】 epoch：0 step:478/14065 loss：0.284180
【train】 epoch：0 step:479/14065 loss：0.251560
【train】 epoch：0 step:480/14065 loss：0.341401
【train】 epoch：0 step:481/14065 loss：0.157618
【train】 epoch：0 step:482/14065 loss：0.208426
【train】 epoch：0 step:483/14065 loss：0.071258
【train】 epoch：0 step:484/14065 loss：0.208166
【train】 epoch：0 step:485/14065 loss：0.228267
【train】 epoch：0 step:486/14065 loss：0.163086
【train】 epoch：0 step:487/14065 loss：0.427080
【train】 epoch：0 step:488/14065 loss：0.350779
【train】 epoch：0 step:489/14065 loss：0.330553
【train】 epoch：0 step:490/14065 loss：0.207898
【train】 epoch：0 step:491/14065 loss：0.195756
【train】 epoch：0 step:492/14065 loss：0.362693
【train】 epoch：0 step:493/14065 loss：0.182322
【train】 epoch：0 step:494/14065 loss：0.256608
【train】 epoch：0 step:495/14065 loss：0.334315
【train】 epoch：0 step:496/14065 loss：0.315494
【train】 epoch：0 step:497/14065 loss：0.107702
【train】 epoch：0 step:498/14065 loss：0.205295
【train】 epoch：0 step:499/14065 loss：0.261034
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：619.710085 accuracy：0.9340 precision：0.9340 recall：0.9340 f1：0.9340
------------>保存当前最好的模型
【train】 epoch：0 step:500/14065 loss：0.199385
【train】 epoch：0 step:501/14065 loss：0.428353
【train】 epoch：0 step:502/14065 loss：0.250372
【train】 epoch：0 step:503/14065 loss：0.130879
【train】 epoch：0 step:504/14065 loss：0.170859
【train】 epoch：0 step:505/14065 loss：0.346815
【train】 epoch：0 step:506/14065 loss：0.197588
【train】 epoch：0 step:507/14065 loss：0.289226
【train】 epoch：0 step:508/14065 loss：0.295832
【train】 epoch：0 step:509/14065 loss：0.312277
【train】 epoch：0 step:510/14065 loss：0.226621
【train】 epoch：0 step:511/14065 loss：0.364975
【train】 epoch：0 step:512/14065 loss：0.308771
【train】 epoch：0 step:513/14065 loss：0.214778
【train】 epoch：0 step:514/14065 loss：0.240547
【train】 epoch：0 step:515/14065 loss：0.274641
【train】 epoch：0 step:516/14065 loss：0.184675
【train】 epoch：0 step:517/14065 loss：0.245319
【train】 epoch：0 step:518/14065 loss：0.360565
【train】 epoch：0 step:519/14065 loss：0.243847
【train】 epoch：0 step:520/14065 loss：0.220688
【train】 epoch：0 step:521/14065 loss：0.295153
【train】 epoch：0 step:522/14065 loss：0.195379
【train】 epoch：0 step:523/14065 loss：0.342863
【train】 epoch：0 step:524/14065 loss：0.115739
【train】 epoch：0 step:525/14065 loss：0.207375
【train】 epoch：0 step:526/14065 loss：0.204220
【train】 epoch：0 step:527/14065 loss：0.216406
【train】 epoch：0 step:528/14065 loss：0.225022
【train】 epoch：0 step:529/14065 loss：0.316087
【train】 epoch：0 step:530/14065 loss：0.305043
【train】 epoch：0 step:531/14065 loss：0.280908
【train】 epoch：0 step:532/14065 loss：0.329382
【train】 epoch：0 step:533/14065 loss：0.336775
【train】 epoch：0 step:534/14065 loss：0.355346
【train】 epoch：0 step:535/14065 loss：0.140002
【train】 epoch：0 step:536/14065 loss：0.361015
【train】 epoch：0 step:537/14065 loss：0.276518
【train】 epoch：0 step:538/14065 loss：0.294354
【train】 epoch：0 step:539/14065 loss：0.255862
【train】 epoch：0 step:540/14065 loss：0.362996
【train】 epoch：0 step:541/14065 loss：0.198435
【train】 epoch：0 step:542/14065 loss：0.186775
【train】 epoch：0 step:543/14065 loss：0.179266
【train】 epoch：0 step:544/14065 loss：0.290930
【train】 epoch：0 step:545/14065 loss：0.434036
【train】 epoch：0 step:546/14065 loss：0.256755
【train】 epoch：0 step:547/14065 loss：0.226758
【train】 epoch：0 step:548/14065 loss：0.262427
【train】 epoch：0 step:549/14065 loss：0.401462
【train】 epoch：0 step:550/14065 loss：0.278576
【train】 epoch：0 step:551/14065 loss：0.217774
【train】 epoch：0 step:552/14065 loss：0.118588
【train】 epoch：0 step:553/14065 loss：0.186444
【train】 epoch：0 step:554/14065 loss：0.114701
【train】 epoch：0 step:555/14065 loss：0.263944
【train】 epoch：0 step:556/14065 loss：0.490054
【train】 epoch：0 step:557/14065 loss：0.265853
【train】 epoch：0 step:558/14065 loss：0.237298
【train】 epoch：0 step:559/14065 loss：0.084704
【train】 epoch：0 step:560/14065 loss：0.253464
【train】 epoch：0 step:561/14065 loss：0.257209
【train】 epoch：0 step:562/14065 loss：0.313990
【train】 epoch：0 step:563/14065 loss：0.173372
【train】 epoch：0 step:564/14065 loss：0.083901
【train】 epoch：0 step:565/14065 loss：0.170600
【train】 epoch：0 step:566/14065 loss：0.212544
【train】 epoch：0 step:567/14065 loss：0.160560
【train】 epoch：0 step:568/14065 loss：0.187402
【train】 epoch：0 step:569/14065 loss：0.373529
【train】 epoch：0 step:570/14065 loss：0.341784
【train】 epoch：0 step:571/14065 loss：0.237101
【train】 epoch：0 step:572/14065 loss：0.299057
【train】 epoch：0 step:573/14065 loss：0.188912
【train】 epoch：0 step:574/14065 loss：0.131949
【train】 epoch：0 step:575/14065 loss：0.210415
【train】 epoch：0 step:576/14065 loss：0.235176
【train】 epoch：0 step:577/14065 loss：0.270457
【train】 epoch：0 step:578/14065 loss：0.155827
【train】 epoch：0 step:579/14065 loss：0.327237
【train】 epoch：0 step:580/14065 loss：0.204326
【train】 epoch：0 step:581/14065 loss：0.271779
【train】 epoch：0 step:582/14065 loss：0.106221
【train】 epoch：0 step:583/14065 loss：0.215662
【train】 epoch：0 step:584/14065 loss：0.253107
【train】 epoch：0 step:585/14065 loss：0.246007
【train】 epoch：0 step:586/14065 loss：0.293062
【train】 epoch：0 step:587/14065 loss：0.428674
【train】 epoch：0 step:588/14065 loss：0.228423
【train】 epoch：0 step:589/14065 loss：0.357371
【train】 epoch：0 step:590/14065 loss：0.119417
【train】 epoch：0 step:591/14065 loss：0.236491
【train】 epoch：0 step:592/14065 loss：0.184654
【train】 epoch：0 step:593/14065 loss：0.187665
【train】 epoch：0 step:594/14065 loss：0.318104
【train】 epoch：0 step:595/14065 loss：0.400165
【train】 epoch：0 step:596/14065 loss：0.344417
【train】 epoch：0 step:597/14065 loss：0.193937
【train】 epoch：0 step:598/14065 loss：0.297201
【train】 epoch：0 step:599/14065 loss：0.491216
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：713.874715 accuracy：0.9222 precision：0.9222 recall：0.9222 f1：0.9222
【train】 epoch：0 step:600/14065 loss：0.358746
【train】 epoch：0 step:601/14065 loss：0.363070
【train】 epoch：0 step:602/14065 loss：0.254318
【train】 epoch：0 step:603/14065 loss：0.496973
【train】 epoch：0 step:604/14065 loss：0.479961
【train】 epoch：0 step:605/14065 loss：0.291301
【train】 epoch：0 step:606/14065 loss：0.135166
【train】 epoch：0 step:607/14065 loss：0.341281
【train】 epoch：0 step:608/14065 loss：0.301499
【train】 epoch：0 step:609/14065 loss：0.374331
【train】 epoch：0 step:610/14065 loss：0.253195
【train】 epoch：0 step:611/14065 loss：0.424192
【train】 epoch：0 step:612/14065 loss：0.199154
【train】 epoch：0 step:613/14065 loss：0.291303
【train】 epoch：0 step:614/14065 loss：0.205807
【train】 epoch：0 step:615/14065 loss：0.275423
【train】 epoch：0 step:616/14065 loss：0.219573
【train】 epoch：0 step:617/14065 loss：0.335213
【train】 epoch：0 step:618/14065 loss：0.269154
【train】 epoch：0 step:619/14065 loss：0.261321
【train】 epoch：0 step:620/14065 loss：0.350964
【train】 epoch：0 step:621/14065 loss：0.201235
【train】 epoch：0 step:622/14065 loss：0.387199
【train】 epoch：0 step:623/14065 loss：0.226159
【train】 epoch：0 step:624/14065 loss：0.152512
【train】 epoch：0 step:625/14065 loss：0.278688
【train】 epoch：0 step:626/14065 loss：0.379591
【train】 epoch：0 step:627/14065 loss：0.133011
【train】 epoch：0 step:628/14065 loss：0.351340
【train】 epoch：0 step:629/14065 loss：0.270052
【train】 epoch：0 step:630/14065 loss：0.159363
【train】 epoch：0 step:631/14065 loss：0.237388
【train】 epoch：0 step:632/14065 loss：0.162799
【train】 epoch：0 step:633/14065 loss：0.342779
【train】 epoch：0 step:634/14065 loss：0.255234
【train】 epoch：0 step:635/14065 loss：0.382504
【train】 epoch：0 step:636/14065 loss：0.375449
【train】 epoch：0 step:637/14065 loss：0.297978
【train】 epoch：0 step:638/14065 loss：0.277383
【train】 epoch：0 step:639/14065 loss：0.196353
【train】 epoch：0 step:640/14065 loss：0.231378
【train】 epoch：0 step:641/14065 loss：0.229189
【train】 epoch：0 step:642/14065 loss：0.307650
【train】 epoch：0 step:643/14065 loss：0.186801
【train】 epoch：0 step:644/14065 loss：0.207258
【train】 epoch：0 step:645/14065 loss：0.309338
【train】 epoch：0 step:646/14065 loss：0.249629
【train】 epoch：0 step:647/14065 loss：0.301350
【train】 epoch：0 step:648/14065 loss：0.262545
【train】 epoch：0 step:649/14065 loss：0.332906
【train】 epoch：0 step:650/14065 loss：0.355331
【train】 epoch：0 step:651/14065 loss：0.255244
【train】 epoch：0 step:652/14065 loss：0.109014
【train】 epoch：0 step:653/14065 loss：0.348071
【train】 epoch：0 step:654/14065 loss：0.265825
【train】 epoch：0 step:655/14065 loss：0.139753
【train】 epoch：0 step:656/14065 loss：0.372773
【train】 epoch：0 step:657/14065 loss：0.203544
【train】 epoch：0 step:658/14065 loss：0.174073
【train】 epoch：0 step:659/14065 loss：0.243151
【train】 epoch：0 step:660/14065 loss：0.265025
【train】 epoch：0 step:661/14065 loss：0.212785
【train】 epoch：0 step:662/14065 loss：0.133502
【train】 epoch：0 step:663/14065 loss：0.184691
【train】 epoch：0 step:664/14065 loss：0.292445
【train】 epoch：0 step:665/14065 loss：0.274528
【train】 epoch：0 step:666/14065 loss：0.295902
【train】 epoch：0 step:667/14065 loss：0.325197
【train】 epoch：0 step:668/14065 loss：0.285526
【train】 epoch：0 step:669/14065 loss：0.188495
【train】 epoch：0 step:670/14065 loss：0.219595
【train】 epoch：0 step:671/14065 loss：0.301370
【train】 epoch：0 step:672/14065 loss：0.291241
【train】 epoch：0 step:673/14065 loss：0.252256
【train】 epoch：0 step:674/14065 loss：0.214028
【train】 epoch：0 step:675/14065 loss：0.394573
【train】 epoch：0 step:676/14065 loss：0.185916
【train】 epoch：0 step:677/14065 loss：0.147291
【train】 epoch：0 step:678/14065 loss：0.321216
【train】 epoch：0 step:679/14065 loss：0.168876
【train】 epoch：0 step:680/14065 loss：0.348781
【train】 epoch：0 step:681/14065 loss：0.152158
【train】 epoch：0 step:682/14065 loss：0.248725
【train】 epoch：0 step:683/14065 loss：0.340278
【train】 epoch：0 step:684/14065 loss：0.294657
【train】 epoch：0 step:685/14065 loss：0.245990
【train】 epoch：0 step:686/14065 loss：0.229930
【train】 epoch：0 step:687/14065 loss：0.431784
【train】 epoch：0 step:688/14065 loss：0.223650
【train】 epoch：0 step:689/14065 loss：0.185418
【train】 epoch：0 step:690/14065 loss：0.128984
【train】 epoch：0 step:691/14065 loss：0.453817
【train】 epoch：0 step:692/14065 loss：0.197983
【train】 epoch：0 step:693/14065 loss：0.126876
【train】 epoch：0 step:694/14065 loss：0.297129
【train】 epoch：0 step:695/14065 loss：0.173027
【train】 epoch：0 step:696/14065 loss：0.377549
【train】 epoch：0 step:697/14065 loss：0.231731
【train】 epoch：0 step:698/14065 loss：0.105893
【train】 epoch：0 step:699/14065 loss：0.257189
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：553.683043 accuracy：0.9391 precision：0.9391 recall：0.9391 f1：0.9391
------------>保存当前最好的模型
【train】 epoch：0 step:700/14065 loss：0.258127
【train】 epoch：0 step:701/14065 loss：0.201336
【train】 epoch：0 step:702/14065 loss：0.161684
【train】 epoch：0 step:703/14065 loss：0.164104
【train】 epoch：0 step:704/14065 loss：0.224401
【train】 epoch：0 step:705/14065 loss：0.249178
【train】 epoch：0 step:706/14065 loss：0.338690
【train】 epoch：0 step:707/14065 loss：0.230866
【train】 epoch：0 step:708/14065 loss：0.237324
【train】 epoch：0 step:709/14065 loss：0.297097
【train】 epoch：0 step:710/14065 loss：0.296314
【train】 epoch：0 step:711/14065 loss：0.242623
【train】 epoch：0 step:712/14065 loss：0.211966
【train】 epoch：0 step:713/14065 loss：0.286766
【train】 epoch：0 step:714/14065 loss：0.261448
【train】 epoch：0 step:715/14065 loss：0.273775
【train】 epoch：0 step:716/14065 loss：0.106954
【train】 epoch：0 step:717/14065 loss：0.395371
【train】 epoch：0 step:718/14065 loss：0.235035
【train】 epoch：0 step:719/14065 loss：0.182261
【train】 epoch：0 step:720/14065 loss：0.178343
【train】 epoch：0 step:721/14065 loss：0.376957
【train】 epoch：0 step:722/14065 loss：0.308083
【train】 epoch：0 step:723/14065 loss：0.342972
【train】 epoch：0 step:724/14065 loss：0.111556
【train】 epoch：0 step:725/14065 loss：0.117425
【train】 epoch：0 step:726/14065 loss：0.328274
【train】 epoch：0 step:727/14065 loss：0.284264
【train】 epoch：0 step:728/14065 loss：0.266979
【train】 epoch：0 step:729/14065 loss：0.202280
【train】 epoch：0 step:730/14065 loss：0.302137
【train】 epoch：0 step:731/14065 loss：0.262003
【train】 epoch：0 step:732/14065 loss：0.217266
【train】 epoch：0 step:733/14065 loss：0.196434
【train】 epoch：0 step:734/14065 loss：0.188642
【train】 epoch：0 step:735/14065 loss：0.299471
【train】 epoch：0 step:736/14065 loss：0.251565
【train】 epoch：0 step:737/14065 loss：0.220415
【train】 epoch：0 step:738/14065 loss：0.151770
【train】 epoch：0 step:739/14065 loss：0.229344
【train】 epoch：0 step:740/14065 loss：0.167232
【train】 epoch：0 step:741/14065 loss：0.215751
【train】 epoch：0 step:742/14065 loss：0.254269
【train】 epoch：0 step:743/14065 loss：0.148439
【train】 epoch：0 step:744/14065 loss：0.255925
【train】 epoch：0 step:745/14065 loss：0.424571
【train】 epoch：0 step:746/14065 loss：0.152199
【train】 epoch：0 step:747/14065 loss：0.485769
【train】 epoch：0 step:748/14065 loss：0.183941
【train】 epoch：0 step:749/14065 loss：0.206903
【train】 epoch：0 step:750/14065 loss：0.226293
【train】 epoch：0 step:751/14065 loss：0.158118
【train】 epoch：0 step:752/14065 loss：0.140537
【train】 epoch：0 step:753/14065 loss：0.204445
【train】 epoch：0 step:754/14065 loss：0.187236
【train】 epoch：0 step:755/14065 loss：0.178365
【train】 epoch：0 step:756/14065 loss：0.109102
【train】 epoch：0 step:757/14065 loss：0.218823
【train】 epoch：0 step:758/14065 loss：0.128323
【train】 epoch：0 step:759/14065 loss：0.175260
【train】 epoch：0 step:760/14065 loss：0.255254
【train】 epoch：0 step:761/14065 loss：0.282905
【train】 epoch：0 step:762/14065 loss：0.146439
【train】 epoch：0 step:763/14065 loss：0.251322
【train】 epoch：0 step:764/14065 loss：0.321555
【train】 epoch：0 step:765/14065 loss：0.210379
【train】 epoch：0 step:766/14065 loss：0.249889
【train】 epoch：0 step:767/14065 loss：0.240513
【train】 epoch：0 step:768/14065 loss：0.246260
【train】 epoch：0 step:769/14065 loss：0.328523
【train】 epoch：0 step:770/14065 loss：0.194273
【train】 epoch：0 step:771/14065 loss：0.192885
【train】 epoch：0 step:772/14065 loss：0.367269
【train】 epoch：0 step:773/14065 loss：0.186892
【train】 epoch：0 step:774/14065 loss：0.194390
【train】 epoch：0 step:775/14065 loss：0.289346
【train】 epoch：0 step:776/14065 loss：0.157405
【train】 epoch：0 step:777/14065 loss：0.155849
【train】 epoch：0 step:778/14065 loss：0.340550
【train】 epoch：0 step:779/14065 loss：0.207177
【train】 epoch：0 step:780/14065 loss：0.100491
【train】 epoch：0 step:781/14065 loss：0.339991
【train】 epoch：0 step:782/14065 loss：0.146731
【train】 epoch：0 step:783/14065 loss：0.454968
【train】 epoch：0 step:784/14065 loss：0.138182
【train】 epoch：0 step:785/14065 loss：0.206239
【train】 epoch：0 step:786/14065 loss：0.397750
【train】 epoch：0 step:787/14065 loss：0.175930
【train】 epoch：0 step:788/14065 loss：0.311720
【train】 epoch：0 step:789/14065 loss：0.113427
【train】 epoch：0 step:790/14065 loss：0.187590
【train】 epoch：0 step:791/14065 loss：0.255084
【train】 epoch：0 step:792/14065 loss：0.284592
【train】 epoch：0 step:793/14065 loss：0.313719
【train】 epoch：0 step:794/14065 loss：0.261732
【train】 epoch：0 step:795/14065 loss：0.188029
【train】 epoch：0 step:796/14065 loss：0.354513
【train】 epoch：0 step:797/14065 loss：0.258740
【train】 epoch：0 step:798/14065 loss：0.205521
【train】 epoch：0 step:799/14065 loss：0.144629
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：540.502604 accuracy：0.9413 precision：0.9413 recall：0.9413 f1：0.9413
------------>保存当前最好的模型
【train】 epoch：0 step:800/14065 loss：0.223942
【train】 epoch：0 step:801/14065 loss：0.280435
【train】 epoch：0 step:802/14065 loss：0.204409
【train】 epoch：0 step:803/14065 loss：0.320750
【train】 epoch：0 step:804/14065 loss：0.281799
【train】 epoch：0 step:805/14065 loss：0.263816
【train】 epoch：0 step:806/14065 loss：0.355302
【train】 epoch：0 step:807/14065 loss：0.258015
【train】 epoch：0 step:808/14065 loss：0.220107
【train】 epoch：0 step:809/14065 loss：0.209229
【train】 epoch：0 step:810/14065 loss：0.262692
【train】 epoch：0 step:811/14065 loss：0.169442
【train】 epoch：0 step:812/14065 loss：0.281678
【train】 epoch：0 step:813/14065 loss：0.090301
【train】 epoch：0 step:814/14065 loss：0.284833
【train】 epoch：0 step:815/14065 loss：0.131829
【train】 epoch：0 step:816/14065 loss：0.108541
【train】 epoch：0 step:817/14065 loss：0.294382
【train】 epoch：0 step:818/14065 loss：0.129233
【train】 epoch：0 step:819/14065 loss：0.215588
【train】 epoch：0 step:820/14065 loss：0.112646
【train】 epoch：0 step:821/14065 loss：0.221437
【train】 epoch：0 step:822/14065 loss：0.204745
【train】 epoch：0 step:823/14065 loss：0.383504
【train】 epoch：0 step:824/14065 loss：0.134977
【train】 epoch：0 step:825/14065 loss：0.316583
【train】 epoch：0 step:826/14065 loss：0.222367
【train】 epoch：0 step:827/14065 loss：0.099871
【train】 epoch：0 step:828/14065 loss：0.264503
【train】 epoch：0 step:829/14065 loss：0.196679
【train】 epoch：0 step:830/14065 loss：0.357608
【train】 epoch：0 step:831/14065 loss：0.191355
【train】 epoch：0 step:832/14065 loss：0.223873
【train】 epoch：0 step:833/14065 loss：0.162612
【train】 epoch：0 step:834/14065 loss：0.219683
【train】 epoch：0 step:835/14065 loss：0.337908
【train】 epoch：0 step:836/14065 loss：0.161230
【train】 epoch：0 step:837/14065 loss：0.266522
【train】 epoch：0 step:838/14065 loss：0.244458
【train】 epoch：0 step:839/14065 loss：0.293183
【train】 epoch：0 step:840/14065 loss：0.108394
【train】 epoch：0 step:841/14065 loss：0.298830
【train】 epoch：0 step:842/14065 loss：0.139367
【train】 epoch：0 step:843/14065 loss：0.146358
【train】 epoch：0 step:844/14065 loss：0.211773
【train】 epoch：0 step:845/14065 loss：0.316582
【train】 epoch：0 step:846/14065 loss：0.262811
【train】 epoch：0 step:847/14065 loss：0.349855
【train】 epoch：0 step:848/14065 loss：0.174345
【train】 epoch：0 step:849/14065 loss：0.187057
【train】 epoch：0 step:850/14065 loss：0.272389
【train】 epoch：0 step:851/14065 loss：0.085929
【train】 epoch：0 step:852/14065 loss：0.182135
【train】 epoch：0 step:853/14065 loss：0.404024
【train】 epoch：0 step:854/14065 loss：0.252637
【train】 epoch：0 step:855/14065 loss：0.290974
【train】 epoch：0 step:856/14065 loss：0.278216
【train】 epoch：0 step:857/14065 loss：0.076902
【train】 epoch：0 step:858/14065 loss：0.227022
【train】 epoch：0 step:859/14065 loss：0.337623
【train】 epoch：0 step:860/14065 loss：0.452082
【train】 epoch：0 step:861/14065 loss：0.251703
【train】 epoch：0 step:862/14065 loss：0.215158
【train】 epoch：0 step:863/14065 loss：0.294121
【train】 epoch：0 step:864/14065 loss：0.230909
【train】 epoch：0 step:865/14065 loss：0.181912
【train】 epoch：0 step:866/14065 loss：0.330014
【train】 epoch：0 step:867/14065 loss：0.094807
【train】 epoch：0 step:868/14065 loss：0.589329
【train】 epoch：0 step:869/14065 loss：0.215255
【train】 epoch：0 step:870/14065 loss：0.206922
【train】 epoch：0 step:871/14065 loss：0.259610
【train】 epoch：0 step:872/14065 loss：0.372989
【train】 epoch：0 step:873/14065 loss：0.323708
【train】 epoch：0 step:874/14065 loss：0.236848
【train】 epoch：0 step:875/14065 loss：0.106218
【train】 epoch：0 step:876/14065 loss：0.272928
【train】 epoch：0 step:877/14065 loss：0.283649
【train】 epoch：0 step:878/14065 loss：0.196482
【train】 epoch：0 step:879/14065 loss：0.214214
【train】 epoch：0 step:880/14065 loss：0.268209
【train】 epoch：0 step:881/14065 loss：0.169337
【train】 epoch：0 step:882/14065 loss：0.228906
【train】 epoch：0 step:883/14065 loss：0.255450
【train】 epoch：0 step:884/14065 loss：0.163382
【train】 epoch：0 step:885/14065 loss：0.271976
【train】 epoch：0 step:886/14065 loss：0.211157
【train】 epoch：0 step:887/14065 loss：0.293581
【train】 epoch：0 step:888/14065 loss：0.243157
【train】 epoch：0 step:889/14065 loss：0.228122
【train】 epoch：0 step:890/14065 loss：0.264927
【train】 epoch：0 step:891/14065 loss：0.268307
【train】 epoch：0 step:892/14065 loss：0.269757
【train】 epoch：0 step:893/14065 loss：0.330643
【train】 epoch：0 step:894/14065 loss：0.245710
【train】 epoch：0 step:895/14065 loss：0.326856
【train】 epoch：0 step:896/14065 loss：0.180799
【train】 epoch：0 step:897/14065 loss：0.417365
【train】 epoch：0 step:898/14065 loss：0.165849
【train】 epoch：0 step:899/14065 loss：0.245258
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：522.599676 accuracy：0.9429 precision：0.9429 recall：0.9429 f1：0.9429
------------>保存当前最好的模型
【train】 epoch：0 step:900/14065 loss：0.275195
【train】 epoch：0 step:901/14065 loss：0.202361
【train】 epoch：0 step:902/14065 loss：0.256244
【train】 epoch：0 step:903/14065 loss：0.163418
【train】 epoch：0 step:904/14065 loss：0.403361
【train】 epoch：0 step:905/14065 loss：0.255175
【train】 epoch：0 step:906/14065 loss：0.100273
【train】 epoch：0 step:907/14065 loss：0.127522
【train】 epoch：0 step:908/14065 loss：0.325477
【train】 epoch：0 step:909/14065 loss：0.035966
【train】 epoch：0 step:910/14065 loss：0.418428
【train】 epoch：0 step:911/14065 loss：0.236484
【train】 epoch：0 step:912/14065 loss：0.199672
【train】 epoch：0 step:913/14065 loss：0.282698
【train】 epoch：0 step:914/14065 loss：0.182466
【train】 epoch：0 step:915/14065 loss：0.142847
【train】 epoch：0 step:916/14065 loss：0.177650
【train】 epoch：0 step:917/14065 loss：0.302241
【train】 epoch：0 step:918/14065 loss：0.288119
【train】 epoch：0 step:919/14065 loss：0.266996
【train】 epoch：0 step:920/14065 loss：0.145776
【train】 epoch：0 step:921/14065 loss：0.197784
【train】 epoch：0 step:922/14065 loss：0.152789
【train】 epoch：0 step:923/14065 loss：0.195113
【train】 epoch：0 step:924/14065 loss：0.114394
【train】 epoch：0 step:925/14065 loss：0.304670
【train】 epoch：0 step:926/14065 loss：0.233050
【train】 epoch：0 step:927/14065 loss：0.200758
【train】 epoch：0 step:928/14065 loss：0.062667
【train】 epoch：0 step:929/14065 loss：0.176522
【train】 epoch：0 step:930/14065 loss：0.290713
【train】 epoch：0 step:931/14065 loss：0.151270
【train】 epoch：0 step:932/14065 loss：0.192735
【train】 epoch：0 step:933/14065 loss：0.346876
【train】 epoch：0 step:934/14065 loss：0.265195
【train】 epoch：0 step:935/14065 loss：0.133107
【train】 epoch：0 step:936/14065 loss：0.311980
【train】 epoch：0 step:937/14065 loss：0.308637
【train】 epoch：0 step:938/14065 loss：0.203723
【train】 epoch：0 step:939/14065 loss：0.245068
【train】 epoch：0 step:940/14065 loss：0.107685
【train】 epoch：0 step:941/14065 loss：0.145751
【train】 epoch：0 step:942/14065 loss：0.099850
【train】 epoch：0 step:943/14065 loss：0.188071
【train】 epoch：0 step:944/14065 loss：0.282413
【train】 epoch：0 step:945/14065 loss：0.110593
【train】 epoch：0 step:946/14065 loss：0.155593
【train】 epoch：0 step:947/14065 loss：0.219357
【train】 epoch：0 step:948/14065 loss：0.358715
【train】 epoch：0 step:949/14065 loss：0.246897
【train】 epoch：0 step:950/14065 loss：0.179395
【train】 epoch：0 step:951/14065 loss：0.118329
【train】 epoch：0 step:952/14065 loss：0.289708
【train】 epoch：0 step:953/14065 loss：0.436846
【train】 epoch：0 step:954/14065 loss：0.127491
【train】 epoch：0 step:955/14065 loss：0.259742
【train】 epoch：0 step:956/14065 loss：0.184503
【train】 epoch：0 step:957/14065 loss：0.126386
【train】 epoch：0 step:958/14065 loss：0.169046
【train】 epoch：0 step:959/14065 loss：0.139096
【train】 epoch：0 step:960/14065 loss：0.179206
【train】 epoch：0 step:961/14065 loss：0.283734
【train】 epoch：0 step:962/14065 loss：0.194043
【train】 epoch：0 step:963/14065 loss：0.212662
【train】 epoch：0 step:964/14065 loss：0.501296
【train】 epoch：0 step:965/14065 loss：0.260934
【train】 epoch：0 step:966/14065 loss：0.125644
【train】 epoch：0 step:967/14065 loss：0.360478
【train】 epoch：0 step:968/14065 loss：0.104548
【train】 epoch：0 step:969/14065 loss：0.142232
【train】 epoch：0 step:970/14065 loss：0.160041
【train】 epoch：0 step:971/14065 loss：0.078483
【train】 epoch：0 step:972/14065 loss：0.207477
【train】 epoch：0 step:973/14065 loss：0.263272
【train】 epoch：0 step:974/14065 loss：0.331392
【train】 epoch：0 step:975/14065 loss：0.105805
【train】 epoch：0 step:976/14065 loss：0.425070
【train】 epoch：0 step:977/14065 loss：0.132631
【train】 epoch：0 step:978/14065 loss：0.200454
【train】 epoch：0 step:979/14065 loss：0.476275
【train】 epoch：0 step:980/14065 loss：0.148980
【train】 epoch：0 step:981/14065 loss：0.226835
【train】 epoch：0 step:982/14065 loss：0.372336
【train】 epoch：0 step:983/14065 loss：0.196177
【train】 epoch：0 step:984/14065 loss：0.148950
【train】 epoch：0 step:985/14065 loss：0.177643
【train】 epoch：0 step:986/14065 loss：0.300252
【train】 epoch：0 step:987/14065 loss：0.126900
【train】 epoch：0 step:988/14065 loss：0.148003
【train】 epoch：0 step:989/14065 loss：0.234948
【train】 epoch：0 step:990/14065 loss：0.206178
【train】 epoch：0 step:991/14065 loss：0.184098
【train】 epoch：0 step:992/14065 loss：0.216052
【train】 epoch：0 step:993/14065 loss：0.307234
【train】 epoch：0 step:994/14065 loss：0.106924
【train】 epoch：0 step:995/14065 loss：0.150493
【train】 epoch：0 step:996/14065 loss：0.163217
【train】 epoch：0 step:997/14065 loss：0.175931
【train】 epoch：0 step:998/14065 loss：0.268275
【train】 epoch：0 step:999/14065 loss：0.193090
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：520.747201 accuracy：0.9423 precision：0.9423 recall：0.9423 f1：0.9423
【train】 epoch：0 step:1000/14065 loss：0.219887
【train】 epoch：0 step:1001/14065 loss：0.175514
【train】 epoch：0 step:1002/14065 loss：0.249844
【train】 epoch：0 step:1003/14065 loss：0.189775
【train】 epoch：0 step:1004/14065 loss：0.096444
【train】 epoch：0 step:1005/14065 loss：0.163484
【train】 epoch：0 step:1006/14065 loss：0.091511
【train】 epoch：0 step:1007/14065 loss：0.153660
【train】 epoch：0 step:1008/14065 loss：0.176280
【train】 epoch：0 step:1009/14065 loss：0.188799
【train】 epoch：0 step:1010/14065 loss：0.093104
【train】 epoch：0 step:1011/14065 loss：0.059335
【train】 epoch：0 step:1012/14065 loss：0.370410
【train】 epoch：0 step:1013/14065 loss：0.162960
【train】 epoch：0 step:1014/14065 loss：0.074931
【train】 epoch：0 step:1015/14065 loss：0.375692
【train】 epoch：0 step:1016/14065 loss：0.129435
【train】 epoch：0 step:1017/14065 loss：0.111811
【train】 epoch：0 step:1018/14065 loss：0.210884
【train】 epoch：0 step:1019/14065 loss：0.317342
【train】 epoch：0 step:1020/14065 loss：0.256519
【train】 epoch：0 step:1021/14065 loss：0.140267
【train】 epoch：0 step:1022/14065 loss：0.305969
【train】 epoch：0 step:1023/14065 loss：0.104394
【train】 epoch：0 step:1024/14065 loss：0.311513
【train】 epoch：0 step:1025/14065 loss：0.103927
【train】 epoch：0 step:1026/14065 loss：0.250113
【train】 epoch：0 step:1027/14065 loss：0.195373
【train】 epoch：0 step:1028/14065 loss：0.358009
【train】 epoch：0 step:1029/14065 loss：0.275748
【train】 epoch：0 step:1030/14065 loss：0.206646
【train】 epoch：0 step:1031/14065 loss：0.182138
【train】 epoch：0 step:1032/14065 loss：0.113198
【train】 epoch：0 step:1033/14065 loss：0.201141
【train】 epoch：0 step:1034/14065 loss：0.424100
【train】 epoch：0 step:1035/14065 loss：0.261475
【train】 epoch：0 step:1036/14065 loss：0.206136
【train】 epoch：0 step:1037/14065 loss：0.284429
【train】 epoch：0 step:1038/14065 loss：0.354885
【train】 epoch：0 step:1039/14065 loss：0.286922
【train】 epoch：0 step:1040/14065 loss：0.170996
【train】 epoch：0 step:1041/14065 loss：0.144514
【train】 epoch：0 step:1042/14065 loss：0.344447
【train】 epoch：0 step:1043/14065 loss：0.137078
【train】 epoch：0 step:1044/14065 loss：0.240361
【train】 epoch：0 step:1045/14065 loss：0.189385
【train】 epoch：0 step:1046/14065 loss：0.098712
【train】 epoch：0 step:1047/14065 loss：0.476314
【train】 epoch：0 step:1048/14065 loss：0.260738
【train】 epoch：0 step:1049/14065 loss：0.236050
【train】 epoch：0 step:1050/14065 loss：0.247570
【train】 epoch：0 step:1051/14065 loss：0.311029
【train】 epoch：0 step:1052/14065 loss：0.230579
【train】 epoch：0 step:1053/14065 loss：0.090601
【train】 epoch：0 step:1054/14065 loss：0.206190
【train】 epoch：0 step:1055/14065 loss：0.178412
【train】 epoch：0 step:1056/14065 loss：0.273709
【train】 epoch：0 step:1057/14065 loss：0.224217
【train】 epoch：0 step:1058/14065 loss：0.122732
【train】 epoch：0 step:1059/14065 loss：0.165048
【train】 epoch：0 step:1060/14065 loss：0.135528
【train】 epoch：0 step:1061/14065 loss：0.123810
【train】 epoch：0 step:1062/14065 loss：0.200865
【train】 epoch：0 step:1063/14065 loss：0.124980
【train】 epoch：0 step:1064/14065 loss：0.405651
【train】 epoch：0 step:1065/14065 loss：0.071645
【train】 epoch：0 step:1066/14065 loss：0.222350
【train】 epoch：0 step:1067/14065 loss：0.176456
【train】 epoch：0 step:1068/14065 loss：0.346974
【train】 epoch：0 step:1069/14065 loss：0.101879
【train】 epoch：0 step:1070/14065 loss：0.265852
【train】 epoch：0 step:1071/14065 loss：0.154284
【train】 epoch：0 step:1072/14065 loss：0.221748
【train】 epoch：0 step:1073/14065 loss：0.116622
【train】 epoch：0 step:1074/14065 loss：0.220893
【train】 epoch：0 step:1075/14065 loss：0.118055
【train】 epoch：0 step:1076/14065 loss：0.115876
【train】 epoch：0 step:1077/14065 loss：0.149275
【train】 epoch：0 step:1078/14065 loss：0.301689
【train】 epoch：0 step:1079/14065 loss：0.237396
【train】 epoch：0 step:1080/14065 loss：0.383529
【train】 epoch：0 step:1081/14065 loss：0.190986
【train】 epoch：0 step:1082/14065 loss：0.161857
【train】 epoch：0 step:1083/14065 loss：0.086108
【train】 epoch：0 step:1084/14065 loss：0.369280
【train】 epoch：0 step:1085/14065 loss：0.469217
【train】 epoch：0 step:1086/14065 loss：0.206336
【train】 epoch：0 step:1087/14065 loss：0.279094
【train】 epoch：0 step:1088/14065 loss：0.278504
【train】 epoch：0 step:1089/14065 loss：0.176206
【train】 epoch：0 step:1090/14065 loss：0.480390
【train】 epoch：0 step:1091/14065 loss：0.336155
【train】 epoch：0 step:1092/14065 loss：0.057801
【train】 epoch：0 step:1093/14065 loss：0.054997
【train】 epoch：0 step:1094/14065 loss：0.084135
【train】 epoch：0 step:1095/14065 loss：0.240433
【train】 epoch：0 step:1096/14065 loss：0.127855
【train】 epoch：0 step:1097/14065 loss：0.195876
【train】 epoch：0 step:1098/14065 loss：0.335994
【train】 epoch：0 step:1099/14065 loss：0.205226
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：495.267931 accuracy：0.9455 precision：0.9455 recall：0.9455 f1：0.9455
------------>保存当前最好的模型
【train】 epoch：0 step:1100/14065 loss：0.083545
【train】 epoch：0 step:1101/14065 loss：0.258419
【train】 epoch：0 step:1102/14065 loss：0.292425
【train】 epoch：0 step:1103/14065 loss：0.306984
【train】 epoch：0 step:1104/14065 loss：0.139609
【train】 epoch：0 step:1105/14065 loss：0.140492
【train】 epoch：0 step:1106/14065 loss：0.348181
【train】 epoch：0 step:1107/14065 loss：0.105547
【train】 epoch：0 step:1108/14065 loss：0.269116
【train】 epoch：0 step:1109/14065 loss：0.277637
【train】 epoch：0 step:1110/14065 loss：0.103824
【train】 epoch：0 step:1111/14065 loss：0.107152
【train】 epoch：0 step:1112/14065 loss：0.256970
【train】 epoch：0 step:1113/14065 loss：0.308853
【train】 epoch：0 step:1114/14065 loss：0.127759
【train】 epoch：0 step:1115/14065 loss：0.253399
【train】 epoch：0 step:1116/14065 loss：0.119089
【train】 epoch：0 step:1117/14065 loss：0.083159
【train】 epoch：0 step:1118/14065 loss：0.148831
【train】 epoch：0 step:1119/14065 loss：0.347936
【train】 epoch：0 step:1120/14065 loss：0.179914
【train】 epoch：0 step:1121/14065 loss：0.111306
【train】 epoch：0 step:1122/14065 loss：0.077052
【train】 epoch：0 step:1123/14065 loss：0.258937
【train】 epoch：0 step:1124/14065 loss：0.102029
【train】 epoch：0 step:1125/14065 loss：0.159180
【train】 epoch：0 step:1126/14065 loss：0.290412
【train】 epoch：0 step:1127/14065 loss：0.213674
【train】 epoch：0 step:1128/14065 loss：0.211356
【train】 epoch：0 step:1129/14065 loss：0.402990
【train】 epoch：0 step:1130/14065 loss：0.314886
【train】 epoch：0 step:1131/14065 loss：0.162036
【train】 epoch：0 step:1132/14065 loss：0.131085
【train】 epoch：0 step:1133/14065 loss：0.086366
【train】 epoch：0 step:1134/14065 loss：0.124144
【train】 epoch：0 step:1135/14065 loss：0.200944
【train】 epoch：0 step:1136/14065 loss：0.307480
【train】 epoch：0 step:1137/14065 loss：0.254770
【train】 epoch：0 step:1138/14065 loss：0.230727
【train】 epoch：0 step:1139/14065 loss：0.185649
【train】 epoch：0 step:1140/14065 loss：0.234985
【train】 epoch：0 step:1141/14065 loss：0.301905
【train】 epoch：0 step:1142/14065 loss：0.186859
【train】 epoch：0 step:1143/14065 loss：0.363179
【train】 epoch：0 step:1144/14065 loss：0.395879
【train】 epoch：0 step:1145/14065 loss：0.376114
【train】 epoch：0 step:1146/14065 loss：0.316077
【train】 epoch：0 step:1147/14065 loss：0.387013
【train】 epoch：0 step:1148/14065 loss：0.471172
【train】 epoch：0 step:1149/14065 loss：0.152657
【train】 epoch：0 step:1150/14065 loss：0.275068
【train】 epoch：0 step:1151/14065 loss：0.258479
【train】 epoch：0 step:1152/14065 loss：0.245780
【train】 epoch：0 step:1153/14065 loss：0.150581
【train】 epoch：0 step:1154/14065 loss：0.197784
【train】 epoch：0 step:1155/14065 loss：0.098644
【train】 epoch：0 step:1156/14065 loss：0.301892
【train】 epoch：0 step:1157/14065 loss：0.171989
【train】 epoch：0 step:1158/14065 loss：0.331936
【train】 epoch：0 step:1159/14065 loss：0.228464
【train】 epoch：0 step:1160/14065 loss：0.330148
【train】 epoch：0 step:1161/14065 loss：0.075798
【train】 epoch：0 step:1162/14065 loss：0.204527
【train】 epoch：0 step:1163/14065 loss：0.480581
【train】 epoch：0 step:1164/14065 loss：0.223214
【train】 epoch：0 step:1165/14065 loss：0.142409
【train】 epoch：0 step:1166/14065 loss：0.178951
【train】 epoch：0 step:1167/14065 loss：0.327308
【train】 epoch：0 step:1168/14065 loss：0.106886
【train】 epoch：0 step:1169/14065 loss：0.153158
【train】 epoch：0 step:1170/14065 loss：0.152598
【train】 epoch：0 step:1171/14065 loss：0.211223
【train】 epoch：0 step:1172/14065 loss：0.221984
【train】 epoch：0 step:1173/14065 loss：0.308238
【train】 epoch：0 step:1174/14065 loss：0.190716
【train】 epoch：0 step:1175/14065 loss：0.190468
【train】 epoch：0 step:1176/14065 loss：0.256580
【train】 epoch：0 step:1177/14065 loss：0.283543
【train】 epoch：0 step:1178/14065 loss：0.145974
【train】 epoch：0 step:1179/14065 loss：0.218656
【train】 epoch：0 step:1180/14065 loss：0.284190
【train】 epoch：0 step:1181/14065 loss：0.218569
【train】 epoch：0 step:1182/14065 loss：0.216160
【train】 epoch：0 step:1183/14065 loss：0.206984
【train】 epoch：0 step:1184/14065 loss：0.316872
【train】 epoch：0 step:1185/14065 loss：0.288827
【train】 epoch：0 step:1186/14065 loss：0.143528
【train】 epoch：0 step:1187/14065 loss：0.363185
【train】 epoch：0 step:1188/14065 loss：0.180960
【train】 epoch：0 step:1189/14065 loss：0.094058
【train】 epoch：0 step:1190/14065 loss：0.165147
【train】 epoch：0 step:1191/14065 loss：0.236874
【train】 epoch：0 step:1192/14065 loss：0.246237
【train】 epoch：0 step:1193/14065 loss：0.228890
【train】 epoch：0 step:1194/14065 loss：0.080573
【train】 epoch：0 step:1195/14065 loss：0.086883
【train】 epoch：0 step:1196/14065 loss：0.106569
【train】 epoch：0 step:1197/14065 loss：0.200331
【train】 epoch：0 step:1198/14065 loss：0.173610
【train】 epoch：0 step:1199/14065 loss：0.360944
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：515.394822 accuracy：0.9429 precision：0.9429 recall：0.9429 f1：0.9429
【train】 epoch：0 step:1200/14065 loss：0.144171
【train】 epoch：0 step:1201/14065 loss：0.169075
【train】 epoch：0 step:1202/14065 loss：0.154068
【train】 epoch：0 step:1203/14065 loss：0.258126
【train】 epoch：0 step:1204/14065 loss：0.170735
【train】 epoch：0 step:1205/14065 loss：0.141944
【train】 epoch：0 step:1206/14065 loss：0.397111
【train】 epoch：0 step:1207/14065 loss：0.301049
【train】 epoch：0 step:1208/14065 loss：0.273871
【train】 epoch：0 step:1209/14065 loss：0.136044
【train】 epoch：0 step:1210/14065 loss：0.190655
【train】 epoch：0 step:1211/14065 loss：0.155619
【train】 epoch：0 step:1212/14065 loss：0.240407
【train】 epoch：0 step:1213/14065 loss：0.161634
【train】 epoch：0 step:1214/14065 loss：0.266945
【train】 epoch：0 step:1215/14065 loss：0.131281
【train】 epoch：0 step:1216/14065 loss：0.168947
【train】 epoch：0 step:1217/14065 loss：0.325954
【train】 epoch：0 step:1218/14065 loss：0.169561
【train】 epoch：0 step:1219/14065 loss：0.352616
【train】 epoch：0 step:1220/14065 loss：0.274633
【train】 epoch：0 step:1221/14065 loss：0.205293
【train】 epoch：0 step:1222/14065 loss：0.157787
【train】 epoch：0 step:1223/14065 loss：0.073622
【train】 epoch：0 step:1224/14065 loss：0.119179
【train】 epoch：0 step:1225/14065 loss：0.160774
【train】 epoch：0 step:1226/14065 loss：0.222705
【train】 epoch：0 step:1227/14065 loss：0.163818
【train】 epoch：0 step:1228/14065 loss：0.220744
【train】 epoch：0 step:1229/14065 loss：0.189043
【train】 epoch：0 step:1230/14065 loss：0.026710
【train】 epoch：0 step:1231/14065 loss：0.210669
【train】 epoch：0 step:1232/14065 loss：0.280889
【train】 epoch：0 step:1233/14065 loss：0.209598
【train】 epoch：0 step:1234/14065 loss：0.300344
【train】 epoch：0 step:1235/14065 loss：0.172027
【train】 epoch：0 step:1236/14065 loss：0.179318
【train】 epoch：0 step:1237/14065 loss：0.140555
【train】 epoch：0 step:1238/14065 loss：0.449663
【train】 epoch：0 step:1239/14065 loss：0.268210
【train】 epoch：0 step:1240/14065 loss：0.100555
【train】 epoch：0 step:1241/14065 loss：0.174001
【train】 epoch：0 step:1242/14065 loss：0.066179
【train】 epoch：0 step:1243/14065 loss：0.175373
【train】 epoch：0 step:1244/14065 loss：0.287343
【train】 epoch：0 step:1245/14065 loss：0.232324
【train】 epoch：0 step:1246/14065 loss：0.227489
【train】 epoch：0 step:1247/14065 loss：0.144937
【train】 epoch：0 step:1248/14065 loss：0.137437
【train】 epoch：0 step:1249/14065 loss：0.373479
【train】 epoch：0 step:1250/14065 loss：0.209095
【train】 epoch：0 step:1251/14065 loss：0.278569
【train】 epoch：0 step:1252/14065 loss：0.106617
【train】 epoch：0 step:1253/14065 loss：0.193080
【train】 epoch：0 step:1254/14065 loss：0.061212
【train】 epoch：0 step:1255/14065 loss：0.246098
【train】 epoch：0 step:1256/14065 loss：0.205319
【train】 epoch：0 step:1257/14065 loss：0.290350
【train】 epoch：0 step:1258/14065 loss：0.145356
【train】 epoch：0 step:1259/14065 loss：0.306884
【train】 epoch：0 step:1260/14065 loss：0.295595
【train】 epoch：0 step:1261/14065 loss：0.246294
【train】 epoch：0 step:1262/14065 loss：0.156115
【train】 epoch：0 step:1263/14065 loss：0.166183
【train】 epoch：0 step:1264/14065 loss：0.259770
【train】 epoch：0 step:1265/14065 loss：0.307330
【train】 epoch：0 step:1266/14065 loss：0.159198
【train】 epoch：0 step:1267/14065 loss：0.102659
【train】 epoch：0 step:1268/14065 loss：0.330810
【train】 epoch：0 step:1269/14065 loss：0.161814
【train】 epoch：0 step:1270/14065 loss：0.151525
【train】 epoch：0 step:1271/14065 loss：0.215662
【train】 epoch：0 step:1272/14065 loss：0.190294
【train】 epoch：0 step:1273/14065 loss：0.231861
【train】 epoch：0 step:1274/14065 loss：0.250076
【train】 epoch：0 step:1275/14065 loss：0.151769
【train】 epoch：0 step:1276/14065 loss：0.210671
【train】 epoch：0 step:1277/14065 loss：0.102252
【train】 epoch：0 step:1278/14065 loss：0.249061
【train】 epoch：0 step:1279/14065 loss：0.091153
【train】 epoch：0 step:1280/14065 loss：0.142296
【train】 epoch：0 step:1281/14065 loss：0.360250
【train】 epoch：0 step:1282/14065 loss：0.186157
【train】 epoch：0 step:1283/14065 loss：0.154476
【train】 epoch：0 step:1284/14065 loss：0.114359
【train】 epoch：0 step:1285/14065 loss：0.215875
【train】 epoch：0 step:1286/14065 loss：0.168598
【train】 epoch：0 step:1287/14065 loss：0.223040
【train】 epoch：0 step:1288/14065 loss：0.184124
【train】 epoch：0 step:1289/14065 loss：0.263525
【train】 epoch：0 step:1290/14065 loss：0.203429
【train】 epoch：0 step:1291/14065 loss：0.247622
【train】 epoch：0 step:1292/14065 loss：0.179077
【train】 epoch：0 step:1293/14065 loss：0.193129
【train】 epoch：0 step:1294/14065 loss：0.323698
【train】 epoch：0 step:1295/14065 loss：0.155070
【train】 epoch：0 step:1296/14065 loss：0.220658
【train】 epoch：0 step:1297/14065 loss：0.088440
【train】 epoch：0 step:1298/14065 loss：0.120282
【train】 epoch：0 step:1299/14065 loss：0.206353
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：480.356098 accuracy：0.9468 precision：0.9468 recall：0.9468 f1：0.9468
------------>保存当前最好的模型
【train】 epoch：0 step:1300/14065 loss：0.131866
【train】 epoch：0 step:1301/14065 loss：0.178763
【train】 epoch：0 step:1302/14065 loss：0.222177
【train】 epoch：0 step:1303/14065 loss：0.161379
【train】 epoch：0 step:1304/14065 loss：0.427094
【train】 epoch：0 step:1305/14065 loss：0.307250
【train】 epoch：0 step:1306/14065 loss：0.132284
【train】 epoch：0 step:1307/14065 loss：0.117545
【train】 epoch：0 step:1308/14065 loss：0.133470
【train】 epoch：0 step:1309/14065 loss：0.305425
【train】 epoch：0 step:1310/14065 loss：0.218494
【train】 epoch：0 step:1311/14065 loss：0.212521
【train】 epoch：0 step:1312/14065 loss：0.284935
【train】 epoch：0 step:1313/14065 loss：0.229008
【train】 epoch：0 step:1314/14065 loss：0.142320
【train】 epoch：0 step:1315/14065 loss：0.224695
【train】 epoch：0 step:1316/14065 loss：0.266050
【train】 epoch：0 step:1317/14065 loss：0.097002
【train】 epoch：0 step:1318/14065 loss：0.081804
【train】 epoch：0 step:1319/14065 loss：0.146759
【train】 epoch：0 step:1320/14065 loss：0.244723
【train】 epoch：0 step:1321/14065 loss：0.307437
【train】 epoch：0 step:1322/14065 loss：0.172877
【train】 epoch：0 step:1323/14065 loss：0.109717
【train】 epoch：0 step:1324/14065 loss：0.176201
【train】 epoch：0 step:1325/14065 loss：0.272207
【train】 epoch：0 step:1326/14065 loss：0.118117
【train】 epoch：0 step:1327/14065 loss：0.125533
【train】 epoch：0 step:1328/14065 loss：0.146640
【train】 epoch：0 step:1329/14065 loss：0.094263
【train】 epoch：0 step:1330/14065 loss：0.229928
【train】 epoch：0 step:1331/14065 loss：0.197012
【train】 epoch：0 step:1332/14065 loss：0.254717
【train】 epoch：0 step:1333/14065 loss：0.219656
【train】 epoch：0 step:1334/14065 loss：0.186028
【train】 epoch：0 step:1335/14065 loss：0.101931
【train】 epoch：0 step:1336/14065 loss：0.163457
【train】 epoch：0 step:1337/14065 loss：0.333725
【train】 epoch：0 step:1338/14065 loss：0.130141
【train】 epoch：0 step:1339/14065 loss：0.237669
【train】 epoch：0 step:1340/14065 loss：0.172673
【train】 epoch：0 step:1341/14065 loss：0.129057
【train】 epoch：0 step:1342/14065 loss：0.349465
【train】 epoch：0 step:1343/14065 loss：0.289376
【train】 epoch：0 step:1344/14065 loss：0.138976
【train】 epoch：0 step:1345/14065 loss：0.291182
【train】 epoch：0 step:1346/14065 loss：0.218927
【train】 epoch：0 step:1347/14065 loss：0.200546
【train】 epoch：0 step:1348/14065 loss：0.092532
【train】 epoch：0 step:1349/14065 loss：0.323165
【train】 epoch：0 step:1350/14065 loss：0.243624
【train】 epoch：0 step:1351/14065 loss：0.235785
【train】 epoch：0 step:1352/14065 loss：0.161884
【train】 epoch：0 step:1353/14065 loss：0.170298
【train】 epoch：0 step:1354/14065 loss：0.168220
【train】 epoch：0 step:1355/14065 loss：0.406525
【train】 epoch：0 step:1356/14065 loss：0.316698
【train】 epoch：0 step:1357/14065 loss：0.207277
【train】 epoch：0 step:1358/14065 loss：0.133120
【train】 epoch：0 step:1359/14065 loss：0.289667
【train】 epoch：0 step:1360/14065 loss：0.135696
【train】 epoch：0 step:1361/14065 loss：0.080089
【train】 epoch：0 step:1362/14065 loss：0.134279
【train】 epoch：0 step:1363/14065 loss：0.139433
【train】 epoch：0 step:1364/14065 loss：0.247393
【train】 epoch：0 step:1365/14065 loss：0.160930
【train】 epoch：0 step:1366/14065 loss：0.175015
【train】 epoch：0 step:1367/14065 loss：0.204225
【train】 epoch：0 step:1368/14065 loss：0.252308
【train】 epoch：0 step:1369/14065 loss：0.096301
【train】 epoch：0 step:1370/14065 loss：0.203784
【train】 epoch：0 step:1371/14065 loss：0.343612
【train】 epoch：0 step:1372/14065 loss：0.348524
【train】 epoch：0 step:1373/14065 loss：0.160103
【train】 epoch：0 step:1374/14065 loss：0.161571
【train】 epoch：0 step:1375/14065 loss：0.061687
【train】 epoch：0 step:1376/14065 loss：0.219700
【train】 epoch：0 step:1377/14065 loss：0.438199
【train】 epoch：0 step:1378/14065 loss：0.143778
【train】 epoch：0 step:1379/14065 loss：0.148425
【train】 epoch：0 step:1380/14065 loss：0.215942
【train】 epoch：0 step:1381/14065 loss：0.342241
【train】 epoch：0 step:1382/14065 loss：0.175931
【train】 epoch：0 step:1383/14065 loss：0.169372
【train】 epoch：0 step:1384/14065 loss：0.064239
【train】 epoch：0 step:1385/14065 loss：0.138909
【train】 epoch：0 step:1386/14065 loss：0.215322
【train】 epoch：0 step:1387/14065 loss：0.109063
【train】 epoch：0 step:1388/14065 loss：0.383399
【train】 epoch：0 step:1389/14065 loss：0.211398
【train】 epoch：0 step:1390/14065 loss：0.134503
【train】 epoch：0 step:1391/14065 loss：0.155528
【train】 epoch：0 step:1392/14065 loss：0.126344
【train】 epoch：0 step:1393/14065 loss：0.148749
【train】 epoch：0 step:1394/14065 loss：0.074371
【train】 epoch：0 step:1395/14065 loss：0.179468
【train】 epoch：0 step:1396/14065 loss：0.108928
【train】 epoch：0 step:1397/14065 loss：0.187723
【train】 epoch：0 step:1398/14065 loss：0.142727
【train】 epoch：0 step:1399/14065 loss：0.288520
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：457.183323 accuracy：0.9492 precision：0.9492 recall：0.9492 f1：0.9492
------------>保存当前最好的模型
【train】 epoch：0 step:1400/14065 loss：0.142702
【train】 epoch：0 step:1401/14065 loss：0.491093
【train】 epoch：0 step:1402/14065 loss：0.134605
【train】 epoch：0 step:1403/14065 loss：0.092165
【train】 epoch：0 step:1404/14065 loss：0.271744
【train】 epoch：0 step:1405/14065 loss：0.126379
【train】 epoch：0 step:1406/14065 loss：0.223216
【train】 epoch：0 step:1407/14065 loss：0.198384
【train】 epoch：0 step:1408/14065 loss：0.186397
【train】 epoch：0 step:1409/14065 loss：0.140441
【train】 epoch：0 step:1410/14065 loss：0.370371
【train】 epoch：0 step:1411/14065 loss：0.212655
【train】 epoch：0 step:1412/14065 loss：0.113518
【train】 epoch：0 step:1413/14065 loss：0.105660
【train】 epoch：0 step:1414/14065 loss：0.223566
【train】 epoch：0 step:1415/14065 loss：0.181938
【train】 epoch：0 step:1416/14065 loss：0.206891
【train】 epoch：0 step:1417/14065 loss：0.092057
【train】 epoch：0 step:1418/14065 loss：0.226772
【train】 epoch：0 step:1419/14065 loss：0.333149
【train】 epoch：0 step:1420/14065 loss：0.165763
【train】 epoch：0 step:1421/14065 loss：0.128388
【train】 epoch：0 step:1422/14065 loss：0.091009
【train】 epoch：0 step:1423/14065 loss：0.271194
【train】 epoch：0 step:1424/14065 loss：0.115531
【train】 epoch：0 step:1425/14065 loss：0.269058
【train】 epoch：0 step:1426/14065 loss：0.183719
【train】 epoch：0 step:1427/14065 loss：0.093710
【train】 epoch：0 step:1428/14065 loss：0.222746
【train】 epoch：0 step:1429/14065 loss：0.093432
【train】 epoch：0 step:1430/14065 loss：0.195399
【train】 epoch：0 step:1431/14065 loss：0.249353
【train】 epoch：0 step:1432/14065 loss：0.111192
【train】 epoch：0 step:1433/14065 loss：0.172807
【train】 epoch：0 step:1434/14065 loss：0.191367
【train】 epoch：0 step:1435/14065 loss：0.168891
【train】 epoch：0 step:1436/14065 loss：0.371455
【train】 epoch：0 step:1437/14065 loss：0.448570
【train】 epoch：0 step:1438/14065 loss：0.225815
【train】 epoch：0 step:1439/14065 loss：0.150957
【train】 epoch：0 step:1440/14065 loss：0.204458
【train】 epoch：0 step:1441/14065 loss：0.246108
【train】 epoch：0 step:1442/14065 loss：0.253723
【train】 epoch：0 step:1443/14065 loss：0.092235
【train】 epoch：0 step:1444/14065 loss：0.090407
【train】 epoch：0 step:1445/14065 loss：0.178483
【train】 epoch：0 step:1446/14065 loss：0.106603
【train】 epoch：0 step:1447/14065 loss：0.245465
【train】 epoch：0 step:1448/14065 loss：0.267247
【train】 epoch：0 step:1449/14065 loss：0.201124
【train】 epoch：0 step:1450/14065 loss：0.391461
【train】 epoch：0 step:1451/14065 loss：0.061394
【train】 epoch：0 step:1452/14065 loss：0.078830
【train】 epoch：0 step:1453/14065 loss：0.254389
【train】 epoch：0 step:1454/14065 loss：0.180021
【train】 epoch：0 step:1455/14065 loss：0.202650
【train】 epoch：0 step:1456/14065 loss：0.193182
【train】 epoch：0 step:1457/14065 loss：0.043696
【train】 epoch：0 step:1458/14065 loss：0.220904
【train】 epoch：0 step:1459/14065 loss：0.358328
【train】 epoch：0 step:1460/14065 loss：0.222567
【train】 epoch：0 step:1461/14065 loss：0.192752
【train】 epoch：0 step:1462/14065 loss：0.321199
【train】 epoch：0 step:1463/14065 loss：0.329097
【train】 epoch：0 step:1464/14065 loss：0.158141
【train】 epoch：0 step:1465/14065 loss：0.225314
【train】 epoch：0 step:1466/14065 loss：0.211820
【train】 epoch：0 step:1467/14065 loss：0.240624
【train】 epoch：0 step:1468/14065 loss：0.166624
【train】 epoch：0 step:1469/14065 loss：0.178804
【train】 epoch：0 step:1470/14065 loss：0.252913
【train】 epoch：0 step:1471/14065 loss：0.122495
【train】 epoch：0 step:1472/14065 loss：0.225553
【train】 epoch：0 step:1473/14065 loss：0.111728
【train】 epoch：0 step:1474/14065 loss：0.373239
【train】 epoch：0 step:1475/14065 loss：0.452762
【train】 epoch：0 step:1476/14065 loss：0.200697
【train】 epoch：0 step:1477/14065 loss：0.273923
【train】 epoch：0 step:1478/14065 loss：0.211605
【train】 epoch：0 step:1479/14065 loss：0.050204
【train】 epoch：0 step:1480/14065 loss：0.064928
【train】 epoch：0 step:1481/14065 loss：0.244878
【train】 epoch：0 step:1482/14065 loss：0.187912
【train】 epoch：0 step:1483/14065 loss：0.358655
【train】 epoch：0 step:1484/14065 loss：0.282792
【train】 epoch：0 step:1485/14065 loss：0.161143
【train】 epoch：0 step:1486/14065 loss：0.108685
【train】 epoch：0 step:1487/14065 loss：0.241393
【train】 epoch：0 step:1488/14065 loss：0.080174
【train】 epoch：0 step:1489/14065 loss：0.157996
【train】 epoch：0 step:1490/14065 loss：0.306047
【train】 epoch：0 step:1491/14065 loss：0.060001
【train】 epoch：0 step:1492/14065 loss：0.367183
【train】 epoch：0 step:1493/14065 loss：0.294908
【train】 epoch：0 step:1494/14065 loss：0.114682
【train】 epoch：0 step:1495/14065 loss：0.115294
【train】 epoch：0 step:1496/14065 loss：0.352669
【train】 epoch：0 step:1497/14065 loss：0.134870
【train】 epoch：0 step:1498/14065 loss：0.039196
【train】 epoch：0 step:1499/14065 loss：0.200721
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：443.552770 accuracy：0.9504 precision：0.9504 recall：0.9504 f1：0.9504
------------>保存当前最好的模型
【train】 epoch：0 step:1500/14065 loss：0.114024
【train】 epoch：0 step:1501/14065 loss：0.219331
【train】 epoch：0 step:1502/14065 loss：0.198749
【train】 epoch：0 step:1503/14065 loss：0.160149
【train】 epoch：0 step:1504/14065 loss：0.183421
【train】 epoch：0 step:1505/14065 loss：0.189159
【train】 epoch：0 step:1506/14065 loss：0.219431
【train】 epoch：0 step:1507/14065 loss：0.112545
【train】 epoch：0 step:1508/14065 loss：0.213787
【train】 epoch：0 step:1509/14065 loss：0.326451
【train】 epoch：0 step:1510/14065 loss：0.126221
【train】 epoch：0 step:1511/14065 loss：0.123696
【train】 epoch：0 step:1512/14065 loss：0.137375
【train】 epoch：0 step:1513/14065 loss：0.162636
【train】 epoch：0 step:1514/14065 loss：0.051179
【train】 epoch：0 step:1515/14065 loss：0.148337
【train】 epoch：0 step:1516/14065 loss：0.173919
【train】 epoch：0 step:1517/14065 loss：0.211850
【train】 epoch：0 step:1518/14065 loss：0.168930
【train】 epoch：0 step:1519/14065 loss：0.143567
【train】 epoch：0 step:1520/14065 loss：0.135442
【train】 epoch：0 step:1521/14065 loss：0.138149
【train】 epoch：0 step:1522/14065 loss：0.099307
【train】 epoch：0 step:1523/14065 loss：0.174910
【train】 epoch：0 step:1524/14065 loss：0.127643
【train】 epoch：0 step:1525/14065 loss：0.166513
【train】 epoch：0 step:1526/14065 loss：0.199420
【train】 epoch：0 step:1527/14065 loss：0.270176
【train】 epoch：0 step:1528/14065 loss：0.351180
【train】 epoch：0 step:1529/14065 loss：0.124627
【train】 epoch：0 step:1530/14065 loss：0.226233
【train】 epoch：0 step:1531/14065 loss：0.258279
【train】 epoch：0 step:1532/14065 loss：0.182186
【train】 epoch：0 step:1533/14065 loss：0.293808
【train】 epoch：0 step:1534/14065 loss：0.241606
【train】 epoch：0 step:1535/14065 loss：0.233167
【train】 epoch：0 step:1536/14065 loss：0.326085
【train】 epoch：0 step:1537/14065 loss：0.349977
【train】 epoch：0 step:1538/14065 loss：0.152575
【train】 epoch：0 step:1539/14065 loss：0.062349
【train】 epoch：0 step:1540/14065 loss：0.042378
【train】 epoch：0 step:1541/14065 loss：0.296854
【train】 epoch：0 step:1542/14065 loss：0.116431
【train】 epoch：0 step:1543/14065 loss：0.098119
【train】 epoch：0 step:1544/14065 loss：0.152388
【train】 epoch：0 step:1545/14065 loss：0.159608
【train】 epoch：0 step:1546/14065 loss：0.186372
【train】 epoch：0 step:1547/14065 loss：0.467380
【train】 epoch：0 step:1548/14065 loss：0.340914
【train】 epoch：0 step:1549/14065 loss：0.202452
【train】 epoch：0 step:1550/14065 loss：0.253332
【train】 epoch：0 step:1551/14065 loss：0.249161
【train】 epoch：0 step:1552/14065 loss：0.140651
【train】 epoch：0 step:1553/14065 loss：0.311439
【train】 epoch：0 step:1554/14065 loss：0.182929
【train】 epoch：0 step:1555/14065 loss：0.169698
【train】 epoch：0 step:1556/14065 loss：0.094333
【train】 epoch：0 step:1557/14065 loss：0.237212
【train】 epoch：0 step:1558/14065 loss：0.131398
【train】 epoch：0 step:1559/14065 loss：0.124472
【train】 epoch：0 step:1560/14065 loss：0.133814
【train】 epoch：0 step:1561/14065 loss：0.043398
【train】 epoch：0 step:1562/14065 loss：0.171078
【train】 epoch：0 step:1563/14065 loss：0.142956
【train】 epoch：0 step:1564/14065 loss：0.139002
【train】 epoch：0 step:1565/14065 loss：0.121855
【train】 epoch：0 step:1566/14065 loss：0.182460
【train】 epoch：0 step:1567/14065 loss：0.207100
【train】 epoch：0 step:1568/14065 loss：0.123474
【train】 epoch：0 step:1569/14065 loss：0.297703
【train】 epoch：0 step:1570/14065 loss：0.212126
【train】 epoch：0 step:1571/14065 loss：0.369311
【train】 epoch：0 step:1572/14065 loss：0.072333
【train】 epoch：0 step:1573/14065 loss：0.246881
【train】 epoch：0 step:1574/14065 loss：0.382064
【train】 epoch：0 step:1575/14065 loss：0.202523
【train】 epoch：0 step:1576/14065 loss：0.336929
【train】 epoch：0 step:1577/14065 loss：0.199091
【train】 epoch：0 step:1578/14065 loss：0.112445
【train】 epoch：0 step:1579/14065 loss：0.252594
【train】 epoch：0 step:1580/14065 loss：0.152895
【train】 epoch：0 step:1581/14065 loss：0.148780
【train】 epoch：0 step:1582/14065 loss：0.153819
【train】 epoch：0 step:1583/14065 loss：0.155559
【train】 epoch：0 step:1584/14065 loss：0.220926
【train】 epoch：0 step:1585/14065 loss：0.265893
【train】 epoch：0 step:1586/14065 loss：0.207696
【train】 epoch：0 step:1587/14065 loss：0.173530
【train】 epoch：0 step:1588/14065 loss：0.072722
【train】 epoch：0 step:1589/14065 loss：0.313610
【train】 epoch：0 step:1590/14065 loss：0.229681
【train】 epoch：0 step:1591/14065 loss：0.132444
【train】 epoch：0 step:1592/14065 loss：0.163252
【train】 epoch：0 step:1593/14065 loss：0.155769
【train】 epoch：0 step:1594/14065 loss：0.377759
【train】 epoch：0 step:1595/14065 loss：0.521115
【train】 epoch：0 step:1596/14065 loss：0.252398
【train】 epoch：0 step:1597/14065 loss：0.194141
【train】 epoch：0 step:1598/14065 loss：0.174927
【train】 epoch：0 step:1599/14065 loss：0.173121
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：471.089947 accuracy：0.9468 precision：0.9468 recall：0.9468 f1：0.9468
【train】 epoch：0 step:1600/14065 loss：0.139098
【train】 epoch：0 step:1601/14065 loss：0.416073
【train】 epoch：0 step:1602/14065 loss：0.276089
【train】 epoch：0 step:1603/14065 loss：0.333278
【train】 epoch：0 step:1604/14065 loss：0.194239
【train】 epoch：0 step:1605/14065 loss：0.222934
【train】 epoch：0 step:1606/14065 loss：0.269716
【train】 epoch：0 step:1607/14065 loss：0.075844
【train】 epoch：0 step:1608/14065 loss：0.289875
【train】 epoch：0 step:1609/14065 loss：0.144638
【train】 epoch：0 step:1610/14065 loss：0.492800
【train】 epoch：0 step:1611/14065 loss：0.205063
【train】 epoch：0 step:1612/14065 loss：0.033911
【train】 epoch：0 step:1613/14065 loss：0.187575
【train】 epoch：0 step:1614/14065 loss：0.297423
【train】 epoch：0 step:1615/14065 loss：0.298500
【train】 epoch：0 step:1616/14065 loss：0.164432
【train】 epoch：0 step:1617/14065 loss：0.099586
【train】 epoch：0 step:1618/14065 loss：0.153928
【train】 epoch：0 step:1619/14065 loss：0.103134
【train】 epoch：0 step:1620/14065 loss：0.328730
【train】 epoch：0 step:1621/14065 loss：0.293364
【train】 epoch：0 step:1622/14065 loss：0.240118
【train】 epoch：0 step:1623/14065 loss：0.233666
【train】 epoch：0 step:1624/14065 loss：0.199184
【train】 epoch：0 step:1625/14065 loss：0.108819
【train】 epoch：0 step:1626/14065 loss：0.152323
【train】 epoch：0 step:1627/14065 loss：0.155660
【train】 epoch：0 step:1628/14065 loss：0.273376
【train】 epoch：0 step:1629/14065 loss：0.092694
【train】 epoch：0 step:1630/14065 loss：0.079220
【train】 epoch：0 step:1631/14065 loss：0.224709
【train】 epoch：0 step:1632/14065 loss：0.192563
【train】 epoch：0 step:1633/14065 loss：0.108950
【train】 epoch：0 step:1634/14065 loss：0.299290
【train】 epoch：0 step:1635/14065 loss：0.114128
【train】 epoch：0 step:1636/14065 loss：0.238122
【train】 epoch：0 step:1637/14065 loss：0.313148
【train】 epoch：0 step:1638/14065 loss：0.326591
【train】 epoch：0 step:1639/14065 loss：0.280920
【train】 epoch：0 step:1640/14065 loss：0.092437
【train】 epoch：0 step:1641/14065 loss：0.173984
【train】 epoch：0 step:1642/14065 loss：0.217996
【train】 epoch：0 step:1643/14065 loss：0.123427
【train】 epoch：0 step:1644/14065 loss：0.333355
【train】 epoch：0 step:1645/14065 loss：0.303298
【train】 epoch：0 step:1646/14065 loss：0.245126
【train】 epoch：0 step:1647/14065 loss：0.317642
【train】 epoch：0 step:1648/14065 loss：0.165044
【train】 epoch：0 step:1649/14065 loss：0.216882
【train】 epoch：0 step:1650/14065 loss：0.240771
【train】 epoch：0 step:1651/14065 loss：0.191581
【train】 epoch：0 step:1652/14065 loss：0.300401
【train】 epoch：0 step:1653/14065 loss：0.235633
【train】 epoch：0 step:1654/14065 loss：0.281481
【train】 epoch：0 step:1655/14065 loss：0.293445
【train】 epoch：0 step:1656/14065 loss：0.130932
【train】 epoch：0 step:1657/14065 loss：0.302595
【train】 epoch：0 step:1658/14065 loss：0.144508
【train】 epoch：0 step:1659/14065 loss：0.312798
【train】 epoch：0 step:1660/14065 loss：0.129614
【train】 epoch：0 step:1661/14065 loss：0.351844
【train】 epoch：0 step:1662/14065 loss：0.206729
【train】 epoch：0 step:1663/14065 loss：0.274627
【train】 epoch：0 step:1664/14065 loss：0.156845
【train】 epoch：0 step:1665/14065 loss：0.155214
【train】 epoch：0 step:1666/14065 loss：0.070020
【train】 epoch：0 step:1667/14065 loss：0.160057
【train】 epoch：0 step:1668/14065 loss：0.091481
【train】 epoch：0 step:1669/14065 loss：0.230234
【train】 epoch：0 step:1670/14065 loss：0.142372
【train】 epoch：0 step:1671/14065 loss：0.056690
【train】 epoch：0 step:1672/14065 loss：0.240470
【train】 epoch：0 step:1673/14065 loss：0.266847
【train】 epoch：0 step:1674/14065 loss：0.124922
【train】 epoch：0 step:1675/14065 loss：0.247052
【train】 epoch：0 step:1676/14065 loss：0.276666
【train】 epoch：0 step:1677/14065 loss：0.222845
【train】 epoch：0 step:1678/14065 loss：0.137086
【train】 epoch：0 step:1679/14065 loss：0.362278
【train】 epoch：0 step:1680/14065 loss：0.181569
【train】 epoch：0 step:1681/14065 loss：0.356517
【train】 epoch：0 step:1682/14065 loss：0.299000
【train】 epoch：0 step:1683/14065 loss：0.355630
【train】 epoch：0 step:1684/14065 loss：0.221142
【train】 epoch：0 step:1685/14065 loss：0.166076
【train】 epoch：0 step:1686/14065 loss：0.243635
【train】 epoch：0 step:1687/14065 loss：0.193828
【train】 epoch：0 step:1688/14065 loss：0.085985
【train】 epoch：0 step:1689/14065 loss：0.109584
【train】 epoch：0 step:1690/14065 loss：0.423668
【train】 epoch：0 step:1691/14065 loss：0.065605
【train】 epoch：0 step:1692/14065 loss：0.302303
【train】 epoch：0 step:1693/14065 loss：0.131605
【train】 epoch：0 step:1694/14065 loss：0.108426
【train】 epoch：0 step:1695/14065 loss：0.167332
【train】 epoch：0 step:1696/14065 loss：0.116463
【train】 epoch：0 step:1697/14065 loss：0.304291
【train】 epoch：0 step:1698/14065 loss：0.122010
【train】 epoch：0 step:1699/14065 loss：0.146009
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：426.596042 accuracy：0.9519 precision：0.9519 recall：0.9519 f1：0.9519
------------>保存当前最好的模型
【train】 epoch：0 step:1700/14065 loss：0.041309
【train】 epoch：0 step:1701/14065 loss：0.239507
【train】 epoch：0 step:1702/14065 loss：0.070854
【train】 epoch：0 step:1703/14065 loss：0.138039
【train】 epoch：0 step:1704/14065 loss：0.092927
【train】 epoch：0 step:1705/14065 loss：0.168219
【train】 epoch：0 step:1706/14065 loss：0.120039
【train】 epoch：0 step:1707/14065 loss：0.102820
【train】 epoch：0 step:1708/14065 loss：0.117485
【train】 epoch：0 step:1709/14065 loss：0.254041
【train】 epoch：0 step:1710/14065 loss：0.169109
【train】 epoch：0 step:1711/14065 loss：0.169837
【train】 epoch：0 step:1712/14065 loss：0.243158
【train】 epoch：0 step:1713/14065 loss：0.130333
【train】 epoch：0 step:1714/14065 loss：0.291290
【train】 epoch：0 step:1715/14065 loss：0.356943
【train】 epoch：0 step:1716/14065 loss：0.117307
【train】 epoch：0 step:1717/14065 loss：0.135010
【train】 epoch：0 step:1718/14065 loss：0.250778
【train】 epoch：0 step:1719/14065 loss：0.274364
【train】 epoch：0 step:1720/14065 loss：0.319401
【train】 epoch：0 step:1721/14065 loss：0.295873
【train】 epoch：0 step:1722/14065 loss：0.335199
【train】 epoch：0 step:1723/14065 loss：0.325596
【train】 epoch：0 step:1724/14065 loss：0.075594
【train】 epoch：0 step:1725/14065 loss：0.034357
【train】 epoch：0 step:1726/14065 loss：0.150472
【train】 epoch：0 step:1727/14065 loss：0.112997
【train】 epoch：0 step:1728/14065 loss：0.085935
【train】 epoch：0 step:1729/14065 loss：0.183846
【train】 epoch：0 step:1730/14065 loss：0.128319
【train】 epoch：0 step:1731/14065 loss：0.139999
【train】 epoch：0 step:1732/14065 loss：0.189717
【train】 epoch：0 step:1733/14065 loss：0.234863
【train】 epoch：0 step:1734/14065 loss：0.219413
【train】 epoch：0 step:1735/14065 loss：0.255242
【train】 epoch：0 step:1736/14065 loss：0.174386
【train】 epoch：0 step:1737/14065 loss：0.162046
【train】 epoch：0 step:1738/14065 loss：0.083615
【train】 epoch：0 step:1739/14065 loss：0.158081
【train】 epoch：0 step:1740/14065 loss：0.203439
【train】 epoch：0 step:1741/14065 loss：0.210598
【train】 epoch：0 step:1742/14065 loss：0.329901
【train】 epoch：0 step:1743/14065 loss：0.212342
【train】 epoch：0 step:1744/14065 loss：0.229482
【train】 epoch：0 step:1745/14065 loss：0.274892
【train】 epoch：0 step:1746/14065 loss：0.288497
【train】 epoch：0 step:1747/14065 loss：0.214329
【train】 epoch：0 step:1748/14065 loss：0.188875
【train】 epoch：0 step:1749/14065 loss：0.268649
【train】 epoch：0 step:1750/14065 loss：0.145545
【train】 epoch：0 step:1751/14065 loss：0.330812
【train】 epoch：0 step:1752/14065 loss：0.054351
【train】 epoch：0 step:1753/14065 loss：0.216064
【train】 epoch：0 step:1754/14065 loss：0.230361
【train】 epoch：0 step:1755/14065 loss：0.290163
【train】 epoch：0 step:1756/14065 loss：0.156061
【train】 epoch：0 step:1757/14065 loss：0.102965
【train】 epoch：0 step:1758/14065 loss：0.288971
【train】 epoch：0 step:1759/14065 loss：0.320602
【train】 epoch：0 step:1760/14065 loss：0.159607
【train】 epoch：0 step:1761/14065 loss：0.151925
【train】 epoch：0 step:1762/14065 loss：0.078114
【train】 epoch：0 step:1763/14065 loss：0.206816
【train】 epoch：0 step:1764/14065 loss：0.164584
【train】 epoch：0 step:1765/14065 loss：0.089646
【train】 epoch：0 step:1766/14065 loss：0.298104
【train】 epoch：0 step:1767/14065 loss：0.125636
【train】 epoch：0 step:1768/14065 loss：0.193142
【train】 epoch：0 step:1769/14065 loss：0.078924
【train】 epoch：0 step:1770/14065 loss：0.276416
【train】 epoch：0 step:1771/14065 loss：0.473672
【train】 epoch：0 step:1772/14065 loss：0.075997
【train】 epoch：0 step:1773/14065 loss：0.272077
【train】 epoch：0 step:1774/14065 loss：0.218105
【train】 epoch：0 step:1775/14065 loss：0.275884
【train】 epoch：0 step:1776/14065 loss：0.405707
【train】 epoch：0 step:1777/14065 loss：0.324295
【train】 epoch：0 step:1778/14065 loss：0.155260
【train】 epoch：0 step:1779/14065 loss：0.136123
【train】 epoch：0 step:1780/14065 loss：0.045859
【train】 epoch：0 step:1781/14065 loss：0.194835
【train】 epoch：0 step:1782/14065 loss：0.195118
【train】 epoch：0 step:1783/14065 loss：0.566095
【train】 epoch：0 step:1784/14065 loss：0.036020
【train】 epoch：0 step:1785/14065 loss：0.293686
【train】 epoch：0 step:1786/14065 loss：0.187141
【train】 epoch：0 step:1787/14065 loss：0.297910
【train】 epoch：0 step:1788/14065 loss：0.302683
【train】 epoch：0 step:1789/14065 loss：0.276147
【train】 epoch：0 step:1790/14065 loss：0.142208
【train】 epoch：0 step:1791/14065 loss：0.180179
【train】 epoch：0 step:1792/14065 loss：0.234545
【train】 epoch：0 step:1793/14065 loss：0.206482
【train】 epoch：0 step:1794/14065 loss：0.120604
【train】 epoch：0 step:1795/14065 loss：0.386288
【train】 epoch：0 step:1796/14065 loss：0.101028
【train】 epoch：0 step:1797/14065 loss：0.207125
【train】 epoch：0 step:1798/14065 loss：0.231133
【train】 epoch：0 step:1799/14065 loss：0.142633
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：436.984762 accuracy：0.9514 precision：0.9514 recall：0.9514 f1：0.9514
【train】 epoch：0 step:1800/14065 loss：0.161525
【train】 epoch：0 step:1801/14065 loss：0.084125
【train】 epoch：0 step:1802/14065 loss：0.210559
【train】 epoch：0 step:1803/14065 loss：0.216610
【train】 epoch：0 step:1804/14065 loss：0.209619
【train】 epoch：0 step:1805/14065 loss：0.168709
【train】 epoch：0 step:1806/14065 loss：0.082928
【train】 epoch：0 step:1807/14065 loss：0.085794
【train】 epoch：0 step:1808/14065 loss：0.217532
【train】 epoch：0 step:1809/14065 loss：0.206848
【train】 epoch：0 step:1810/14065 loss：0.152392
【train】 epoch：0 step:1811/14065 loss：0.386617
【train】 epoch：0 step:1812/14065 loss：0.105649
【train】 epoch：0 step:1813/14065 loss：0.286308
【train】 epoch：0 step:1814/14065 loss：0.292190
【train】 epoch：0 step:1815/14065 loss：0.117029
【train】 epoch：0 step:1816/14065 loss：0.411263
【train】 epoch：0 step:1817/14065 loss：0.266290
【train】 epoch：0 step:1818/14065 loss：0.217443
【train】 epoch：0 step:1819/14065 loss：0.144282
【train】 epoch：0 step:1820/14065 loss：0.049749
【train】 epoch：0 step:1821/14065 loss：0.274701
【train】 epoch：0 step:1822/14065 loss：0.153320
【train】 epoch：0 step:1823/14065 loss：0.202668
【train】 epoch：0 step:1824/14065 loss：0.197970
【train】 epoch：0 step:1825/14065 loss：0.109131
【train】 epoch：0 step:1826/14065 loss：0.158671
【train】 epoch：0 step:1827/14065 loss：0.211610
【train】 epoch：0 step:1828/14065 loss：0.176965
【train】 epoch：0 step:1829/14065 loss：0.229818
【train】 epoch：0 step:1830/14065 loss：0.139709
【train】 epoch：0 step:1831/14065 loss：0.302102
【train】 epoch：0 step:1832/14065 loss：0.090247
【train】 epoch：0 step:1833/14065 loss：0.125107
【train】 epoch：0 step:1834/14065 loss：0.143181
【train】 epoch：0 step:1835/14065 loss：0.327117
【train】 epoch：0 step:1836/14065 loss：0.242206
【train】 epoch：0 step:1837/14065 loss：0.166691
【train】 epoch：0 step:1838/14065 loss：0.086403
【train】 epoch：0 step:1839/14065 loss：0.221627
【train】 epoch：0 step:1840/14065 loss：0.084308
【train】 epoch：0 step:1841/14065 loss：0.082709
【train】 epoch：0 step:1842/14065 loss：0.202952
【train】 epoch：0 step:1843/14065 loss：0.192005
【train】 epoch：0 step:1844/14065 loss：0.058144
【train】 epoch：0 step:1845/14065 loss：0.322977
【train】 epoch：0 step:1846/14065 loss：0.189679
【train】 epoch：0 step:1847/14065 loss：0.253475
【train】 epoch：0 step:1848/14065 loss：0.196066
【train】 epoch：0 step:1849/14065 loss：0.129485
【train】 epoch：0 step:1850/14065 loss：0.140243
【train】 epoch：0 step:1851/14065 loss：0.249566
【train】 epoch：0 step:1852/14065 loss：0.235312
【train】 epoch：0 step:1853/14065 loss：0.232775
【train】 epoch：0 step:1854/14065 loss：0.177705
【train】 epoch：0 step:1855/14065 loss：0.206298
【train】 epoch：0 step:1856/14065 loss：0.184925
【train】 epoch：0 step:1857/14065 loss：0.158749
【train】 epoch：0 step:1858/14065 loss：0.156665
【train】 epoch：0 step:1859/14065 loss：0.140929
【train】 epoch：0 step:1860/14065 loss：0.461473
【train】 epoch：0 step:1861/14065 loss：0.137619
【train】 epoch：0 step:1862/14065 loss：0.216346
【train】 epoch：0 step:1863/14065 loss：0.241921
【train】 epoch：0 step:1864/14065 loss：0.218582
【train】 epoch：0 step:1865/14065 loss：0.345451
【train】 epoch：0 step:1866/14065 loss：0.063138
【train】 epoch：0 step:1867/14065 loss：0.061358
【train】 epoch：0 step:1868/14065 loss：0.144556
【train】 epoch：0 step:1869/14065 loss：0.249201
【train】 epoch：0 step:1870/14065 loss：0.287721
【train】 epoch：0 step:1871/14065 loss：0.135991
【train】 epoch：0 step:1872/14065 loss：0.306419
【train】 epoch：0 step:1873/14065 loss：0.049336
【train】 epoch：0 step:1874/14065 loss：0.087389
【train】 epoch：0 step:1875/14065 loss：0.267064
【train】 epoch：0 step:1876/14065 loss：0.432792
【train】 epoch：0 step:1877/14065 loss：0.099705
【train】 epoch：0 step:1878/14065 loss：0.296231
【train】 epoch：0 step:1879/14065 loss：0.267129
【train】 epoch：0 step:1880/14065 loss：0.196455
【train】 epoch：0 step:1881/14065 loss：0.294331
【train】 epoch：0 step:1882/14065 loss：0.126837
【train】 epoch：0 step:1883/14065 loss：0.172351
【train】 epoch：0 step:1884/14065 loss：0.225413
【train】 epoch：0 step:1885/14065 loss：0.167563
【train】 epoch：0 step:1886/14065 loss：0.037088
【train】 epoch：0 step:1887/14065 loss：0.201909
【train】 epoch：0 step:1888/14065 loss：0.084567
【train】 epoch：0 step:1889/14065 loss：0.142291
【train】 epoch：0 step:1890/14065 loss：0.142388
【train】 epoch：0 step:1891/14065 loss：0.126837
【train】 epoch：0 step:1892/14065 loss：0.313298
【train】 epoch：0 step:1893/14065 loss：0.325712
【train】 epoch：0 step:1894/14065 loss：0.058892
【train】 epoch：0 step:1895/14065 loss：0.253664
【train】 epoch：0 step:1896/14065 loss：0.160580
【train】 epoch：0 step:1897/14065 loss：0.202290
【train】 epoch：0 step:1898/14065 loss：0.267209
【train】 epoch：0 step:1899/14065 loss：0.179540
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：403.391001 accuracy：0.9544 precision：0.9544 recall：0.9544 f1：0.9544
------------>保存当前最好的模型
【train】 epoch：0 step:1900/14065 loss：0.180263
【train】 epoch：0 step:1901/14065 loss：0.282314
【train】 epoch：0 step:1902/14065 loss：0.180638
【train】 epoch：0 step:1903/14065 loss：0.190786
【train】 epoch：0 step:1904/14065 loss：0.147004
【train】 epoch：0 step:1905/14065 loss：0.064536
【train】 epoch：0 step:1906/14065 loss：0.149345
【train】 epoch：0 step:1907/14065 loss：0.075488
【train】 epoch：0 step:1908/14065 loss：0.164681
【train】 epoch：0 step:1909/14065 loss：0.262287
【train】 epoch：0 step:1910/14065 loss：0.273079
【train】 epoch：0 step:1911/14065 loss：0.132727
【train】 epoch：0 step:1912/14065 loss：0.213837
【train】 epoch：0 step:1913/14065 loss：0.254169
【train】 epoch：0 step:1914/14065 loss：0.212590
【train】 epoch：0 step:1915/14065 loss：0.088507
【train】 epoch：0 step:1916/14065 loss：0.183272
【train】 epoch：0 step:1917/14065 loss：0.081878
【train】 epoch：0 step:1918/14065 loss：0.073622
【train】 epoch：0 step:1919/14065 loss：0.358322
【train】 epoch：0 step:1920/14065 loss：0.313542
【train】 epoch：0 step:1921/14065 loss：0.362772
【train】 epoch：0 step:1922/14065 loss：0.194328
【train】 epoch：0 step:1923/14065 loss：0.300006
【train】 epoch：0 step:1924/14065 loss：0.129838
【train】 epoch：0 step:1925/14065 loss：0.133283
【train】 epoch：0 step:1926/14065 loss：0.203166
【train】 epoch：0 step:1927/14065 loss：0.235944
【train】 epoch：0 step:1928/14065 loss：0.034668
【train】 epoch：0 step:1929/14065 loss：0.244129
【train】 epoch：0 step:1930/14065 loss：0.219926
【train】 epoch：0 step:1931/14065 loss：0.216834
【train】 epoch：0 step:1932/14065 loss：0.307715
【train】 epoch：0 step:1933/14065 loss：0.085641
【train】 epoch：0 step:1934/14065 loss：0.129563
【train】 epoch：0 step:1935/14065 loss：0.213721
【train】 epoch：0 step:1936/14065 loss：0.174752
【train】 epoch：0 step:1937/14065 loss：0.193609
【train】 epoch：0 step:1938/14065 loss：0.200939
【train】 epoch：0 step:1939/14065 loss：0.149226
【train】 epoch：0 step:1940/14065 loss：0.245271
【train】 epoch：0 step:1941/14065 loss：0.187620
【train】 epoch：0 step:1942/14065 loss：0.153770
【train】 epoch：0 step:1943/14065 loss：0.223514
【train】 epoch：0 step:1944/14065 loss：0.164082
【train】 epoch：0 step:1945/14065 loss：0.118563
【train】 epoch：0 step:1946/14065 loss：0.343184
【train】 epoch：0 step:1947/14065 loss：0.208529
【train】 epoch：0 step:1948/14065 loss：0.250366
【train】 epoch：0 step:1949/14065 loss：0.163416
【train】 epoch：0 step:1950/14065 loss：0.192236
【train】 epoch：0 step:1951/14065 loss：0.062713
【train】 epoch：0 step:1952/14065 loss：0.222144
【train】 epoch：0 step:1953/14065 loss：0.328257
【train】 epoch：0 step:1954/14065 loss：0.144222
【train】 epoch：0 step:1955/14065 loss：0.182285
【train】 epoch：0 step:1956/14065 loss：0.050994
【train】 epoch：0 step:1957/14065 loss：0.146606
【train】 epoch：0 step:1958/14065 loss：0.213116
【train】 epoch：0 step:1959/14065 loss：0.167334
【train】 epoch：0 step:1960/14065 loss：0.118246
【train】 epoch：0 step:1961/14065 loss：0.254266
【train】 epoch：0 step:1962/14065 loss：0.085740
【train】 epoch：0 step:1963/14065 loss：0.103954
【train】 epoch：0 step:1964/14065 loss：0.138812
【train】 epoch：0 step:1965/14065 loss：0.204684
【train】 epoch：0 step:1966/14065 loss：0.103918
【train】 epoch：0 step:1967/14065 loss：0.180067
【train】 epoch：0 step:1968/14065 loss：0.390917
【train】 epoch：0 step:1969/14065 loss：0.152538
【train】 epoch：0 step:1970/14065 loss：0.162201
【train】 epoch：0 step:1971/14065 loss：0.292912
【train】 epoch：0 step:1972/14065 loss：0.250049
【train】 epoch：0 step:1973/14065 loss：0.232386
【train】 epoch：0 step:1974/14065 loss：0.255682
【train】 epoch：0 step:1975/14065 loss：0.276078
【train】 epoch：0 step:1976/14065 loss：0.047049
【train】 epoch：0 step:1977/14065 loss：0.376009
【train】 epoch：0 step:1978/14065 loss：0.264972
【train】 epoch：0 step:1979/14065 loss：0.120185
【train】 epoch：0 step:1980/14065 loss：0.204801
【train】 epoch：0 step:1981/14065 loss：0.267416
【train】 epoch：0 step:1982/14065 loss：0.223452
【train】 epoch：0 step:1983/14065 loss：0.280214
【train】 epoch：0 step:1984/14065 loss：0.110354
【train】 epoch：0 step:1985/14065 loss：0.109348
【train】 epoch：0 step:1986/14065 loss：0.169723
【train】 epoch：0 step:1987/14065 loss：0.241242
【train】 epoch：0 step:1988/14065 loss：0.278104
【train】 epoch：0 step:1989/14065 loss：0.155361
【train】 epoch：0 step:1990/14065 loss：0.343936
【train】 epoch：0 step:1991/14065 loss：0.089124
【train】 epoch：0 step:1992/14065 loss：0.113162
【train】 epoch：0 step:1993/14065 loss：0.070395
【train】 epoch：0 step:1994/14065 loss：0.119485
【train】 epoch：0 step:1995/14065 loss：0.063483
【train】 epoch：0 step:1996/14065 loss：0.092381
【train】 epoch：0 step:1997/14065 loss：0.198967
【train】 epoch：0 step:1998/14065 loss：0.119445
【train】 epoch：0 step:1999/14065 loss：0.119268
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：388.522075 accuracy：0.9564 precision：0.9564 recall：0.9564 f1：0.9564
------------>保存当前最好的模型
【train】 epoch：0 step:2000/14065 loss：0.471840
【train】 epoch：0 step:2001/14065 loss：0.220204
【train】 epoch：0 step:2002/14065 loss：0.085856
【train】 epoch：0 step:2003/14065 loss：0.113606
【train】 epoch：0 step:2004/14065 loss：0.205375
【train】 epoch：0 step:2005/14065 loss：0.132335
【train】 epoch：0 step:2006/14065 loss：0.126531
【train】 epoch：0 step:2007/14065 loss：0.163346
【train】 epoch：0 step:2008/14065 loss：0.081749
【train】 epoch：0 step:2009/14065 loss：0.087132
【train】 epoch：0 step:2010/14065 loss：0.223639
【train】 epoch：0 step:2011/14065 loss：0.110837
【train】 epoch：0 step:2012/14065 loss：0.203259
【train】 epoch：0 step:2013/14065 loss：0.103739
【train】 epoch：0 step:2014/14065 loss：0.083533
【train】 epoch：0 step:2015/14065 loss：0.208352
【train】 epoch：0 step:2016/14065 loss：0.275238
【train】 epoch：0 step:2017/14065 loss：0.320342
【train】 epoch：0 step:2018/14065 loss：0.197432
【train】 epoch：0 step:2019/14065 loss：0.067351
【train】 epoch：0 step:2020/14065 loss：0.246506
【train】 epoch：0 step:2021/14065 loss：0.124975
【train】 epoch：0 step:2022/14065 loss：0.224863
【train】 epoch：0 step:2023/14065 loss：0.033323
【train】 epoch：0 step:2024/14065 loss：0.142776
【train】 epoch：0 step:2025/14065 loss：0.350077
【train】 epoch：0 step:2026/14065 loss：0.226895
【train】 epoch：0 step:2027/14065 loss：0.148610
【train】 epoch：0 step:2028/14065 loss：0.205930
【train】 epoch：0 step:2029/14065 loss：0.127821
【train】 epoch：0 step:2030/14065 loss：0.121655
【train】 epoch：0 step:2031/14065 loss：0.294540
【train】 epoch：0 step:2032/14065 loss：0.060634
【train】 epoch：0 step:2033/14065 loss：0.268325
【train】 epoch：0 step:2034/14065 loss：0.325235
【train】 epoch：0 step:2035/14065 loss：0.227246
【train】 epoch：0 step:2036/14065 loss：0.185962
【train】 epoch：0 step:2037/14065 loss：0.093735
【train】 epoch：0 step:2038/14065 loss：0.134506
【train】 epoch：0 step:2039/14065 loss：0.093068
【train】 epoch：0 step:2040/14065 loss：0.350204
【train】 epoch：0 step:2041/14065 loss：0.243824
【train】 epoch：0 step:2042/14065 loss：0.157400
【train】 epoch：0 step:2043/14065 loss：0.101971
【train】 epoch：0 step:2044/14065 loss：0.114891
【train】 epoch：0 step:2045/14065 loss：0.247603
【train】 epoch：0 step:2046/14065 loss：0.233466
【train】 epoch：0 step:2047/14065 loss：0.188212
【train】 epoch：0 step:2048/14065 loss：0.088293
【train】 epoch：0 step:2049/14065 loss：0.128840
【train】 epoch：0 step:2050/14065 loss：0.125851
【train】 epoch：0 step:2051/14065 loss：0.184310
【train】 epoch：0 step:2052/14065 loss：0.165129
【train】 epoch：0 step:2053/14065 loss：0.241893
【train】 epoch：0 step:2054/14065 loss：0.165043
【train】 epoch：0 step:2055/14065 loss：0.171335
【train】 epoch：0 step:2056/14065 loss：0.178937
【train】 epoch：0 step:2057/14065 loss：0.176346
【train】 epoch：0 step:2058/14065 loss：0.241625
【train】 epoch：0 step:2059/14065 loss：0.167735
【train】 epoch：0 step:2060/14065 loss：0.285607
【train】 epoch：0 step:2061/14065 loss：0.312946
【train】 epoch：0 step:2062/14065 loss：0.262617
【train】 epoch：0 step:2063/14065 loss：0.194941
【train】 epoch：0 step:2064/14065 loss：0.139452
【train】 epoch：0 step:2065/14065 loss：0.297604
【train】 epoch：0 step:2066/14065 loss：0.095684
【train】 epoch：0 step:2067/14065 loss：0.163794
【train】 epoch：0 step:2068/14065 loss：0.256632
【train】 epoch：0 step:2069/14065 loss：0.106233
【train】 epoch：0 step:2070/14065 loss：0.177014
【train】 epoch：0 step:2071/14065 loss：0.328926
【train】 epoch：0 step:2072/14065 loss：0.152603
【train】 epoch：0 step:2073/14065 loss：0.249414
【train】 epoch：0 step:2074/14065 loss：0.368165
【train】 epoch：0 step:2075/14065 loss：0.221712
【train】 epoch：0 step:2076/14065 loss：0.183630
【train】 epoch：0 step:2077/14065 loss：0.247518
【train】 epoch：0 step:2078/14065 loss：0.087569
【train】 epoch：0 step:2079/14065 loss：0.091892
【train】 epoch：0 step:2080/14065 loss：0.064640
【train】 epoch：0 step:2081/14065 loss：0.204400
【train】 epoch：0 step:2082/14065 loss：0.193916
【train】 epoch：0 step:2083/14065 loss：0.306874
【train】 epoch：0 step:2084/14065 loss：0.083567
【train】 epoch：0 step:2085/14065 loss：0.129260
【train】 epoch：0 step:2086/14065 loss：0.077522
【train】 epoch：0 step:2087/14065 loss：0.281575
【train】 epoch：0 step:2088/14065 loss：0.236687
【train】 epoch：0 step:2089/14065 loss：0.413975
【train】 epoch：0 step:2090/14065 loss：0.129685
【train】 epoch：0 step:2091/14065 loss：0.156110
【train】 epoch：0 step:2092/14065 loss：0.182231
【train】 epoch：0 step:2093/14065 loss：0.176348
【train】 epoch：0 step:2094/14065 loss：0.154658
【train】 epoch：0 step:2095/14065 loss：0.163688
【train】 epoch：0 step:2096/14065 loss：0.214453
【train】 epoch：0 step:2097/14065 loss：0.080645
【train】 epoch：0 step:2098/14065 loss：0.371235
【train】 epoch：0 step:2099/14065 loss：0.284854
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：384.241733 accuracy：0.9551 precision：0.9551 recall：0.9551 f1：0.9551
【train】 epoch：0 step:2100/14065 loss：0.251467
【train】 epoch：0 step:2101/14065 loss：0.117553
【train】 epoch：0 step:2102/14065 loss：0.322609
【train】 epoch：0 step:2103/14065 loss：0.116453
【train】 epoch：0 step:2104/14065 loss：0.120460
【train】 epoch：0 step:2105/14065 loss：0.189240
【train】 epoch：0 step:2106/14065 loss：0.307876
【train】 epoch：0 step:2107/14065 loss：0.111622
【train】 epoch：0 step:2108/14065 loss：0.154876
【train】 epoch：0 step:2109/14065 loss：0.162020
【train】 epoch：0 step:2110/14065 loss：0.253982
【train】 epoch：0 step:2111/14065 loss：0.054823
【train】 epoch：0 step:2112/14065 loss：0.123220
【train】 epoch：0 step:2113/14065 loss：0.140201
【train】 epoch：0 step:2114/14065 loss：0.191987
【train】 epoch：0 step:2115/14065 loss：0.090780
【train】 epoch：0 step:2116/14065 loss：0.120341
【train】 epoch：0 step:2117/14065 loss：0.234983
【train】 epoch：0 step:2118/14065 loss：0.066676
【train】 epoch：0 step:2119/14065 loss：0.076107
【train】 epoch：0 step:2120/14065 loss：0.205013
【train】 epoch：0 step:2121/14065 loss：0.309629
【train】 epoch：0 step:2122/14065 loss：0.091934
【train】 epoch：0 step:2123/14065 loss：0.260865
【train】 epoch：0 step:2124/14065 loss：0.031875
【train】 epoch：0 step:2125/14065 loss：0.219131
【train】 epoch：0 step:2126/14065 loss：0.234182
【train】 epoch：0 step:2127/14065 loss：0.221101
【train】 epoch：0 step:2128/14065 loss：0.272066
【train】 epoch：0 step:2129/14065 loss：0.251884
【train】 epoch：0 step:2130/14065 loss：0.286933
【train】 epoch：0 step:2131/14065 loss：0.094105
【train】 epoch：0 step:2132/14065 loss：0.129736
【train】 epoch：0 step:2133/14065 loss：0.069862
【train】 epoch：0 step:2134/14065 loss：0.214384
【train】 epoch：0 step:2135/14065 loss：0.192119
【train】 epoch：0 step:2136/14065 loss：0.111951
【train】 epoch：0 step:2137/14065 loss：0.237399
【train】 epoch：0 step:2138/14065 loss：0.239269
【train】 epoch：0 step:2139/14065 loss：0.291088
【train】 epoch：0 step:2140/14065 loss：0.236494
【train】 epoch：0 step:2141/14065 loss：0.325987
【train】 epoch：0 step:2142/14065 loss：0.164281
【train】 epoch：0 step:2143/14065 loss：0.346011
【train】 epoch：0 step:2144/14065 loss：0.199650
【train】 epoch：0 step:2145/14065 loss：0.190050
【train】 epoch：0 step:2146/14065 loss：0.162423
【train】 epoch：0 step:2147/14065 loss：0.214886
【train】 epoch：0 step:2148/14065 loss：0.277939
【train】 epoch：0 step:2149/14065 loss：0.121403
【train】 epoch：0 step:2150/14065 loss：0.322228
【train】 epoch：0 step:2151/14065 loss：0.255518
【train】 epoch：0 step:2152/14065 loss：0.109040
【train】 epoch：0 step:2153/14065 loss：0.324749
【train】 epoch：0 step:2154/14065 loss：0.133773
【train】 epoch：0 step:2155/14065 loss：0.182524
【train】 epoch：0 step:2156/14065 loss：0.191001
【train】 epoch：0 step:2157/14065 loss：0.305326
【train】 epoch：0 step:2158/14065 loss：0.194065
【train】 epoch：0 step:2159/14065 loss：0.220648
【train】 epoch：0 step:2160/14065 loss：0.192198
【train】 epoch：0 step:2161/14065 loss：0.217055
【train】 epoch：0 step:2162/14065 loss：0.049014
【train】 epoch：0 step:2163/14065 loss：0.235980
【train】 epoch：0 step:2164/14065 loss：0.192113
【train】 epoch：0 step:2165/14065 loss：0.283653
【train】 epoch：0 step:2166/14065 loss：0.134976
【train】 epoch：0 step:2167/14065 loss：0.208071
【train】 epoch：0 step:2168/14065 loss：0.310207
【train】 epoch：0 step:2169/14065 loss：0.094608
【train】 epoch：0 step:2170/14065 loss：0.188617
【train】 epoch：0 step:2171/14065 loss：0.357759
【train】 epoch：0 step:2172/14065 loss：0.162549
【train】 epoch：0 step:2173/14065 loss：0.178073
【train】 epoch：0 step:2174/14065 loss：0.223051
【train】 epoch：0 step:2175/14065 loss：0.313150
【train】 epoch：0 step:2176/14065 loss：0.054266
【train】 epoch：0 step:2177/14065 loss：0.222936
【train】 epoch：0 step:2178/14065 loss：0.107320
【train】 epoch：0 step:2179/14065 loss：0.080479
【train】 epoch：0 step:2180/14065 loss：0.091930
【train】 epoch：0 step:2181/14065 loss：0.142298
【train】 epoch：0 step:2182/14065 loss：0.098699
【train】 epoch：0 step:2183/14065 loss：0.177306
【train】 epoch：0 step:2184/14065 loss：0.183570
【train】 epoch：0 step:2185/14065 loss：0.045383
【train】 epoch：0 step:2186/14065 loss：0.033090
【train】 epoch：0 step:2187/14065 loss：0.433673
【train】 epoch：0 step:2188/14065 loss：0.172154
【train】 epoch：0 step:2189/14065 loss：0.121610
【train】 epoch：0 step:2190/14065 loss：0.307480
【train】 epoch：0 step:2191/14065 loss：0.265044
【train】 epoch：0 step:2192/14065 loss：0.102823
【train】 epoch：0 step:2193/14065 loss：0.101342
【train】 epoch：0 step:2194/14065 loss：0.108884
【train】 epoch：0 step:2195/14065 loss：0.085623
【train】 epoch：0 step:2196/14065 loss：0.313943
【train】 epoch：0 step:2197/14065 loss：0.173673
【train】 epoch：0 step:2198/14065 loss：0.117678
【train】 epoch：0 step:2199/14065 loss：0.154946
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：403.774868 accuracy：0.9538 precision：0.9538 recall：0.9538 f1：0.9538
【train】 epoch：0 step:2200/14065 loss：0.151908
【train】 epoch：0 step:2201/14065 loss：0.337380
【train】 epoch：0 step:2202/14065 loss：0.331557
【train】 epoch：0 step:2203/14065 loss：0.182307
【train】 epoch：0 step:2204/14065 loss：0.303957
【train】 epoch：0 step:2205/14065 loss：0.142100
【train】 epoch：0 step:2206/14065 loss：0.215108
【train】 epoch：0 step:2207/14065 loss：0.173286
【train】 epoch：0 step:2208/14065 loss：0.208833
【train】 epoch：0 step:2209/14065 loss：0.303365
【train】 epoch：0 step:2210/14065 loss：0.227339
【train】 epoch：0 step:2211/14065 loss：0.127055
【train】 epoch：0 step:2212/14065 loss：0.198563
【train】 epoch：0 step:2213/14065 loss：0.073085
【train】 epoch：0 step:2214/14065 loss：0.439106
【train】 epoch：0 step:2215/14065 loss：0.085192
【train】 epoch：0 step:2216/14065 loss：0.194685
【train】 epoch：0 step:2217/14065 loss：0.251655
【train】 epoch：0 step:2218/14065 loss：0.138190
【train】 epoch：0 step:2219/14065 loss：0.230437
【train】 epoch：0 step:2220/14065 loss：0.237718
【train】 epoch：0 step:2221/14065 loss：0.171896
【train】 epoch：0 step:2222/14065 loss：0.148945
【train】 epoch：0 step:2223/14065 loss：0.231286
【train】 epoch：0 step:2224/14065 loss：0.231672
【train】 epoch：0 step:2225/14065 loss：0.077624
【train】 epoch：0 step:2226/14065 loss：0.257372
【train】 epoch：0 step:2227/14065 loss：0.095032
【train】 epoch：0 step:2228/14065 loss：0.157132
【train】 epoch：0 step:2229/14065 loss：0.357811
【train】 epoch：0 step:2230/14065 loss：0.067049
【train】 epoch：0 step:2231/14065 loss：0.169580
【train】 epoch：0 step:2232/14065 loss：0.103059
【train】 epoch：0 step:2233/14065 loss：0.176493
【train】 epoch：0 step:2234/14065 loss：0.213055
【train】 epoch：0 step:2235/14065 loss：0.291112
【train】 epoch：0 step:2236/14065 loss：0.045124
【train】 epoch：0 step:2237/14065 loss：0.258892
【train】 epoch：0 step:2238/14065 loss：0.349273
【train】 epoch：0 step:2239/14065 loss：0.184154
【train】 epoch：0 step:2240/14065 loss：0.080497
【train】 epoch：0 step:2241/14065 loss：0.102500
【train】 epoch：0 step:2242/14065 loss：0.226633
【train】 epoch：0 step:2243/14065 loss：0.169963
【train】 epoch：0 step:2244/14065 loss：0.257763
【train】 epoch：0 step:2245/14065 loss：0.058498
【train】 epoch：0 step:2246/14065 loss：0.125146
【train】 epoch：0 step:2247/14065 loss：0.308740
【train】 epoch：0 step:2248/14065 loss：0.079133
【train】 epoch：0 step:2249/14065 loss：0.205605
【train】 epoch：0 step:2250/14065 loss：0.087211
【train】 epoch：0 step:2251/14065 loss：0.082350
【train】 epoch：0 step:2252/14065 loss：0.292642
【train】 epoch：0 step:2253/14065 loss：0.282579
【train】 epoch：0 step:2254/14065 loss：0.227654
【train】 epoch：0 step:2255/14065 loss：0.336026
【train】 epoch：0 step:2256/14065 loss：0.087001
【train】 epoch：0 step:2257/14065 loss：0.189532
【train】 epoch：0 step:2258/14065 loss：0.212270
【train】 epoch：0 step:2259/14065 loss：0.176329
【train】 epoch：0 step:2260/14065 loss：0.248465
【train】 epoch：0 step:2261/14065 loss：0.177317
【train】 epoch：0 step:2262/14065 loss：0.246814
【train】 epoch：0 step:2263/14065 loss：0.186018
【train】 epoch：0 step:2264/14065 loss：0.173109
【train】 epoch：0 step:2265/14065 loss：0.174013
【train】 epoch：0 step:2266/14065 loss：0.202868
【train】 epoch：0 step:2267/14065 loss：0.303155
【train】 epoch：0 step:2268/14065 loss：0.156666
【train】 epoch：0 step:2269/14065 loss：0.161743
【train】 epoch：0 step:2270/14065 loss：0.224400
【train】 epoch：0 step:2271/14065 loss：0.175714
【train】 epoch：0 step:2272/14065 loss：0.255224
【train】 epoch：0 step:2273/14065 loss：0.232892
【train】 epoch：0 step:2274/14065 loss：0.178519
【train】 epoch：0 step:2275/14065 loss：0.088080
【train】 epoch：0 step:2276/14065 loss：0.137754
【train】 epoch：0 step:2277/14065 loss：0.134612
【train】 epoch：0 step:2278/14065 loss：0.149117
【train】 epoch：0 step:2279/14065 loss：0.050544
【train】 epoch：0 step:2280/14065 loss：0.085550
【train】 epoch：0 step:2281/14065 loss：0.146663
【train】 epoch：0 step:2282/14065 loss：0.098046
【train】 epoch：0 step:2283/14065 loss：0.165344
【train】 epoch：0 step:2284/14065 loss：0.090342
【train】 epoch：0 step:2285/14065 loss：0.147988
【train】 epoch：0 step:2286/14065 loss：0.092095
【train】 epoch：0 step:2287/14065 loss：0.110474
【train】 epoch：0 step:2288/14065 loss：0.218412
【train】 epoch：0 step:2289/14065 loss：0.091775
【train】 epoch：0 step:2290/14065 loss：0.150241
【train】 epoch：0 step:2291/14065 loss：0.253264
【train】 epoch：0 step:2292/14065 loss：0.170346
【train】 epoch：0 step:2293/14065 loss：0.174220
【train】 epoch：0 step:2294/14065 loss：0.215575
【train】 epoch：0 step:2295/14065 loss：0.288983
【train】 epoch：0 step:2296/14065 loss：0.129262
【train】 epoch：0 step:2297/14065 loss：0.165434
【train】 epoch：0 step:2298/14065 loss：0.309401
【train】 epoch：0 step:2299/14065 loss：0.112904
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：368.894859 accuracy：0.9578 precision：0.9578 recall：0.9578 f1：0.9578
------------>保存当前最好的模型
【train】 epoch：0 step:2300/14065 loss：0.218822
【train】 epoch：0 step:2301/14065 loss：0.210331
【train】 epoch：0 step:2302/14065 loss：0.238990
【train】 epoch：0 step:2303/14065 loss：0.254677
【train】 epoch：0 step:2304/14065 loss：0.185226
【train】 epoch：0 step:2305/14065 loss：0.230342
【train】 epoch：0 step:2306/14065 loss：0.231051
【train】 epoch：0 step:2307/14065 loss：0.175131
【train】 epoch：0 step:2308/14065 loss：0.143737
【train】 epoch：0 step:2309/14065 loss：0.140699
【train】 epoch：0 step:2310/14065 loss：0.109970
【train】 epoch：0 step:2311/14065 loss：0.183598
【train】 epoch：0 step:2312/14065 loss：0.314479
【train】 epoch：0 step:2313/14065 loss：0.093782
【train】 epoch：0 step:2314/14065 loss：0.164415
【train】 epoch：0 step:2315/14065 loss：0.211084
【train】 epoch：0 step:2316/14065 loss：0.177364
【train】 epoch：0 step:2317/14065 loss：0.070527
【train】 epoch：0 step:2318/14065 loss：0.253188
【train】 epoch：0 step:2319/14065 loss：0.191360
【train】 epoch：0 step:2320/14065 loss：0.170523
【train】 epoch：0 step:2321/14065 loss：0.171786
【train】 epoch：0 step:2322/14065 loss：0.332104
【train】 epoch：0 step:2323/14065 loss：0.124569
【train】 epoch：0 step:2324/14065 loss：0.337082
【train】 epoch：0 step:2325/14065 loss：0.039273
【train】 epoch：0 step:2326/14065 loss：0.308440
【train】 epoch：0 step:2327/14065 loss：0.181464
【train】 epoch：0 step:2328/14065 loss：0.215532
【train】 epoch：0 step:2329/14065 loss：0.160079
【train】 epoch：0 step:2330/14065 loss：0.150402
【train】 epoch：0 step:2331/14065 loss：0.137654
【train】 epoch：0 step:2332/14065 loss：0.227562
【train】 epoch：0 step:2333/14065 loss：0.141937
【train】 epoch：0 step:2334/14065 loss：0.063403
【train】 epoch：0 step:2335/14065 loss：0.102495
【train】 epoch：0 step:2336/14065 loss：0.238701
【train】 epoch：0 step:2337/14065 loss：0.184808
【train】 epoch：0 step:2338/14065 loss：0.175069
【train】 epoch：0 step:2339/14065 loss：0.156004
【train】 epoch：0 step:2340/14065 loss：0.221830
【train】 epoch：0 step:2341/14065 loss：0.139281
【train】 epoch：0 step:2342/14065 loss：0.118326
【train】 epoch：0 step:2343/14065 loss：0.111475
【train】 epoch：0 step:2344/14065 loss：0.162782
【train】 epoch：0 step:2345/14065 loss：0.216933
【train】 epoch：0 step:2346/14065 loss：0.127734
【train】 epoch：0 step:2347/14065 loss：0.155039
【train】 epoch：0 step:2348/14065 loss：0.228232
【train】 epoch：0 step:2349/14065 loss：0.132839
【train】 epoch：0 step:2350/14065 loss：0.060621
【train】 epoch：0 step:2351/14065 loss：0.122291
【train】 epoch：0 step:2352/14065 loss：0.165543
【train】 epoch：0 step:2353/14065 loss：0.100259
【train】 epoch：0 step:2354/14065 loss：0.330495
【train】 epoch：0 step:2355/14065 loss：0.118094
【train】 epoch：0 step:2356/14065 loss：0.245779
【train】 epoch：0 step:2357/14065 loss：0.095762
【train】 epoch：0 step:2358/14065 loss：0.117759
【train】 epoch：0 step:2359/14065 loss：0.085943
【train】 epoch：0 step:2360/14065 loss：0.306923
【train】 epoch：0 step:2361/14065 loss：0.089497
【train】 epoch：0 step:2362/14065 loss：0.035459
【train】 epoch：0 step:2363/14065 loss：0.239982
【train】 epoch：0 step:2364/14065 loss：0.200147
【train】 epoch：0 step:2365/14065 loss：0.251645
【train】 epoch：0 step:2366/14065 loss：0.110652
【train】 epoch：0 step:2367/14065 loss：0.114546
【train】 epoch：0 step:2368/14065 loss：0.110420
【train】 epoch：0 step:2369/14065 loss：0.065756
【train】 epoch：0 step:2370/14065 loss：0.198531
【train】 epoch：0 step:2371/14065 loss：0.102487
【train】 epoch：0 step:2372/14065 loss：0.300153
【train】 epoch：0 step:2373/14065 loss：0.068676
【train】 epoch：0 step:2374/14065 loss：0.231802
【train】 epoch：0 step:2375/14065 loss：0.121679
【train】 epoch：0 step:2376/14065 loss：0.151939
【train】 epoch：0 step:2377/14065 loss：0.101197
【train】 epoch：0 step:2378/14065 loss：0.187312
【train】 epoch：0 step:2379/14065 loss：0.039111
【train】 epoch：0 step:2380/14065 loss：0.183339
【train】 epoch：0 step:2381/14065 loss：0.050309
【train】 epoch：0 step:2382/14065 loss：0.308093
【train】 epoch：0 step:2383/14065 loss：0.214790
【train】 epoch：0 step:2384/14065 loss：0.234316
【train】 epoch：0 step:2385/14065 loss：0.214154
【train】 epoch：0 step:2386/14065 loss：0.217781
【train】 epoch：0 step:2387/14065 loss：0.174546
【train】 epoch：0 step:2388/14065 loss：0.186578
【train】 epoch：0 step:2389/14065 loss：0.137577
【train】 epoch：0 step:2390/14065 loss：0.238056
【train】 epoch：0 step:2391/14065 loss：0.205255
【train】 epoch：0 step:2392/14065 loss：0.108190
【train】 epoch：0 step:2393/14065 loss：0.170919
【train】 epoch：0 step:2394/14065 loss：0.334684
【train】 epoch：0 step:2395/14065 loss：0.077308
【train】 epoch：0 step:2396/14065 loss：0.235114
【train】 epoch：0 step:2397/14065 loss：0.071857
【train】 epoch：0 step:2398/14065 loss：0.183152
【train】 epoch：0 step:2399/14065 loss：0.183125
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：415.975570 accuracy：0.9524 precision：0.9524 recall：0.9524 f1：0.9524
【train】 epoch：0 step:2400/14065 loss：0.258731
【train】 epoch：0 step:2401/14065 loss：0.305705
【train】 epoch：0 step:2402/14065 loss：0.304399
【train】 epoch：0 step:2403/14065 loss：0.286052
【train】 epoch：0 step:2404/14065 loss：0.343525
【train】 epoch：0 step:2405/14065 loss：0.133523
【train】 epoch：0 step:2406/14065 loss：0.085726
【train】 epoch：0 step:2407/14065 loss：0.091698
【train】 epoch：0 step:2408/14065 loss：0.202252
【train】 epoch：0 step:2409/14065 loss：0.214321
【train】 epoch：0 step:2410/14065 loss：0.207006
【train】 epoch：0 step:2411/14065 loss：0.272738
【train】 epoch：0 step:2412/14065 loss：0.100118
【train】 epoch：0 step:2413/14065 loss：0.139698
【train】 epoch：0 step:2414/14065 loss：0.090490
【train】 epoch：0 step:2415/14065 loss：0.295190
【train】 epoch：0 step:2416/14065 loss：0.177186
【train】 epoch：0 step:2417/14065 loss：0.296057
【train】 epoch：0 step:2418/14065 loss：0.199165
【train】 epoch：0 step:2419/14065 loss：0.179586
【train】 epoch：0 step:2420/14065 loss：0.259983
【train】 epoch：0 step:2421/14065 loss：0.360304
【train】 epoch：0 step:2422/14065 loss：0.139802
【train】 epoch：0 step:2423/14065 loss：0.124228
【train】 epoch：0 step:2424/14065 loss：0.157059
【train】 epoch：0 step:2425/14065 loss：0.421202
【train】 epoch：0 step:2426/14065 loss：0.285865
【train】 epoch：0 step:2427/14065 loss：0.138382
【train】 epoch：0 step:2428/14065 loss：0.248583
【train】 epoch：0 step:2429/14065 loss：0.092647
【train】 epoch：0 step:2430/14065 loss：0.063924
【train】 epoch：0 step:2431/14065 loss：0.210276
【train】 epoch：0 step:2432/14065 loss：0.075248
【train】 epoch：0 step:2433/14065 loss：0.104624
【train】 epoch：0 step:2434/14065 loss：0.207987
【train】 epoch：0 step:2435/14065 loss：0.208803
【train】 epoch：0 step:2436/14065 loss：0.177985
【train】 epoch：0 step:2437/14065 loss：0.322711
【train】 epoch：0 step:2438/14065 loss：0.236292
【train】 epoch：0 step:2439/14065 loss：0.126342
【train】 epoch：0 step:2440/14065 loss：0.137925
【train】 epoch：0 step:2441/14065 loss：0.103825
【train】 epoch：0 step:2442/14065 loss：0.045774
【train】 epoch：0 step:2443/14065 loss：0.208576
【train】 epoch：0 step:2444/14065 loss：0.142941
【train】 epoch：0 step:2445/14065 loss：0.092106
【train】 epoch：0 step:2446/14065 loss：0.081315
【train】 epoch：0 step:2447/14065 loss：0.072901
【train】 epoch：0 step:2448/14065 loss：0.080039
【train】 epoch：0 step:2449/14065 loss：0.275344
【train】 epoch：0 step:2450/14065 loss：0.122249
【train】 epoch：0 step:2451/14065 loss：0.196900
【train】 epoch：0 step:2452/14065 loss：0.149580
【train】 epoch：0 step:2453/14065 loss：0.151614
【train】 epoch：0 step:2454/14065 loss：0.216370
【train】 epoch：0 step:2455/14065 loss：0.113960
【train】 epoch：0 step:2456/14065 loss：0.298146
【train】 epoch：0 step:2457/14065 loss：0.148544
【train】 epoch：0 step:2458/14065 loss：0.189826
【train】 epoch：0 step:2459/14065 loss：0.335602
【train】 epoch：0 step:2460/14065 loss：0.208296
【train】 epoch：0 step:2461/14065 loss：0.061136
【train】 epoch：0 step:2462/14065 loss：0.027481
【train】 epoch：0 step:2463/14065 loss：0.152291
【train】 epoch：0 step:2464/14065 loss：0.172958
【train】 epoch：0 step:2465/14065 loss：0.079321
【train】 epoch：0 step:2466/14065 loss：0.092183
【train】 epoch：0 step:2467/14065 loss：0.341443
【train】 epoch：0 step:2468/14065 loss：0.194345
【train】 epoch：0 step:2469/14065 loss：0.108433
【train】 epoch：0 step:2470/14065 loss：0.417320
【train】 epoch：0 step:2471/14065 loss：0.344275
【train】 epoch：0 step:2472/14065 loss：0.088525
【train】 epoch：0 step:2473/14065 loss：0.253261
【train】 epoch：0 step:2474/14065 loss：0.167816
【train】 epoch：0 step:2475/14065 loss：0.218259
【train】 epoch：0 step:2476/14065 loss：0.250921
【train】 epoch：0 step:2477/14065 loss：0.231551
【train】 epoch：0 step:2478/14065 loss：0.196358
【train】 epoch：0 step:2479/14065 loss：0.059477
【train】 epoch：0 step:2480/14065 loss：0.265466
【train】 epoch：0 step:2481/14065 loss：0.148433
【train】 epoch：0 step:2482/14065 loss：0.173974
【train】 epoch：0 step:2483/14065 loss：0.198411
【train】 epoch：0 step:2484/14065 loss：0.105021
【train】 epoch：0 step:2485/14065 loss：0.355527
【train】 epoch：0 step:2486/14065 loss：0.100893
【train】 epoch：0 step:2487/14065 loss：0.141313
【train】 epoch：0 step:2488/14065 loss：0.088182
【train】 epoch：0 step:2489/14065 loss：0.202909
【train】 epoch：0 step:2490/14065 loss：0.190701
【train】 epoch：0 step:2491/14065 loss：0.292716
【train】 epoch：0 step:2492/14065 loss：0.304768
【train】 epoch：0 step:2493/14065 loss：0.131750
【train】 epoch：0 step:2494/14065 loss：0.183214
【train】 epoch：0 step:2495/14065 loss：0.299271
【train】 epoch：0 step:2496/14065 loss：0.204189
【train】 epoch：0 step:2497/14065 loss：0.137844
【train】 epoch：0 step:2498/14065 loss：0.172945
【train】 epoch：0 step:2499/14065 loss：0.202700
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：389.633923 accuracy：0.9553 precision：0.9553 recall：0.9553 f1：0.9553
【train】 epoch：0 step:2500/14065 loss：0.175830
【train】 epoch：0 step:2501/14065 loss：0.145551
【train】 epoch：0 step:2502/14065 loss：0.123149
【train】 epoch：0 step:2503/14065 loss：0.271043
【train】 epoch：0 step:2504/14065 loss：0.254709
【train】 epoch：0 step:2505/14065 loss：0.293187
【train】 epoch：0 step:2506/14065 loss：0.146545
【train】 epoch：0 step:2507/14065 loss：0.092696
【train】 epoch：0 step:2508/14065 loss：0.346252
【train】 epoch：0 step:2509/14065 loss：0.128996
【train】 epoch：0 step:2510/14065 loss：0.215836
【train】 epoch：0 step:2511/14065 loss：0.209574
【train】 epoch：0 step:2512/14065 loss：0.044271
【train】 epoch：0 step:2513/14065 loss：0.227301
【train】 epoch：0 step:2514/14065 loss：0.267662
【train】 epoch：0 step:2515/14065 loss：0.153944
【train】 epoch：0 step:2516/14065 loss：0.225323
【train】 epoch：0 step:2517/14065 loss：0.152712
【train】 epoch：0 step:2518/14065 loss：0.224691
【train】 epoch：0 step:2519/14065 loss：0.142349
【train】 epoch：0 step:2520/14065 loss：0.194299
【train】 epoch：0 step:2521/14065 loss：0.193162
【train】 epoch：0 step:2522/14065 loss：0.283663
【train】 epoch：0 step:2523/14065 loss：0.188155
【train】 epoch：0 step:2524/14065 loss：0.142044
【train】 epoch：0 step:2525/14065 loss：0.179107
【train】 epoch：0 step:2526/14065 loss：0.158445
【train】 epoch：0 step:2527/14065 loss：0.085412
【train】 epoch：0 step:2528/14065 loss：0.047961
【train】 epoch：0 step:2529/14065 loss：0.171694
【train】 epoch：0 step:2530/14065 loss：0.123530
【train】 epoch：0 step:2531/14065 loss：0.244692
【train】 epoch：0 step:2532/14065 loss：0.118957
【train】 epoch：0 step:2533/14065 loss：0.305707
【train】 epoch：0 step:2534/14065 loss：0.192127
【train】 epoch：0 step:2535/14065 loss：0.178125
【train】 epoch：0 step:2536/14065 loss：0.127772
【train】 epoch：0 step:2537/14065 loss：0.035861
【train】 epoch：0 step:2538/14065 loss：0.203007
【train】 epoch：0 step:2539/14065 loss：0.463231
【train】 epoch：0 step:2540/14065 loss：0.226749
【train】 epoch：0 step:2541/14065 loss：0.134447
【train】 epoch：0 step:2542/14065 loss：0.337481
【train】 epoch：0 step:2543/14065 loss：0.358076
【train】 epoch：0 step:2544/14065 loss：0.157735
【train】 epoch：0 step:2545/14065 loss：0.183070
【train】 epoch：0 step:2546/14065 loss：0.144282
【train】 epoch：0 step:2547/14065 loss：0.149694
【train】 epoch：0 step:2548/14065 loss：0.140035
【train】 epoch：0 step:2549/14065 loss：0.177955
【train】 epoch：0 step:2550/14065 loss：0.184990
【train】 epoch：0 step:2551/14065 loss：0.061356
【train】 epoch：0 step:2552/14065 loss：0.130843
【train】 epoch：0 step:2553/14065 loss：0.194843
【train】 epoch：0 step:2554/14065 loss：0.357932
【train】 epoch：0 step:2555/14065 loss：0.275894
【train】 epoch：0 step:2556/14065 loss：0.170895
【train】 epoch：0 step:2557/14065 loss：0.109816
【train】 epoch：0 step:2558/14065 loss：0.268675
【train】 epoch：0 step:2559/14065 loss：0.129104
【train】 epoch：0 step:2560/14065 loss：0.039047
【train】 epoch：0 step:2561/14065 loss：0.253649
【train】 epoch：0 step:2562/14065 loss：0.044108
【train】 epoch：0 step:2563/14065 loss：0.187594
【train】 epoch：0 step:2564/14065 loss：0.350932
【train】 epoch：0 step:2565/14065 loss：0.191318
【train】 epoch：0 step:2566/14065 loss：0.117094
【train】 epoch：0 step:2567/14065 loss：0.113364
【train】 epoch：0 step:2568/14065 loss：0.274637
【train】 epoch：0 step:2569/14065 loss：0.139885
【train】 epoch：0 step:2570/14065 loss：0.184140
【train】 epoch：0 step:2571/14065 loss：0.126784
【train】 epoch：0 step:2572/14065 loss：0.200823
【train】 epoch：0 step:2573/14065 loss：0.134123
【train】 epoch：0 step:2574/14065 loss：0.108893
【train】 epoch：0 step:2575/14065 loss：0.374686
【train】 epoch：0 step:2576/14065 loss：0.147919
【train】 epoch：0 step:2577/14065 loss：0.133594
【train】 epoch：0 step:2578/14065 loss：0.302472
【train】 epoch：0 step:2579/14065 loss：0.257663
【train】 epoch：0 step:2580/14065 loss：0.108688
【train】 epoch：0 step:2581/14065 loss：0.213785
【train】 epoch：0 step:2582/14065 loss：0.258387
【train】 epoch：0 step:2583/14065 loss：0.204196
【train】 epoch：0 step:2584/14065 loss：0.188214
【train】 epoch：0 step:2585/14065 loss：0.268582
【train】 epoch：0 step:2586/14065 loss：0.375479
【train】 epoch：0 step:2587/14065 loss：0.145013
【train】 epoch：0 step:2588/14065 loss：0.250925
【train】 epoch：0 step:2589/14065 loss：0.114133
【train】 epoch：0 step:2590/14065 loss：0.187151
【train】 epoch：0 step:2591/14065 loss：0.185955
【train】 epoch：0 step:2592/14065 loss：0.174361
【train】 epoch：0 step:2593/14065 loss：0.155100
【train】 epoch：0 step:2594/14065 loss：0.144989
【train】 epoch：0 step:2595/14065 loss：0.140897
【train】 epoch：0 step:2596/14065 loss：0.047886
【train】 epoch：0 step:2597/14065 loss：0.138340
【train】 epoch：0 step:2598/14065 loss：0.235057
【train】 epoch：0 step:2599/14065 loss：0.112963
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：356.476581 accuracy：0.9593 precision：0.9593 recall：0.9593 f1：0.9593
------------>保存当前最好的模型
【train】 epoch：0 step:2600/14065 loss：0.109004
【train】 epoch：0 step:2601/14065 loss：0.263451
【train】 epoch：0 step:2602/14065 loss：0.243182
【train】 epoch：0 step:2603/14065 loss：0.217428
【train】 epoch：0 step:2604/14065 loss：0.258972
【train】 epoch：0 step:2605/14065 loss：0.113478
【train】 epoch：0 step:2606/14065 loss：0.247733
【train】 epoch：0 step:2607/14065 loss：0.046152
【train】 epoch：0 step:2608/14065 loss：0.345822
【train】 epoch：0 step:2609/14065 loss：0.234256
【train】 epoch：0 step:2610/14065 loss：0.276109
【train】 epoch：0 step:2611/14065 loss：0.131633
【train】 epoch：0 step:2612/14065 loss：0.148977
【train】 epoch：0 step:2613/14065 loss：0.204232
【train】 epoch：0 step:2614/14065 loss：0.235297
【train】 epoch：0 step:2615/14065 loss：0.213999
【train】 epoch：0 step:2616/14065 loss：0.266637
【train】 epoch：0 step:2617/14065 loss：0.182696
【train】 epoch：0 step:2618/14065 loss：0.134657
【train】 epoch：0 step:2619/14065 loss：0.251862
【train】 epoch：0 step:2620/14065 loss：0.208918
【train】 epoch：0 step:2621/14065 loss：0.160449
【train】 epoch：0 step:2622/14065 loss：0.361604
【train】 epoch：0 step:2623/14065 loss：0.203955
【train】 epoch：0 step:2624/14065 loss：0.178617
【train】 epoch：0 step:2625/14065 loss：0.233273
【train】 epoch：0 step:2626/14065 loss：0.084057
【train】 epoch：0 step:2627/14065 loss：0.260930
【train】 epoch：0 step:2628/14065 loss：0.170062
【train】 epoch：0 step:2629/14065 loss：0.077833
【train】 epoch：0 step:2630/14065 loss：0.195379
【train】 epoch：0 step:2631/14065 loss：0.227894
【train】 epoch：0 step:2632/14065 loss：0.094125
【train】 epoch：0 step:2633/14065 loss：0.171829
【train】 epoch：0 step:2634/14065 loss：0.081607
【train】 epoch：0 step:2635/14065 loss：0.135455
【train】 epoch：0 step:2636/14065 loss：0.210784
【train】 epoch：0 step:2637/14065 loss：0.205034
【train】 epoch：0 step:2638/14065 loss：0.306121
【train】 epoch：0 step:2639/14065 loss：0.144279
【train】 epoch：0 step:2640/14065 loss：0.276279
【train】 epoch：0 step:2641/14065 loss：0.107467
【train】 epoch：0 step:2642/14065 loss：0.397864
【train】 epoch：0 step:2643/14065 loss：0.127076
【train】 epoch：0 step:2644/14065 loss：0.267171
【train】 epoch：0 step:2645/14065 loss：0.219630
【train】 epoch：0 step:2646/14065 loss：0.058632
【train】 epoch：0 step:2647/14065 loss：0.160661
【train】 epoch：0 step:2648/14065 loss：0.360204
【train】 epoch：0 step:2649/14065 loss：0.097227
【train】 epoch：0 step:2650/14065 loss：0.042092
【train】 epoch：0 step:2651/14065 loss：0.197495
【train】 epoch：0 step:2652/14065 loss：0.181766
【train】 epoch：0 step:2653/14065 loss：0.241982
【train】 epoch：0 step:2654/14065 loss：0.108131
【train】 epoch：0 step:2655/14065 loss：0.203328
【train】 epoch：0 step:2656/14065 loss：0.114083
【train】 epoch：0 step:2657/14065 loss：0.243729
【train】 epoch：0 step:2658/14065 loss：0.260462
【train】 epoch：0 step:2659/14065 loss：0.172531
【train】 epoch：0 step:2660/14065 loss：0.249375
【train】 epoch：0 step:2661/14065 loss：0.150451
【train】 epoch：0 step:2662/14065 loss：0.172286
【train】 epoch：0 step:2663/14065 loss：0.234955
【train】 epoch：0 step:2664/14065 loss：0.049692
【train】 epoch：0 step:2665/14065 loss：0.296120
【train】 epoch：0 step:2666/14065 loss：0.144597
【train】 epoch：0 step:2667/14065 loss：0.360801
【train】 epoch：0 step:2668/14065 loss：0.108283
【train】 epoch：0 step:2669/14065 loss：0.194468
【train】 epoch：0 step:2670/14065 loss：0.218021
【train】 epoch：0 step:2671/14065 loss：0.072004
【train】 epoch：0 step:2672/14065 loss：0.087492
【train】 epoch：0 step:2673/14065 loss：0.089366
【train】 epoch：0 step:2674/14065 loss：0.139196
【train】 epoch：0 step:2675/14065 loss：0.141583
【train】 epoch：0 step:2676/14065 loss：0.211706
【train】 epoch：0 step:2677/14065 loss：0.160289
【train】 epoch：0 step:2678/14065 loss：0.070603
【train】 epoch：0 step:2679/14065 loss：0.215105
【train】 epoch：0 step:2680/14065 loss：0.282166
【train】 epoch：0 step:2681/14065 loss：0.034104
【train】 epoch：0 step:2682/14065 loss：0.190925
【train】 epoch：0 step:2683/14065 loss：0.254384
【train】 epoch：0 step:2684/14065 loss：0.092308
【train】 epoch：0 step:2685/14065 loss：0.094969
【train】 epoch：0 step:2686/14065 loss：0.079768
【train】 epoch：0 step:2687/14065 loss：0.238681
【train】 epoch：0 step:2688/14065 loss：0.079459
【train】 epoch：0 step:2689/14065 loss：0.077620
【train】 epoch：0 step:2690/14065 loss：0.272406
【train】 epoch：0 step:2691/14065 loss：0.152810
【train】 epoch：0 step:2692/14065 loss：0.257489
【train】 epoch：0 step:2693/14065 loss：0.266572
【train】 epoch：0 step:2694/14065 loss：0.118833
【train】 epoch：0 step:2695/14065 loss：0.129713
【train】 epoch：0 step:2696/14065 loss：0.168260
【train】 epoch：0 step:2697/14065 loss：0.216838
【train】 epoch：0 step:2698/14065 loss：0.311396
【train】 epoch：0 step:2699/14065 loss：0.088809
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：350.524503 accuracy：0.9597 precision：0.9597 recall：0.9597 f1：0.9597
------------>保存当前最好的模型
【train】 epoch：0 step:2700/14065 loss：0.249642
【train】 epoch：0 step:2701/14065 loss：0.220522
【train】 epoch：0 step:2702/14065 loss：0.240548
【train】 epoch：0 step:2703/14065 loss：0.104846
【train】 epoch：0 step:2704/14065 loss：0.230728
【train】 epoch：0 step:2705/14065 loss：0.321125
【train】 epoch：0 step:2706/14065 loss：0.200537
【train】 epoch：0 step:2707/14065 loss：0.067310
【train】 epoch：0 step:2708/14065 loss：0.152776
【train】 epoch：0 step:2709/14065 loss：0.187250
【train】 epoch：0 step:2710/14065 loss：0.188275
【train】 epoch：0 step:2711/14065 loss：0.402161
【train】 epoch：0 step:2712/14065 loss：0.145829
【train】 epoch：0 step:2713/14065 loss：0.138688
【train】 epoch：0 step:2714/14065 loss：0.177063
【train】 epoch：0 step:2715/14065 loss：0.200174
【train】 epoch：0 step:2716/14065 loss：0.085822
【train】 epoch：0 step:2717/14065 loss：0.277266
【train】 epoch：0 step:2718/14065 loss：0.140361
【train】 epoch：0 step:2719/14065 loss：0.150200
【train】 epoch：0 step:2720/14065 loss：0.217146
【train】 epoch：0 step:2721/14065 loss：0.155394
【train】 epoch：0 step:2722/14065 loss：0.149901
【train】 epoch：0 step:2723/14065 loss：0.134723
【train】 epoch：0 step:2724/14065 loss：0.162551
【train】 epoch：0 step:2725/14065 loss：0.276479
【train】 epoch：0 step:2726/14065 loss：0.253695
【train】 epoch：0 step:2727/14065 loss：0.213749
【train】 epoch：0 step:2728/14065 loss：0.193461
【train】 epoch：0 step:2729/14065 loss：0.407587
【train】 epoch：0 step:2730/14065 loss：0.194034
【train】 epoch：0 step:2731/14065 loss：0.079462
【train】 epoch：0 step:2732/14065 loss：0.354445
【train】 epoch：0 step:2733/14065 loss：0.241327
【train】 epoch：0 step:2734/14065 loss：0.138803
【train】 epoch：0 step:2735/14065 loss：0.071284
【train】 epoch：0 step:2736/14065 loss：0.285308
【train】 epoch：0 step:2737/14065 loss：0.045226
【train】 epoch：0 step:2738/14065 loss：0.337636
【train】 epoch：0 step:2739/14065 loss：0.043306
【train】 epoch：0 step:2740/14065 loss：0.242126
【train】 epoch：0 step:2741/14065 loss：0.095675
【train】 epoch：0 step:2742/14065 loss：0.255339
【train】 epoch：0 step:2743/14065 loss：0.334296
【train】 epoch：0 step:2744/14065 loss：0.181422
【train】 epoch：0 step:2745/14065 loss：0.140366
【train】 epoch：0 step:2746/14065 loss：0.365864
【train】 epoch：0 step:2747/14065 loss：0.171852
【train】 epoch：0 step:2748/14065 loss：0.162767
【train】 epoch：0 step:2749/14065 loss：0.107500
【train】 epoch：0 step:2750/14065 loss：0.143511
【train】 epoch：0 step:2751/14065 loss：0.228861
【train】 epoch：0 step:2752/14065 loss：0.268369
【train】 epoch：0 step:2753/14065 loss：0.211313
【train】 epoch：0 step:2754/14065 loss：0.267921
【train】 epoch：0 step:2755/14065 loss：0.162007
【train】 epoch：0 step:2756/14065 loss：0.390596
【train】 epoch：0 step:2757/14065 loss：0.131667
【train】 epoch：0 step:2758/14065 loss：0.368353
【train】 epoch：0 step:2759/14065 loss：0.198802
【train】 epoch：0 step:2760/14065 loss：0.164697
【train】 epoch：0 step:2761/14065 loss：0.082046
【train】 epoch：0 step:2762/14065 loss：0.111270
【train】 epoch：0 step:2763/14065 loss：0.038603
【train】 epoch：0 step:2764/14065 loss：0.300522
【train】 epoch：0 step:2765/14065 loss：0.488589
【train】 epoch：0 step:2766/14065 loss：0.267882
【train】 epoch：0 step:2767/14065 loss：0.322570
【train】 epoch：0 step:2768/14065 loss：0.062680
【train】 epoch：0 step:2769/14065 loss：0.217262
【train】 epoch：0 step:2770/14065 loss：0.289898
【train】 epoch：0 step:2771/14065 loss：0.259754
【train】 epoch：0 step:2772/14065 loss：0.289121
【train】 epoch：0 step:2773/14065 loss：0.218548
【train】 epoch：0 step:2774/14065 loss：0.269074
【train】 epoch：0 step:2775/14065 loss：0.051137
【train】 epoch：0 step:2776/14065 loss：0.268945
【train】 epoch：0 step:2777/14065 loss：0.326700
【train】 epoch：0 step:2778/14065 loss：0.234470
【train】 epoch：0 step:2779/14065 loss：0.086750
【train】 epoch：0 step:2780/14065 loss：0.136212
【train】 epoch：0 step:2781/14065 loss：0.083984
【train】 epoch：0 step:2782/14065 loss：0.196041
【train】 epoch：0 step:2783/14065 loss：0.089916
【train】 epoch：0 step:2784/14065 loss：0.111251
【train】 epoch：0 step:2785/14065 loss：0.244409
【train】 epoch：0 step:2786/14065 loss：0.346003
【train】 epoch：0 step:2787/14065 loss：0.211198
【train】 epoch：0 step:2788/14065 loss：0.299644
【train】 epoch：0 step:2789/14065 loss：0.339469
【train】 epoch：0 step:2790/14065 loss：0.226822
【train】 epoch：0 step:2791/14065 loss：0.120922
【train】 epoch：0 step:2792/14065 loss：0.263691
【train】 epoch：0 step:2793/14065 loss：0.131902
【train】 epoch：0 step:2794/14065 loss：0.177269
【train】 epoch：0 step:2795/14065 loss：0.177039
【train】 epoch：0 step:2796/14065 loss：0.252815
【train】 epoch：0 step:2797/14065 loss：0.207123
【train】 epoch：0 step:2798/14065 loss：0.212149
【train】 epoch：0 step:2799/14065 loss：0.106629
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：354.299890 accuracy：0.9606 precision：0.9606 recall：0.9606 f1：0.9606
------------>保存当前最好的模型
【train】 epoch：0 step:2800/14065 loss：0.191863
【train】 epoch：0 step:2801/14065 loss：0.366869
【train】 epoch：0 step:2802/14065 loss：0.114578
【train】 epoch：0 step:2803/14065 loss：0.253628
【train】 epoch：0 step:2804/14065 loss：0.274080
【train】 epoch：0 step:2805/14065 loss：0.183568
【train】 epoch：0 step:2806/14065 loss：0.282954
【train】 epoch：0 step:2807/14065 loss：0.173706
【train】 epoch：0 step:2808/14065 loss：0.048182
【train】 epoch：0 step:2809/14065 loss：0.146518
【train】 epoch：0 step:2810/14065 loss：0.176932
【train】 epoch：0 step:2811/14065 loss：0.149051
【train】 epoch：0 step:2812/14065 loss：0.272761
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【train】 epoch：1 step:2813/14065 loss：0.175802
【train】 epoch：1 step:2814/14065 loss：0.074143
【train】 epoch：1 step:2815/14065 loss：0.193504
【train】 epoch：1 step:2816/14065 loss：0.255125
【train】 epoch：1 step:2817/14065 loss：0.170748
【train】 epoch：1 step:2818/14065 loss：0.140687
【train】 epoch：1 step:2819/14065 loss：0.110762
【train】 epoch：1 step:2820/14065 loss：0.136831
【train】 epoch：1 step:2821/14065 loss：0.099706
【train】 epoch：1 step:2822/14065 loss：0.164371
【train】 epoch：1 step:2823/14065 loss：0.266030
【train】 epoch：1 step:2824/14065 loss：0.125152
【train】 epoch：1 step:2825/14065 loss：0.072003
【train】 epoch：1 step:2826/14065 loss：0.189711
【train】 epoch：1 step:2827/14065 loss：0.049886
【train】 epoch：1 step:2828/14065 loss：0.115503
【train】 epoch：1 step:2829/14065 loss：0.219615
【train】 epoch：1 step:2830/14065 loss：0.105708
【train】 epoch：1 step:2831/14065 loss：0.241238
【train】 epoch：1 step:2832/14065 loss：0.158425
【train】 epoch：1 step:2833/14065 loss：0.184570
【train】 epoch：1 step:2834/14065 loss：0.095422
【train】 epoch：1 step:2835/14065 loss：0.207521
【train】 epoch：1 step:2836/14065 loss：0.193718
【train】 epoch：1 step:2837/14065 loss：0.152355
【train】 epoch：1 step:2838/14065 loss：0.104702
【train】 epoch：1 step:2839/14065 loss：0.164954
【train】 epoch：1 step:2840/14065 loss：0.098838
【train】 epoch：1 step:2841/14065 loss：0.070537
【train】 epoch：1 step:2842/14065 loss：0.054619
【train】 epoch：1 step:2843/14065 loss：0.053959
【train】 epoch：1 step:2844/14065 loss：0.117106
【train】 epoch：1 step:2845/14065 loss：0.083444
【train】 epoch：1 step:2846/14065 loss：0.138456
【train】 epoch：1 step:2847/14065 loss：0.090514
【train】 epoch：1 step:2848/14065 loss：0.066472
【train】 epoch：1 step:2849/14065 loss：0.195608
【train】 epoch：1 step:2850/14065 loss：0.050893
【train】 epoch：1 step:2851/14065 loss：0.199232
【train】 epoch：1 step:2852/14065 loss：0.184143
【train】 epoch：1 step:2853/14065 loss：0.072960
【train】 epoch：1 step:2854/14065 loss：0.170317
【train】 epoch：1 step:2855/14065 loss：0.060426
【train】 epoch：1 step:2856/14065 loss：0.121824
【train】 epoch：1 step:2857/14065 loss：0.105052
【train】 epoch：1 step:2858/14065 loss：0.185184
【train】 epoch：1 step:2859/14065 loss：0.172436
【train】 epoch：1 step:2860/14065 loss：0.084069
【train】 epoch：1 step:2861/14065 loss：0.037048
【train】 epoch：1 step:2862/14065 loss：0.101041
【train】 epoch：1 step:2863/14065 loss：0.163497
【train】 epoch：1 step:2864/14065 loss：0.127566
【train】 epoch：1 step:2865/14065 loss：0.111278
【train】 epoch：1 step:2866/14065 loss：0.235845
【train】 epoch：1 step:2867/14065 loss：0.103711
【train】 epoch：1 step:2868/14065 loss：0.082370
【train】 epoch：1 step:2869/14065 loss：0.097094
【train】 epoch：1 step:2870/14065 loss：0.233351
【train】 epoch：1 step:2871/14065 loss：0.182017
【train】 epoch：1 step:2872/14065 loss：0.129811
【train】 epoch：1 step:2873/14065 loss：0.192152
【train】 epoch：1 step:2874/14065 loss：0.146192
【train】 epoch：1 step:2875/14065 loss：0.111877
【train】 epoch：1 step:2876/14065 loss：0.092293
【train】 epoch：1 step:2877/14065 loss：0.177331
【train】 epoch：1 step:2878/14065 loss：0.173796
【train】 epoch：1 step:2879/14065 loss：0.056823
【train】 epoch：1 step:2880/14065 loss：0.152664
【train】 epoch：1 step:2881/14065 loss：0.102515
【train】 epoch：1 step:2882/14065 loss：0.096515
【train】 epoch：1 step:2883/14065 loss：0.067862
【train】 epoch：1 step:2884/14065 loss：0.180221
【train】 epoch：1 step:2885/14065 loss：0.153020
【train】 epoch：1 step:2886/14065 loss：0.305337
【train】 epoch：1 step:2887/14065 loss：0.124140
【train】 epoch：1 step:2888/14065 loss：0.139482
【train】 epoch：1 step:2889/14065 loss：0.203596
【train】 epoch：1 step:2890/14065 loss：0.107883
【train】 epoch：1 step:2891/14065 loss：0.180247
【train】 epoch：1 step:2892/14065 loss：0.152217
【train】 epoch：1 step:2893/14065 loss：0.118227
【train】 epoch：1 step:2894/14065 loss：0.033486
【train】 epoch：1 step:2895/14065 loss：0.145099
【train】 epoch：1 step:2896/14065 loss：0.183988
【train】 epoch：1 step:2897/14065 loss：0.216078
【train】 epoch：1 step:2898/14065 loss：0.148308
【train】 epoch：1 step:2899/14065 loss：0.133035
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：329.714937 accuracy：0.9619 precision：0.9619 recall：0.9619 f1：0.9619
------------>保存当前最好的模型
【train】 epoch：1 step:2900/14065 loss：0.279413
【train】 epoch：1 step:2901/14065 loss：0.097490
【train】 epoch：1 step:2902/14065 loss：0.063194
【train】 epoch：1 step:2903/14065 loss：0.067525
【train】 epoch：1 step:2904/14065 loss：0.244657
【train】 epoch：1 step:2905/14065 loss：0.114096
【train】 epoch：1 step:2906/14065 loss：0.106303
【train】 epoch：1 step:2907/14065 loss：0.037956
【train】 epoch：1 step:2908/14065 loss：0.070088
【train】 epoch：1 step:2909/14065 loss：0.100189
【train】 epoch：1 step:2910/14065 loss：0.130341
【train】 epoch：1 step:2911/14065 loss：0.245099
【train】 epoch：1 step:2912/14065 loss：0.088210
【train】 epoch：1 step:2913/14065 loss：0.137244
【train】 epoch：1 step:2914/14065 loss：0.176412
【train】 epoch：1 step:2915/14065 loss：0.035001
【train】 epoch：1 step:2916/14065 loss：0.104708
【train】 epoch：1 step:2917/14065 loss：0.134363
【train】 epoch：1 step:2918/14065 loss：0.186305
【train】 epoch：1 step:2919/14065 loss：0.184257
【train】 epoch：1 step:2920/14065 loss：0.240580
【train】 epoch：1 step:2921/14065 loss：0.128408
【train】 epoch：1 step:2922/14065 loss：0.053320
【train】 epoch：1 step:2923/14065 loss：0.080421
【train】 epoch：1 step:2924/14065 loss：0.071938
【train】 epoch：1 step:2925/14065 loss：0.082961
【train】 epoch：1 step:2926/14065 loss：0.097155
【train】 epoch：1 step:2927/14065 loss：0.107522
【train】 epoch：1 step:2928/14065 loss：0.058351
【train】 epoch：1 step:2929/14065 loss：0.175307
【train】 epoch：1 step:2930/14065 loss：0.081095
【train】 epoch：1 step:2931/14065 loss：0.126263
【train】 epoch：1 step:2932/14065 loss：0.081812
【train】 epoch：1 step:2933/14065 loss：0.111077
【train】 epoch：1 step:2934/14065 loss：0.076353
【train】 epoch：1 step:2935/14065 loss：0.035093
【train】 epoch：1 step:2936/14065 loss：0.099717
【train】 epoch：1 step:2937/14065 loss：0.082427
【train】 epoch：1 step:2938/14065 loss：0.187260
【train】 epoch：1 step:2939/14065 loss：0.262740
【train】 epoch：1 step:2940/14065 loss：0.169632
【train】 epoch：1 step:2941/14065 loss：0.047012
【train】 epoch：1 step:2942/14065 loss：0.147121
【train】 epoch：1 step:2943/14065 loss：0.129632
【train】 epoch：1 step:2944/14065 loss：0.074166
【train】 epoch：1 step:2945/14065 loss：0.105087
【train】 epoch：1 step:2946/14065 loss：0.160698
【train】 epoch：1 step:2947/14065 loss：0.053200
【train】 epoch：1 step:2948/14065 loss：0.084470
【train】 epoch：1 step:2949/14065 loss：0.074510
【train】 epoch：1 step:2950/14065 loss：0.384442
【train】 epoch：1 step:2951/14065 loss：0.090434
【train】 epoch：1 step:2952/14065 loss：0.124841
【train】 epoch：1 step:2953/14065 loss：0.273785
【train】 epoch：1 step:2954/14065 loss：0.059813
【train】 epoch：1 step:2955/14065 loss：0.069067
【train】 epoch：1 step:2956/14065 loss：0.046152
【train】 epoch：1 step:2957/14065 loss：0.112665
【train】 epoch：1 step:2958/14065 loss：0.104978
【train】 epoch：1 step:2959/14065 loss：0.096139
【train】 epoch：1 step:2960/14065 loss：0.096319
【train】 epoch：1 step:2961/14065 loss：0.057145
【train】 epoch：1 step:2962/14065 loss：0.130119
【train】 epoch：1 step:2963/14065 loss：0.169117
【train】 epoch：1 step:2964/14065 loss：0.028541
【train】 epoch：1 step:2965/14065 loss：0.046381
【train】 epoch：1 step:2966/14065 loss：0.267084
【train】 epoch：1 step:2967/14065 loss：0.043210
【train】 epoch：1 step:2968/14065 loss：0.026980
【train】 epoch：1 step:2969/14065 loss：0.084004
【train】 epoch：1 step:2970/14065 loss：0.208264
【train】 epoch：1 step:2971/14065 loss：0.091915
【train】 epoch：1 step:2972/14065 loss：0.207676
【train】 epoch：1 step:2973/14065 loss：0.093395
【train】 epoch：1 step:2974/14065 loss：0.165819
【train】 epoch：1 step:2975/14065 loss：0.089820
【train】 epoch：1 step:2976/14065 loss：0.037215
【train】 epoch：1 step:2977/14065 loss：0.064716
【train】 epoch：1 step:2978/14065 loss：0.064749
【train】 epoch：1 step:2979/14065 loss：0.078911
【train】 epoch：1 step:2980/14065 loss：0.150317
【train】 epoch：1 step:2981/14065 loss：0.253572
【train】 epoch：1 step:2982/14065 loss：0.058305
【train】 epoch：1 step:2983/14065 loss：0.106505
【train】 epoch：1 step:2984/14065 loss：0.025065
【train】 epoch：1 step:2985/14065 loss：0.080082
【train】 epoch：1 step:2986/14065 loss：0.177806
【train】 epoch：1 step:2987/14065 loss：0.080693
【train】 epoch：1 step:2988/14065 loss：0.108696
【train】 epoch：1 step:2989/14065 loss：0.300040
【train】 epoch：1 step:2990/14065 loss：0.183856
【train】 epoch：1 step:2991/14065 loss：0.112413
【train】 epoch：1 step:2992/14065 loss：0.092288
【train】 epoch：1 step:2993/14065 loss：0.106777
【train】 epoch：1 step:2994/14065 loss：0.087198
【train】 epoch：1 step:2995/14065 loss：0.126954
【train】 epoch：1 step:2996/14065 loss：0.016194
【train】 epoch：1 step:2997/14065 loss：0.130060
【train】 epoch：1 step:2998/14065 loss：0.195369
【train】 epoch：1 step:2999/14065 loss：0.056016
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：310.754900 accuracy：0.9642 precision：0.9642 recall：0.9642 f1：0.9642
------------>保存当前最好的模型
【train】 epoch：1 step:3000/14065 loss：0.149867
【train】 epoch：1 step:3001/14065 loss：0.368474
【train】 epoch：1 step:3002/14065 loss：0.027701
【train】 epoch：1 step:3003/14065 loss：0.039422
【train】 epoch：1 step:3004/14065 loss：0.140129
【train】 epoch：1 step:3005/14065 loss：0.081173
【train】 epoch：1 step:3006/14065 loss：0.224621
【train】 epoch：1 step:3007/14065 loss：0.044043
【train】 epoch：1 step:3008/14065 loss：0.141116
【train】 epoch：1 step:3009/14065 loss：0.254695
【train】 epoch：1 step:3010/14065 loss：0.061061
【train】 epoch：1 step:3011/14065 loss：0.039762
【train】 epoch：1 step:3012/14065 loss：0.193802
【train】 epoch：1 step:3013/14065 loss：0.107019
【train】 epoch：1 step:3014/14065 loss：0.168864
【train】 epoch：1 step:3015/14065 loss：0.129193
【train】 epoch：1 step:3016/14065 loss：0.196106
【train】 epoch：1 step:3017/14065 loss：0.154413
【train】 epoch：1 step:3018/14065 loss：0.150807
【train】 epoch：1 step:3019/14065 loss：0.081884
【train】 epoch：1 step:3020/14065 loss：0.109817
【train】 epoch：1 step:3021/14065 loss：0.207246
【train】 epoch：1 step:3022/14065 loss：0.132486
【train】 epoch：1 step:3023/14065 loss：0.170856
【train】 epoch：1 step:3024/14065 loss：0.129022
【train】 epoch：1 step:3025/14065 loss：0.029412
【train】 epoch：1 step:3026/14065 loss：0.036410
【train】 epoch：1 step:3027/14065 loss：0.140370
【train】 epoch：1 step:3028/14065 loss：0.186896
【train】 epoch：1 step:3029/14065 loss：0.123607
【train】 epoch：1 step:3030/14065 loss：0.116066
【train】 epoch：1 step:3031/14065 loss：0.157190
【train】 epoch：1 step:3032/14065 loss：0.132980
【train】 epoch：1 step:3033/14065 loss：0.139104
【train】 epoch：1 step:3034/14065 loss：0.087804
【train】 epoch：1 step:3035/14065 loss：0.177301
【train】 epoch：1 step:3036/14065 loss：0.081281
【train】 epoch：1 step:3037/14065 loss：0.077337
【train】 epoch：1 step:3038/14065 loss：0.247959
【train】 epoch：1 step:3039/14065 loss：0.051428
【train】 epoch：1 step:3040/14065 loss：0.030080
【train】 epoch：1 step:3041/14065 loss：0.211103
【train】 epoch：1 step:3042/14065 loss：0.216018
【train】 epoch：1 step:3043/14065 loss：0.085008
【train】 epoch：1 step:3044/14065 loss：0.138885
【train】 epoch：1 step:3045/14065 loss：0.029164
【train】 epoch：1 step:3046/14065 loss：0.120401
【train】 epoch：1 step:3047/14065 loss：0.110079
【train】 epoch：1 step:3048/14065 loss：0.345925
【train】 epoch：1 step:3049/14065 loss：0.082881
【train】 epoch：1 step:3050/14065 loss：0.175532
【train】 epoch：1 step:3051/14065 loss：0.082321
【train】 epoch：1 step:3052/14065 loss：0.094032
【train】 epoch：1 step:3053/14065 loss：0.219302
【train】 epoch：1 step:3054/14065 loss：0.105766
【train】 epoch：1 step:3055/14065 loss：0.155860
【train】 epoch：1 step:3056/14065 loss：0.170300
【train】 epoch：1 step:3057/14065 loss：0.159253
【train】 epoch：1 step:3058/14065 loss：0.157620
【train】 epoch：1 step:3059/14065 loss：0.120716
【train】 epoch：1 step:3060/14065 loss：0.187931
【train】 epoch：1 step:3061/14065 loss：0.117954
【train】 epoch：1 step:3062/14065 loss：0.241459
【train】 epoch：1 step:3063/14065 loss：0.177988
【train】 epoch：1 step:3064/14065 loss：0.088592
【train】 epoch：1 step:3065/14065 loss：0.264656
【train】 epoch：1 step:3066/14065 loss：0.128323
【train】 epoch：1 step:3067/14065 loss：0.013511
【train】 epoch：1 step:3068/14065 loss：0.174034
【train】 epoch：1 step:3069/14065 loss：0.183475
【train】 epoch：1 step:3070/14065 loss：0.178507
【train】 epoch：1 step:3071/14065 loss：0.159312
【train】 epoch：1 step:3072/14065 loss：0.123881
【train】 epoch：1 step:3073/14065 loss：0.104548
【train】 epoch：1 step:3074/14065 loss：0.218956
【train】 epoch：1 step:3075/14065 loss：0.145142
【train】 epoch：1 step:3076/14065 loss：0.045872
【train】 epoch：1 step:3077/14065 loss：0.044038
【train】 epoch：1 step:3078/14065 loss：0.161586
【train】 epoch：1 step:3079/14065 loss：0.073173
【train】 epoch：1 step:3080/14065 loss：0.119674
【train】 epoch：1 step:3081/14065 loss：0.108720
【train】 epoch：1 step:3082/14065 loss：0.190386
【train】 epoch：1 step:3083/14065 loss：0.118289
【train】 epoch：1 step:3084/14065 loss：0.223793
【train】 epoch：1 step:3085/14065 loss：0.066148
【train】 epoch：1 step:3086/14065 loss：0.146335
【train】 epoch：1 step:3087/14065 loss：0.092391
【train】 epoch：1 step:3088/14065 loss：0.126143
【train】 epoch：1 step:3089/14065 loss：0.099705
【train】 epoch：1 step:3090/14065 loss：0.050544
【train】 epoch：1 step:3091/14065 loss：0.242274
【train】 epoch：1 step:3092/14065 loss：0.102828
【train】 epoch：1 step:3093/14065 loss：0.217971
【train】 epoch：1 step:3094/14065 loss：0.043503
【train】 epoch：1 step:3095/14065 loss：0.113260
【train】 epoch：1 step:3096/14065 loss：0.217144
【train】 epoch：1 step:3097/14065 loss：0.166557
【train】 epoch：1 step:3098/14065 loss：0.159312
【train】 epoch：1 step:3099/14065 loss：0.186949
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：315.472164 accuracy：0.9635 precision：0.9635 recall：0.9635 f1：0.9635
【train】 epoch：1 step:3100/14065 loss：0.146454
【train】 epoch：1 step:3101/14065 loss：0.148622
【train】 epoch：1 step:3102/14065 loss：0.106536
【train】 epoch：1 step:3103/14065 loss：0.126205
【train】 epoch：1 step:3104/14065 loss：0.188313
【train】 epoch：1 step:3105/14065 loss：0.106187
【train】 epoch：1 step:3106/14065 loss：0.084355
【train】 epoch：1 step:3107/14065 loss：0.092697
【train】 epoch：1 step:3108/14065 loss：0.106582
【train】 epoch：1 step:3109/14065 loss：0.044409
【train】 epoch：1 step:3110/14065 loss：0.108827
【train】 epoch：1 step:3111/14065 loss：0.087183
【train】 epoch：1 step:3112/14065 loss：0.105788
【train】 epoch：1 step:3113/14065 loss：0.066247
【train】 epoch：1 step:3114/14065 loss：0.248334
【train】 epoch：1 step:3115/14065 loss：0.113962
【train】 epoch：1 step:3116/14065 loss：0.121002
【train】 epoch：1 step:3117/14065 loss：0.062363
【train】 epoch：1 step:3118/14065 loss：0.074367
【train】 epoch：1 step:3119/14065 loss：0.102487
【train】 epoch：1 step:3120/14065 loss：0.015289
【train】 epoch：1 step:3121/14065 loss：0.154354
【train】 epoch：1 step:3122/14065 loss：0.184306
【train】 epoch：1 step:3123/14065 loss：0.070551
【train】 epoch：1 step:3124/14065 loss：0.132623
【train】 epoch：1 step:3125/14065 loss：0.085635
【train】 epoch：1 step:3126/14065 loss：0.064319
【train】 epoch：1 step:3127/14065 loss：0.216367
【train】 epoch：1 step:3128/14065 loss：0.190800
【train】 epoch：1 step:3129/14065 loss：0.109109
【train】 epoch：1 step:3130/14065 loss：0.150700
【train】 epoch：1 step:3131/14065 loss：0.086373
【train】 epoch：1 step:3132/14065 loss：0.181834
【train】 epoch：1 step:3133/14065 loss：0.135623
【train】 epoch：1 step:3134/14065 loss：0.206334
【train】 epoch：1 step:3135/14065 loss：0.018934
【train】 epoch：1 step:3136/14065 loss：0.086339
【train】 epoch：1 step:3137/14065 loss：0.059628
【train】 epoch：1 step:3138/14065 loss：0.155068
【train】 epoch：1 step:3139/14065 loss：0.023711
【train】 epoch：1 step:3140/14065 loss：0.063447
【train】 epoch：1 step:3141/14065 loss：0.093189
【train】 epoch：1 step:3142/14065 loss：0.157484
【train】 epoch：1 step:3143/14065 loss：0.099209
【train】 epoch：1 step:3144/14065 loss：0.146655
【train】 epoch：1 step:3145/14065 loss：0.139693
【train】 epoch：1 step:3146/14065 loss：0.099583
【train】 epoch：1 step:3147/14065 loss：0.120454
【train】 epoch：1 step:3148/14065 loss：0.122739
【train】 epoch：1 step:3149/14065 loss：0.097500
【train】 epoch：1 step:3150/14065 loss：0.072596
【train】 epoch：1 step:3151/14065 loss：0.075434
【train】 epoch：1 step:3152/14065 loss：0.239052
【train】 epoch：1 step:3153/14065 loss：0.055153
【train】 epoch：1 step:3154/14065 loss：0.139405
【train】 epoch：1 step:3155/14065 loss：0.157190
【train】 epoch：1 step:3156/14065 loss：0.071124
【train】 epoch：1 step:3157/14065 loss：0.213978
【train】 epoch：1 step:3158/14065 loss：0.098424
【train】 epoch：1 step:3159/14065 loss：0.109476
【train】 epoch：1 step:3160/14065 loss：0.110604
【train】 epoch：1 step:3161/14065 loss：0.141034
【train】 epoch：1 step:3162/14065 loss：0.118668
【train】 epoch：1 step:3163/14065 loss：0.053605
【train】 epoch：1 step:3164/14065 loss：0.086169
【train】 epoch：1 step:3165/14065 loss：0.153103
【train】 epoch：1 step:3166/14065 loss：0.185098
【train】 epoch：1 step:3167/14065 loss：0.064632
【train】 epoch：1 step:3168/14065 loss：0.112849
【train】 epoch：1 step:3169/14065 loss：0.163735
【train】 epoch：1 step:3170/14065 loss：0.220088
【train】 epoch：1 step:3171/14065 loss：0.116720
【train】 epoch：1 step:3172/14065 loss：0.119729
【train】 epoch：1 step:3173/14065 loss：0.080644
【train】 epoch：1 step:3174/14065 loss：0.067732
【train】 epoch：1 step:3175/14065 loss：0.188028
【train】 epoch：1 step:3176/14065 loss：0.360242
【train】 epoch：1 step:3177/14065 loss：0.172027
【train】 epoch：1 step:3178/14065 loss：0.052061
【train】 epoch：1 step:3179/14065 loss：0.120438
【train】 epoch：1 step:3180/14065 loss：0.186121
【train】 epoch：1 step:3181/14065 loss：0.188810
【train】 epoch：1 step:3182/14065 loss：0.151201
【train】 epoch：1 step:3183/14065 loss：0.132249
【train】 epoch：1 step:3184/14065 loss：0.053109
【train】 epoch：1 step:3185/14065 loss：0.436662
【train】 epoch：1 step:3186/14065 loss：0.100020
【train】 epoch：1 step:3187/14065 loss：0.153436
【train】 epoch：1 step:3188/14065 loss：0.100622
【train】 epoch：1 step:3189/14065 loss：0.173229
【train】 epoch：1 step:3190/14065 loss：0.159262
【train】 epoch：1 step:3191/14065 loss：0.179913
【train】 epoch：1 step:3192/14065 loss：0.133503
【train】 epoch：1 step:3193/14065 loss：0.042397
【train】 epoch：1 step:3194/14065 loss：0.046995
【train】 epoch：1 step:3195/14065 loss：0.277274
【train】 epoch：1 step:3196/14065 loss：0.011452
【train】 epoch：1 step:3197/14065 loss：0.265672
【train】 epoch：1 step:3198/14065 loss：0.085605
【train】 epoch：1 step:3199/14065 loss：0.058667
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：319.589918 accuracy：0.9633 precision：0.9633 recall：0.9633 f1：0.9633
【train】 epoch：1 step:3200/14065 loss：0.083788
【train】 epoch：1 step:3201/14065 loss：0.147649
【train】 epoch：1 step:3202/14065 loss：0.092515
【train】 epoch：1 step:3203/14065 loss：0.072658
【train】 epoch：1 step:3204/14065 loss：0.084881
【train】 epoch：1 step:3205/14065 loss：0.144707
【train】 epoch：1 step:3206/14065 loss：0.075367
【train】 epoch：1 step:3207/14065 loss：0.079735
【train】 epoch：1 step:3208/14065 loss：0.041081
【train】 epoch：1 step:3209/14065 loss：0.031620
【train】 epoch：1 step:3210/14065 loss：0.072251
【train】 epoch：1 step:3211/14065 loss：0.072537
【train】 epoch：1 step:3212/14065 loss：0.078677
【train】 epoch：1 step:3213/14065 loss：0.255009
【train】 epoch：1 step:3214/14065 loss：0.150774
【train】 epoch：1 step:3215/14065 loss：0.082838
【train】 epoch：1 step:3216/14065 loss：0.146462
【train】 epoch：1 step:3217/14065 loss：0.264580
【train】 epoch：1 step:3218/14065 loss：0.057337
【train】 epoch：1 step:3219/14065 loss：0.290574
【train】 epoch：1 step:3220/14065 loss：0.091715
【train】 epoch：1 step:3221/14065 loss：0.228807
【train】 epoch：1 step:3222/14065 loss：0.154375
【train】 epoch：1 step:3223/14065 loss：0.058216
【train】 epoch：1 step:3224/14065 loss：0.165347
【train】 epoch：1 step:3225/14065 loss：0.116935
【train】 epoch：1 step:3226/14065 loss：0.086953
【train】 epoch：1 step:3227/14065 loss：0.155733
【train】 epoch：1 step:3228/14065 loss：0.049154
【train】 epoch：1 step:3229/14065 loss：0.050090
【train】 epoch：1 step:3230/14065 loss：0.116320
【train】 epoch：1 step:3231/14065 loss：0.028848
【train】 epoch：1 step:3232/14065 loss：0.096357
【train】 epoch：1 step:3233/14065 loss：0.129914
【train】 epoch：1 step:3234/14065 loss：0.083212
【train】 epoch：1 step:3235/14065 loss：0.093718
【train】 epoch：1 step:3236/14065 loss：0.096694
【train】 epoch：1 step:3237/14065 loss：0.079075
【train】 epoch：1 step:3238/14065 loss：0.218026
【train】 epoch：1 step:3239/14065 loss：0.041029
【train】 epoch：1 step:3240/14065 loss：0.058883
【train】 epoch：1 step:3241/14065 loss：0.059431
【train】 epoch：1 step:3242/14065 loss：0.196064
【train】 epoch：1 step:3243/14065 loss：0.199807
【train】 epoch：1 step:3244/14065 loss：0.046438
【train】 epoch：1 step:3245/14065 loss：0.135089
【train】 epoch：1 step:3246/14065 loss：0.048497
【train】 epoch：1 step:3247/14065 loss：0.136014
【train】 epoch：1 step:3248/14065 loss：0.156412
【train】 epoch：1 step:3249/14065 loss：0.117561
【train】 epoch：1 step:3250/14065 loss：0.024287
【train】 epoch：1 step:3251/14065 loss：0.094514
【train】 epoch：1 step:3252/14065 loss：0.056164
【train】 epoch：1 step:3253/14065 loss：0.195841
【train】 epoch：1 step:3254/14065 loss：0.095238
【train】 epoch：1 step:3255/14065 loss：0.081052
【train】 epoch：1 step:3256/14065 loss：0.100675
【train】 epoch：1 step:3257/14065 loss：0.109811
【train】 epoch：1 step:3258/14065 loss：0.050123
【train】 epoch：1 step:3259/14065 loss：0.051690
【train】 epoch：1 step:3260/14065 loss：0.068240
【train】 epoch：1 step:3261/14065 loss：0.214654
【train】 epoch：1 step:3262/14065 loss：0.045461
【train】 epoch：1 step:3263/14065 loss：0.134697
【train】 epoch：1 step:3264/14065 loss：0.061781
【train】 epoch：1 step:3265/14065 loss：0.229214
【train】 epoch：1 step:3266/14065 loss：0.242833
【train】 epoch：1 step:3267/14065 loss：0.174949
【train】 epoch：1 step:3268/14065 loss：0.151231
【train】 epoch：1 step:3269/14065 loss：0.033158
【train】 epoch：1 step:3270/14065 loss：0.067149
【train】 epoch：1 step:3271/14065 loss：0.105505
【train】 epoch：1 step:3272/14065 loss：0.119405
【train】 epoch：1 step:3273/14065 loss：0.104893
【train】 epoch：1 step:3274/14065 loss：0.116771
【train】 epoch：1 step:3275/14065 loss：0.250741
【train】 epoch：1 step:3276/14065 loss：0.221879
【train】 epoch：1 step:3277/14065 loss：0.046308
【train】 epoch：1 step:3278/14065 loss：0.095495
【train】 epoch：1 step:3279/14065 loss：0.068397
【train】 epoch：1 step:3280/14065 loss：0.035253
【train】 epoch：1 step:3281/14065 loss：0.126432
【train】 epoch：1 step:3282/14065 loss：0.027532
【train】 epoch：1 step:3283/14065 loss：0.053259
【train】 epoch：1 step:3284/14065 loss：0.171180
【train】 epoch：1 step:3285/14065 loss：0.098464
【train】 epoch：1 step:3286/14065 loss：0.144602
【train】 epoch：1 step:3287/14065 loss：0.071173
【train】 epoch：1 step:3288/14065 loss：0.083867
【train】 epoch：1 step:3289/14065 loss：0.126795
【train】 epoch：1 step:3290/14065 loss：0.125866
【train】 epoch：1 step:3291/14065 loss：0.096134
【train】 epoch：1 step:3292/14065 loss：0.143944
【train】 epoch：1 step:3293/14065 loss：0.188937
【train】 epoch：1 step:3294/14065 loss：0.062065
【train】 epoch：1 step:3295/14065 loss：0.201316
【train】 epoch：1 step:3296/14065 loss：0.031489
【train】 epoch：1 step:3297/14065 loss：0.087950
【train】 epoch：1 step:3298/14065 loss：0.148501
【train】 epoch：1 step:3299/14065 loss：0.155767
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：356.619608 accuracy：0.9586 precision：0.9586 recall：0.9586 f1：0.9586
【train】 epoch：1 step:3300/14065 loss：0.191611
【train】 epoch：1 step:3301/14065 loss：0.195955
【train】 epoch：1 step:3302/14065 loss：0.132065
【train】 epoch：1 step:3303/14065 loss：0.069342
【train】 epoch：1 step:3304/14065 loss：0.097556
【train】 epoch：1 step:3305/14065 loss：0.108595
【train】 epoch：1 step:3306/14065 loss：0.195623
【train】 epoch：1 step:3307/14065 loss：0.091732
【train】 epoch：1 step:3308/14065 loss：0.245965
【train】 epoch：1 step:3309/14065 loss：0.199914
【train】 epoch：1 step:3310/14065 loss：0.073894
【train】 epoch：1 step:3311/14065 loss：0.178679
【train】 epoch：1 step:3312/14065 loss：0.273945
【train】 epoch：1 step:3313/14065 loss：0.178139
【train】 epoch：1 step:3314/14065 loss：0.155674
【train】 epoch：1 step:3315/14065 loss：0.025208
【train】 epoch：1 step:3316/14065 loss：0.327408
【train】 epoch：1 step:3317/14065 loss：0.098865
【train】 epoch：1 step:3318/14065 loss：0.133520
【train】 epoch：1 step:3319/14065 loss：0.046095
【train】 epoch：1 step:3320/14065 loss：0.086561
【train】 epoch：1 step:3321/14065 loss：0.159422
【train】 epoch：1 step:3322/14065 loss：0.174424
【train】 epoch：1 step:3323/14065 loss：0.022770
【train】 epoch：1 step:3324/14065 loss：0.269140
【train】 epoch：1 step:3325/14065 loss：0.186362
【train】 epoch：1 step:3326/14065 loss：0.130913
【train】 epoch：1 step:3327/14065 loss：0.207109
【train】 epoch：1 step:3328/14065 loss：0.192756
【train】 epoch：1 step:3329/14065 loss：0.135252
【train】 epoch：1 step:3330/14065 loss：0.077490
【train】 epoch：1 step:3331/14065 loss：0.079496
【train】 epoch：1 step:3332/14065 loss：0.057155
【train】 epoch：1 step:3333/14065 loss：0.225631
【train】 epoch：1 step:3334/14065 loss：0.257575
【train】 epoch：1 step:3335/14065 loss：0.206464
【train】 epoch：1 step:3336/14065 loss：0.185232
【train】 epoch：1 step:3337/14065 loss：0.076935
【train】 epoch：1 step:3338/14065 loss：0.230329
【train】 epoch：1 step:3339/14065 loss：0.111991
【train】 epoch：1 step:3340/14065 loss：0.062836
【train】 epoch：1 step:3341/14065 loss：0.170866
【train】 epoch：1 step:3342/14065 loss：0.058735
【train】 epoch：1 step:3343/14065 loss：0.098915
【train】 epoch：1 step:3344/14065 loss：0.149028
【train】 epoch：1 step:3345/14065 loss：0.194703
【train】 epoch：1 step:3346/14065 loss：0.105936
【train】 epoch：1 step:3347/14065 loss：0.089369
【train】 epoch：1 step:3348/14065 loss：0.126659
【train】 epoch：1 step:3349/14065 loss：0.092887
【train】 epoch：1 step:3350/14065 loss：0.267062
【train】 epoch：1 step:3351/14065 loss：0.120177
【train】 epoch：1 step:3352/14065 loss：0.158834
【train】 epoch：1 step:3353/14065 loss：0.083990
【train】 epoch：1 step:3354/14065 loss：0.256412
【train】 epoch：1 step:3355/14065 loss：0.131148
【train】 epoch：1 step:3356/14065 loss：0.142441
【train】 epoch：1 step:3357/14065 loss：0.139664
【train】 epoch：1 step:3358/14065 loss：0.105048
【train】 epoch：1 step:3359/14065 loss：0.224140
【train】 epoch：1 step:3360/14065 loss：0.093945
【train】 epoch：1 step:3361/14065 loss：0.032932
【train】 epoch：1 step:3362/14065 loss：0.210618
【train】 epoch：1 step:3363/14065 loss：0.165775
【train】 epoch：1 step:3364/14065 loss：0.134931
【train】 epoch：1 step:3365/14065 loss：0.054981
【train】 epoch：1 step:3366/14065 loss：0.202486
【train】 epoch：1 step:3367/14065 loss：0.135807
【train】 epoch：1 step:3368/14065 loss：0.108520
【train】 epoch：1 step:3369/14065 loss：0.188207
【train】 epoch：1 step:3370/14065 loss：0.057312
【train】 epoch：1 step:3371/14065 loss：0.150863
【train】 epoch：1 step:3372/14065 loss：0.098991
【train】 epoch：1 step:3373/14065 loss：0.181619
【train】 epoch：1 step:3374/14065 loss：0.043338
【train】 epoch：1 step:3375/14065 loss：0.215996
【train】 epoch：1 step:3376/14065 loss：0.173543
【train】 epoch：1 step:3377/14065 loss：0.170205
【train】 epoch：1 step:3378/14065 loss：0.204591
【train】 epoch：1 step:3379/14065 loss：0.218809
【train】 epoch：1 step:3380/14065 loss：0.170751
【train】 epoch：1 step:3381/14065 loss：0.229957
【train】 epoch：1 step:3382/14065 loss：0.102119
【train】 epoch：1 step:3383/14065 loss：0.058507
【train】 epoch：1 step:3384/14065 loss：0.140242
【train】 epoch：1 step:3385/14065 loss：0.249860
【train】 epoch：1 step:3386/14065 loss：0.159819
【train】 epoch：1 step:3387/14065 loss：0.231536
【train】 epoch：1 step:3388/14065 loss：0.117184
【train】 epoch：1 step:3389/14065 loss：0.070292
【train】 epoch：1 step:3390/14065 loss：0.133458
【train】 epoch：1 step:3391/14065 loss：0.193183
【train】 epoch：1 step:3392/14065 loss：0.157611
【train】 epoch：1 step:3393/14065 loss：0.105425
【train】 epoch：1 step:3394/14065 loss：0.096245
【train】 epoch：1 step:3395/14065 loss：0.057376
【train】 epoch：1 step:3396/14065 loss：0.083589
【train】 epoch：1 step:3397/14065 loss：0.090030
【train】 epoch：1 step:3398/14065 loss：0.143956
【train】 epoch：1 step:3399/14065 loss：0.099463
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：326.149677 accuracy：0.9623 precision：0.9623 recall：0.9623 f1：0.9623
【train】 epoch：1 step:3400/14065 loss：0.069003
【train】 epoch：1 step:3401/14065 loss：0.205756
【train】 epoch：1 step:3402/14065 loss：0.133854
【train】 epoch：1 step:3403/14065 loss：0.193525
【train】 epoch：1 step:3404/14065 loss：0.074972
【train】 epoch：1 step:3405/14065 loss：0.168440
【train】 epoch：1 step:3406/14065 loss：0.160285
【train】 epoch：1 step:3407/14065 loss：0.035292
【train】 epoch：1 step:3408/14065 loss：0.027877
【train】 epoch：1 step:3409/14065 loss：0.069074
【train】 epoch：1 step:3410/14065 loss：0.099141
【train】 epoch：1 step:3411/14065 loss：0.072884
【train】 epoch：1 step:3412/14065 loss：0.071690
【train】 epoch：1 step:3413/14065 loss：0.094940
【train】 epoch：1 step:3414/14065 loss：0.283119
【train】 epoch：1 step:3415/14065 loss：0.107980
【train】 epoch：1 step:3416/14065 loss：0.138203
【train】 epoch：1 step:3417/14065 loss：0.166201
【train】 epoch：1 step:3418/14065 loss：0.080719
【train】 epoch：1 step:3419/14065 loss：0.204891
【train】 epoch：1 step:3420/14065 loss：0.103585
【train】 epoch：1 step:3421/14065 loss：0.143280
【train】 epoch：1 step:3422/14065 loss：0.326415
【train】 epoch：1 step:3423/14065 loss：0.428937
【train】 epoch：1 step:3424/14065 loss：0.103132
【train】 epoch：1 step:3425/14065 loss：0.140536
【train】 epoch：1 step:3426/14065 loss：0.315197
【train】 epoch：1 step:3427/14065 loss：0.200684
【train】 epoch：1 step:3428/14065 loss：0.188959
【train】 epoch：1 step:3429/14065 loss：0.292629
【train】 epoch：1 step:3430/14065 loss：0.233633
【train】 epoch：1 step:3431/14065 loss：0.041200
【train】 epoch：1 step:3432/14065 loss：0.163603
【train】 epoch：1 step:3433/14065 loss：0.070766
【train】 epoch：1 step:3434/14065 loss：0.255428
【train】 epoch：1 step:3435/14065 loss：0.233572
【train】 epoch：1 step:3436/14065 loss：0.194474
【train】 epoch：1 step:3437/14065 loss：0.247385
【train】 epoch：1 step:3438/14065 loss：0.211394
【train】 epoch：1 step:3439/14065 loss：0.210152
【train】 epoch：1 step:3440/14065 loss：0.061947
【train】 epoch：1 step:3441/14065 loss：0.047187
【train】 epoch：1 step:3442/14065 loss：0.122398
【train】 epoch：1 step:3443/14065 loss：0.195744
【train】 epoch：1 step:3444/14065 loss：0.068644
【train】 epoch：1 step:3445/14065 loss：0.118288
【train】 epoch：1 step:3446/14065 loss：0.151235
【train】 epoch：1 step:3447/14065 loss：0.077185
【train】 epoch：1 step:3448/14065 loss：0.350643
【train】 epoch：1 step:3449/14065 loss：0.181705
【train】 epoch：1 step:3450/14065 loss：0.129794
【train】 epoch：1 step:3451/14065 loss：0.049110
【train】 epoch：1 step:3452/14065 loss：0.116551
【train】 epoch：1 step:3453/14065 loss：0.062886
【train】 epoch：1 step:3454/14065 loss：0.041006
【train】 epoch：1 step:3455/14065 loss：0.105571
【train】 epoch：1 step:3456/14065 loss：0.148772
【train】 epoch：1 step:3457/14065 loss：0.088113
【train】 epoch：1 step:3458/14065 loss：0.053210
【train】 epoch：1 step:3459/14065 loss：0.173773
【train】 epoch：1 step:3460/14065 loss：0.061399
【train】 epoch：1 step:3461/14065 loss：0.045398
【train】 epoch：1 step:3462/14065 loss：0.048906
【train】 epoch：1 step:3463/14065 loss：0.079138
【train】 epoch：1 step:3464/14065 loss：0.040151
【train】 epoch：1 step:3465/14065 loss：0.234818
【train】 epoch：1 step:3466/14065 loss：0.074593
【train】 epoch：1 step:3467/14065 loss：0.166651
【train】 epoch：1 step:3468/14065 loss：0.185220
【train】 epoch：1 step:3469/14065 loss：0.086085
【train】 epoch：1 step:3470/14065 loss：0.224488
【train】 epoch：1 step:3471/14065 loss：0.059025
【train】 epoch：1 step:3472/14065 loss：0.086293
【train】 epoch：1 step:3473/14065 loss：0.155875
【train】 epoch：1 step:3474/14065 loss：0.059943
【train】 epoch：1 step:3475/14065 loss：0.078942
【train】 epoch：1 step:3476/14065 loss：0.193975
【train】 epoch：1 step:3477/14065 loss：0.136506
【train】 epoch：1 step:3478/14065 loss：0.115269
【train】 epoch：1 step:3479/14065 loss：0.111165
【train】 epoch：1 step:3480/14065 loss：0.146860
【train】 epoch：1 step:3481/14065 loss：0.343659
【train】 epoch：1 step:3482/14065 loss：0.079357
【train】 epoch：1 step:3483/14065 loss：0.072163
【train】 epoch：1 step:3484/14065 loss：0.096856
【train】 epoch：1 step:3485/14065 loss：0.166050
【train】 epoch：1 step:3486/14065 loss：0.094244
【train】 epoch：1 step:3487/14065 loss：0.171349
【train】 epoch：1 step:3488/14065 loss：0.203670
【train】 epoch：1 step:3489/14065 loss：0.109034
【train】 epoch：1 step:3490/14065 loss：0.105280
【train】 epoch：1 step:3491/14065 loss：0.043555
【train】 epoch：1 step:3492/14065 loss：0.132450
【train】 epoch：1 step:3493/14065 loss：0.195609
【train】 epoch：1 step:3494/14065 loss：0.126621
【train】 epoch：1 step:3495/14065 loss：0.117048
【train】 epoch：1 step:3496/14065 loss：0.038672
【train】 epoch：1 step:3497/14065 loss：0.083182
【train】 epoch：1 step:3498/14065 loss：0.106781
【train】 epoch：1 step:3499/14065 loss：0.174070
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：308.489318 accuracy：0.9647 precision：0.9647 recall：0.9647 f1：0.9647
------------>保存当前最好的模型
【train】 epoch：1 step:3500/14065 loss：0.078896
【train】 epoch：1 step:3501/14065 loss：0.250804
【train】 epoch：1 step:3502/14065 loss：0.152233
【train】 epoch：1 step:3503/14065 loss：0.181630
【train】 epoch：1 step:3504/14065 loss：0.103836
【train】 epoch：1 step:3505/14065 loss：0.091218
【train】 epoch：1 step:3506/14065 loss：0.046688
【train】 epoch：1 step:3507/14065 loss：0.069916
【train】 epoch：1 step:3508/14065 loss：0.133449
【train】 epoch：1 step:3509/14065 loss：0.065401
【train】 epoch：1 step:3510/14065 loss：0.185693
【train】 epoch：1 step:3511/14065 loss：0.261059
【train】 epoch：1 step:3512/14065 loss：0.127261
【train】 epoch：1 step:3513/14065 loss：0.120559
【train】 epoch：1 step:3514/14065 loss：0.197160
【train】 epoch：1 step:3515/14065 loss：0.060378
【train】 epoch：1 step:3516/14065 loss：0.087819
【train】 epoch：1 step:3517/14065 loss：0.140270
【train】 epoch：1 step:3518/14065 loss：0.159063
【train】 epoch：1 step:3519/14065 loss：0.193749
【train】 epoch：1 step:3520/14065 loss：0.171323
【train】 epoch：1 step:3521/14065 loss：0.088512
【train】 epoch：1 step:3522/14065 loss：0.062004
【train】 epoch：1 step:3523/14065 loss：0.166705
【train】 epoch：1 step:3524/14065 loss：0.179131
【train】 epoch：1 step:3525/14065 loss：0.268640
【train】 epoch：1 step:3526/14065 loss：0.047869
【train】 epoch：1 step:3527/14065 loss：0.093846
【train】 epoch：1 step:3528/14065 loss：0.112846
【train】 epoch：1 step:3529/14065 loss：0.194942
【train】 epoch：1 step:3530/14065 loss：0.128741
【train】 epoch：1 step:3531/14065 loss：0.190194
【train】 epoch：1 step:3532/14065 loss：0.132465
【train】 epoch：1 step:3533/14065 loss：0.129264
【train】 epoch：1 step:3534/14065 loss：0.193319
【train】 epoch：1 step:3535/14065 loss：0.142927
【train】 epoch：1 step:3536/14065 loss：0.121297
【train】 epoch：1 step:3537/14065 loss：0.187337
【train】 epoch：1 step:3538/14065 loss：0.143829
【train】 epoch：1 step:3539/14065 loss：0.021076
【train】 epoch：1 step:3540/14065 loss：0.071211
【train】 epoch：1 step:3541/14065 loss：0.171553
【train】 epoch：1 step:3542/14065 loss：0.072932
【train】 epoch：1 step:3543/14065 loss：0.284744
【train】 epoch：1 step:3544/14065 loss：0.082820
【train】 epoch：1 step:3545/14065 loss：0.202541
【train】 epoch：1 step:3546/14065 loss：0.058386
【train】 epoch：1 step:3547/14065 loss：0.210734
【train】 epoch：1 step:3548/14065 loss：0.214845
【train】 epoch：1 step:3549/14065 loss：0.036818
【train】 epoch：1 step:3550/14065 loss：0.189418
【train】 epoch：1 step:3551/14065 loss：0.042422
【train】 epoch：1 step:3552/14065 loss：0.113192
【train】 epoch：1 step:3553/14065 loss：0.164679
【train】 epoch：1 step:3554/14065 loss：0.148828
【train】 epoch：1 step:3555/14065 loss：0.149981
【train】 epoch：1 step:3556/14065 loss：0.173774
【train】 epoch：1 step:3557/14065 loss：0.166413
【train】 epoch：1 step:3558/14065 loss：0.221984
【train】 epoch：1 step:3559/14065 loss：0.360379
【train】 epoch：1 step:3560/14065 loss：0.094001
【train】 epoch：1 step:3561/14065 loss：0.225222
【train】 epoch：1 step:3562/14065 loss：0.209235
【train】 epoch：1 step:3563/14065 loss：0.197771
【train】 epoch：1 step:3564/14065 loss：0.066161
【train】 epoch：1 step:3565/14065 loss：0.223364
【train】 epoch：1 step:3566/14065 loss：0.037854
【train】 epoch：1 step:3567/14065 loss：0.096085
【train】 epoch：1 step:3568/14065 loss：0.063203
【train】 epoch：1 step:3569/14065 loss：0.139427
【train】 epoch：1 step:3570/14065 loss：0.073082
【train】 epoch：1 step:3571/14065 loss：0.152612
【train】 epoch：1 step:3572/14065 loss：0.171271
【train】 epoch：1 step:3573/14065 loss：0.190650
【train】 epoch：1 step:3574/14065 loss：0.190010
【train】 epoch：1 step:3575/14065 loss：0.143188
【train】 epoch：1 step:3576/14065 loss：0.214181
【train】 epoch：1 step:3577/14065 loss：0.151417
【train】 epoch：1 step:3578/14065 loss：0.057718
【train】 epoch：1 step:3579/14065 loss：0.077322
【train】 epoch：1 step:3580/14065 loss：0.217170
【train】 epoch：1 step:3581/14065 loss：0.187863
【train】 epoch：1 step:3582/14065 loss：0.125856
【train】 epoch：1 step:3583/14065 loss：0.086671
【train】 epoch：1 step:3584/14065 loss：0.207128
【train】 epoch：1 step:3585/14065 loss：0.058390
【train】 epoch：1 step:3586/14065 loss：0.077530
【train】 epoch：1 step:3587/14065 loss：0.136536
【train】 epoch：1 step:3588/14065 loss：0.067291
【train】 epoch：1 step:3589/14065 loss：0.050502
【train】 epoch：1 step:3590/14065 loss：0.167899
【train】 epoch：1 step:3591/14065 loss：0.088207
【train】 epoch：1 step:3592/14065 loss：0.077502
【train】 epoch：1 step:3593/14065 loss：0.062809
【train】 epoch：1 step:3594/14065 loss：0.110012
【train】 epoch：1 step:3595/14065 loss：0.024519
【train】 epoch：1 step:3596/14065 loss：0.147505
【train】 epoch：1 step:3597/14065 loss：0.183306
【train】 epoch：1 step:3598/14065 loss：0.179336
【train】 epoch：1 step:3599/14065 loss：0.069878
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：301.876385 accuracy：0.9653 precision：0.9653 recall：0.9653 f1：0.9653
------------>保存当前最好的模型
【train】 epoch：1 step:3600/14065 loss：0.148632
【train】 epoch：1 step:3601/14065 loss：0.138203
【train】 epoch：1 step:3602/14065 loss：0.160847
【train】 epoch：1 step:3603/14065 loss：0.123637
【train】 epoch：1 step:3604/14065 loss：0.196492
【train】 epoch：1 step:3605/14065 loss：0.099614
【train】 epoch：1 step:3606/14065 loss：0.038845
【train】 epoch：1 step:3607/14065 loss：0.132287
【train】 epoch：1 step:3608/14065 loss：0.072094
【train】 epoch：1 step:3609/14065 loss：0.160142
【train】 epoch：1 step:3610/14065 loss：0.081595
【train】 epoch：1 step:3611/14065 loss：0.166213
【train】 epoch：1 step:3612/14065 loss：0.168293
【train】 epoch：1 step:3613/14065 loss：0.140552
【train】 epoch：1 step:3614/14065 loss：0.136821
【train】 epoch：1 step:3615/14065 loss：0.093747
【train】 epoch：1 step:3616/14065 loss：0.047336
【train】 epoch：1 step:3617/14065 loss：0.047863
【train】 epoch：1 step:3618/14065 loss：0.109945
【train】 epoch：1 step:3619/14065 loss：0.090047
【train】 epoch：1 step:3620/14065 loss：0.182921
【train】 epoch：1 step:3621/14065 loss：0.062775
【train】 epoch：1 step:3622/14065 loss：0.167699
【train】 epoch：1 step:3623/14065 loss：0.043876
【train】 epoch：1 step:3624/14065 loss：0.148808
【train】 epoch：1 step:3625/14065 loss：0.151065
【train】 epoch：1 step:3626/14065 loss：0.173215
【train】 epoch：1 step:3627/14065 loss：0.124394
【train】 epoch：1 step:3628/14065 loss：0.076296
【train】 epoch：1 step:3629/14065 loss：0.233250
【train】 epoch：1 step:3630/14065 loss：0.118262
【train】 epoch：1 step:3631/14065 loss：0.064488
【train】 epoch：1 step:3632/14065 loss：0.120365
【train】 epoch：1 step:3633/14065 loss：0.132152
【train】 epoch：1 step:3634/14065 loss：0.196814
【train】 epoch：1 step:3635/14065 loss：0.373894
【train】 epoch：1 step:3636/14065 loss：0.095915
【train】 epoch：1 step:3637/14065 loss：0.077270
【train】 epoch：1 step:3638/14065 loss：0.169239
【train】 epoch：1 step:3639/14065 loss：0.160064
【train】 epoch：1 step:3640/14065 loss：0.096247
【train】 epoch：1 step:3641/14065 loss：0.112315
【train】 epoch：1 step:3642/14065 loss：0.082694
【train】 epoch：1 step:3643/14065 loss：0.050300
【train】 epoch：1 step:3644/14065 loss：0.072013
【train】 epoch：1 step:3645/14065 loss：0.069986
【train】 epoch：1 step:3646/14065 loss：0.214000
【train】 epoch：1 step:3647/14065 loss：0.149963
【train】 epoch：1 step:3648/14065 loss：0.050408
【train】 epoch：1 step:3649/14065 loss：0.173067
【train】 epoch：1 step:3650/14065 loss：0.274213
【train】 epoch：1 step:3651/14065 loss：0.094596
【train】 epoch：1 step:3652/14065 loss：0.131944
【train】 epoch：1 step:3653/14065 loss：0.056828
【train】 epoch：1 step:3654/14065 loss：0.232478
【train】 epoch：1 step:3655/14065 loss：0.149264
【train】 epoch：1 step:3656/14065 loss：0.131512
【train】 epoch：1 step:3657/14065 loss：0.253379
【train】 epoch：1 step:3658/14065 loss：0.142255
【train】 epoch：1 step:3659/14065 loss：0.078588
【train】 epoch：1 step:3660/14065 loss：0.193010
【train】 epoch：1 step:3661/14065 loss：0.079350
【train】 epoch：1 step:3662/14065 loss：0.086769
【train】 epoch：1 step:3663/14065 loss：0.106310
【train】 epoch：1 step:3664/14065 loss：0.289250
【train】 epoch：1 step:3665/14065 loss：0.145091
【train】 epoch：1 step:3666/14065 loss：0.151165
【train】 epoch：1 step:3667/14065 loss：0.088968
【train】 epoch：1 step:3668/14065 loss：0.062737
【train】 epoch：1 step:3669/14065 loss：0.081941
【train】 epoch：1 step:3670/14065 loss：0.223505
【train】 epoch：1 step:3671/14065 loss：0.264038
【train】 epoch：1 step:3672/14065 loss：0.189922
【train】 epoch：1 step:3673/14065 loss：0.171409
【train】 epoch：1 step:3674/14065 loss：0.113307
【train】 epoch：1 step:3675/14065 loss：0.166397
【train】 epoch：1 step:3676/14065 loss：0.309257
【train】 epoch：1 step:3677/14065 loss：0.231754
【train】 epoch：1 step:3678/14065 loss：0.265841
【train】 epoch：1 step:3679/14065 loss：0.072495
【train】 epoch：1 step:3680/14065 loss：0.075260
【train】 epoch：1 step:3681/14065 loss：0.136220
【train】 epoch：1 step:3682/14065 loss：0.084370
【train】 epoch：1 step:3683/14065 loss：0.227159
【train】 epoch：1 step:3684/14065 loss：0.240838
【train】 epoch：1 step:3685/14065 loss：0.195977
【train】 epoch：1 step:3686/14065 loss：0.234035
【train】 epoch：1 step:3687/14065 loss：0.146614
【train】 epoch：1 step:3688/14065 loss：0.093748
【train】 epoch：1 step:3689/14065 loss：0.223381
【train】 epoch：1 step:3690/14065 loss：0.226345
【train】 epoch：1 step:3691/14065 loss：0.109482
【train】 epoch：1 step:3692/14065 loss：0.192007
【train】 epoch：1 step:3693/14065 loss：0.198566
【train】 epoch：1 step:3694/14065 loss：0.140502
【train】 epoch：1 step:3695/14065 loss：0.201932
【train】 epoch：1 step:3696/14065 loss：0.231975
【train】 epoch：1 step:3697/14065 loss：0.186739
【train】 epoch：1 step:3698/14065 loss：0.174263
【train】 epoch：1 step:3699/14065 loss：0.173291
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：390.810204 accuracy：0.9548 precision：0.9548 recall：0.9548 f1：0.9548
【train】 epoch：1 step:3700/14065 loss：0.285044
【train】 epoch：1 step:3701/14065 loss：0.092622
【train】 epoch：1 step:3702/14065 loss：0.069420
【train】 epoch：1 step:3703/14065 loss：0.185215
【train】 epoch：1 step:3704/14065 loss：0.185292
【train】 epoch：1 step:3705/14065 loss：0.129399
【train】 epoch：1 step:3706/14065 loss：0.260484
【train】 epoch：1 step:3707/14065 loss：0.121248
【train】 epoch：1 step:3708/14065 loss：0.095255
【train】 epoch：1 step:3709/14065 loss：0.176646
【train】 epoch：1 step:3710/14065 loss：0.186674
【train】 epoch：1 step:3711/14065 loss：0.154668
【train】 epoch：1 step:3712/14065 loss：0.073358
【train】 epoch：1 step:3713/14065 loss：0.186985
【train】 epoch：1 step:3714/14065 loss：0.218297
【train】 epoch：1 step:3715/14065 loss：0.159335
【train】 epoch：1 step:3716/14065 loss：0.053741
【train】 epoch：1 step:3717/14065 loss：0.152029
【train】 epoch：1 step:3718/14065 loss：0.226958
【train】 epoch：1 step:3719/14065 loss：0.126104
【train】 epoch：1 step:3720/14065 loss：0.337404
【train】 epoch：1 step:3721/14065 loss：0.208507
【train】 epoch：1 step:3722/14065 loss：0.150871
【train】 epoch：1 step:3723/14065 loss：0.257907
【train】 epoch：1 step:3724/14065 loss：0.083304
【train】 epoch：1 step:3725/14065 loss：0.154326
【train】 epoch：1 step:3726/14065 loss：0.321855
【train】 epoch：1 step:3727/14065 loss：0.139955
【train】 epoch：1 step:3728/14065 loss：0.241986
【train】 epoch：1 step:3729/14065 loss：0.222838
【train】 epoch：1 step:3730/14065 loss：0.277700
【train】 epoch：1 step:3731/14065 loss：0.052599
【train】 epoch：1 step:3732/14065 loss：0.106365
【train】 epoch：1 step:3733/14065 loss：0.093783
【train】 epoch：1 step:3734/14065 loss：0.289408
【train】 epoch：1 step:3735/14065 loss：0.207314
【train】 epoch：1 step:3736/14065 loss：0.160972
【train】 epoch：1 step:3737/14065 loss：0.216300
【train】 epoch：1 step:3738/14065 loss：0.135244
【train】 epoch：1 step:3739/14065 loss：0.238836
【train】 epoch：1 step:3740/14065 loss：0.232371
【train】 epoch：1 step:3741/14065 loss：0.282423
【train】 epoch：1 step:3742/14065 loss：0.124057
【train】 epoch：1 step:3743/14065 loss：0.079730
【train】 epoch：1 step:3744/14065 loss：0.319678
【train】 epoch：1 step:3745/14065 loss：0.098497
【train】 epoch：1 step:3746/14065 loss：0.200785
【train】 epoch：1 step:3747/14065 loss：0.111079
【train】 epoch：1 step:3748/14065 loss：0.122645
【train】 epoch：1 step:3749/14065 loss：0.179971
【train】 epoch：1 step:3750/14065 loss：0.171069
【train】 epoch：1 step:3751/14065 loss：0.156001
【train】 epoch：1 step:3752/14065 loss：0.155362
【train】 epoch：1 step:3753/14065 loss：0.038706
【train】 epoch：1 step:3754/14065 loss：0.074999
【train】 epoch：1 step:3755/14065 loss：0.202862
【train】 epoch：1 step:3756/14065 loss：0.172290
【train】 epoch：1 step:3757/14065 loss：0.235882
【train】 epoch：1 step:3758/14065 loss：0.084667
【train】 epoch：1 step:3759/14065 loss：0.282585
【train】 epoch：1 step:3760/14065 loss：0.079438
【train】 epoch：1 step:3761/14065 loss：0.332450
【train】 epoch：1 step:3762/14065 loss：0.143022
【train】 epoch：1 step:3763/14065 loss：0.181905
【train】 epoch：1 step:3764/14065 loss：0.096566
【train】 epoch：1 step:3765/14065 loss：0.226187
【train】 epoch：1 step:3766/14065 loss：0.287421
【train】 epoch：1 step:3767/14065 loss：0.079936
【train】 epoch：1 step:3768/14065 loss：0.179452
【train】 epoch：1 step:3769/14065 loss：0.071850
【train】 epoch：1 step:3770/14065 loss：0.198366
【train】 epoch：1 step:3771/14065 loss：0.177409
【train】 epoch：1 step:3772/14065 loss：0.176004
【train】 epoch：1 step:3773/14065 loss：0.207264
【train】 epoch：1 step:3774/14065 loss：0.049603
【train】 epoch：1 step:3775/14065 loss：0.176769
【train】 epoch：1 step:3776/14065 loss：0.112466
【train】 epoch：1 step:3777/14065 loss：0.187774
【train】 epoch：1 step:3778/14065 loss：0.098680
【train】 epoch：1 step:3779/14065 loss：0.100318
【train】 epoch：1 step:3780/14065 loss：0.079798
【train】 epoch：1 step:3781/14065 loss：0.198685
【train】 epoch：1 step:3782/14065 loss：0.073040
【train】 epoch：1 step:3783/14065 loss：0.150233
【train】 epoch：1 step:3784/14065 loss：0.169424
【train】 epoch：1 step:3785/14065 loss：0.105290
【train】 epoch：1 step:3786/14065 loss：0.128869
【train】 epoch：1 step:3787/14065 loss：0.123022
【train】 epoch：1 step:3788/14065 loss：0.108857
【train】 epoch：1 step:3789/14065 loss：0.185123
【train】 epoch：1 step:3790/14065 loss：0.141110
【train】 epoch：1 step:3791/14065 loss：0.288956
【train】 epoch：1 step:3792/14065 loss：0.349362
【train】 epoch：1 step:3793/14065 loss：0.121995
【train】 epoch：1 step:3794/14065 loss：0.099502
【train】 epoch：1 step:3795/14065 loss：0.052275
【train】 epoch：1 step:3796/14065 loss：0.038492
【train】 epoch：1 step:3797/14065 loss：0.095337
【train】 epoch：1 step:3798/14065 loss：0.133831
【train】 epoch：1 step:3799/14065 loss：0.030033
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：302.561239 accuracy：0.9656 precision：0.9656 recall：0.9656 f1：0.9656
------------>保存当前最好的模型
【train】 epoch：1 step:3800/14065 loss：0.153562
【train】 epoch：1 step:3801/14065 loss：0.086493
【train】 epoch：1 step:3802/14065 loss：0.079005
【train】 epoch：1 step:3803/14065 loss：0.134333
【train】 epoch：1 step:3804/14065 loss：0.246792
【train】 epoch：1 step:3805/14065 loss：0.052023
【train】 epoch：1 step:3806/14065 loss：0.112048
【train】 epoch：1 step:3807/14065 loss：0.314670
【train】 epoch：1 step:3808/14065 loss：0.170130
【train】 epoch：1 step:3809/14065 loss：0.193846
【train】 epoch：1 step:3810/14065 loss：0.250030
【train】 epoch：1 step:3811/14065 loss：0.093454
【train】 epoch：1 step:3812/14065 loss：0.111263
【train】 epoch：1 step:3813/14065 loss：0.239973
【train】 epoch：1 step:3814/14065 loss：0.213342
【train】 epoch：1 step:3815/14065 loss：0.157389
【train】 epoch：1 step:3816/14065 loss：0.103395
【train】 epoch：1 step:3817/14065 loss：0.172594
【train】 epoch：1 step:3818/14065 loss：0.128629
【train】 epoch：1 step:3819/14065 loss：0.045274
【train】 epoch：1 step:3820/14065 loss：0.169368
【train】 epoch：1 step:3821/14065 loss：0.107131
【train】 epoch：1 step:3822/14065 loss：0.157140
【train】 epoch：1 step:3823/14065 loss：0.074829
【train】 epoch：1 step:3824/14065 loss：0.103417
【train】 epoch：1 step:3825/14065 loss：0.249792
【train】 epoch：1 step:3826/14065 loss：0.090972
【train】 epoch：1 step:3827/14065 loss：0.217038
【train】 epoch：1 step:3828/14065 loss：0.089077
【train】 epoch：1 step:3829/14065 loss：0.107174
【train】 epoch：1 step:3830/14065 loss：0.164392
【train】 epoch：1 step:3831/14065 loss：0.164192
【train】 epoch：1 step:3832/14065 loss：0.218935
【train】 epoch：1 step:3833/14065 loss：0.155813
【train】 epoch：1 step:3834/14065 loss：0.230333
【train】 epoch：1 step:3835/14065 loss：0.164465
【train】 epoch：1 step:3836/14065 loss：0.115173
【train】 epoch：1 step:3837/14065 loss：0.098864
【train】 epoch：1 step:3838/14065 loss：0.167443
【train】 epoch：1 step:3839/14065 loss：0.082866
【train】 epoch：1 step:3840/14065 loss：0.117331
【train】 epoch：1 step:3841/14065 loss：0.149122
【train】 epoch：1 step:3842/14065 loss：0.098477
【train】 epoch：1 step:3843/14065 loss：0.157192
【train】 epoch：1 step:3844/14065 loss：0.211633
【train】 epoch：1 step:3845/14065 loss：0.108467
【train】 epoch：1 step:3846/14065 loss：0.115927
【train】 epoch：1 step:3847/14065 loss：0.212114
【train】 epoch：1 step:3848/14065 loss：0.121931
【train】 epoch：1 step:3849/14065 loss：0.062335
【train】 epoch：1 step:3850/14065 loss：0.256159
【train】 epoch：1 step:3851/14065 loss：0.381773
【train】 epoch：1 step:3852/14065 loss：0.243764
【train】 epoch：1 step:3853/14065 loss：0.145453
【train】 epoch：1 step:3854/14065 loss：0.057050
【train】 epoch：1 step:3855/14065 loss：0.283475
【train】 epoch：1 step:3856/14065 loss：0.140216
【train】 epoch：1 step:3857/14065 loss：0.257091
【train】 epoch：1 step:3858/14065 loss：0.234456
【train】 epoch：1 step:3859/14065 loss：0.301475
【train】 epoch：1 step:3860/14065 loss：0.076659
【train】 epoch：1 step:3861/14065 loss：0.082124
【train】 epoch：1 step:3862/14065 loss：0.166478
【train】 epoch：1 step:3863/14065 loss：0.116962
【train】 epoch：1 step:3864/14065 loss：0.095377
【train】 epoch：1 step:3865/14065 loss：0.084236
【train】 epoch：1 step:3866/14065 loss：0.166373
【train】 epoch：1 step:3867/14065 loss：0.247175
【train】 epoch：1 step:3868/14065 loss：0.236163
【train】 epoch：1 step:3869/14065 loss：0.099563
【train】 epoch：1 step:3870/14065 loss：0.123277
【train】 epoch：1 step:3871/14065 loss：0.153860
【train】 epoch：1 step:3872/14065 loss：0.173818
【train】 epoch：1 step:3873/14065 loss：0.142087
【train】 epoch：1 step:3874/14065 loss：0.183732
【train】 epoch：1 step:3875/14065 loss：0.125561
【train】 epoch：1 step:3876/14065 loss：0.220954
【train】 epoch：1 step:3877/14065 loss：0.279343
【train】 epoch：1 step:3878/14065 loss：0.075409
【train】 epoch：1 step:3879/14065 loss：0.080472
【train】 epoch：1 step:3880/14065 loss：0.157891
【train】 epoch：1 step:3881/14065 loss：0.189678
【train】 epoch：1 step:3882/14065 loss：0.174955
【train】 epoch：1 step:3883/14065 loss：0.070055
【train】 epoch：1 step:3884/14065 loss：0.087503
【train】 epoch：1 step:3885/14065 loss：0.206316
【train】 epoch：1 step:3886/14065 loss：0.270372
【train】 epoch：1 step:3887/14065 loss：0.027462
【train】 epoch：1 step:3888/14065 loss：0.139928
【train】 epoch：1 step:3889/14065 loss：0.147905
【train】 epoch：1 step:3890/14065 loss：0.091451
【train】 epoch：1 step:3891/14065 loss：0.052392
【train】 epoch：1 step:3892/14065 loss：0.146197
【train】 epoch：1 step:3893/14065 loss：0.105392
【train】 epoch：1 step:3894/14065 loss：0.194676
【train】 epoch：1 step:3895/14065 loss：0.180703
【train】 epoch：1 step:3896/14065 loss：0.143486
【train】 epoch：1 step:3897/14065 loss：0.063229
【train】 epoch：1 step:3898/14065 loss：0.104761
【train】 epoch：1 step:3899/14065 loss：0.080897
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：283.264887 accuracy：0.9681 precision：0.9681 recall：0.9681 f1：0.9681
------------>保存当前最好的模型
【train】 epoch：1 step:3900/14065 loss：0.191276
【train】 epoch：1 step:3901/14065 loss：0.229981
【train】 epoch：1 step:3902/14065 loss：0.216235
【train】 epoch：1 step:3903/14065 loss：0.045174
【train】 epoch：1 step:3904/14065 loss：0.070200
【train】 epoch：1 step:3905/14065 loss：0.170060
【train】 epoch：1 step:3906/14065 loss：0.102147
【train】 epoch：1 step:3907/14065 loss：0.460243
【train】 epoch：1 step:3908/14065 loss：0.134881
【train】 epoch：1 step:3909/14065 loss：0.108105
【train】 epoch：1 step:3910/14065 loss：0.131839
【train】 epoch：1 step:3911/14065 loss：0.132949
【train】 epoch：1 step:3912/14065 loss：0.129588
【train】 epoch：1 step:3913/14065 loss：0.115896
【train】 epoch：1 step:3914/14065 loss：0.125439
【train】 epoch：1 step:3915/14065 loss：0.189028
【train】 epoch：1 step:3916/14065 loss：0.033240
【train】 epoch：1 step:3917/14065 loss：0.083331
【train】 epoch：1 step:3918/14065 loss：0.058811
【train】 epoch：1 step:3919/14065 loss：0.181507
【train】 epoch：1 step:3920/14065 loss：0.087875
【train】 epoch：1 step:3921/14065 loss：0.177200
【train】 epoch：1 step:3922/14065 loss：0.134350
【train】 epoch：1 step:3923/14065 loss：0.108459
【train】 epoch：1 step:3924/14065 loss：0.079404
【train】 epoch：1 step:3925/14065 loss：0.195168
【train】 epoch：1 step:3926/14065 loss：0.103706
【train】 epoch：1 step:3927/14065 loss：0.033354
【train】 epoch：1 step:3928/14065 loss：0.056866
【train】 epoch：1 step:3929/14065 loss：0.175105
【train】 epoch：1 step:3930/14065 loss：0.248220
【train】 epoch：1 step:3931/14065 loss：0.023532
【train】 epoch：1 step:3932/14065 loss：0.117671
【train】 epoch：1 step:3933/14065 loss：0.137346
【train】 epoch：1 step:3934/14065 loss：0.246198
【train】 epoch：1 step:3935/14065 loss：0.022032
【train】 epoch：1 step:3936/14065 loss：0.275258
【train】 epoch：1 step:3937/14065 loss：0.143151
【train】 epoch：1 step:3938/14065 loss：0.169890
【train】 epoch：1 step:3939/14065 loss：0.055690
【train】 epoch：1 step:3940/14065 loss：0.243845
【train】 epoch：1 step:3941/14065 loss：0.039559
【train】 epoch：1 step:3942/14065 loss：0.094523
【train】 epoch：1 step:3943/14065 loss：0.270109
【train】 epoch：1 step:3944/14065 loss：0.039831
【train】 epoch：1 step:3945/14065 loss：0.250239
【train】 epoch：1 step:3946/14065 loss：0.226900
【train】 epoch：1 step:3947/14065 loss：0.151522
【train】 epoch：1 step:3948/14065 loss：0.174859
【train】 epoch：1 step:3949/14065 loss：0.116894
【train】 epoch：1 step:3950/14065 loss：0.098130
【train】 epoch：1 step:3951/14065 loss：0.117523
【train】 epoch：1 step:3952/14065 loss：0.093223
【train】 epoch：1 step:3953/14065 loss：0.126432
【train】 epoch：1 step:3954/14065 loss：0.095059
【train】 epoch：1 step:3955/14065 loss：0.105234
【train】 epoch：1 step:3956/14065 loss：0.184049
【train】 epoch：1 step:3957/14065 loss：0.053911
【train】 epoch：1 step:3958/14065 loss：0.044117
【train】 epoch：1 step:3959/14065 loss：0.213909
【train】 epoch：1 step:3960/14065 loss：0.063422
【train】 epoch：1 step:3961/14065 loss：0.057513
【train】 epoch：1 step:3962/14065 loss：0.113342
【train】 epoch：1 step:3963/14065 loss：0.163641
【train】 epoch：1 step:3964/14065 loss：0.143701
【train】 epoch：1 step:3965/14065 loss：0.149529
【train】 epoch：1 step:3966/14065 loss：0.171628
【train】 epoch：1 step:3967/14065 loss：0.140610
【train】 epoch：1 step:3968/14065 loss：0.101533
【train】 epoch：1 step:3969/14065 loss：0.086090
【train】 epoch：1 step:3970/14065 loss：0.187078
【train】 epoch：1 step:3971/14065 loss：0.146072
【train】 epoch：1 step:3972/14065 loss：0.062170
【train】 epoch：1 step:3973/14065 loss：0.100610
【train】 epoch：1 step:3974/14065 loss：0.123639
【train】 epoch：1 step:3975/14065 loss：0.087904
【train】 epoch：1 step:3976/14065 loss：0.197782
【train】 epoch：1 step:3977/14065 loss：0.167698
【train】 epoch：1 step:3978/14065 loss：0.208527
【train】 epoch：1 step:3979/14065 loss：0.242190
【train】 epoch：1 step:3980/14065 loss：0.187853
【train】 epoch：1 step:3981/14065 loss：0.340524
【train】 epoch：1 step:3982/14065 loss：0.130107
【train】 epoch：1 step:3983/14065 loss：0.084660
【train】 epoch：1 step:3984/14065 loss：0.137406
【train】 epoch：1 step:3985/14065 loss：0.085213
【train】 epoch：1 step:3986/14065 loss：0.103626
【train】 epoch：1 step:3987/14065 loss：0.094044
【train】 epoch：1 step:3988/14065 loss：0.143044
【train】 epoch：1 step:3989/14065 loss：0.108289
【train】 epoch：1 step:3990/14065 loss：0.134155
【train】 epoch：1 step:3991/14065 loss：0.169130
【train】 epoch：1 step:3992/14065 loss：0.060274
【train】 epoch：1 step:3993/14065 loss：0.051720
【train】 epoch：1 step:3994/14065 loss：0.097392
【train】 epoch：1 step:3995/14065 loss：0.129110
【train】 epoch：1 step:3996/14065 loss：0.110323
【train】 epoch：1 step:3997/14065 loss：0.164981
【train】 epoch：1 step:3998/14065 loss：0.089664
【train】 epoch：1 step:3999/14065 loss：0.214467
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：302.415935 accuracy：0.9649 precision：0.9649 recall：0.9649 f1：0.9649
【train】 epoch：1 step:4000/14065 loss：0.166871
【train】 epoch：1 step:4001/14065 loss：0.179712
【train】 epoch：1 step:4002/14065 loss：0.176412
【train】 epoch：1 step:4003/14065 loss：0.178705
【train】 epoch：1 step:4004/14065 loss：0.259203
【train】 epoch：1 step:4005/14065 loss：0.172857
【train】 epoch：1 step:4006/14065 loss：0.246781
【train】 epoch：1 step:4007/14065 loss：0.048150
【train】 epoch：1 step:4008/14065 loss：0.141263
【train】 epoch：1 step:4009/14065 loss：0.133557
【train】 epoch：1 step:4010/14065 loss：0.082897
【train】 epoch：1 step:4011/14065 loss：0.122268
【train】 epoch：1 step:4012/14065 loss：0.376456
【train】 epoch：1 step:4013/14065 loss：0.078776
【train】 epoch：1 step:4014/14065 loss：0.085345
【train】 epoch：1 step:4015/14065 loss：0.133930
【train】 epoch：1 step:4016/14065 loss：0.052928
【train】 epoch：1 step:4017/14065 loss：0.151863
【train】 epoch：1 step:4018/14065 loss：0.080917
【train】 epoch：1 step:4019/14065 loss：0.078443
【train】 epoch：1 step:4020/14065 loss：0.149654
【train】 epoch：1 step:4021/14065 loss：0.104902
【train】 epoch：1 step:4022/14065 loss：0.134802
【train】 epoch：1 step:4023/14065 loss：0.069406
【train】 epoch：1 step:4024/14065 loss：0.146768
【train】 epoch：1 step:4025/14065 loss：0.071212
【train】 epoch：1 step:4026/14065 loss：0.102421
【train】 epoch：1 step:4027/14065 loss：0.256573
【train】 epoch：1 step:4028/14065 loss：0.122848
【train】 epoch：1 step:4029/14065 loss：0.134025
【train】 epoch：1 step:4030/14065 loss：0.190789
【train】 epoch：1 step:4031/14065 loss：0.123683
【train】 epoch：1 step:4032/14065 loss：0.146109
【train】 epoch：1 step:4033/14065 loss：0.064622
【train】 epoch：1 step:4034/14065 loss：0.303147
【train】 epoch：1 step:4035/14065 loss：0.269768
【train】 epoch：1 step:4036/14065 loss：0.190856
【train】 epoch：1 step:4037/14065 loss：0.040489
【train】 epoch：1 step:4038/14065 loss：0.179388
【train】 epoch：1 step:4039/14065 loss：0.053450
【train】 epoch：1 step:4040/14065 loss：0.156879
【train】 epoch：1 step:4041/14065 loss：0.060065
【train】 epoch：1 step:4042/14065 loss：0.100063
【train】 epoch：1 step:4043/14065 loss：0.117645
【train】 epoch：1 step:4044/14065 loss：0.194778
【train】 epoch：1 step:4045/14065 loss：0.133545
【train】 epoch：1 step:4046/14065 loss：0.225408
【train】 epoch：1 step:4047/14065 loss：0.265609
【train】 epoch：1 step:4048/14065 loss：0.215678
【train】 epoch：1 step:4049/14065 loss：0.034003
【train】 epoch：1 step:4050/14065 loss：0.053499
【train】 epoch：1 step:4051/14065 loss：0.089196
【train】 epoch：1 step:4052/14065 loss：0.133885
【train】 epoch：1 step:4053/14065 loss：0.129702
【train】 epoch：1 step:4054/14065 loss：0.133587
【train】 epoch：1 step:4055/14065 loss：0.299598
【train】 epoch：1 step:4056/14065 loss：0.219983
【train】 epoch：1 step:4057/14065 loss：0.202238
【train】 epoch：1 step:4058/14065 loss：0.143736
【train】 epoch：1 step:4059/14065 loss：0.121930
【train】 epoch：1 step:4060/14065 loss：0.309027
【train】 epoch：1 step:4061/14065 loss：0.056940
【train】 epoch：1 step:4062/14065 loss：0.137074
【train】 epoch：1 step:4063/14065 loss：0.241057
【train】 epoch：1 step:4064/14065 loss：0.241235
【train】 epoch：1 step:4065/14065 loss：0.120427
【train】 epoch：1 step:4066/14065 loss：0.152413
【train】 epoch：1 step:4067/14065 loss：0.110745
【train】 epoch：1 step:4068/14065 loss：0.366745
【train】 epoch：1 step:4069/14065 loss：0.178338
【train】 epoch：1 step:4070/14065 loss：0.158981
【train】 epoch：1 step:4071/14065 loss：0.171003
【train】 epoch：1 step:4072/14065 loss：0.084576
【train】 epoch：1 step:4073/14065 loss：0.085404
【train】 epoch：1 step:4074/14065 loss：0.034285
【train】 epoch：1 step:4075/14065 loss：0.158544
【train】 epoch：1 step:4076/14065 loss：0.292240
【train】 epoch：1 step:4077/14065 loss：0.229580
【train】 epoch：1 step:4078/14065 loss：0.032685
【train】 epoch：1 step:4079/14065 loss：0.043272
【train】 epoch：1 step:4080/14065 loss：0.089000
【train】 epoch：1 step:4081/14065 loss：0.095663
【train】 epoch：1 step:4082/14065 loss：0.130838
【train】 epoch：1 step:4083/14065 loss：0.186050
【train】 epoch：1 step:4084/14065 loss：0.064785
【train】 epoch：1 step:4085/14065 loss：0.103729
【train】 epoch：1 step:4086/14065 loss：0.054519
【train】 epoch：1 step:4087/14065 loss：0.120663
【train】 epoch：1 step:4088/14065 loss：0.158674
【train】 epoch：1 step:4089/14065 loss：0.054771
【train】 epoch：1 step:4090/14065 loss：0.130237
【train】 epoch：1 step:4091/14065 loss：0.244047
【train】 epoch：1 step:4092/14065 loss：0.035950
【train】 epoch：1 step:4093/14065 loss：0.135869
【train】 epoch：1 step:4094/14065 loss：0.117425
【train】 epoch：1 step:4095/14065 loss：0.144889
【train】 epoch：1 step:4096/14065 loss：0.107503
【train】 epoch：1 step:4097/14065 loss：0.091982
【train】 epoch：1 step:4098/14065 loss：0.109578
【train】 epoch：1 step:4099/14065 loss：0.153299
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：263.187592 accuracy：0.9701 precision：0.9701 recall：0.9701 f1：0.9701
------------>保存当前最好的模型
【train】 epoch：1 step:4100/14065 loss：0.091777
【train】 epoch：1 step:4101/14065 loss：0.041782
【train】 epoch：1 step:4102/14065 loss：0.031397
【train】 epoch：1 step:4103/14065 loss：0.096324
【train】 epoch：1 step:4104/14065 loss：0.291033
【train】 epoch：1 step:4105/14065 loss：0.247671
【train】 epoch：1 step:4106/14065 loss：0.033290
【train】 epoch：1 step:4107/14065 loss：0.134626
【train】 epoch：1 step:4108/14065 loss：0.195157
【train】 epoch：1 step:4109/14065 loss：0.215918
【train】 epoch：1 step:4110/14065 loss：0.189194
【train】 epoch：1 step:4111/14065 loss：0.141571
【train】 epoch：1 step:4112/14065 loss：0.127557
【train】 epoch：1 step:4113/14065 loss：0.124100
【train】 epoch：1 step:4114/14065 loss：0.078565
【train】 epoch：1 step:4115/14065 loss：0.168637
【train】 epoch：1 step:4116/14065 loss：0.038694
【train】 epoch：1 step:4117/14065 loss：0.152542
【train】 epoch：1 step:4118/14065 loss：0.117202
【train】 epoch：1 step:4119/14065 loss：0.071924
【train】 epoch：1 step:4120/14065 loss：0.197228
【train】 epoch：1 step:4121/14065 loss：0.119941
【train】 epoch：1 step:4122/14065 loss：0.247595
【train】 epoch：1 step:4123/14065 loss：0.014439
【train】 epoch：1 step:4124/14065 loss：0.033083
【train】 epoch：1 step:4125/14065 loss：0.348679
【train】 epoch：1 step:4126/14065 loss：0.101918
【train】 epoch：1 step:4127/14065 loss：0.077318
【train】 epoch：1 step:4128/14065 loss：0.096377
【train】 epoch：1 step:4129/14065 loss：0.103712
【train】 epoch：1 step:4130/14065 loss：0.143480
【train】 epoch：1 step:4131/14065 loss：0.183633
【train】 epoch：1 step:4132/14065 loss：0.098841
【train】 epoch：1 step:4133/14065 loss：0.061122
【train】 epoch：1 step:4134/14065 loss：0.197865
【train】 epoch：1 step:4135/14065 loss：0.382373
【train】 epoch：1 step:4136/14065 loss：0.031349
【train】 epoch：1 step:4137/14065 loss：0.126321
【train】 epoch：1 step:4138/14065 loss：0.094342
【train】 epoch：1 step:4139/14065 loss：0.058650
【train】 epoch：1 step:4140/14065 loss：0.146880
【train】 epoch：1 step:4141/14065 loss：0.245968
【train】 epoch：1 step:4142/14065 loss：0.119792
【train】 epoch：1 step:4143/14065 loss：0.130635
【train】 epoch：1 step:4144/14065 loss：0.080776
【train】 epoch：1 step:4145/14065 loss：0.110267
【train】 epoch：1 step:4146/14065 loss：0.074025
【train】 epoch：1 step:4147/14065 loss：0.050913
【train】 epoch：1 step:4148/14065 loss：0.137580
【train】 epoch：1 step:4149/14065 loss：0.194918
【train】 epoch：1 step:4150/14065 loss：0.126664
【train】 epoch：1 step:4151/14065 loss：0.127488
【train】 epoch：1 step:4152/14065 loss：0.316505
【train】 epoch：1 step:4153/14065 loss：0.036202
【train】 epoch：1 step:4154/14065 loss：0.202533
【train】 epoch：1 step:4155/14065 loss：0.045207
【train】 epoch：1 step:4156/14065 loss：0.183119
【train】 epoch：1 step:4157/14065 loss：0.097522
【train】 epoch：1 step:4158/14065 loss：0.228056
【train】 epoch：1 step:4159/14065 loss：0.055121
【train】 epoch：1 step:4160/14065 loss：0.142143
【train】 epoch：1 step:4161/14065 loss：0.048535
【train】 epoch：1 step:4162/14065 loss：0.044117
【train】 epoch：1 step:4163/14065 loss：0.118193
【train】 epoch：1 step:4164/14065 loss：0.135846
【train】 epoch：1 step:4165/14065 loss：0.215535
【train】 epoch：1 step:4166/14065 loss：0.210803
【train】 epoch：1 step:4167/14065 loss：0.303562
【train】 epoch：1 step:4168/14065 loss：0.031202
【train】 epoch：1 step:4169/14065 loss：0.072451
【train】 epoch：1 step:4170/14065 loss：0.129889
【train】 epoch：1 step:4171/14065 loss：0.096268
【train】 epoch：1 step:4172/14065 loss：0.035331
【train】 epoch：1 step:4173/14065 loss：0.363148
【train】 epoch：1 step:4174/14065 loss：0.077535
【train】 epoch：1 step:4175/14065 loss：0.167142
【train】 epoch：1 step:4176/14065 loss：0.107089
【train】 epoch：1 step:4177/14065 loss：0.052332
【train】 epoch：1 step:4178/14065 loss：0.045214
【train】 epoch：1 step:4179/14065 loss：0.171133
【train】 epoch：1 step:4180/14065 loss：0.217900
【train】 epoch：1 step:4181/14065 loss：0.092597
【train】 epoch：1 step:4182/14065 loss：0.098257
【train】 epoch：1 step:4183/14065 loss：0.140842
【train】 epoch：1 step:4184/14065 loss：0.035165
【train】 epoch：1 step:4185/14065 loss：0.164858
【train】 epoch：1 step:4186/14065 loss：0.014003
【train】 epoch：1 step:4187/14065 loss：0.124557
【train】 epoch：1 step:4188/14065 loss：0.146216
【train】 epoch：1 step:4189/14065 loss：0.318992
【train】 epoch：1 step:4190/14065 loss：0.073583
【train】 epoch：1 step:4191/14065 loss：0.099813
【train】 epoch：1 step:4192/14065 loss：0.174391
【train】 epoch：1 step:4193/14065 loss：0.084568
【train】 epoch：1 step:4194/14065 loss：0.122497
【train】 epoch：1 step:4195/14065 loss：0.101056
【train】 epoch：1 step:4196/14065 loss：0.105401
【train】 epoch：1 step:4197/14065 loss：0.195372
【train】 epoch：1 step:4198/14065 loss：0.232132
【train】 epoch：1 step:4199/14065 loss：0.120825
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：267.674874 accuracy：0.9697 precision：0.9697 recall：0.9697 f1：0.9697
【train】 epoch：1 step:4200/14065 loss：0.167413
【train】 epoch：1 step:4201/14065 loss：0.216721
【train】 epoch：1 step:4202/14065 loss：0.248091
【train】 epoch：1 step:4203/14065 loss：0.195019
【train】 epoch：1 step:4204/14065 loss：0.028411
【train】 epoch：1 step:4205/14065 loss：0.076056
【train】 epoch：1 step:4206/14065 loss：0.077847
【train】 epoch：1 step:4207/14065 loss：0.201416
【train】 epoch：1 step:4208/14065 loss：0.206099
【train】 epoch：1 step:4209/14065 loss：0.177507
【train】 epoch：1 step:4210/14065 loss：0.153773
【train】 epoch：1 step:4211/14065 loss：0.264008
【train】 epoch：1 step:4212/14065 loss：0.113154
【train】 epoch：1 step:4213/14065 loss：0.123988
【train】 epoch：1 step:4214/14065 loss：0.269089
【train】 epoch：1 step:4215/14065 loss：0.385459
【train】 epoch：1 step:4216/14065 loss：0.160591
【train】 epoch：1 step:4217/14065 loss：0.095347
【train】 epoch：1 step:4218/14065 loss：0.199369
【train】 epoch：1 step:4219/14065 loss：0.146285
【train】 epoch：1 step:4220/14065 loss：0.128864
【train】 epoch：1 step:4221/14065 loss：0.173036
【train】 epoch：1 step:4222/14065 loss：0.078944
【train】 epoch：1 step:4223/14065 loss：0.229597
【train】 epoch：1 step:4224/14065 loss：0.253562
【train】 epoch：1 step:4225/14065 loss：0.187857
【train】 epoch：1 step:4226/14065 loss：0.131368
【train】 epoch：1 step:4227/14065 loss：0.182071
【train】 epoch：1 step:4228/14065 loss：0.077990
【train】 epoch：1 step:4229/14065 loss：0.123896
【train】 epoch：1 step:4230/14065 loss：0.089144
【train】 epoch：1 step:4231/14065 loss：0.138305
【train】 epoch：1 step:4232/14065 loss：0.133000
【train】 epoch：1 step:4233/14065 loss：0.057895
【train】 epoch：1 step:4234/14065 loss：0.065306
【train】 epoch：1 step:4235/14065 loss：0.134313
【train】 epoch：1 step:4236/14065 loss：0.127893
【train】 epoch：1 step:4237/14065 loss：0.139898
【train】 epoch：1 step:4238/14065 loss：0.074784
【train】 epoch：1 step:4239/14065 loss：0.124793
【train】 epoch：1 step:4240/14065 loss：0.178694
【train】 epoch：1 step:4241/14065 loss：0.285139
【train】 epoch：1 step:4242/14065 loss：0.109385
【train】 epoch：1 step:4243/14065 loss：0.294874
【train】 epoch：1 step:4244/14065 loss：0.158068
【train】 epoch：1 step:4245/14065 loss：0.045193
【train】 epoch：1 step:4246/14065 loss：0.073507
【train】 epoch：1 step:4247/14065 loss：0.112565
【train】 epoch：1 step:4248/14065 loss：0.180678
【train】 epoch：1 step:4249/14065 loss：0.124145
【train】 epoch：1 step:4250/14065 loss：0.197303
【train】 epoch：1 step:4251/14065 loss：0.064869
【train】 epoch：1 step:4252/14065 loss：0.133601
【train】 epoch：1 step:4253/14065 loss：0.286579
【train】 epoch：1 step:4254/14065 loss：0.103328
【train】 epoch：1 step:4255/14065 loss：0.087545
【train】 epoch：1 step:4256/14065 loss：0.095716
【train】 epoch：1 step:4257/14065 loss：0.071234
【train】 epoch：1 step:4258/14065 loss：0.201145
【train】 epoch：1 step:4259/14065 loss：0.087539
【train】 epoch：1 step:4260/14065 loss：0.065231
【train】 epoch：1 step:4261/14065 loss：0.048220
【train】 epoch：1 step:4262/14065 loss：0.050307
【train】 epoch：1 step:4263/14065 loss：0.078901
【train】 epoch：1 step:4264/14065 loss：0.044627
【train】 epoch：1 step:4265/14065 loss：0.141400
【train】 epoch：1 step:4266/14065 loss：0.154023
【train】 epoch：1 step:4267/14065 loss：0.080591
【train】 epoch：1 step:4268/14065 loss：0.111047
【train】 epoch：1 step:4269/14065 loss：0.217274
【train】 epoch：1 step:4270/14065 loss：0.196058
【train】 epoch：1 step:4271/14065 loss：0.167647
【train】 epoch：1 step:4272/14065 loss：0.142641
【train】 epoch：1 step:4273/14065 loss：0.123269
【train】 epoch：1 step:4274/14065 loss：0.169808
【train】 epoch：1 step:4275/14065 loss：0.114921
【train】 epoch：1 step:4276/14065 loss：0.038622
【train】 epoch：1 step:4277/14065 loss：0.106490
【train】 epoch：1 step:4278/14065 loss：0.058605
【train】 epoch：1 step:4279/14065 loss：0.035949
【train】 epoch：1 step:4280/14065 loss：0.033280
【train】 epoch：1 step:4281/14065 loss：0.206559
【train】 epoch：1 step:4282/14065 loss：0.153297
【train】 epoch：1 step:4283/14065 loss：0.078680
【train】 epoch：1 step:4284/14065 loss：0.337805
【train】 epoch：1 step:4285/14065 loss：0.188776
【train】 epoch：1 step:4286/14065 loss：0.268118
【train】 epoch：1 step:4287/14065 loss：0.193965
【train】 epoch：1 step:4288/14065 loss：0.109457
【train】 epoch：1 step:4289/14065 loss：0.150654
【train】 epoch：1 step:4290/14065 loss：0.068163
【train】 epoch：1 step:4291/14065 loss：0.240643
【train】 epoch：1 step:4292/14065 loss：0.268990
【train】 epoch：1 step:4293/14065 loss：0.186222
【train】 epoch：1 step:4294/14065 loss：0.051617
【train】 epoch：1 step:4295/14065 loss：0.182344
【train】 epoch：1 step:4296/14065 loss：0.167443
【train】 epoch：1 step:4297/14065 loss：0.049972
【train】 epoch：1 step:4298/14065 loss：0.178825
【train】 epoch：1 step:4299/14065 loss：0.071241
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：283.635703 accuracy：0.9680 precision：0.9680 recall：0.9680 f1：0.9680
【train】 epoch：1 step:4300/14065 loss：0.102280
【train】 epoch：1 step:4301/14065 loss：0.146373
【train】 epoch：1 step:4302/14065 loss：0.076598
【train】 epoch：1 step:4303/14065 loss：0.213301
【train】 epoch：1 step:4304/14065 loss：0.290479
【train】 epoch：1 step:4305/14065 loss：0.012120
【train】 epoch：1 step:4306/14065 loss：0.021288
【train】 epoch：1 step:4307/14065 loss：0.151121
【train】 epoch：1 step:4308/14065 loss：0.091087
【train】 epoch：1 step:4309/14065 loss：0.124308
【train】 epoch：1 step:4310/14065 loss：0.102373
【train】 epoch：1 step:4311/14065 loss：0.047711
【train】 epoch：1 step:4312/14065 loss：0.219232
【train】 epoch：1 step:4313/14065 loss：0.018115
【train】 epoch：1 step:4314/14065 loss：0.075497
【train】 epoch：1 step:4315/14065 loss：0.130541
【train】 epoch：1 step:4316/14065 loss：0.225023
【train】 epoch：1 step:4317/14065 loss：0.215560
【train】 epoch：1 step:4318/14065 loss：0.227679
【train】 epoch：1 step:4319/14065 loss：0.154032
【train】 epoch：1 step:4320/14065 loss：0.177146
【train】 epoch：1 step:4321/14065 loss：0.229333
【train】 epoch：1 step:4322/14065 loss：0.134242
【train】 epoch：1 step:4323/14065 loss：0.164052
【train】 epoch：1 step:4324/14065 loss：0.175950
【train】 epoch：1 step:4325/14065 loss：0.095427
【train】 epoch：1 step:4326/14065 loss：0.172519
【train】 epoch：1 step:4327/14065 loss：0.378238
【train】 epoch：1 step:4328/14065 loss：0.111373
【train】 epoch：1 step:4329/14065 loss：0.118260
【train】 epoch：1 step:4330/14065 loss：0.210766
【train】 epoch：1 step:4331/14065 loss：0.061925
【train】 epoch：1 step:4332/14065 loss：0.033090
【train】 epoch：1 step:4333/14065 loss：0.138232
【train】 epoch：1 step:4334/14065 loss：0.162425
【train】 epoch：1 step:4335/14065 loss：0.104276
【train】 epoch：1 step:4336/14065 loss：0.242507
【train】 epoch：1 step:4337/14065 loss：0.172172
【train】 epoch：1 step:4338/14065 loss：0.152030
【train】 epoch：1 step:4339/14065 loss：0.096373
【train】 epoch：1 step:4340/14065 loss：0.093194
【train】 epoch：1 step:4341/14065 loss：0.113442
【train】 epoch：1 step:4342/14065 loss：0.087871
【train】 epoch：1 step:4343/14065 loss：0.242980
【train】 epoch：1 step:4344/14065 loss：0.071144
【train】 epoch：1 step:4345/14065 loss：0.193155
【train】 epoch：1 step:4346/14065 loss：0.069875
【train】 epoch：1 step:4347/14065 loss：0.096207
【train】 epoch：1 step:4348/14065 loss：0.078911
【train】 epoch：1 step:4349/14065 loss：0.315035
【train】 epoch：1 step:4350/14065 loss：0.116717
【train】 epoch：1 step:4351/14065 loss：0.077154
【train】 epoch：1 step:4352/14065 loss：0.088720
【train】 epoch：1 step:4353/14065 loss：0.067969
【train】 epoch：1 step:4354/14065 loss：0.133165
【train】 epoch：1 step:4355/14065 loss：0.099826
【train】 epoch：1 step:4356/14065 loss：0.095669
【train】 epoch：1 step:4357/14065 loss：0.083598
【train】 epoch：1 step:4358/14065 loss：0.087172
【train】 epoch：1 step:4359/14065 loss：0.143789
【train】 epoch：1 step:4360/14065 loss：0.078001
【train】 epoch：1 step:4361/14065 loss：0.133883
【train】 epoch：1 step:4362/14065 loss：0.138505
【train】 epoch：1 step:4363/14065 loss：0.134143
【train】 epoch：1 step:4364/14065 loss：0.215655
【train】 epoch：1 step:4365/14065 loss：0.089113
【train】 epoch：1 step:4366/14065 loss：0.086441
【train】 epoch：1 step:4367/14065 loss：0.080532
【train】 epoch：1 step:4368/14065 loss：0.127690
【train】 epoch：1 step:4369/14065 loss：0.053092
【train】 epoch：1 step:4370/14065 loss：0.109473
【train】 epoch：1 step:4371/14065 loss：0.146347
【train】 epoch：1 step:4372/14065 loss：0.076178
【train】 epoch：1 step:4373/14065 loss：0.116889
【train】 epoch：1 step:4374/14065 loss：0.109313
【train】 epoch：1 step:4375/14065 loss：0.084201
【train】 epoch：1 step:4376/14065 loss：0.050030
【train】 epoch：1 step:4377/14065 loss：0.311840
【train】 epoch：1 step:4378/14065 loss：0.107266
【train】 epoch：1 step:4379/14065 loss：0.065809
【train】 epoch：1 step:4380/14065 loss：0.226112
【train】 epoch：1 step:4381/14065 loss：0.090406
【train】 epoch：1 step:4382/14065 loss：0.131452
【train】 epoch：1 step:4383/14065 loss：0.255353
【train】 epoch：1 step:4384/14065 loss：0.162951
【train】 epoch：1 step:4385/14065 loss：0.183193
【train】 epoch：1 step:4386/14065 loss：0.138848
【train】 epoch：1 step:4387/14065 loss：0.166034
【train】 epoch：1 step:4388/14065 loss：0.046725
【train】 epoch：1 step:4389/14065 loss：0.173225
【train】 epoch：1 step:4390/14065 loss：0.053517
【train】 epoch：1 step:4391/14065 loss：0.178026
【train】 epoch：1 step:4392/14065 loss：0.127753
【train】 epoch：1 step:4393/14065 loss：0.272764
【train】 epoch：1 step:4394/14065 loss：0.070352
【train】 epoch：1 step:4395/14065 loss：0.133898
【train】 epoch：1 step:4396/14065 loss：0.147625
【train】 epoch：1 step:4397/14065 loss：0.124793
【train】 epoch：1 step:4398/14065 loss：0.083712
【train】 epoch：1 step:4399/14065 loss：0.090563
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：262.466979 accuracy：0.9701 precision：0.9701 recall：0.9701 f1：0.9701
【train】 epoch：1 step:4400/14065 loss：0.117386
【train】 epoch：1 step:4401/14065 loss：0.130346
【train】 epoch：1 step:4402/14065 loss：0.201734
【train】 epoch：1 step:4403/14065 loss：0.207924
【train】 epoch：1 step:4404/14065 loss：0.091599
【train】 epoch：1 step:4405/14065 loss：0.263222
【train】 epoch：1 step:4406/14065 loss：0.142677
【train】 epoch：1 step:4407/14065 loss：0.065700
【train】 epoch：1 step:4408/14065 loss：0.215818
【train】 epoch：1 step:4409/14065 loss：0.082356
【train】 epoch：1 step:4410/14065 loss：0.156839
【train】 epoch：1 step:4411/14065 loss：0.205989
【train】 epoch：1 step:4412/14065 loss：0.285192
【train】 epoch：1 step:4413/14065 loss：0.159464
【train】 epoch：1 step:4414/14065 loss：0.166701
【train】 epoch：1 step:4415/14065 loss：0.055997
【train】 epoch：1 step:4416/14065 loss：0.092472
【train】 epoch：1 step:4417/14065 loss：0.073520
【train】 epoch：1 step:4418/14065 loss：0.066239
【train】 epoch：1 step:4419/14065 loss：0.100846
【train】 epoch：1 step:4420/14065 loss：0.097944
【train】 epoch：1 step:4421/14065 loss：0.125443
【train】 epoch：1 step:4422/14065 loss：0.090967
【train】 epoch：1 step:4423/14065 loss：0.093964
【train】 epoch：1 step:4424/14065 loss：0.098530
【train】 epoch：1 step:4425/14065 loss：0.046075
【train】 epoch：1 step:4426/14065 loss：0.083352
【train】 epoch：1 step:4427/14065 loss：0.050320
【train】 epoch：1 step:4428/14065 loss：0.100199
【train】 epoch：1 step:4429/14065 loss：0.185930
【train】 epoch：1 step:4430/14065 loss：0.140333
【train】 epoch：1 step:4431/14065 loss：0.056427
【train】 epoch：1 step:4432/14065 loss：0.170725
【train】 epoch：1 step:4433/14065 loss：0.139744
【train】 epoch：1 step:4434/14065 loss：0.129115
【train】 epoch：1 step:4435/14065 loss：0.127438
【train】 epoch：1 step:4436/14065 loss：0.085578
【train】 epoch：1 step:4437/14065 loss：0.333052
【train】 epoch：1 step:4438/14065 loss：0.132877
【train】 epoch：1 step:4439/14065 loss：0.151677
【train】 epoch：1 step:4440/14065 loss：0.099798
【train】 epoch：1 step:4441/14065 loss：0.155473
【train】 epoch：1 step:4442/14065 loss：0.046717
【train】 epoch：1 step:4443/14065 loss：0.118062
【train】 epoch：1 step:4444/14065 loss：0.040935
【train】 epoch：1 step:4445/14065 loss：0.049491
【train】 epoch：1 step:4446/14065 loss：0.192583
【train】 epoch：1 step:4447/14065 loss：0.059902
【train】 epoch：1 step:4448/14065 loss：0.041353
【train】 epoch：1 step:4449/14065 loss：0.088111
【train】 epoch：1 step:4450/14065 loss：0.159884
【train】 epoch：1 step:4451/14065 loss：0.157301
【train】 epoch：1 step:4452/14065 loss：0.211544
【train】 epoch：1 step:4453/14065 loss：0.288914
【train】 epoch：1 step:4454/14065 loss：0.138260
【train】 epoch：1 step:4455/14065 loss：0.129504
【train】 epoch：1 step:4456/14065 loss：0.130401
【train】 epoch：1 step:4457/14065 loss：0.055345
【train】 epoch：1 step:4458/14065 loss：0.213717
【train】 epoch：1 step:4459/14065 loss：0.246825
【train】 epoch：1 step:4460/14065 loss：0.233859
【train】 epoch：1 step:4461/14065 loss：0.113640
【train】 epoch：1 step:4462/14065 loss：0.183873
【train】 epoch：1 step:4463/14065 loss：0.085202
【train】 epoch：1 step:4464/14065 loss：0.078211
【train】 epoch：1 step:4465/14065 loss：0.199322
【train】 epoch：1 step:4466/14065 loss：0.079202
【train】 epoch：1 step:4467/14065 loss：0.096161
【train】 epoch：1 step:4468/14065 loss：0.151959
【train】 epoch：1 step:4469/14065 loss：0.098859
【train】 epoch：1 step:4470/14065 loss：0.090358
【train】 epoch：1 step:4471/14065 loss：0.083703
【train】 epoch：1 step:4472/14065 loss：0.112498
【train】 epoch：1 step:4473/14065 loss：0.169207
【train】 epoch：1 step:4474/14065 loss：0.067499
【train】 epoch：1 step:4475/14065 loss：0.104047
【train】 epoch：1 step:4476/14065 loss：0.181269
【train】 epoch：1 step:4477/14065 loss：0.134359
【train】 epoch：1 step:4478/14065 loss：0.049886
【train】 epoch：1 step:4479/14065 loss：0.129628
【train】 epoch：1 step:4480/14065 loss：0.251860
【train】 epoch：1 step:4481/14065 loss：0.151932
【train】 epoch：1 step:4482/14065 loss：0.147966
【train】 epoch：1 step:4483/14065 loss：0.210432
【train】 epoch：1 step:4484/14065 loss：0.116974
【train】 epoch：1 step:4485/14065 loss：0.224294
【train】 epoch：1 step:4486/14065 loss：0.246861
【train】 epoch：1 step:4487/14065 loss：0.244869
【train】 epoch：1 step:4488/14065 loss：0.097994
【train】 epoch：1 step:4489/14065 loss：0.061585
【train】 epoch：1 step:4490/14065 loss：0.061483
【train】 epoch：1 step:4491/14065 loss：0.095556
【train】 epoch：1 step:4492/14065 loss：0.082925
【train】 epoch：1 step:4493/14065 loss：0.185381
【train】 epoch：1 step:4494/14065 loss：0.165330
【train】 epoch：1 step:4495/14065 loss：0.139162
【train】 epoch：1 step:4496/14065 loss：0.160270
【train】 epoch：1 step:4497/14065 loss：0.145772
【train】 epoch：1 step:4498/14065 loss：0.267076
【train】 epoch：1 step:4499/14065 loss：0.351709
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：286.135627 accuracy：0.9677 precision：0.9677 recall：0.9677 f1：0.9677
【train】 epoch：1 step:4500/14065 loss：0.264129
【train】 epoch：1 step:4501/14065 loss：0.049932
【train】 epoch：1 step:4502/14065 loss：0.149979
【train】 epoch：1 step:4503/14065 loss：0.215508
【train】 epoch：1 step:4504/14065 loss：0.129148
【train】 epoch：1 step:4505/14065 loss：0.092443
【train】 epoch：1 step:4506/14065 loss：0.162247
【train】 epoch：1 step:4507/14065 loss：0.114916
【train】 epoch：1 step:4508/14065 loss：0.084139
【train】 epoch：1 step:4509/14065 loss：0.083109
【train】 epoch：1 step:4510/14065 loss：0.137155
【train】 epoch：1 step:4511/14065 loss：0.084936
【train】 epoch：1 step:4512/14065 loss：0.259945
【train】 epoch：1 step:4513/14065 loss：0.082017
【train】 epoch：1 step:4514/14065 loss：0.104267
【train】 epoch：1 step:4515/14065 loss：0.040903
【train】 epoch：1 step:4516/14065 loss：0.080314
【train】 epoch：1 step:4517/14065 loss：0.066899
【train】 epoch：1 step:4518/14065 loss：0.124325
【train】 epoch：1 step:4519/14065 loss：0.174232
【train】 epoch：1 step:4520/14065 loss：0.093604
【train】 epoch：1 step:4521/14065 loss：0.149325
【train】 epoch：1 step:4522/14065 loss：0.191568
【train】 epoch：1 step:4523/14065 loss：0.158574
【train】 epoch：1 step:4524/14065 loss：0.061662
【train】 epoch：1 step:4525/14065 loss：0.086880
【train】 epoch：1 step:4526/14065 loss：0.076917
【train】 epoch：1 step:4527/14065 loss：0.076967
【train】 epoch：1 step:4528/14065 loss：0.096402
【train】 epoch：1 step:4529/14065 loss：0.117158
【train】 epoch：1 step:4530/14065 loss：0.088841
【train】 epoch：1 step:4531/14065 loss：0.214169
【train】 epoch：1 step:4532/14065 loss：0.157487
【train】 epoch：1 step:4533/14065 loss：0.055727
【train】 epoch：1 step:4534/14065 loss：0.129490
【train】 epoch：1 step:4535/14065 loss：0.104095
【train】 epoch：1 step:4536/14065 loss：0.092710
【train】 epoch：1 step:4537/14065 loss：0.313416
【train】 epoch：1 step:4538/14065 loss：0.089129
【train】 epoch：1 step:4539/14065 loss：0.167379
【train】 epoch：1 step:4540/14065 loss：0.155515
【train】 epoch：1 step:4541/14065 loss：0.223857
【train】 epoch：1 step:4542/14065 loss：0.067276
【train】 epoch：1 step:4543/14065 loss：0.125596
【train】 epoch：1 step:4544/14065 loss：0.213049
【train】 epoch：1 step:4545/14065 loss：0.056704
【train】 epoch：1 step:4546/14065 loss：0.104514
【train】 epoch：1 step:4547/14065 loss：0.083471
【train】 epoch：1 step:4548/14065 loss：0.143330
【train】 epoch：1 step:4549/14065 loss：0.200724
【train】 epoch：1 step:4550/14065 loss：0.111003
【train】 epoch：1 step:4551/14065 loss：0.101205
【train】 epoch：1 step:4552/14065 loss：0.140968
【train】 epoch：1 step:4553/14065 loss：0.102289
【train】 epoch：1 step:4554/14065 loss：0.107518
【train】 epoch：1 step:4555/14065 loss：0.148960
【train】 epoch：1 step:4556/14065 loss：0.055099
【train】 epoch：1 step:4557/14065 loss：0.063553
【train】 epoch：1 step:4558/14065 loss：0.102832
【train】 epoch：1 step:4559/14065 loss：0.158875
【train】 epoch：1 step:4560/14065 loss：0.096467
【train】 epoch：1 step:4561/14065 loss：0.188671
【train】 epoch：1 step:4562/14065 loss：0.207419
【train】 epoch：1 step:4563/14065 loss：0.240166
【train】 epoch：1 step:4564/14065 loss：0.229089
【train】 epoch：1 step:4565/14065 loss：0.179165
【train】 epoch：1 step:4566/14065 loss：0.058053
【train】 epoch：1 step:4567/14065 loss：0.041526
【train】 epoch：1 step:4568/14065 loss：0.145254
【train】 epoch：1 step:4569/14065 loss：0.082321
【train】 epoch：1 step:4570/14065 loss：0.240705
【train】 epoch：1 step:4571/14065 loss：0.149031
【train】 epoch：1 step:4572/14065 loss：0.180323
【train】 epoch：1 step:4573/14065 loss：0.016207
【train】 epoch：1 step:4574/14065 loss：0.062746
【train】 epoch：1 step:4575/14065 loss：0.103153
【train】 epoch：1 step:4576/14065 loss：0.212869
【train】 epoch：1 step:4577/14065 loss：0.106694
【train】 epoch：1 step:4578/14065 loss：0.185148
【train】 epoch：1 step:4579/14065 loss：0.251761
【train】 epoch：1 step:4580/14065 loss：0.183403
【train】 epoch：1 step:4581/14065 loss：0.095309
【train】 epoch：1 step:4582/14065 loss：0.066767
【train】 epoch：1 step:4583/14065 loss：0.231770
【train】 epoch：1 step:4584/14065 loss：0.275612
【train】 epoch：1 step:4585/14065 loss：0.082419
【train】 epoch：1 step:4586/14065 loss：0.088312
【train】 epoch：1 step:4587/14065 loss：0.136701
【train】 epoch：1 step:4588/14065 loss：0.046281
【train】 epoch：1 step:4589/14065 loss：0.339721
【train】 epoch：1 step:4590/14065 loss：0.279720
【train】 epoch：1 step:4591/14065 loss：0.163511
【train】 epoch：1 step:4592/14065 loss：0.132300
【train】 epoch：1 step:4593/14065 loss：0.146105
【train】 epoch：1 step:4594/14065 loss：0.081014
【train】 epoch：1 step:4595/14065 loss：0.211067
【train】 epoch：1 step:4596/14065 loss：0.162150
【train】 epoch：1 step:4597/14065 loss：0.029877
【train】 epoch：1 step:4598/14065 loss：0.167716
【train】 epoch：1 step:4599/14065 loss：0.247410
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：271.538626 accuracy：0.9694 precision：0.9694 recall：0.9694 f1：0.9694
【train】 epoch：1 step:4600/14065 loss：0.178408
【train】 epoch：1 step:4601/14065 loss：0.138581
【train】 epoch：1 step:4602/14065 loss：0.086054
【train】 epoch：1 step:4603/14065 loss：0.221797
【train】 epoch：1 step:4604/14065 loss：0.063908
【train】 epoch：1 step:4605/14065 loss：0.052226
【train】 epoch：1 step:4606/14065 loss：0.199156
【train】 epoch：1 step:4607/14065 loss：0.082923
【train】 epoch：1 step:4608/14065 loss：0.157184
【train】 epoch：1 step:4609/14065 loss：0.112852
【train】 epoch：1 step:4610/14065 loss：0.043316
【train】 epoch：1 step:4611/14065 loss：0.092551
【train】 epoch：1 step:4612/14065 loss：0.122306
【train】 epoch：1 step:4613/14065 loss：0.118079
【train】 epoch：1 step:4614/14065 loss：0.102343
【train】 epoch：1 step:4615/14065 loss：0.201597
【train】 epoch：1 step:4616/14065 loss：0.157096
【train】 epoch：1 step:4617/14065 loss：0.072233
【train】 epoch：1 step:4618/14065 loss：0.117947
【train】 epoch：1 step:4619/14065 loss：0.084604
【train】 epoch：1 step:4620/14065 loss：0.135656
【train】 epoch：1 step:4621/14065 loss：0.173133
【train】 epoch：1 step:4622/14065 loss：0.112859
【train】 epoch：1 step:4623/14065 loss：0.093396
【train】 epoch：1 step:4624/14065 loss：0.122232
【train】 epoch：1 step:4625/14065 loss：0.090944
【train】 epoch：1 step:4626/14065 loss：0.073524
【train】 epoch：1 step:4627/14065 loss：0.193641
【train】 epoch：1 step:4628/14065 loss：0.101839
【train】 epoch：1 step:4629/14065 loss：0.124847
【train】 epoch：1 step:4630/14065 loss：0.084534
【train】 epoch：1 step:4631/14065 loss：0.067938
【train】 epoch：1 step:4632/14065 loss：0.064627
【train】 epoch：1 step:4633/14065 loss：0.104760
【train】 epoch：1 step:4634/14065 loss：0.076146
【train】 epoch：1 step:4635/14065 loss：0.037204
【train】 epoch：1 step:4636/14065 loss：0.102822
【train】 epoch：1 step:4637/14065 loss：0.170982
【train】 epoch：1 step:4638/14065 loss：0.068128
【train】 epoch：1 step:4639/14065 loss：0.149450
【train】 epoch：1 step:4640/14065 loss：0.172320
【train】 epoch：1 step:4641/14065 loss：0.093469
【train】 epoch：1 step:4642/14065 loss：0.084356
【train】 epoch：1 step:4643/14065 loss：0.024514
【train】 epoch：1 step:4644/14065 loss：0.171056
【train】 epoch：1 step:4645/14065 loss：0.071787
【train】 epoch：1 step:4646/14065 loss：0.039160
【train】 epoch：1 step:4647/14065 loss：0.178417
【train】 epoch：1 step:4648/14065 loss：0.259587
【train】 epoch：1 step:4649/14065 loss：0.100654
【train】 epoch：1 step:4650/14065 loss：0.129767
【train】 epoch：1 step:4651/14065 loss：0.029748
【train】 epoch：1 step:4652/14065 loss：0.183456
【train】 epoch：1 step:4653/14065 loss：0.269907
【train】 epoch：1 step:4654/14065 loss：0.215726
【train】 epoch：1 step:4655/14065 loss：0.094853
【train】 epoch：1 step:4656/14065 loss：0.076426
【train】 epoch：1 step:4657/14065 loss：0.382623
【train】 epoch：1 step:4658/14065 loss：0.151631
【train】 epoch：1 step:4659/14065 loss：0.138132
【train】 epoch：1 step:4660/14065 loss：0.133891
【train】 epoch：1 step:4661/14065 loss：0.112566
【train】 epoch：1 step:4662/14065 loss：0.090393
【train】 epoch：1 step:4663/14065 loss：0.126556
【train】 epoch：1 step:4664/14065 loss：0.048448
【train】 epoch：1 step:4665/14065 loss：0.299290
【train】 epoch：1 step:4666/14065 loss：0.172152
【train】 epoch：1 step:4667/14065 loss：0.216758
【train】 epoch：1 step:4668/14065 loss：0.105680
【train】 epoch：1 step:4669/14065 loss：0.160970
【train】 epoch：1 step:4670/14065 loss：0.110601
【train】 epoch：1 step:4671/14065 loss：0.039869
【train】 epoch：1 step:4672/14065 loss：0.162867
【train】 epoch：1 step:4673/14065 loss：0.155503
【train】 epoch：1 step:4674/14065 loss：0.075115
【train】 epoch：1 step:4675/14065 loss：0.044228
【train】 epoch：1 step:4676/14065 loss：0.225084
【train】 epoch：1 step:4677/14065 loss：0.195789
【train】 epoch：1 step:4678/14065 loss：0.188955
【train】 epoch：1 step:4679/14065 loss：0.048705
【train】 epoch：1 step:4680/14065 loss：0.213954
【train】 epoch：1 step:4681/14065 loss：0.077617
【train】 epoch：1 step:4682/14065 loss：0.203983
【train】 epoch：1 step:4683/14065 loss：0.107082
【train】 epoch：1 step:4684/14065 loss：0.047059
【train】 epoch：1 step:4685/14065 loss：0.256099
【train】 epoch：1 step:4686/14065 loss：0.178822
【train】 epoch：1 step:4687/14065 loss：0.056406
【train】 epoch：1 step:4688/14065 loss：0.118598
【train】 epoch：1 step:4689/14065 loss：0.098617
【train】 epoch：1 step:4690/14065 loss：0.141054
【train】 epoch：1 step:4691/14065 loss：0.042468
【train】 epoch：1 step:4692/14065 loss：0.053141
【train】 epoch：1 step:4693/14065 loss：0.099088
【train】 epoch：1 step:4694/14065 loss：0.137211
【train】 epoch：1 step:4695/14065 loss：0.113087
【train】 epoch：1 step:4696/14065 loss：0.115735
【train】 epoch：1 step:4697/14065 loss：0.054159
【train】 epoch：1 step:4698/14065 loss：0.084866
【train】 epoch：1 step:4699/14065 loss：0.295657
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：258.561368 accuracy：0.9706 precision：0.9706 recall：0.9706 f1：0.9706
------------>保存当前最好的模型
【train】 epoch：1 step:4700/14065 loss：0.030894
【train】 epoch：1 step:4701/14065 loss：0.083735
【train】 epoch：1 step:4702/14065 loss：0.140916
【train】 epoch：1 step:4703/14065 loss：0.096368
【train】 epoch：1 step:4704/14065 loss：0.050954
【train】 epoch：1 step:4705/14065 loss：0.121027
【train】 epoch：1 step:4706/14065 loss：0.151699
【train】 epoch：1 step:4707/14065 loss：0.034557
【train】 epoch：1 step:4708/14065 loss：0.039390
【train】 epoch：1 step:4709/14065 loss：0.085070
【train】 epoch：1 step:4710/14065 loss：0.128243
【train】 epoch：1 step:4711/14065 loss：0.133068
【train】 epoch：1 step:4712/14065 loss：0.086813
【train】 epoch：1 step:4713/14065 loss：0.100630
【train】 epoch：1 step:4714/14065 loss：0.071968
【train】 epoch：1 step:4715/14065 loss：0.149563
【train】 epoch：1 step:4716/14065 loss：0.129086
【train】 epoch：1 step:4717/14065 loss：0.151767
【train】 epoch：1 step:4718/14065 loss：0.232218
【train】 epoch：1 step:4719/14065 loss：0.217034
【train】 epoch：1 step:4720/14065 loss：0.067865
【train】 epoch：1 step:4721/14065 loss：0.220692
【train】 epoch：1 step:4722/14065 loss：0.286162
【train】 epoch：1 step:4723/14065 loss：0.244000
【train】 epoch：1 step:4724/14065 loss：0.305919
【train】 epoch：1 step:4725/14065 loss：0.188093
【train】 epoch：1 step:4726/14065 loss：0.111666
【train】 epoch：1 step:4727/14065 loss：0.182432
【train】 epoch：1 step:4728/14065 loss：0.092635
【train】 epoch：1 step:4729/14065 loss：0.132632
【train】 epoch：1 step:4730/14065 loss：0.127784
【train】 epoch：1 step:4731/14065 loss：0.066505
【train】 epoch：1 step:4732/14065 loss：0.063763
【train】 epoch：1 step:4733/14065 loss：0.057434
【train】 epoch：1 step:4734/14065 loss：0.216573
【train】 epoch：1 step:4735/14065 loss：0.091409
【train】 epoch：1 step:4736/14065 loss：0.107351
【train】 epoch：1 step:4737/14065 loss：0.072812
【train】 epoch：1 step:4738/14065 loss：0.096501
【train】 epoch：1 step:4739/14065 loss：0.205581
【train】 epoch：1 step:4740/14065 loss：0.079395
【train】 epoch：1 step:4741/14065 loss：0.239887
【train】 epoch：1 step:4742/14065 loss：0.250299
【train】 epoch：1 step:4743/14065 loss：0.050747
【train】 epoch：1 step:4744/14065 loss：0.053731
【train】 epoch：1 step:4745/14065 loss：0.080331
【train】 epoch：1 step:4746/14065 loss：0.175057
【train】 epoch：1 step:4747/14065 loss：0.246833
【train】 epoch：1 step:4748/14065 loss：0.136181
【train】 epoch：1 step:4749/14065 loss：0.144855
【train】 epoch：1 step:4750/14065 loss：0.168139
【train】 epoch：1 step:4751/14065 loss：0.192205
【train】 epoch：1 step:4752/14065 loss：0.046979
【train】 epoch：1 step:4753/14065 loss：0.248715
【train】 epoch：1 step:4754/14065 loss：0.103248
【train】 epoch：1 step:4755/14065 loss：0.136428
【train】 epoch：1 step:4756/14065 loss：0.096424
【train】 epoch：1 step:4757/14065 loss：0.138155
【train】 epoch：1 step:4758/14065 loss：0.092144
【train】 epoch：1 step:4759/14065 loss：0.154467
【train】 epoch：1 step:4760/14065 loss：0.129742
【train】 epoch：1 step:4761/14065 loss：0.177333
【train】 epoch：1 step:4762/14065 loss：0.071679
【train】 epoch：1 step:4763/14065 loss：0.183602
【train】 epoch：1 step:4764/14065 loss：0.233844
【train】 epoch：1 step:4765/14065 loss：0.088463
【train】 epoch：1 step:4766/14065 loss：0.183231
【train】 epoch：1 step:4767/14065 loss：0.258433
【train】 epoch：1 step:4768/14065 loss：0.254185
【train】 epoch：1 step:4769/14065 loss：0.124032
【train】 epoch：1 step:4770/14065 loss：0.160190
【train】 epoch：1 step:4771/14065 loss：0.047371
【train】 epoch：1 step:4772/14065 loss：0.104246
【train】 epoch：1 step:4773/14065 loss：0.235212
【train】 epoch：1 step:4774/14065 loss：0.168091
【train】 epoch：1 step:4775/14065 loss：0.172706
【train】 epoch：1 step:4776/14065 loss：0.117199
【train】 epoch：1 step:4777/14065 loss：0.256968
【train】 epoch：1 step:4778/14065 loss：0.147158
【train】 epoch：1 step:4779/14065 loss：0.042234
【train】 epoch：1 step:4780/14065 loss：0.249434
【train】 epoch：1 step:4781/14065 loss：0.261925
【train】 epoch：1 step:4782/14065 loss：0.054808
【train】 epoch：1 step:4783/14065 loss：0.352658
【train】 epoch：1 step:4784/14065 loss：0.060541
【train】 epoch：1 step:4785/14065 loss：0.172086
【train】 epoch：1 step:4786/14065 loss：0.111699
【train】 epoch：1 step:4787/14065 loss：0.304356
【train】 epoch：1 step:4788/14065 loss：0.100496
【train】 epoch：1 step:4789/14065 loss：0.164795
【train】 epoch：1 step:4790/14065 loss：0.055470
【train】 epoch：1 step:4791/14065 loss：0.081231
【train】 epoch：1 step:4792/14065 loss：0.223720
【train】 epoch：1 step:4793/14065 loss：0.168874
【train】 epoch：1 step:4794/14065 loss：0.121281
【train】 epoch：1 step:4795/14065 loss：0.169099
【train】 epoch：1 step:4796/14065 loss：0.280063
【train】 epoch：1 step:4797/14065 loss：0.101499
【train】 epoch：1 step:4798/14065 loss：0.100464
【train】 epoch：1 step:4799/14065 loss：0.111098
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：257.585699 accuracy：0.9709 precision：0.9709 recall：0.9709 f1：0.9709
------------>保存当前最好的模型
【train】 epoch：1 step:4800/14065 loss：0.058934
【train】 epoch：1 step:4801/14065 loss：0.142727
【train】 epoch：1 step:4802/14065 loss：0.066823
【train】 epoch：1 step:4803/14065 loss：0.220281
【train】 epoch：1 step:4804/14065 loss：0.116635
【train】 epoch：1 step:4805/14065 loss：0.233287
【train】 epoch：1 step:4806/14065 loss：0.111742
【train】 epoch：1 step:4807/14065 loss：0.241057
【train】 epoch：1 step:4808/14065 loss：0.089117
【train】 epoch：1 step:4809/14065 loss：0.125678
【train】 epoch：1 step:4810/14065 loss：0.181396
【train】 epoch：1 step:4811/14065 loss：0.065256
【train】 epoch：1 step:4812/14065 loss：0.165041
【train】 epoch：1 step:4813/14065 loss：0.026177
【train】 epoch：1 step:4814/14065 loss：0.208247
【train】 epoch：1 step:4815/14065 loss：0.077685
【train】 epoch：1 step:4816/14065 loss：0.179355
【train】 epoch：1 step:4817/14065 loss：0.063740
【train】 epoch：1 step:4818/14065 loss：0.138796
【train】 epoch：1 step:4819/14065 loss：0.114715
【train】 epoch：1 step:4820/14065 loss：0.170582
【train】 epoch：1 step:4821/14065 loss：0.177573
【train】 epoch：1 step:4822/14065 loss：0.121647
【train】 epoch：1 step:4823/14065 loss：0.064255
【train】 epoch：1 step:4824/14065 loss：0.076245
【train】 epoch：1 step:4825/14065 loss：0.091268
【train】 epoch：1 step:4826/14065 loss：0.082258
【train】 epoch：1 step:4827/14065 loss：0.179688
【train】 epoch：1 step:4828/14065 loss：0.220809
【train】 epoch：1 step:4829/14065 loss：0.175863
【train】 epoch：1 step:4830/14065 loss：0.093254
【train】 epoch：1 step:4831/14065 loss：0.295679
【train】 epoch：1 step:4832/14065 loss：0.105804
【train】 epoch：1 step:4833/14065 loss：0.057430
【train】 epoch：1 step:4834/14065 loss：0.220705
【train】 epoch：1 step:4835/14065 loss：0.029559
【train】 epoch：1 step:4836/14065 loss：0.039609
【train】 epoch：1 step:4837/14065 loss：0.141501
【train】 epoch：1 step:4838/14065 loss：0.173281
【train】 epoch：1 step:4839/14065 loss：0.139339
【train】 epoch：1 step:4840/14065 loss：0.216513
【train】 epoch：1 step:4841/14065 loss：0.137262
【train】 epoch：1 step:4842/14065 loss：0.115453
【train】 epoch：1 step:4843/14065 loss：0.132445
【train】 epoch：1 step:4844/14065 loss：0.123145
【train】 epoch：1 step:4845/14065 loss：0.083069
【train】 epoch：1 step:4846/14065 loss：0.148226
【train】 epoch：1 step:4847/14065 loss：0.083392
【train】 epoch：1 step:4848/14065 loss：0.144233
【train】 epoch：1 step:4849/14065 loss：0.173706
【train】 epoch：1 step:4850/14065 loss：0.174021
【train】 epoch：1 step:4851/14065 loss：0.079325
【train】 epoch：1 step:4852/14065 loss：0.035897
【train】 epoch：1 step:4853/14065 loss：0.063054
【train】 epoch：1 step:4854/14065 loss：0.092642
【train】 epoch：1 step:4855/14065 loss：0.120915
【train】 epoch：1 step:4856/14065 loss：0.087108
【train】 epoch：1 step:4857/14065 loss：0.164797
【train】 epoch：1 step:4858/14065 loss：0.208141
【train】 epoch：1 step:4859/14065 loss：0.209246
【train】 epoch：1 step:4860/14065 loss：0.085820
【train】 epoch：1 step:4861/14065 loss：0.341152
【train】 epoch：1 step:4862/14065 loss：0.062958
【train】 epoch：1 step:4863/14065 loss：0.287973
【train】 epoch：1 step:4864/14065 loss：0.111683
【train】 epoch：1 step:4865/14065 loss：0.125945
【train】 epoch：1 step:4866/14065 loss：0.124943
【train】 epoch：1 step:4867/14065 loss：0.071008
【train】 epoch：1 step:4868/14065 loss：0.233379
【train】 epoch：1 step:4869/14065 loss：0.094768
【train】 epoch：1 step:4870/14065 loss：0.049522
【train】 epoch：1 step:4871/14065 loss：0.178140
【train】 epoch：1 step:4872/14065 loss：0.157041
【train】 epoch：1 step:4873/14065 loss：0.073697
【train】 epoch：1 step:4874/14065 loss：0.199065
【train】 epoch：1 step:4875/14065 loss：0.040486
【train】 epoch：1 step:4876/14065 loss：0.075637
【train】 epoch：1 step:4877/14065 loss：0.105425
【train】 epoch：1 step:4878/14065 loss：0.106681
【train】 epoch：1 step:4879/14065 loss：0.086696
【train】 epoch：1 step:4880/14065 loss：0.193765
【train】 epoch：1 step:4881/14065 loss：0.079739
【train】 epoch：1 step:4882/14065 loss：0.195430
【train】 epoch：1 step:4883/14065 loss：0.227570
【train】 epoch：1 step:4884/14065 loss：0.169887
【train】 epoch：1 step:4885/14065 loss：0.073477
【train】 epoch：1 step:4886/14065 loss：0.258812
【train】 epoch：1 step:4887/14065 loss：0.142422
【train】 epoch：1 step:4888/14065 loss：0.112872
【train】 epoch：1 step:4889/14065 loss：0.077824
【train】 epoch：1 step:4890/14065 loss：0.190230
【train】 epoch：1 step:4891/14065 loss：0.081796
【train】 epoch：1 step:4892/14065 loss：0.060754
【train】 epoch：1 step:4893/14065 loss：0.099250
【train】 epoch：1 step:4894/14065 loss：0.097115
【train】 epoch：1 step:4895/14065 loss：0.159814
【train】 epoch：1 step:4896/14065 loss：0.141795
【train】 epoch：1 step:4897/14065 loss：0.214444
【train】 epoch：1 step:4898/14065 loss：0.107639
【train】 epoch：1 step:4899/14065 loss：0.131689
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：252.167472 accuracy：0.9708 precision：0.9708 recall：0.9708 f1：0.9708
【train】 epoch：1 step:4900/14065 loss：0.200678
【train】 epoch：1 step:4901/14065 loss：0.115702
【train】 epoch：1 step:4902/14065 loss：0.180849
【train】 epoch：1 step:4903/14065 loss：0.064138
【train】 epoch：1 step:4904/14065 loss：0.163486
【train】 epoch：1 step:4905/14065 loss：0.095585
【train】 epoch：1 step:4906/14065 loss：0.092491
【train】 epoch：1 step:4907/14065 loss：0.059014
【train】 epoch：1 step:4908/14065 loss：0.071847
【train】 epoch：1 step:4909/14065 loss：0.112659
【train】 epoch：1 step:4910/14065 loss：0.164835
【train】 epoch：1 step:4911/14065 loss：0.099246
【train】 epoch：1 step:4912/14065 loss：0.077910
【train】 epoch：1 step:4913/14065 loss：0.117208
【train】 epoch：1 step:4914/14065 loss：0.155115
【train】 epoch：1 step:4915/14065 loss：0.063725
【train】 epoch：1 step:4916/14065 loss：0.265803
【train】 epoch：1 step:4917/14065 loss：0.076770
【train】 epoch：1 step:4918/14065 loss：0.167963
【train】 epoch：1 step:4919/14065 loss：0.084577
【train】 epoch：1 step:4920/14065 loss：0.037376
【train】 epoch：1 step:4921/14065 loss：0.164453
【train】 epoch：1 step:4922/14065 loss：0.075327
【train】 epoch：1 step:4923/14065 loss：0.136427
【train】 epoch：1 step:4924/14065 loss：0.088417
【train】 epoch：1 step:4925/14065 loss：0.249067
【train】 epoch：1 step:4926/14065 loss：0.289150
【train】 epoch：1 step:4927/14065 loss：0.051158
【train】 epoch：1 step:4928/14065 loss：0.238678
【train】 epoch：1 step:4929/14065 loss：0.122820
【train】 epoch：1 step:4930/14065 loss：0.132622
【train】 epoch：1 step:4931/14065 loss：0.079290
【train】 epoch：1 step:4932/14065 loss：0.116149
【train】 epoch：1 step:4933/14065 loss：0.116902
【train】 epoch：1 step:4934/14065 loss：0.137496
【train】 epoch：1 step:4935/14065 loss：0.116985
【train】 epoch：1 step:4936/14065 loss：0.135836
【train】 epoch：1 step:4937/14065 loss：0.118591
【train】 epoch：1 step:4938/14065 loss：0.297573
【train】 epoch：1 step:4939/14065 loss：0.148232
【train】 epoch：1 step:4940/14065 loss：0.213550
【train】 epoch：1 step:4941/14065 loss：0.167869
【train】 epoch：1 step:4942/14065 loss：0.075485
【train】 epoch：1 step:4943/14065 loss：0.220934
【train】 epoch：1 step:4944/14065 loss：0.229719
【train】 epoch：1 step:4945/14065 loss：0.029201
【train】 epoch：1 step:4946/14065 loss：0.249728
【train】 epoch：1 step:4947/14065 loss：0.178788
【train】 epoch：1 step:4948/14065 loss：0.183978
【train】 epoch：1 step:4949/14065 loss：0.225861
【train】 epoch：1 step:4950/14065 loss：0.068338
【train】 epoch：1 step:4951/14065 loss：0.078579
【train】 epoch：1 step:4952/14065 loss：0.150951
【train】 epoch：1 step:4953/14065 loss：0.137613
【train】 epoch：1 step:4954/14065 loss：0.020222
【train】 epoch：1 step:4955/14065 loss：0.106286
【train】 epoch：1 step:4956/14065 loss：0.123473
【train】 epoch：1 step:4957/14065 loss：0.112299
【train】 epoch：1 step:4958/14065 loss：0.253016
【train】 epoch：1 step:4959/14065 loss：0.133425
【train】 epoch：1 step:4960/14065 loss：0.112718
【train】 epoch：1 step:4961/14065 loss：0.052211
【train】 epoch：1 step:4962/14065 loss：0.065113
【train】 epoch：1 step:4963/14065 loss：0.093780
【train】 epoch：1 step:4964/14065 loss：0.043768
【train】 epoch：1 step:4965/14065 loss：0.080284
【train】 epoch：1 step:4966/14065 loss：0.224545
【train】 epoch：1 step:4967/14065 loss：0.119458
【train】 epoch：1 step:4968/14065 loss：0.072403
【train】 epoch：1 step:4969/14065 loss：0.180612
【train】 epoch：1 step:4970/14065 loss：0.095867
【train】 epoch：1 step:4971/14065 loss：0.109770
【train】 epoch：1 step:4972/14065 loss：0.052914
【train】 epoch：1 step:4973/14065 loss：0.110516
【train】 epoch：1 step:4974/14065 loss：0.099064
【train】 epoch：1 step:4975/14065 loss：0.184527
【train】 epoch：1 step:4976/14065 loss：0.097485
【train】 epoch：1 step:4977/14065 loss：0.035994
【train】 epoch：1 step:4978/14065 loss：0.099149
【train】 epoch：1 step:4979/14065 loss：0.164967
【train】 epoch：1 step:4980/14065 loss：0.115286
【train】 epoch：1 step:4981/14065 loss：0.054109
【train】 epoch：1 step:4982/14065 loss：0.110458
【train】 epoch：1 step:4983/14065 loss：0.143082
【train】 epoch：1 step:4984/14065 loss：0.221654
【train】 epoch：1 step:4985/14065 loss：0.227825
【train】 epoch：1 step:4986/14065 loss：0.076695
【train】 epoch：1 step:4987/14065 loss：0.129855
【train】 epoch：1 step:4988/14065 loss：0.149560
【train】 epoch：1 step:4989/14065 loss：0.173293
【train】 epoch：1 step:4990/14065 loss：0.112901
【train】 epoch：1 step:4991/14065 loss：0.032723
【train】 epoch：1 step:4992/14065 loss：0.112809
【train】 epoch：1 step:4993/14065 loss：0.182192
【train】 epoch：1 step:4994/14065 loss：0.097580
【train】 epoch：1 step:4995/14065 loss：0.114241
【train】 epoch：1 step:4996/14065 loss：0.152973
【train】 epoch：1 step:4997/14065 loss：0.130876
【train】 epoch：1 step:4998/14065 loss：0.051517
【train】 epoch：1 step:4999/14065 loss：0.081107
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：235.039341 accuracy：0.9732 precision：0.9732 recall：0.9732 f1：0.9732
------------>保存当前最好的模型
【train】 epoch：1 step:5000/14065 loss：0.168813
【train】 epoch：1 step:5001/14065 loss：0.167804
【train】 epoch：1 step:5002/14065 loss：0.088925
【train】 epoch：1 step:5003/14065 loss：0.125513
【train】 epoch：1 step:5004/14065 loss：0.118193
【train】 epoch：1 step:5005/14065 loss：0.147269
【train】 epoch：1 step:5006/14065 loss：0.251551
【train】 epoch：1 step:5007/14065 loss：0.149880
【train】 epoch：1 step:5008/14065 loss：0.143935
【train】 epoch：1 step:5009/14065 loss：0.052714
【train】 epoch：1 step:5010/14065 loss：0.186300
【train】 epoch：1 step:5011/14065 loss：0.073147
【train】 epoch：1 step:5012/14065 loss：0.204250
【train】 epoch：1 step:5013/14065 loss：0.147956
【train】 epoch：1 step:5014/14065 loss：0.125878
【train】 epoch：1 step:5015/14065 loss：0.144670
【train】 epoch：1 step:5016/14065 loss：0.274550
【train】 epoch：1 step:5017/14065 loss：0.159884
【train】 epoch：1 step:5018/14065 loss：0.061113
【train】 epoch：1 step:5019/14065 loss：0.159076
【train】 epoch：1 step:5020/14065 loss：0.173894
【train】 epoch：1 step:5021/14065 loss：0.226292
【train】 epoch：1 step:5022/14065 loss：0.117316
【train】 epoch：1 step:5023/14065 loss：0.144587
【train】 epoch：1 step:5024/14065 loss：0.201007
【train】 epoch：1 step:5025/14065 loss：0.107771
【train】 epoch：1 step:5026/14065 loss：0.119883
【train】 epoch：1 step:5027/14065 loss：0.109977
【train】 epoch：1 step:5028/14065 loss：0.073652
【train】 epoch：1 step:5029/14065 loss：0.082243
【train】 epoch：1 step:5030/14065 loss：0.310554
【train】 epoch：1 step:5031/14065 loss：0.138963
【train】 epoch：1 step:5032/14065 loss：0.119475
【train】 epoch：1 step:5033/14065 loss：0.106344
【train】 epoch：1 step:5034/14065 loss：0.231887
【train】 epoch：1 step:5035/14065 loss：0.183669
【train】 epoch：1 step:5036/14065 loss：0.206589
【train】 epoch：1 step:5037/14065 loss：0.050338
【train】 epoch：1 step:5038/14065 loss：0.029158
【train】 epoch：1 step:5039/14065 loss：0.037102
【train】 epoch：1 step:5040/14065 loss：0.040660
【train】 epoch：1 step:5041/14065 loss：0.180812
【train】 epoch：1 step:5042/14065 loss：0.112732
【train】 epoch：1 step:5043/14065 loss：0.078602
【train】 epoch：1 step:5044/14065 loss：0.176496
【train】 epoch：1 step:5045/14065 loss：0.120981
【train】 epoch：1 step:5046/14065 loss：0.153315
【train】 epoch：1 step:5047/14065 loss：0.093107
【train】 epoch：1 step:5048/14065 loss：0.058805
【train】 epoch：1 step:5049/14065 loss：0.112208
【train】 epoch：1 step:5050/14065 loss：0.058309
【train】 epoch：1 step:5051/14065 loss：0.081115
【train】 epoch：1 step:5052/14065 loss：0.088046
【train】 epoch：1 step:5053/14065 loss：0.051969
【train】 epoch：1 step:5054/14065 loss：0.147622
【train】 epoch：1 step:5055/14065 loss：0.228301
【train】 epoch：1 step:5056/14065 loss：0.115711
【train】 epoch：1 step:5057/14065 loss：0.249876
【train】 epoch：1 step:5058/14065 loss：0.100681
【train】 epoch：1 step:5059/14065 loss：0.110377
【train】 epoch：1 step:5060/14065 loss：0.171622
【train】 epoch：1 step:5061/14065 loss：0.054218
【train】 epoch：1 step:5062/14065 loss：0.227430
【train】 epoch：1 step:5063/14065 loss：0.223339
【train】 epoch：1 step:5064/14065 loss：0.140750
【train】 epoch：1 step:5065/14065 loss：0.104055
【train】 epoch：1 step:5066/14065 loss：0.102987
【train】 epoch：1 step:5067/14065 loss：0.076375
【train】 epoch：1 step:5068/14065 loss：0.133016
【train】 epoch：1 step:5069/14065 loss：0.227159
【train】 epoch：1 step:5070/14065 loss：0.178324
【train】 epoch：1 step:5071/14065 loss：0.288425
【train】 epoch：1 step:5072/14065 loss：0.200548
【train】 epoch：1 step:5073/14065 loss：0.158323
【train】 epoch：1 step:5074/14065 loss：0.104679
【train】 epoch：1 step:5075/14065 loss：0.068977
【train】 epoch：1 step:5076/14065 loss：0.254613
【train】 epoch：1 step:5077/14065 loss：0.086412
【train】 epoch：1 step:5078/14065 loss：0.169231
【train】 epoch：1 step:5079/14065 loss：0.099195
【train】 epoch：1 step:5080/14065 loss：0.073934
【train】 epoch：1 step:5081/14065 loss：0.087251
【train】 epoch：1 step:5082/14065 loss：0.147728
【train】 epoch：1 step:5083/14065 loss：0.099868
【train】 epoch：1 step:5084/14065 loss：0.148473
【train】 epoch：1 step:5085/14065 loss：0.258300
【train】 epoch：1 step:5086/14065 loss：0.141955
【train】 epoch：1 step:5087/14065 loss：0.069219
【train】 epoch：1 step:5088/14065 loss：0.238383
【train】 epoch：1 step:5089/14065 loss：0.105658
【train】 epoch：1 step:5090/14065 loss：0.081587
【train】 epoch：1 step:5091/14065 loss：0.254480
【train】 epoch：1 step:5092/14065 loss：0.173578
【train】 epoch：1 step:5093/14065 loss：0.135276
【train】 epoch：1 step:5094/14065 loss：0.096043
【train】 epoch：1 step:5095/14065 loss：0.104375
【train】 epoch：1 step:5096/14065 loss：0.094137
【train】 epoch：1 step:5097/14065 loss：0.184204
【train】 epoch：1 step:5098/14065 loss：0.065990
【train】 epoch：1 step:5099/14065 loss：0.075173
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：242.654780 accuracy：0.9723 precision：0.9723 recall：0.9723 f1：0.9723
【train】 epoch：1 step:5100/14065 loss：0.254595
【train】 epoch：1 step:5101/14065 loss：0.106119
【train】 epoch：1 step:5102/14065 loss：0.203791
【train】 epoch：1 step:5103/14065 loss：0.070563
【train】 epoch：1 step:5104/14065 loss：0.130877
【train】 epoch：1 step:5105/14065 loss：0.036943
【train】 epoch：1 step:5106/14065 loss：0.148111
【train】 epoch：1 step:5107/14065 loss：0.154234
【train】 epoch：1 step:5108/14065 loss：0.346112
【train】 epoch：1 step:5109/14065 loss：0.077807
【train】 epoch：1 step:5110/14065 loss：0.271858
【train】 epoch：1 step:5111/14065 loss：0.191677
【train】 epoch：1 step:5112/14065 loss：0.069881
【train】 epoch：1 step:5113/14065 loss：0.164168
【train】 epoch：1 step:5114/14065 loss：0.191464
【train】 epoch：1 step:5115/14065 loss：0.179652
【train】 epoch：1 step:5116/14065 loss：0.157864
【train】 epoch：1 step:5117/14065 loss：0.194279
【train】 epoch：1 step:5118/14065 loss：0.086888
【train】 epoch：1 step:5119/14065 loss：0.203645
【train】 epoch：1 step:5120/14065 loss：0.149570
【train】 epoch：1 step:5121/14065 loss：0.107365
【train】 epoch：1 step:5122/14065 loss：0.171534
【train】 epoch：1 step:5123/14065 loss：0.124067
【train】 epoch：1 step:5124/14065 loss：0.092058
【train】 epoch：1 step:5125/14065 loss：0.135941
【train】 epoch：1 step:5126/14065 loss：0.039916
【train】 epoch：1 step:5127/14065 loss：0.108092
【train】 epoch：1 step:5128/14065 loss：0.158940
【train】 epoch：1 step:5129/14065 loss：0.162042
【train】 epoch：1 step:5130/14065 loss：0.126007
【train】 epoch：1 step:5131/14065 loss：0.045174
【train】 epoch：1 step:5132/14065 loss：0.249799
【train】 epoch：1 step:5133/14065 loss：0.135874
【train】 epoch：1 step:5134/14065 loss：0.089293
【train】 epoch：1 step:5135/14065 loss：0.111688
【train】 epoch：1 step:5136/14065 loss：0.073968
【train】 epoch：1 step:5137/14065 loss：0.174059
【train】 epoch：1 step:5138/14065 loss：0.410982
【train】 epoch：1 step:5139/14065 loss：0.060425
【train】 epoch：1 step:5140/14065 loss：0.103763
【train】 epoch：1 step:5141/14065 loss：0.168338
【train】 epoch：1 step:5142/14065 loss：0.048827
【train】 epoch：1 step:5143/14065 loss：0.179218
【train】 epoch：1 step:5144/14065 loss：0.170117
【train】 epoch：1 step:5145/14065 loss：0.206536
【train】 epoch：1 step:5146/14065 loss：0.104574
【train】 epoch：1 step:5147/14065 loss：0.105696
【train】 epoch：1 step:5148/14065 loss：0.056053
【train】 epoch：1 step:5149/14065 loss：0.324223
【train】 epoch：1 step:5150/14065 loss：0.238666
【train】 epoch：1 step:5151/14065 loss：0.145885
【train】 epoch：1 step:5152/14065 loss：0.075423
【train】 epoch：1 step:5153/14065 loss：0.212526
【train】 epoch：1 step:5154/14065 loss：0.342145
【train】 epoch：1 step:5155/14065 loss：0.094859
【train】 epoch：1 step:5156/14065 loss：0.087051
【train】 epoch：1 step:5157/14065 loss：0.245111
【train】 epoch：1 step:5158/14065 loss：0.102028
【train】 epoch：1 step:5159/14065 loss：0.135186
【train】 epoch：1 step:5160/14065 loss：0.175744
【train】 epoch：1 step:5161/14065 loss：0.224810
【train】 epoch：1 step:5162/14065 loss：0.074992
【train】 epoch：1 step:5163/14065 loss：0.042867
【train】 epoch：1 step:5164/14065 loss：0.220141
【train】 epoch：1 step:5165/14065 loss：0.092158
【train】 epoch：1 step:5166/14065 loss：0.036819
【train】 epoch：1 step:5167/14065 loss：0.116884
【train】 epoch：1 step:5168/14065 loss：0.055352
【train】 epoch：1 step:5169/14065 loss：0.076154
【train】 epoch：1 step:5170/14065 loss：0.091875
【train】 epoch：1 step:5171/14065 loss：0.254312
【train】 epoch：1 step:5172/14065 loss：0.137726
【train】 epoch：1 step:5173/14065 loss：0.038813
【train】 epoch：1 step:5174/14065 loss：0.107180
【train】 epoch：1 step:5175/14065 loss：0.223004
【train】 epoch：1 step:5176/14065 loss：0.135503
【train】 epoch：1 step:5177/14065 loss：0.142297
【train】 epoch：1 step:5178/14065 loss：0.082716
【train】 epoch：1 step:5179/14065 loss：0.139932
【train】 epoch：1 step:5180/14065 loss：0.079449
【train】 epoch：1 step:5181/14065 loss：0.214775
【train】 epoch：1 step:5182/14065 loss：0.113429
【train】 epoch：1 step:5183/14065 loss：0.055424
【train】 epoch：1 step:5184/14065 loss：0.102881
【train】 epoch：1 step:5185/14065 loss：0.098684
【train】 epoch：1 step:5186/14065 loss：0.088253
【train】 epoch：1 step:5187/14065 loss：0.039650
【train】 epoch：1 step:5188/14065 loss：0.120495
【train】 epoch：1 step:5189/14065 loss：0.050012
【train】 epoch：1 step:5190/14065 loss：0.140153
【train】 epoch：1 step:5191/14065 loss：0.183888
【train】 epoch：1 step:5192/14065 loss：0.108154
【train】 epoch：1 step:5193/14065 loss：0.214719
【train】 epoch：1 step:5194/14065 loss：0.069944
【train】 epoch：1 step:5195/14065 loss：0.256295
【train】 epoch：1 step:5196/14065 loss：0.088328
【train】 epoch：1 step:5197/14065 loss：0.161561
【train】 epoch：1 step:5198/14065 loss：0.240068
【train】 epoch：1 step:5199/14065 loss：0.222554
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：271.586450 accuracy：0.9682 precision：0.9682 recall：0.9682 f1：0.9682
【train】 epoch：1 step:5200/14065 loss：0.093075
【train】 epoch：1 step:5201/14065 loss：0.054256
【train】 epoch：1 step:5202/14065 loss：0.080319
【train】 epoch：1 step:5203/14065 loss：0.164890
【train】 epoch：1 step:5204/14065 loss：0.144417
【train】 epoch：1 step:5205/14065 loss：0.086339
【train】 epoch：1 step:5206/14065 loss：0.018152
【train】 epoch：1 step:5207/14065 loss：0.158582
【train】 epoch：1 step:5208/14065 loss：0.136959
【train】 epoch：1 step:5209/14065 loss：0.238088
【train】 epoch：1 step:5210/14065 loss：0.178095
【train】 epoch：1 step:5211/14065 loss：0.215398
【train】 epoch：1 step:5212/14065 loss：0.128032
【train】 epoch：1 step:5213/14065 loss：0.067338
【train】 epoch：1 step:5214/14065 loss：0.205698
【train】 epoch：1 step:5215/14065 loss：0.125174
【train】 epoch：1 step:5216/14065 loss：0.050766
【train】 epoch：1 step:5217/14065 loss：0.159177
【train】 epoch：1 step:5218/14065 loss：0.152816
【train】 epoch：1 step:5219/14065 loss：0.224649
【train】 epoch：1 step:5220/14065 loss：0.047718
【train】 epoch：1 step:5221/14065 loss：0.128394
【train】 epoch：1 step:5222/14065 loss：0.079686
【train】 epoch：1 step:5223/14065 loss：0.118857
【train】 epoch：1 step:5224/14065 loss：0.233932
【train】 epoch：1 step:5225/14065 loss：0.192318
【train】 epoch：1 step:5226/14065 loss：0.084606
【train】 epoch：1 step:5227/14065 loss：0.132711
【train】 epoch：1 step:5228/14065 loss：0.175057
【train】 epoch：1 step:5229/14065 loss：0.113051
【train】 epoch：1 step:5230/14065 loss：0.135293
【train】 epoch：1 step:5231/14065 loss：0.221012
【train】 epoch：1 step:5232/14065 loss：0.193689
【train】 epoch：1 step:5233/14065 loss：0.095499
【train】 epoch：1 step:5234/14065 loss：0.024802
【train】 epoch：1 step:5235/14065 loss：0.098502
【train】 epoch：1 step:5236/14065 loss：0.100349
【train】 epoch：1 step:5237/14065 loss：0.203443
【train】 epoch：1 step:5238/14065 loss：0.161778
【train】 epoch：1 step:5239/14065 loss：0.256009
【train】 epoch：1 step:5240/14065 loss：0.144159
【train】 epoch：1 step:5241/14065 loss：0.322776
【train】 epoch：1 step:5242/14065 loss：0.126756
【train】 epoch：1 step:5243/14065 loss：0.143187
【train】 epoch：1 step:5244/14065 loss：0.067518
【train】 epoch：1 step:5245/14065 loss：0.104058
【train】 epoch：1 step:5246/14065 loss：0.128358
【train】 epoch：1 step:5247/14065 loss：0.065397
【train】 epoch：1 step:5248/14065 loss：0.075629
【train】 epoch：1 step:5249/14065 loss：0.040163
【train】 epoch：1 step:5250/14065 loss：0.212483
【train】 epoch：1 step:5251/14065 loss：0.151201
【train】 epoch：1 step:5252/14065 loss：0.035951
【train】 epoch：1 step:5253/14065 loss：0.096149
【train】 epoch：1 step:5254/14065 loss：0.103779
【train】 epoch：1 step:5255/14065 loss：0.217171
【train】 epoch：1 step:5256/14065 loss：0.305285
【train】 epoch：1 step:5257/14065 loss：0.085742
【train】 epoch：1 step:5258/14065 loss：0.080549
【train】 epoch：1 step:5259/14065 loss：0.149464
【train】 epoch：1 step:5260/14065 loss：0.046144
【train】 epoch：1 step:5261/14065 loss：0.094160
【train】 epoch：1 step:5262/14065 loss：0.066699
【train】 epoch：1 step:5263/14065 loss：0.190804
【train】 epoch：1 step:5264/14065 loss：0.063308
【train】 epoch：1 step:5265/14065 loss：0.055973
【train】 epoch：1 step:5266/14065 loss：0.047110
【train】 epoch：1 step:5267/14065 loss：0.061630
【train】 epoch：1 step:5268/14065 loss：0.150322
【train】 epoch：1 step:5269/14065 loss：0.171432
【train】 epoch：1 step:5270/14065 loss：0.268979
【train】 epoch：1 step:5271/14065 loss：0.152190
【train】 epoch：1 step:5272/14065 loss：0.027788
【train】 epoch：1 step:5273/14065 loss：0.157266
【train】 epoch：1 step:5274/14065 loss：0.104635
【train】 epoch：1 step:5275/14065 loss：0.046002
【train】 epoch：1 step:5276/14065 loss：0.062886
【train】 epoch：1 step:5277/14065 loss：0.049693
【train】 epoch：1 step:5278/14065 loss：0.121796
【train】 epoch：1 step:5279/14065 loss：0.198284
【train】 epoch：1 step:5280/14065 loss：0.018399
【train】 epoch：1 step:5281/14065 loss：0.156514
【train】 epoch：1 step:5282/14065 loss：0.183405
【train】 epoch：1 step:5283/14065 loss：0.107104
【train】 epoch：1 step:5284/14065 loss：0.053686
【train】 epoch：1 step:5285/14065 loss：0.180823
【train】 epoch：1 step:5286/14065 loss：0.021251
【train】 epoch：1 step:5287/14065 loss：0.205954
【train】 epoch：1 step:5288/14065 loss：0.256706
【train】 epoch：1 step:5289/14065 loss：0.106024
【train】 epoch：1 step:5290/14065 loss：0.259977
【train】 epoch：1 step:5291/14065 loss：0.106885
【train】 epoch：1 step:5292/14065 loss：0.022630
【train】 epoch：1 step:5293/14065 loss：0.225956
【train】 epoch：1 step:5294/14065 loss：0.249956
【train】 epoch：1 step:5295/14065 loss：0.069029
【train】 epoch：1 step:5296/14065 loss：0.149827
【train】 epoch：1 step:5297/14065 loss：0.131924
【train】 epoch：1 step:5298/14065 loss：0.067715
【train】 epoch：1 step:5299/14065 loss：0.135413
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：237.769620 accuracy：0.9722 precision：0.9722 recall：0.9722 f1：0.9722
【train】 epoch：1 step:5300/14065 loss：0.079676
【train】 epoch：1 step:5301/14065 loss：0.126887
【train】 epoch：1 step:5302/14065 loss：0.175560
【train】 epoch：1 step:5303/14065 loss：0.300499
【train】 epoch：1 step:5304/14065 loss：0.267075
【train】 epoch：1 step:5305/14065 loss：0.133764
【train】 epoch：1 step:5306/14065 loss：0.204828
【train】 epoch：1 step:5307/14065 loss：0.141084
【train】 epoch：1 step:5308/14065 loss：0.174301
【train】 epoch：1 step:5309/14065 loss：0.060084
【train】 epoch：1 step:5310/14065 loss：0.064560
【train】 epoch：1 step:5311/14065 loss：0.062023
【train】 epoch：1 step:5312/14065 loss：0.046628
【train】 epoch：1 step:5313/14065 loss：0.090213
【train】 epoch：1 step:5314/14065 loss：0.134848
【train】 epoch：1 step:5315/14065 loss：0.173914
【train】 epoch：1 step:5316/14065 loss：0.152095
【train】 epoch：1 step:5317/14065 loss：0.155864
【train】 epoch：1 step:5318/14065 loss：0.094957
【train】 epoch：1 step:5319/14065 loss：0.060132
【train】 epoch：1 step:5320/14065 loss：0.146635
【train】 epoch：1 step:5321/14065 loss：0.068323
【train】 epoch：1 step:5322/14065 loss：0.166021
【train】 epoch：1 step:5323/14065 loss：0.144011
【train】 epoch：1 step:5324/14065 loss：0.045273
【train】 epoch：1 step:5325/14065 loss：0.205457
【train】 epoch：1 step:5326/14065 loss：0.110629
【train】 epoch：1 step:5327/14065 loss：0.124200
【train】 epoch：1 step:5328/14065 loss：0.146730
【train】 epoch：1 step:5329/14065 loss：0.130402
【train】 epoch：1 step:5330/14065 loss：0.043445
【train】 epoch：1 step:5331/14065 loss：0.271966
【train】 epoch：1 step:5332/14065 loss：0.135763
【train】 epoch：1 step:5333/14065 loss：0.134932
【train】 epoch：1 step:5334/14065 loss：0.079372
【train】 epoch：1 step:5335/14065 loss：0.146963
【train】 epoch：1 step:5336/14065 loss：0.063622
【train】 epoch：1 step:5337/14065 loss：0.098977
【train】 epoch：1 step:5338/14065 loss：0.162132
【train】 epoch：1 step:5339/14065 loss：0.286149
【train】 epoch：1 step:5340/14065 loss：0.142769
【train】 epoch：1 step:5341/14065 loss：0.117156
【train】 epoch：1 step:5342/14065 loss：0.066707
【train】 epoch：1 step:5343/14065 loss：0.046684
【train】 epoch：1 step:5344/14065 loss：0.082952
【train】 epoch：1 step:5345/14065 loss：0.031179
【train】 epoch：1 step:5346/14065 loss：0.137425
【train】 epoch：1 step:5347/14065 loss：0.036308
【train】 epoch：1 step:5348/14065 loss：0.110059
【train】 epoch：1 step:5349/14065 loss：0.033407
【train】 epoch：1 step:5350/14065 loss：0.201795
【train】 epoch：1 step:5351/14065 loss：0.177479
【train】 epoch：1 step:5352/14065 loss：0.124322
【train】 epoch：1 step:5353/14065 loss：0.190988
【train】 epoch：1 step:5354/14065 loss：0.146621
【train】 epoch：1 step:5355/14065 loss：0.246001
【train】 epoch：1 step:5356/14065 loss：0.302230
【train】 epoch：1 step:5357/14065 loss：0.099327
【train】 epoch：1 step:5358/14065 loss：0.083512
【train】 epoch：1 step:5359/14065 loss：0.099857
【train】 epoch：1 step:5360/14065 loss：0.127087
【train】 epoch：1 step:5361/14065 loss：0.374901
【train】 epoch：1 step:5362/14065 loss：0.058638
【train】 epoch：1 step:5363/14065 loss：0.223801
【train】 epoch：1 step:5364/14065 loss：0.123622
【train】 epoch：1 step:5365/14065 loss：0.049188
【train】 epoch：1 step:5366/14065 loss：0.077562
【train】 epoch：1 step:5367/14065 loss：0.214601
【train】 epoch：1 step:5368/14065 loss：0.189260
【train】 epoch：1 step:5369/14065 loss：0.211061
【train】 epoch：1 step:5370/14065 loss：0.212730
【train】 epoch：1 step:5371/14065 loss：0.069902
【train】 epoch：1 step:5372/14065 loss：0.039391
【train】 epoch：1 step:5373/14065 loss：0.046318
【train】 epoch：1 step:5374/14065 loss：0.176460
【train】 epoch：1 step:5375/14065 loss：0.066204
【train】 epoch：1 step:5376/14065 loss：0.172435
【train】 epoch：1 step:5377/14065 loss：0.235534
【train】 epoch：1 step:5378/14065 loss：0.166262
【train】 epoch：1 step:5379/14065 loss：0.061623
【train】 epoch：1 step:5380/14065 loss：0.305391
【train】 epoch：1 step:5381/14065 loss：0.237911
【train】 epoch：1 step:5382/14065 loss：0.062542
【train】 epoch：1 step:5383/14065 loss：0.202444
【train】 epoch：1 step:5384/14065 loss：0.027161
【train】 epoch：1 step:5385/14065 loss：0.174407
【train】 epoch：1 step:5386/14065 loss：0.169383
【train】 epoch：1 step:5387/14065 loss：0.096309
【train】 epoch：1 step:5388/14065 loss：0.196743
【train】 epoch：1 step:5389/14065 loss：0.123590
【train】 epoch：1 step:5390/14065 loss：0.084898
【train】 epoch：1 step:5391/14065 loss：0.087876
【train】 epoch：1 step:5392/14065 loss：0.236341
【train】 epoch：1 step:5393/14065 loss：0.136918
【train】 epoch：1 step:5394/14065 loss：0.008198
【train】 epoch：1 step:5395/14065 loss：0.245639
【train】 epoch：1 step:5396/14065 loss：0.167645
【train】 epoch：1 step:5397/14065 loss：0.117743
【train】 epoch：1 step:5398/14065 loss：0.112817
【train】 epoch：1 step:5399/14065 loss：0.096229
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：223.245566 accuracy：0.9746 precision：0.9746 recall：0.9746 f1：0.9746
------------>保存当前最好的模型
【train】 epoch：1 step:5400/14065 loss：0.050974
【train】 epoch：1 step:5401/14065 loss：0.045459
【train】 epoch：1 step:5402/14065 loss：0.062503
【train】 epoch：1 step:5403/14065 loss：0.134975
【train】 epoch：1 step:5404/14065 loss：0.106894
【train】 epoch：1 step:5405/14065 loss：0.052122
【train】 epoch：1 step:5406/14065 loss：0.216729
【train】 epoch：1 step:5407/14065 loss：0.098806
【train】 epoch：1 step:5408/14065 loss：0.112281
【train】 epoch：1 step:5409/14065 loss：0.235806
【train】 epoch：1 step:5410/14065 loss：0.071496
【train】 epoch：1 step:5411/14065 loss：0.123621
【train】 epoch：1 step:5412/14065 loss：0.079279
【train】 epoch：1 step:5413/14065 loss：0.260479
【train】 epoch：1 step:5414/14065 loss：0.111478
【train】 epoch：1 step:5415/14065 loss：0.166024
【train】 epoch：1 step:5416/14065 loss：0.058349
【train】 epoch：1 step:5417/14065 loss：0.071873
【train】 epoch：1 step:5418/14065 loss：0.147309
【train】 epoch：1 step:5419/14065 loss：0.172407
【train】 epoch：1 step:5420/14065 loss：0.142133
【train】 epoch：1 step:5421/14065 loss：0.114060
【train】 epoch：1 step:5422/14065 loss：0.187133
【train】 epoch：1 step:5423/14065 loss：0.098446
【train】 epoch：1 step:5424/14065 loss：0.032314
【train】 epoch：1 step:5425/14065 loss：0.257294
【train】 epoch：1 step:5426/14065 loss：0.071512
【train】 epoch：1 step:5427/14065 loss：0.085333
【train】 epoch：1 step:5428/14065 loss：0.031812
【train】 epoch：1 step:5429/14065 loss：0.096232
【train】 epoch：1 step:5430/14065 loss：0.125861
【train】 epoch：1 step:5431/14065 loss：0.094327
【train】 epoch：1 step:5432/14065 loss：0.118791
【train】 epoch：1 step:5433/14065 loss：0.096492
【train】 epoch：1 step:5434/14065 loss：0.054755
【train】 epoch：1 step:5435/14065 loss：0.194130
【train】 epoch：1 step:5436/14065 loss：0.064447
【train】 epoch：1 step:5437/14065 loss：0.088408
【train】 epoch：1 step:5438/14065 loss：0.039021
【train】 epoch：1 step:5439/14065 loss：0.051437
【train】 epoch：1 step:5440/14065 loss：0.159974
【train】 epoch：1 step:5441/14065 loss：0.129659
【train】 epoch：1 step:5442/14065 loss：0.098324
【train】 epoch：1 step:5443/14065 loss：0.121202
【train】 epoch：1 step:5444/14065 loss：0.140136
【train】 epoch：1 step:5445/14065 loss：0.139854
【train】 epoch：1 step:5446/14065 loss：0.044056
【train】 epoch：1 step:5447/14065 loss：0.127417
【train】 epoch：1 step:5448/14065 loss：0.132248
【train】 epoch：1 step:5449/14065 loss：0.204274
【train】 epoch：1 step:5450/14065 loss：0.119994
【train】 epoch：1 step:5451/14065 loss：0.112574
【train】 epoch：1 step:5452/14065 loss：0.290045
【train】 epoch：1 step:5453/14065 loss：0.206947
【train】 epoch：1 step:5454/14065 loss：0.187808
【train】 epoch：1 step:5455/14065 loss：0.157877
【train】 epoch：1 step:5456/14065 loss：0.019254
【train】 epoch：1 step:5457/14065 loss：0.081425
【train】 epoch：1 step:5458/14065 loss：0.317930
【train】 epoch：1 step:5459/14065 loss：0.179533
【train】 epoch：1 step:5460/14065 loss：0.090550
【train】 epoch：1 step:5461/14065 loss：0.249393
【train】 epoch：1 step:5462/14065 loss：0.057328
【train】 epoch：1 step:5463/14065 loss：0.180313
【train】 epoch：1 step:5464/14065 loss：0.046243
【train】 epoch：1 step:5465/14065 loss：0.161845
【train】 epoch：1 step:5466/14065 loss：0.147766
【train】 epoch：1 step:5467/14065 loss：0.205495
【train】 epoch：1 step:5468/14065 loss：0.024234
【train】 epoch：1 step:5469/14065 loss：0.195461
【train】 epoch：1 step:5470/14065 loss：0.075840
【train】 epoch：1 step:5471/14065 loss：0.168222
【train】 epoch：1 step:5472/14065 loss：0.122506
【train】 epoch：1 step:5473/14065 loss：0.108514
【train】 epoch：1 step:5474/14065 loss：0.072280
【train】 epoch：1 step:5475/14065 loss：0.058664
【train】 epoch：1 step:5476/14065 loss：0.102623
【train】 epoch：1 step:5477/14065 loss：0.182642
【train】 epoch：1 step:5478/14065 loss：0.109235
【train】 epoch：1 step:5479/14065 loss：0.246935
【train】 epoch：1 step:5480/14065 loss：0.152438
【train】 epoch：1 step:5481/14065 loss：0.173467
【train】 epoch：1 step:5482/14065 loss：0.139415
【train】 epoch：1 step:5483/14065 loss：0.210126
【train】 epoch：1 step:5484/14065 loss：0.125039
【train】 epoch：1 step:5485/14065 loss：0.113277
【train】 epoch：1 step:5486/14065 loss：0.125226
【train】 epoch：1 step:5487/14065 loss：0.102605
【train】 epoch：1 step:5488/14065 loss：0.106605
【train】 epoch：1 step:5489/14065 loss：0.085597
【train】 epoch：1 step:5490/14065 loss：0.044825
【train】 epoch：1 step:5491/14065 loss：0.152980
【train】 epoch：1 step:5492/14065 loss：0.142801
【train】 epoch：1 step:5493/14065 loss：0.076399
【train】 epoch：1 step:5494/14065 loss：0.168896
【train】 epoch：1 step:5495/14065 loss：0.143116
【train】 epoch：1 step:5496/14065 loss：0.087490
【train】 epoch：1 step:5497/14065 loss：0.073449
【train】 epoch：1 step:5498/14065 loss：0.047710
【train】 epoch：1 step:5499/14065 loss：0.068495
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：211.892932 accuracy：0.9759 precision：0.9759 recall：0.9759 f1：0.9759
------------>保存当前最好的模型
【train】 epoch：1 step:5500/14065 loss：0.136038
【train】 epoch：1 step:5501/14065 loss：0.160688
【train】 epoch：1 step:5502/14065 loss：0.146755
【train】 epoch：1 step:5503/14065 loss：0.075634
【train】 epoch：1 step:5504/14065 loss：0.135534
【train】 epoch：1 step:5505/14065 loss：0.221530
【train】 epoch：1 step:5506/14065 loss：0.100237
【train】 epoch：1 step:5507/14065 loss：0.121491
【train】 epoch：1 step:5508/14065 loss：0.053491
【train】 epoch：1 step:5509/14065 loss：0.136153
【train】 epoch：1 step:5510/14065 loss：0.069653
【train】 epoch：1 step:5511/14065 loss：0.183022
【train】 epoch：1 step:5512/14065 loss：0.163927
【train】 epoch：1 step:5513/14065 loss：0.085762
【train】 epoch：1 step:5514/14065 loss：0.174504
【train】 epoch：1 step:5515/14065 loss：0.020604
【train】 epoch：1 step:5516/14065 loss：0.155154
【train】 epoch：1 step:5517/14065 loss：0.143414
【train】 epoch：1 step:5518/14065 loss：0.136580
【train】 epoch：1 step:5519/14065 loss：0.254196
【train】 epoch：1 step:5520/14065 loss：0.259426
【train】 epoch：1 step:5521/14065 loss：0.217771
【train】 epoch：1 step:5522/14065 loss：0.207011
【train】 epoch：1 step:5523/14065 loss：0.049005
【train】 epoch：1 step:5524/14065 loss：0.108652
【train】 epoch：1 step:5525/14065 loss：0.178574
【train】 epoch：1 step:5526/14065 loss：0.123939
【train】 epoch：1 step:5527/14065 loss：0.199414
【train】 epoch：1 step:5528/14065 loss：0.079771
【train】 epoch：1 step:5529/14065 loss：0.110497
【train】 epoch：1 step:5530/14065 loss：0.133797
【train】 epoch：1 step:5531/14065 loss：0.159617
【train】 epoch：1 step:5532/14065 loss：0.087684
【train】 epoch：1 step:5533/14065 loss：0.268158
【train】 epoch：1 step:5534/14065 loss：0.119224
【train】 epoch：1 step:5535/14065 loss：0.100378
【train】 epoch：1 step:5536/14065 loss：0.074330
【train】 epoch：1 step:5537/14065 loss：0.345024
【train】 epoch：1 step:5538/14065 loss：0.192883
【train】 epoch：1 step:5539/14065 loss：0.318416
【train】 epoch：1 step:5540/14065 loss：0.116548
【train】 epoch：1 step:5541/14065 loss：0.237622
【train】 epoch：1 step:5542/14065 loss：0.066811
【train】 epoch：1 step:5543/14065 loss：0.253098
【train】 epoch：1 step:5544/14065 loss：0.195034
【train】 epoch：1 step:5545/14065 loss：0.134601
【train】 epoch：1 step:5546/14065 loss：0.153848
【train】 epoch：1 step:5547/14065 loss：0.119967
【train】 epoch：1 step:5548/14065 loss：0.104429
【train】 epoch：1 step:5549/14065 loss：0.104815
【train】 epoch：1 step:5550/14065 loss：0.078677
【train】 epoch：1 step:5551/14065 loss：0.164664
【train】 epoch：1 step:5552/14065 loss：0.186208
【train】 epoch：1 step:5553/14065 loss：0.088782
【train】 epoch：1 step:5554/14065 loss：0.365889
【train】 epoch：1 step:5555/14065 loss：0.204524
【train】 epoch：1 step:5556/14065 loss：0.112988
【train】 epoch：1 step:5557/14065 loss：0.164952
【train】 epoch：1 step:5558/14065 loss：0.155360
【train】 epoch：1 step:5559/14065 loss：0.125375
【train】 epoch：1 step:5560/14065 loss：0.282484
【train】 epoch：1 step:5561/14065 loss：0.037223
【train】 epoch：1 step:5562/14065 loss：0.187702
【train】 epoch：1 step:5563/14065 loss：0.167469
【train】 epoch：1 step:5564/14065 loss：0.172631
【train】 epoch：1 step:5565/14065 loss：0.113355
【train】 epoch：1 step:5566/14065 loss：0.143577
【train】 epoch：1 step:5567/14065 loss：0.100889
【train】 epoch：1 step:5568/14065 loss：0.134078
【train】 epoch：1 step:5569/14065 loss：0.182798
【train】 epoch：1 step:5570/14065 loss：0.063913
【train】 epoch：1 step:5571/14065 loss：0.095623
【train】 epoch：1 step:5572/14065 loss：0.070037
【train】 epoch：1 step:5573/14065 loss：0.089819
【train】 epoch：1 step:5574/14065 loss：0.073143
【train】 epoch：1 step:5575/14065 loss：0.117972
【train】 epoch：1 step:5576/14065 loss：0.200025
【train】 epoch：1 step:5577/14065 loss：0.140753
【train】 epoch：1 step:5578/14065 loss：0.097195
【train】 epoch：1 step:5579/14065 loss：0.240259
【train】 epoch：1 step:5580/14065 loss：0.122841
【train】 epoch：1 step:5581/14065 loss：0.039300
【train】 epoch：1 step:5582/14065 loss：0.097302
【train】 epoch：1 step:5583/14065 loss：0.176452
【train】 epoch：1 step:5584/14065 loss：0.128394
【train】 epoch：1 step:5585/14065 loss：0.114308
【train】 epoch：1 step:5586/14065 loss：0.181289
【train】 epoch：1 step:5587/14065 loss：0.182334
【train】 epoch：1 step:5588/14065 loss：0.077244
【train】 epoch：1 step:5589/14065 loss：0.221905
【train】 epoch：1 step:5590/14065 loss：0.271435
【train】 epoch：1 step:5591/14065 loss：0.156667
【train】 epoch：1 step:5592/14065 loss：0.027276
【train】 epoch：1 step:5593/14065 loss：0.110320
【train】 epoch：1 step:5594/14065 loss：0.171743
【train】 epoch：1 step:5595/14065 loss：0.144044
【train】 epoch：1 step:5596/14065 loss：0.204417
【train】 epoch：1 step:5597/14065 loss：0.140574
【train】 epoch：1 step:5598/14065 loss：0.156958
【train】 epoch：1 step:5599/14065 loss：0.135973
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：214.089636 accuracy：0.9762 precision：0.9762 recall：0.9762 f1：0.9762
------------>保存当前最好的模型
【train】 epoch：1 step:5600/14065 loss：0.148136
【train】 epoch：1 step:5601/14065 loss：0.150516
【train】 epoch：1 step:5602/14065 loss：0.109205
【train】 epoch：1 step:5603/14065 loss：0.075781
【train】 epoch：1 step:5604/14065 loss：0.040541
【train】 epoch：1 step:5605/14065 loss：0.157961
【train】 epoch：1 step:5606/14065 loss：0.089833
【train】 epoch：1 step:5607/14065 loss：0.088182
【train】 epoch：1 step:5608/14065 loss：0.224865
【train】 epoch：1 step:5609/14065 loss：0.274704
【train】 epoch：1 step:5610/14065 loss：0.127233
【train】 epoch：1 step:5611/14065 loss：0.142599
【train】 epoch：1 step:5612/14065 loss：0.190058
【train】 epoch：1 step:5613/14065 loss：0.235686
【train】 epoch：1 step:5614/14065 loss：0.087023
【train】 epoch：1 step:5615/14065 loss：0.161413
【train】 epoch：1 step:5616/14065 loss：0.100837
【train】 epoch：1 step:5617/14065 loss：0.200939
【train】 epoch：1 step:5618/14065 loss：0.155256
【train】 epoch：1 step:5619/14065 loss：0.087414
【train】 epoch：1 step:5620/14065 loss：0.148353
【train】 epoch：1 step:5621/14065 loss：0.054397
【train】 epoch：1 step:5622/14065 loss：0.172986
【train】 epoch：1 step:5623/14065 loss：0.146479
【train】 epoch：1 step:5624/14065 loss：0.188236
【train】 epoch：1 step:5625/14065 loss：0.190784
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【train】 epoch：2 step:5626/14065 loss：0.049546
【train】 epoch：2 step:5627/14065 loss：0.183664
【train】 epoch：2 step:5628/14065 loss：0.186823
【train】 epoch：2 step:5629/14065 loss：0.067633
【train】 epoch：2 step:5630/14065 loss：0.067269
【train】 epoch：2 step:5631/14065 loss：0.178826
【train】 epoch：2 step:5632/14065 loss：0.072113
【train】 epoch：2 step:5633/14065 loss：0.063574
【train】 epoch：2 step:5634/14065 loss：0.320077
【train】 epoch：2 step:5635/14065 loss：0.085743
【train】 epoch：2 step:5636/14065 loss：0.067887
【train】 epoch：2 step:5637/14065 loss：0.113814
【train】 epoch：2 step:5638/14065 loss：0.141213
【train】 epoch：2 step:5639/14065 loss：0.155371
【train】 epoch：2 step:5640/14065 loss：0.082897
【train】 epoch：2 step:5641/14065 loss：0.116912
【train】 epoch：2 step:5642/14065 loss：0.105093
【train】 epoch：2 step:5643/14065 loss：0.088656
【train】 epoch：2 step:5644/14065 loss：0.017099
【train】 epoch：2 step:5645/14065 loss：0.070027
【train】 epoch：2 step:5646/14065 loss：0.110153
【train】 epoch：2 step:5647/14065 loss：0.036327
【train】 epoch：2 step:5648/14065 loss：0.291823
【train】 epoch：2 step:5649/14065 loss：0.132928
【train】 epoch：2 step:5650/14065 loss：0.138422
【train】 epoch：2 step:5651/14065 loss：0.085061
【train】 epoch：2 step:5652/14065 loss：0.034733
【train】 epoch：2 step:5653/14065 loss：0.035241
【train】 epoch：2 step:5654/14065 loss：0.076004
【train】 epoch：2 step:5655/14065 loss：0.048841
【train】 epoch：2 step:5656/14065 loss：0.047671
【train】 epoch：2 step:5657/14065 loss：0.051688
【train】 epoch：2 step:5658/14065 loss：0.145008
【train】 epoch：2 step:5659/14065 loss：0.037041
【train】 epoch：2 step:5660/14065 loss：0.110465
【train】 epoch：2 step:5661/14065 loss：0.032420
【train】 epoch：2 step:5662/14065 loss：0.038057
【train】 epoch：2 step:5663/14065 loss：0.138715
【train】 epoch：2 step:5664/14065 loss：0.126053
【train】 epoch：2 step:5665/14065 loss：0.026717
【train】 epoch：2 step:5666/14065 loss：0.076110
【train】 epoch：2 step:5667/14065 loss：0.113261
【train】 epoch：2 step:5668/14065 loss：0.118109
【train】 epoch：2 step:5669/14065 loss：0.097963
【train】 epoch：2 step:5670/14065 loss：0.045756
【train】 epoch：2 step:5671/14065 loss：0.074719
【train】 epoch：2 step:5672/14065 loss：0.174938
【train】 epoch：2 step:5673/14065 loss：0.058220
【train】 epoch：2 step:5674/14065 loss：0.148135
【train】 epoch：2 step:5675/14065 loss：0.075514
【train】 epoch：2 step:5676/14065 loss：0.171100
【train】 epoch：2 step:5677/14065 loss：0.034762
【train】 epoch：2 step:5678/14065 loss：0.062796
【train】 epoch：2 step:5679/14065 loss：0.128899
【train】 epoch：2 step:5680/14065 loss：0.076396
【train】 epoch：2 step:5681/14065 loss：0.086396
【train】 epoch：2 step:5682/14065 loss：0.018207
【train】 epoch：2 step:5683/14065 loss：0.035408
【train】 epoch：2 step:5684/14065 loss：0.037737
【train】 epoch：2 step:5685/14065 loss：0.116213
【train】 epoch：2 step:5686/14065 loss：0.072528
【train】 epoch：2 step:5687/14065 loss：0.091794
【train】 epoch：2 step:5688/14065 loss：0.009732
【train】 epoch：2 step:5689/14065 loss：0.194303
【train】 epoch：2 step:5690/14065 loss：0.185442
【train】 epoch：2 step:5691/14065 loss：0.028004
【train】 epoch：2 step:5692/14065 loss：0.120198
【train】 epoch：2 step:5693/14065 loss：0.048164
【train】 epoch：2 step:5694/14065 loss：0.046065
【train】 epoch：2 step:5695/14065 loss：0.146972
【train】 epoch：2 step:5696/14065 loss：0.113883
【train】 epoch：2 step:5697/14065 loss：0.072676
【train】 epoch：2 step:5698/14065 loss：0.076030
【train】 epoch：2 step:5699/14065 loss：0.084601
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：202.035626 accuracy：0.9769 precision：0.9769 recall：0.9769 f1：0.9769
------------>保存当前最好的模型
【train】 epoch：2 step:5700/14065 loss：0.022763
【train】 epoch：2 step:5701/14065 loss：0.076235
【train】 epoch：2 step:5702/14065 loss：0.146823
【train】 epoch：2 step:5703/14065 loss：0.090025
【train】 epoch：2 step:5704/14065 loss：0.076458
【train】 epoch：2 step:5705/14065 loss：0.052854
【train】 epoch：2 step:5706/14065 loss：0.087440
【train】 epoch：2 step:5707/14065 loss：0.020613
【train】 epoch：2 step:5708/14065 loss：0.102278
【train】 epoch：2 step:5709/14065 loss：0.074908
【train】 epoch：2 step:5710/14065 loss：0.029567
【train】 epoch：2 step:5711/14065 loss：0.083215
【train】 epoch：2 step:5712/14065 loss：0.084305
【train】 epoch：2 step:5713/14065 loss：0.028065
【train】 epoch：2 step:5714/14065 loss：0.081704
【train】 epoch：2 step:5715/14065 loss：0.039621
【train】 epoch：2 step:5716/14065 loss：0.094085
【train】 epoch：2 step:5717/14065 loss：0.284306
【train】 epoch：2 step:5718/14065 loss：0.098397
【train】 epoch：2 step:5719/14065 loss：0.082647
【train】 epoch：2 step:5720/14065 loss：0.056196
【train】 epoch：2 step:5721/14065 loss：0.076093
【train】 epoch：2 step:5722/14065 loss：0.094701
【train】 epoch：2 step:5723/14065 loss：0.085306
【train】 epoch：2 step:5724/14065 loss：0.128353
【train】 epoch：2 step:5725/14065 loss：0.030448
【train】 epoch：2 step:5726/14065 loss：0.019957
【train】 epoch：2 step:5727/14065 loss：0.116859
【train】 epoch：2 step:5728/14065 loss：0.082660
【train】 epoch：2 step:5729/14065 loss：0.032166
【train】 epoch：2 step:5730/14065 loss：0.060940
【train】 epoch：2 step:5731/14065 loss：0.103102
【train】 epoch：2 step:5732/14065 loss：0.169506
【train】 epoch：2 step:5733/14065 loss：0.136530
【train】 epoch：2 step:5734/14065 loss：0.051112
【train】 epoch：2 step:5735/14065 loss：0.037257
【train】 epoch：2 step:5736/14065 loss：0.119051
【train】 epoch：2 step:5737/14065 loss：0.028454
【train】 epoch：2 step:5738/14065 loss：0.139201
【train】 epoch：2 step:5739/14065 loss：0.087947
【train】 epoch：2 step:5740/14065 loss：0.057583
【train】 epoch：2 step:5741/14065 loss：0.098095
【train】 epoch：2 step:5742/14065 loss：0.055526
【train】 epoch：2 step:5743/14065 loss：0.480013
【train】 epoch：2 step:5744/14065 loss：0.065898
【train】 epoch：2 step:5745/14065 loss：0.041284
【train】 epoch：2 step:5746/14065 loss：0.018025
【train】 epoch：2 step:5747/14065 loss：0.004477
【train】 epoch：2 step:5748/14065 loss：0.029145
【train】 epoch：2 step:5749/14065 loss：0.172028
【train】 epoch：2 step:5750/14065 loss：0.019814
【train】 epoch：2 step:5751/14065 loss：0.025126
【train】 epoch：2 step:5752/14065 loss：0.218547
【train】 epoch：2 step:5753/14065 loss：0.146950
【train】 epoch：2 step:5754/14065 loss：0.040088
【train】 epoch：2 step:5755/14065 loss：0.026134
【train】 epoch：2 step:5756/14065 loss：0.096193
【train】 epoch：2 step:5757/14065 loss：0.064305
【train】 epoch：2 step:5758/14065 loss：0.064482
【train】 epoch：2 step:5759/14065 loss：0.136999
【train】 epoch：2 step:5760/14065 loss：0.048089
【train】 epoch：2 step:5761/14065 loss：0.115579
【train】 epoch：2 step:5762/14065 loss：0.013054
【train】 epoch：2 step:5763/14065 loss：0.152061
【train】 epoch：2 step:5764/14065 loss：0.045486
【train】 epoch：2 step:5765/14065 loss：0.198689
【train】 epoch：2 step:5766/14065 loss：0.051308
【train】 epoch：2 step:5767/14065 loss：0.079240
【train】 epoch：2 step:5768/14065 loss：0.009400
【train】 epoch：2 step:5769/14065 loss：0.144740
【train】 epoch：2 step:5770/14065 loss：0.073870
【train】 epoch：2 step:5771/14065 loss：0.101806
【train】 epoch：2 step:5772/14065 loss：0.070256
【train】 epoch：2 step:5773/14065 loss：0.056591
【train】 epoch：2 step:5774/14065 loss：0.159837
【train】 epoch：2 step:5775/14065 loss：0.091976
【train】 epoch：2 step:5776/14065 loss：0.040285
【train】 epoch：2 step:5777/14065 loss：0.175358
【train】 epoch：2 step:5778/14065 loss：0.081414
【train】 epoch：2 step:5779/14065 loss：0.042802
【train】 epoch：2 step:5780/14065 loss：0.069750
【train】 epoch：2 step:5781/14065 loss：0.221345
【train】 epoch：2 step:5782/14065 loss：0.037248
【train】 epoch：2 step:5783/14065 loss：0.106793
【train】 epoch：2 step:5784/14065 loss：0.165022
【train】 epoch：2 step:5785/14065 loss：0.041289
【train】 epoch：2 step:5786/14065 loss：0.145426
【train】 epoch：2 step:5787/14065 loss：0.129453
【train】 epoch：2 step:5788/14065 loss：0.075909
【train】 epoch：2 step:5789/14065 loss：0.171870
【train】 epoch：2 step:5790/14065 loss：0.135980
【train】 epoch：2 step:5791/14065 loss：0.037242
【train】 epoch：2 step:5792/14065 loss：0.024639
【train】 epoch：2 step:5793/14065 loss：0.093791
【train】 epoch：2 step:5794/14065 loss：0.054700
【train】 epoch：2 step:5795/14065 loss：0.115005
【train】 epoch：2 step:5796/14065 loss：0.024288
【train】 epoch：2 step:5797/14065 loss：0.040470
【train】 epoch：2 step:5798/14065 loss：0.033497
【train】 epoch：2 step:5799/14065 loss：0.073383
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：198.881652 accuracy：0.9764 precision：0.9764 recall：0.9764 f1：0.9764
【train】 epoch：2 step:5800/14065 loss：0.145965
【train】 epoch：2 step:5801/14065 loss：0.099702
【train】 epoch：2 step:5802/14065 loss：0.044947
【train】 epoch：2 step:5803/14065 loss：0.096625
【train】 epoch：2 step:5804/14065 loss：0.036268
【train】 epoch：2 step:5805/14065 loss：0.198379
【train】 epoch：2 step:5806/14065 loss：0.074976
【train】 epoch：2 step:5807/14065 loss：0.010944
【train】 epoch：2 step:5808/14065 loss：0.137521
【train】 epoch：2 step:5809/14065 loss：0.111906
【train】 epoch：2 step:5810/14065 loss：0.087697
【train】 epoch：2 step:5811/14065 loss：0.046539
【train】 epoch：2 step:5812/14065 loss：0.095870
【train】 epoch：2 step:5813/14065 loss：0.074570
【train】 epoch：2 step:5814/14065 loss：0.069687
【train】 epoch：2 step:5815/14065 loss：0.081490
【train】 epoch：2 step:5816/14065 loss：0.139870
【train】 epoch：2 step:5817/14065 loss：0.111053
【train】 epoch：2 step:5818/14065 loss：0.031545
【train】 epoch：2 step:5819/14065 loss：0.016290
【train】 epoch：2 step:5820/14065 loss：0.120214
【train】 epoch：2 step:5821/14065 loss：0.148408
【train】 epoch：2 step:5822/14065 loss：0.030584
【train】 epoch：2 step:5823/14065 loss：0.014579
【train】 epoch：2 step:5824/14065 loss：0.050749
【train】 epoch：2 step:5825/14065 loss：0.082482
【train】 epoch：2 step:5826/14065 loss：0.093658
【train】 epoch：2 step:5827/14065 loss：0.081130
【train】 epoch：2 step:5828/14065 loss：0.280634
【train】 epoch：2 step:5829/14065 loss：0.038590
【train】 epoch：2 step:5830/14065 loss：0.060829
【train】 epoch：2 step:5831/14065 loss：0.026040
【train】 epoch：2 step:5832/14065 loss：0.165273
【train】 epoch：2 step:5833/14065 loss：0.032467
【train】 epoch：2 step:5834/14065 loss：0.183092
【train】 epoch：2 step:5835/14065 loss：0.073340
【train】 epoch：2 step:5836/14065 loss：0.217085
【train】 epoch：2 step:5837/14065 loss：0.061346
【train】 epoch：2 step:5838/14065 loss：0.142334
【train】 epoch：2 step:5839/14065 loss：0.013349
【train】 epoch：2 step:5840/14065 loss：0.052995
【train】 epoch：2 step:5841/14065 loss：0.059371
【train】 epoch：2 step:5842/14065 loss：0.086636
【train】 epoch：2 step:5843/14065 loss：0.036734
【train】 epoch：2 step:5844/14065 loss：0.038717
【train】 epoch：2 step:5845/14065 loss：0.110786
【train】 epoch：2 step:5846/14065 loss：0.084685
【train】 epoch：2 step:5847/14065 loss：0.030401
【train】 epoch：2 step:5848/14065 loss：0.068658
【train】 epoch：2 step:5849/14065 loss：0.143501
【train】 epoch：2 step:5850/14065 loss：0.034949
【train】 epoch：2 step:5851/14065 loss：0.102830
【train】 epoch：2 step:5852/14065 loss：0.111513
【train】 epoch：2 step:5853/14065 loss：0.102617
【train】 epoch：2 step:5854/14065 loss：0.102890
【train】 epoch：2 step:5855/14065 loss：0.162868
【train】 epoch：2 step:5856/14065 loss：0.033547
【train】 epoch：2 step:5857/14065 loss：0.013706
【train】 epoch：2 step:5858/14065 loss：0.198209
【train】 epoch：2 step:5859/14065 loss：0.094218
【train】 epoch：2 step:5860/14065 loss：0.056060
【train】 epoch：2 step:5861/14065 loss：0.116082
【train】 epoch：2 step:5862/14065 loss：0.093760
【train】 epoch：2 step:5863/14065 loss：0.095341
【train】 epoch：2 step:5864/14065 loss：0.106528
【train】 epoch：2 step:5865/14065 loss：0.009953
【train】 epoch：2 step:5866/14065 loss：0.168866
【train】 epoch：2 step:5867/14065 loss：0.074994
【train】 epoch：2 step:5868/14065 loss：0.174518
【train】 epoch：2 step:5869/14065 loss：0.032699
【train】 epoch：2 step:5870/14065 loss：0.037439
【train】 epoch：2 step:5871/14065 loss：0.039038
【train】 epoch：2 step:5872/14065 loss：0.149061
【train】 epoch：2 step:5873/14065 loss：0.095400
【train】 epoch：2 step:5874/14065 loss：0.075372
【train】 epoch：2 step:5875/14065 loss：0.046607
【train】 epoch：2 step:5876/14065 loss：0.069164
【train】 epoch：2 step:5877/14065 loss：0.154806
【train】 epoch：2 step:5878/14065 loss：0.039854
【train】 epoch：2 step:5879/14065 loss：0.032325
【train】 epoch：2 step:5880/14065 loss：0.054534
【train】 epoch：2 step:5881/14065 loss：0.135416
【train】 epoch：2 step:5882/14065 loss：0.130249
【train】 epoch：2 step:5883/14065 loss：0.112931
【train】 epoch：2 step:5884/14065 loss：0.030521
【train】 epoch：2 step:5885/14065 loss：0.101915
【train】 epoch：2 step:5886/14065 loss：0.020348
【train】 epoch：2 step:5887/14065 loss：0.020812
【train】 epoch：2 step:5888/14065 loss：0.044087
【train】 epoch：2 step:5889/14065 loss：0.013620
【train】 epoch：2 step:5890/14065 loss：0.010726
【train】 epoch：2 step:5891/14065 loss：0.061230
【train】 epoch：2 step:5892/14065 loss：0.091531
【train】 epoch：2 step:5893/14065 loss：0.168866
【train】 epoch：2 step:5894/14065 loss：0.108381
【train】 epoch：2 step:5895/14065 loss：0.107399
【train】 epoch：2 step:5896/14065 loss：0.127842
【train】 epoch：2 step:5897/14065 loss：0.111229
【train】 epoch：2 step:5898/14065 loss：0.088767
【train】 epoch：2 step:5899/14065 loss：0.089667
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：196.542584 accuracy：0.9769 precision：0.9769 recall：0.9769 f1：0.9769
------------>保存当前最好的模型
【train】 epoch：2 step:5900/14065 loss：0.089972
【train】 epoch：2 step:5901/14065 loss：0.034952
【train】 epoch：2 step:5902/14065 loss：0.114110
【train】 epoch：2 step:5903/14065 loss：0.086292
【train】 epoch：2 step:5904/14065 loss：0.046508
【train】 epoch：2 step:5905/14065 loss：0.111724
【train】 epoch：2 step:5906/14065 loss：0.037061
【train】 epoch：2 step:5907/14065 loss：0.013344
【train】 epoch：2 step:5908/14065 loss：0.060845
【train】 epoch：2 step:5909/14065 loss：0.141707
【train】 epoch：2 step:5910/14065 loss：0.041747
【train】 epoch：2 step:5911/14065 loss：0.041915
【train】 epoch：2 step:5912/14065 loss：0.078868
【train】 epoch：2 step:5913/14065 loss：0.030705
【train】 epoch：2 step:5914/14065 loss：0.182731
【train】 epoch：2 step:5915/14065 loss：0.039877
【train】 epoch：2 step:5916/14065 loss：0.056273
【train】 epoch：2 step:5917/14065 loss：0.080630
【train】 epoch：2 step:5918/14065 loss：0.066908
【train】 epoch：2 step:5919/14065 loss：0.058050
【train】 epoch：2 step:5920/14065 loss：0.032504
【train】 epoch：2 step:5921/14065 loss：0.036411
【train】 epoch：2 step:5922/14065 loss：0.130030
【train】 epoch：2 step:5923/14065 loss：0.148720
【train】 epoch：2 step:5924/14065 loss：0.015154
【train】 epoch：2 step:5925/14065 loss：0.113129
【train】 epoch：2 step:5926/14065 loss：0.100467
【train】 epoch：2 step:5927/14065 loss：0.111452
【train】 epoch：2 step:5928/14065 loss：0.113121
【train】 epoch：2 step:5929/14065 loss：0.020548
【train】 epoch：2 step:5930/14065 loss：0.118898
【train】 epoch：2 step:5931/14065 loss：0.073195
【train】 epoch：2 step:5932/14065 loss：0.047398
【train】 epoch：2 step:5933/14065 loss：0.052469
【train】 epoch：2 step:5934/14065 loss：0.161511
【train】 epoch：2 step:5935/14065 loss：0.180619
【train】 epoch：2 step:5936/14065 loss：0.082933
【train】 epoch：2 step:5937/14065 loss：0.023014
【train】 epoch：2 step:5938/14065 loss：0.071659
【train】 epoch：2 step:5939/14065 loss：0.070404
【train】 epoch：2 step:5940/14065 loss：0.329620
【train】 epoch：2 step:5941/14065 loss：0.022206
【train】 epoch：2 step:5942/14065 loss：0.033887
【train】 epoch：2 step:5943/14065 loss：0.106694
【train】 epoch：2 step:5944/14065 loss：0.033541
【train】 epoch：2 step:5945/14065 loss：0.088296
【train】 epoch：2 step:5946/14065 loss：0.058606
【train】 epoch：2 step:5947/14065 loss：0.044258
【train】 epoch：2 step:5948/14065 loss：0.192958
【train】 epoch：2 step:5949/14065 loss：0.062403
【train】 epoch：2 step:5950/14065 loss：0.080612
【train】 epoch：2 step:5951/14065 loss：0.072804
【train】 epoch：2 step:5952/14065 loss：0.043010
【train】 epoch：2 step:5953/14065 loss：0.008523
【train】 epoch：2 step:5954/14065 loss：0.041569
【train】 epoch：2 step:5955/14065 loss：0.013035
【train】 epoch：2 step:5956/14065 loss：0.062440
【train】 epoch：2 step:5957/14065 loss：0.183571
【train】 epoch：2 step:5958/14065 loss：0.117608
【train】 epoch：2 step:5959/14065 loss：0.133602
【train】 epoch：2 step:5960/14065 loss：0.124747
【train】 epoch：2 step:5961/14065 loss：0.068488
【train】 epoch：2 step:5962/14065 loss：0.060043
【train】 epoch：2 step:5963/14065 loss：0.061269
【train】 epoch：2 step:5964/14065 loss：0.080428
【train】 epoch：2 step:5965/14065 loss：0.071138
【train】 epoch：2 step:5966/14065 loss：0.013981
【train】 epoch：2 step:5967/14065 loss：0.089911
【train】 epoch：2 step:5968/14065 loss：0.075407
【train】 epoch：2 step:5969/14065 loss：0.023669
【train】 epoch：2 step:5970/14065 loss：0.019519
【train】 epoch：2 step:5971/14065 loss：0.009085
【train】 epoch：2 step:5972/14065 loss：0.053173
【train】 epoch：2 step:5973/14065 loss：0.108435
【train】 epoch：2 step:5974/14065 loss：0.117097
【train】 epoch：2 step:5975/14065 loss：0.032871
【train】 epoch：2 step:5976/14065 loss：0.065244
【train】 epoch：2 step:5977/14065 loss：0.050057
【train】 epoch：2 step:5978/14065 loss：0.021477
【train】 epoch：2 step:5979/14065 loss：0.131300
【train】 epoch：2 step:5980/14065 loss：0.021663
【train】 epoch：2 step:5981/14065 loss：0.281901
【train】 epoch：2 step:5982/14065 loss：0.057161
【train】 epoch：2 step:5983/14065 loss：0.196591
【train】 epoch：2 step:5984/14065 loss：0.051342
【train】 epoch：2 step:5985/14065 loss：0.087775
【train】 epoch：2 step:5986/14065 loss：0.055735
【train】 epoch：2 step:5987/14065 loss：0.052309
【train】 epoch：2 step:5988/14065 loss：0.034415
【train】 epoch：2 step:5989/14065 loss：0.097124
【train】 epoch：2 step:5990/14065 loss：0.113979
【train】 epoch：2 step:5991/14065 loss：0.023863
【train】 epoch：2 step:5992/14065 loss：0.025321
【train】 epoch：2 step:5993/14065 loss：0.041156
【train】 epoch：2 step:5994/14065 loss：0.027575
【train】 epoch：2 step:5995/14065 loss：0.047172
【train】 epoch：2 step:5996/14065 loss：0.103501
【train】 epoch：2 step:5997/14065 loss：0.108022
【train】 epoch：2 step:5998/14065 loss：0.096841
【train】 epoch：2 step:5999/14065 loss：0.062111
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：196.285447 accuracy：0.9770 precision：0.9770 recall：0.9770 f1：0.9770
------------>保存当前最好的模型
【train】 epoch：2 step:6000/14065 loss：0.041126
【train】 epoch：2 step:6001/14065 loss：0.041339
【train】 epoch：2 step:6002/14065 loss：0.060944
【train】 epoch：2 step:6003/14065 loss：0.044764
【train】 epoch：2 step:6004/14065 loss：0.052303
【train】 epoch：2 step:6005/14065 loss：0.103842
【train】 epoch：2 step:6006/14065 loss：0.127297
【train】 epoch：2 step:6007/14065 loss：0.042201
【train】 epoch：2 step:6008/14065 loss：0.065524
【train】 epoch：2 step:6009/14065 loss：0.031435
【train】 epoch：2 step:6010/14065 loss：0.087423
【train】 epoch：2 step:6011/14065 loss：0.115735
【train】 epoch：2 step:6012/14065 loss：0.152061
【train】 epoch：2 step:6013/14065 loss：0.136936
【train】 epoch：2 step:6014/14065 loss：0.215488
【train】 epoch：2 step:6015/14065 loss：0.178825
【train】 epoch：2 step:6016/14065 loss：0.065516
【train】 epoch：2 step:6017/14065 loss：0.049933
【train】 epoch：2 step:6018/14065 loss：0.080610
【train】 epoch：2 step:6019/14065 loss：0.068794
【train】 epoch：2 step:6020/14065 loss：0.127209
【train】 epoch：2 step:6021/14065 loss：0.101139
【train】 epoch：2 step:6022/14065 loss：0.073586
【train】 epoch：2 step:6023/14065 loss：0.092462
【train】 epoch：2 step:6024/14065 loss：0.102324
【train】 epoch：2 step:6025/14065 loss：0.196415
【train】 epoch：2 step:6026/14065 loss：0.113468
【train】 epoch：2 step:6027/14065 loss：0.156670
【train】 epoch：2 step:6028/14065 loss：0.118237
【train】 epoch：2 step:6029/14065 loss：0.192574
【train】 epoch：2 step:6030/14065 loss：0.040434
【train】 epoch：2 step:6031/14065 loss：0.078578
【train】 epoch：2 step:6032/14065 loss：0.051789
【train】 epoch：2 step:6033/14065 loss：0.081286
【train】 epoch：2 step:6034/14065 loss：0.164427
【train】 epoch：2 step:6035/14065 loss：0.087022
【train】 epoch：2 step:6036/14065 loss：0.109438
【train】 epoch：2 step:6037/14065 loss：0.130872
【train】 epoch：2 step:6038/14065 loss：0.139727
【train】 epoch：2 step:6039/14065 loss：0.110142
【train】 epoch：2 step:6040/14065 loss：0.059671
【train】 epoch：2 step:6041/14065 loss：0.107772
【train】 epoch：2 step:6042/14065 loss：0.137896
【train】 epoch：2 step:6043/14065 loss：0.066709
【train】 epoch：2 step:6044/14065 loss：0.045777
【train】 epoch：2 step:6045/14065 loss：0.137730
【train】 epoch：2 step:6046/14065 loss：0.043210
【train】 epoch：2 step:6047/14065 loss：0.056920
【train】 epoch：2 step:6048/14065 loss：0.088398
【train】 epoch：2 step:6049/14065 loss：0.038636
【train】 epoch：2 step:6050/14065 loss：0.107270
【train】 epoch：2 step:6051/14065 loss：0.041009
【train】 epoch：2 step:6052/14065 loss：0.040297
【train】 epoch：2 step:6053/14065 loss：0.150639
【train】 epoch：2 step:6054/14065 loss：0.061302
【train】 epoch：2 step:6055/14065 loss：0.154902
【train】 epoch：2 step:6056/14065 loss：0.134434
【train】 epoch：2 step:6057/14065 loss：0.106944
【train】 epoch：2 step:6058/14065 loss：0.078280
【train】 epoch：2 step:6059/14065 loss：0.024394
【train】 epoch：2 step:6060/14065 loss：0.110915
【train】 epoch：2 step:6061/14065 loss：0.068644
【train】 epoch：2 step:6062/14065 loss：0.042592
【train】 epoch：2 step:6063/14065 loss：0.153822
【train】 epoch：2 step:6064/14065 loss：0.050314
【train】 epoch：2 step:6065/14065 loss：0.055405
【train】 epoch：2 step:6066/14065 loss：0.182268
【train】 epoch：2 step:6067/14065 loss：0.014569
【train】 epoch：2 step:6068/14065 loss：0.138490
【train】 epoch：2 step:6069/14065 loss：0.084486
【train】 epoch：2 step:6070/14065 loss：0.064466
【train】 epoch：2 step:6071/14065 loss：0.049518
【train】 epoch：2 step:6072/14065 loss：0.037425
【train】 epoch：2 step:6073/14065 loss：0.061830
【train】 epoch：2 step:6074/14065 loss：0.037409
【train】 epoch：2 step:6075/14065 loss：0.077547
【train】 epoch：2 step:6076/14065 loss：0.059541
【train】 epoch：2 step:6077/14065 loss：0.025151
【train】 epoch：2 step:6078/14065 loss：0.036603
【train】 epoch：2 step:6079/14065 loss：0.073909
【train】 epoch：2 step:6080/14065 loss：0.084551
【train】 epoch：2 step:6081/14065 loss：0.081706
【train】 epoch：2 step:6082/14065 loss：0.064064
【train】 epoch：2 step:6083/14065 loss：0.087705
【train】 epoch：2 step:6084/14065 loss：0.033632
【train】 epoch：2 step:6085/14065 loss：0.092876
【train】 epoch：2 step:6086/14065 loss：0.098565
【train】 epoch：2 step:6087/14065 loss：0.050880
【train】 epoch：2 step:6088/14065 loss：0.085831
【train】 epoch：2 step:6089/14065 loss：0.089921
【train】 epoch：2 step:6090/14065 loss：0.128337
【train】 epoch：2 step:6091/14065 loss：0.045150
【train】 epoch：2 step:6092/14065 loss：0.033616
【train】 epoch：2 step:6093/14065 loss：0.105870
【train】 epoch：2 step:6094/14065 loss：0.060674
【train】 epoch：2 step:6095/14065 loss：0.110650
【train】 epoch：2 step:6096/14065 loss：0.035914
【train】 epoch：2 step:6097/14065 loss：0.014319
【train】 epoch：2 step:6098/14065 loss：0.015219
【train】 epoch：2 step:6099/14065 loss：0.249876
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：190.634883 accuracy：0.9781 precision：0.9781 recall：0.9781 f1：0.9781
------------>保存当前最好的模型
【train】 epoch：2 step:6100/14065 loss：0.107717
【train】 epoch：2 step:6101/14065 loss：0.051075
【train】 epoch：2 step:6102/14065 loss：0.063400
【train】 epoch：2 step:6103/14065 loss：0.080369
【train】 epoch：2 step:6104/14065 loss：0.256460
【train】 epoch：2 step:6105/14065 loss：0.020037
【train】 epoch：2 step:6106/14065 loss：0.023956
【train】 epoch：2 step:6107/14065 loss：0.028768
【train】 epoch：2 step:6108/14065 loss：0.245169
【train】 epoch：2 step:6109/14065 loss：0.058390
【train】 epoch：2 step:6110/14065 loss：0.160658
【train】 epoch：2 step:6111/14065 loss：0.281651
【train】 epoch：2 step:6112/14065 loss：0.052760
【train】 epoch：2 step:6113/14065 loss：0.067591
【train】 epoch：2 step:6114/14065 loss：0.100084
【train】 epoch：2 step:6115/14065 loss：0.141081
【train】 epoch：2 step:6116/14065 loss：0.034043
【train】 epoch：2 step:6117/14065 loss：0.103217
【train】 epoch：2 step:6118/14065 loss：0.125862
【train】 epoch：2 step:6119/14065 loss：0.068229
【train】 epoch：2 step:6120/14065 loss：0.057276
【train】 epoch：2 step:6121/14065 loss：0.039099
【train】 epoch：2 step:6122/14065 loss：0.065896
【train】 epoch：2 step:6123/14065 loss：0.026963
【train】 epoch：2 step:6124/14065 loss：0.104826
【train】 epoch：2 step:6125/14065 loss：0.223674
【train】 epoch：2 step:6126/14065 loss：0.067637
【train】 epoch：2 step:6127/14065 loss：0.067327
【train】 epoch：2 step:6128/14065 loss：0.068505
【train】 epoch：2 step:6129/14065 loss：0.011016
【train】 epoch：2 step:6130/14065 loss：0.068773
【train】 epoch：2 step:6131/14065 loss：0.054808
【train】 epoch：2 step:6132/14065 loss：0.112154
【train】 epoch：2 step:6133/14065 loss：0.087473
【train】 epoch：2 step:6134/14065 loss：0.080504
【train】 epoch：2 step:6135/14065 loss：0.173264
【train】 epoch：2 step:6136/14065 loss：0.095487
【train】 epoch：2 step:6137/14065 loss：0.117669
【train】 epoch：2 step:6138/14065 loss：0.031714
【train】 epoch：2 step:6139/14065 loss：0.154267
【train】 epoch：2 step:6140/14065 loss：0.073120
【train】 epoch：2 step:6141/14065 loss：0.145167
【train】 epoch：2 step:6142/14065 loss：0.088272
【train】 epoch：2 step:6143/14065 loss：0.132140
【train】 epoch：2 step:6144/14065 loss：0.046116
【train】 epoch：2 step:6145/14065 loss：0.155840
【train】 epoch：2 step:6146/14065 loss：0.074647
【train】 epoch：2 step:6147/14065 loss：0.039993
【train】 epoch：2 step:6148/14065 loss：0.022296
【train】 epoch：2 step:6149/14065 loss：0.100855
【train】 epoch：2 step:6150/14065 loss：0.044527
【train】 epoch：2 step:6151/14065 loss：0.101800
【train】 epoch：2 step:6152/14065 loss：0.014322
【train】 epoch：2 step:6153/14065 loss：0.163230
【train】 epoch：2 step:6154/14065 loss：0.025570
【train】 epoch：2 step:6155/14065 loss：0.045812
【train】 epoch：2 step:6156/14065 loss：0.075864
【train】 epoch：2 step:6157/14065 loss：0.059900
【train】 epoch：2 step:6158/14065 loss：0.038363
【train】 epoch：2 step:6159/14065 loss：0.085453
【train】 epoch：2 step:6160/14065 loss：0.146878
【train】 epoch：2 step:6161/14065 loss：0.099402
【train】 epoch：2 step:6162/14065 loss：0.080800
【train】 epoch：2 step:6163/14065 loss：0.053822
【train】 epoch：2 step:6164/14065 loss：0.037692
【train】 epoch：2 step:6165/14065 loss：0.042784
【train】 epoch：2 step:6166/14065 loss：0.171554
【train】 epoch：2 step:6167/14065 loss：0.141585
【train】 epoch：2 step:6168/14065 loss：0.109771
【train】 epoch：2 step:6169/14065 loss：0.144286
【train】 epoch：2 step:6170/14065 loss：0.009914
【train】 epoch：2 step:6171/14065 loss：0.052667
【train】 epoch：2 step:6172/14065 loss：0.168113
【train】 epoch：2 step:6173/14065 loss：0.118529
【train】 epoch：2 step:6174/14065 loss：0.116541
【train】 epoch：2 step:6175/14065 loss：0.041572
【train】 epoch：2 step:6176/14065 loss：0.096727
【train】 epoch：2 step:6177/14065 loss：0.089041
【train】 epoch：2 step:6178/14065 loss：0.160315
【train】 epoch：2 step:6179/14065 loss：0.074694
【train】 epoch：2 step:6180/14065 loss：0.107779
【train】 epoch：2 step:6181/14065 loss：0.039760
【train】 epoch：2 step:6182/14065 loss：0.145948
【train】 epoch：2 step:6183/14065 loss：0.089511
【train】 epoch：2 step:6184/14065 loss：0.119154
【train】 epoch：2 step:6185/14065 loss：0.032182
【train】 epoch：2 step:6186/14065 loss：0.224737
【train】 epoch：2 step:6187/14065 loss：0.279893
【train】 epoch：2 step:6188/14065 loss：0.032834
【train】 epoch：2 step:6189/14065 loss：0.087082
【train】 epoch：2 step:6190/14065 loss：0.111476
【train】 epoch：2 step:6191/14065 loss：0.119688
【train】 epoch：2 step:6192/14065 loss：0.061554
【train】 epoch：2 step:6193/14065 loss：0.070564
【train】 epoch：2 step:6194/14065 loss：0.077779
【train】 epoch：2 step:6195/14065 loss：0.066262
【train】 epoch：2 step:6196/14065 loss：0.114555
【train】 epoch：2 step:6197/14065 loss：0.055317
【train】 epoch：2 step:6198/14065 loss：0.103869
【train】 epoch：2 step:6199/14065 loss：0.105010
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：204.266564 accuracy：0.9759 precision：0.9759 recall：0.9759 f1：0.9759
【train】 epoch：2 step:6200/14065 loss：0.028824
【train】 epoch：2 step:6201/14065 loss：0.109787
【train】 epoch：2 step:6202/14065 loss：0.104682
【train】 epoch：2 step:6203/14065 loss：0.022759
【train】 epoch：2 step:6204/14065 loss：0.182607
【train】 epoch：2 step:6205/14065 loss：0.091906
【train】 epoch：2 step:6206/14065 loss：0.047857
【train】 epoch：2 step:6207/14065 loss：0.030647
【train】 epoch：2 step:6208/14065 loss：0.259834
【train】 epoch：2 step:6209/14065 loss：0.111092
【train】 epoch：2 step:6210/14065 loss：0.052470
【train】 epoch：2 step:6211/14065 loss：0.024458
【train】 epoch：2 step:6212/14065 loss：0.086787
【train】 epoch：2 step:6213/14065 loss：0.056807
【train】 epoch：2 step:6214/14065 loss：0.103037
【train】 epoch：2 step:6215/14065 loss：0.079422
【train】 epoch：2 step:6216/14065 loss：0.172094
【train】 epoch：2 step:6217/14065 loss：0.134329
【train】 epoch：2 step:6218/14065 loss：0.068920
【train】 epoch：2 step:6219/14065 loss：0.077168
【train】 epoch：2 step:6220/14065 loss：0.165920
【train】 epoch：2 step:6221/14065 loss：0.097435
【train】 epoch：2 step:6222/14065 loss：0.048693
【train】 epoch：2 step:6223/14065 loss：0.173580
【train】 epoch：2 step:6224/14065 loss：0.058361
【train】 epoch：2 step:6225/14065 loss：0.054418
【train】 epoch：2 step:6226/14065 loss：0.108346
【train】 epoch：2 step:6227/14065 loss：0.032969
【train】 epoch：2 step:6228/14065 loss：0.139770
【train】 epoch：2 step:6229/14065 loss：0.082438
【train】 epoch：2 step:6230/14065 loss：0.141219
【train】 epoch：2 step:6231/14065 loss：0.094889
【train】 epoch：2 step:6232/14065 loss：0.172970
【train】 epoch：2 step:6233/14065 loss：0.093813
【train】 epoch：2 step:6234/14065 loss：0.124980
【train】 epoch：2 step:6235/14065 loss：0.061106
【train】 epoch：2 step:6236/14065 loss：0.020668
【train】 epoch：2 step:6237/14065 loss：0.058068
【train】 epoch：2 step:6238/14065 loss：0.116088
【train】 epoch：2 step:6239/14065 loss：0.053481
【train】 epoch：2 step:6240/14065 loss：0.053133
【train】 epoch：2 step:6241/14065 loss：0.053560
【train】 epoch：2 step:6242/14065 loss：0.109413
【train】 epoch：2 step:6243/14065 loss：0.093058
【train】 epoch：2 step:6244/14065 loss：0.122608
【train】 epoch：2 step:6245/14065 loss：0.111805
【train】 epoch：2 step:6246/14065 loss：0.041474
【train】 epoch：2 step:6247/14065 loss：0.139972
【train】 epoch：2 step:6248/14065 loss：0.136981
【train】 epoch：2 step:6249/14065 loss：0.179267
【train】 epoch：2 step:6250/14065 loss：0.125533
【train】 epoch：2 step:6251/14065 loss：0.048847
【train】 epoch：2 step:6252/14065 loss：0.041076
【train】 epoch：2 step:6253/14065 loss：0.008776
【train】 epoch：2 step:6254/14065 loss：0.104691
【train】 epoch：2 step:6255/14065 loss：0.023171
【train】 epoch：2 step:6256/14065 loss：0.081590
【train】 epoch：2 step:6257/14065 loss：0.016551
【train】 epoch：2 step:6258/14065 loss：0.056044
【train】 epoch：2 step:6259/14065 loss：0.060357
【train】 epoch：2 step:6260/14065 loss：0.022786
【train】 epoch：2 step:6261/14065 loss：0.075451
【train】 epoch：2 step:6262/14065 loss：0.108209
【train】 epoch：2 step:6263/14065 loss：0.096073
【train】 epoch：2 step:6264/14065 loss：0.099599
【train】 epoch：2 step:6265/14065 loss：0.031215
【train】 epoch：2 step:6266/14065 loss：0.095712
【train】 epoch：2 step:6267/14065 loss：0.143805
【train】 epoch：2 step:6268/14065 loss：0.071231
【train】 epoch：2 step:6269/14065 loss：0.085559
【train】 epoch：2 step:6270/14065 loss：0.106200
【train】 epoch：2 step:6271/14065 loss：0.086475
【train】 epoch：2 step:6272/14065 loss：0.061470
【train】 epoch：2 step:6273/14065 loss：0.017852
【train】 epoch：2 step:6274/14065 loss：0.029994
【train】 epoch：2 step:6275/14065 loss：0.093566
【train】 epoch：2 step:6276/14065 loss：0.119757
【train】 epoch：2 step:6277/14065 loss：0.166525
【train】 epoch：2 step:6278/14065 loss：0.030217
【train】 epoch：2 step:6279/14065 loss：0.189352
【train】 epoch：2 step:6280/14065 loss：0.278254
【train】 epoch：2 step:6281/14065 loss：0.125495
【train】 epoch：2 step:6282/14065 loss：0.089639
【train】 epoch：2 step:6283/14065 loss：0.036966
【train】 epoch：2 step:6284/14065 loss：0.016944
【train】 epoch：2 step:6285/14065 loss：0.064712
【train】 epoch：2 step:6286/14065 loss：0.077975
【train】 epoch：2 step:6287/14065 loss：0.038955
【train】 epoch：2 step:6288/14065 loss：0.027419
【train】 epoch：2 step:6289/14065 loss：0.076842
【train】 epoch：2 step:6290/14065 loss：0.056717
【train】 epoch：2 step:6291/14065 loss：0.008316
【train】 epoch：2 step:6292/14065 loss：0.081950
【train】 epoch：2 step:6293/14065 loss：0.065620
【train】 epoch：2 step:6294/14065 loss：0.042872
【train】 epoch：2 step:6295/14065 loss：0.101246
【train】 epoch：2 step:6296/14065 loss：0.048611
【train】 epoch：2 step:6297/14065 loss：0.080384
【train】 epoch：2 step:6298/14065 loss：0.030182
【train】 epoch：2 step:6299/14065 loss：0.076525
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：187.048168 accuracy：0.9783 precision：0.9783 recall：0.9783 f1：0.9783
------------>保存当前最好的模型
【train】 epoch：2 step:6300/14065 loss：0.059775
【train】 epoch：2 step:6301/14065 loss：0.090468
【train】 epoch：2 step:6302/14065 loss：0.089279
【train】 epoch：2 step:6303/14065 loss：0.046409
【train】 epoch：2 step:6304/14065 loss：0.158722
【train】 epoch：2 step:6305/14065 loss：0.271426
【train】 epoch：2 step:6306/14065 loss：0.090812
【train】 epoch：2 step:6307/14065 loss：0.091016
【train】 epoch：2 step:6308/14065 loss：0.022793
【train】 epoch：2 step:6309/14065 loss：0.062076
【train】 epoch：2 step:6310/14065 loss：0.058309
【train】 epoch：2 step:6311/14065 loss：0.174020
【train】 epoch：2 step:6312/14065 loss：0.206557
【train】 epoch：2 step:6313/14065 loss：0.067014
【train】 epoch：2 step:6314/14065 loss：0.076021
【train】 epoch：2 step:6315/14065 loss：0.066115
【train】 epoch：2 step:6316/14065 loss：0.044828
【train】 epoch：2 step:6317/14065 loss：0.029956
【train】 epoch：2 step:6318/14065 loss：0.028772
【train】 epoch：2 step:6319/14065 loss：0.074453
【train】 epoch：2 step:6320/14065 loss：0.011216
【train】 epoch：2 step:6321/14065 loss：0.136423
【train】 epoch：2 step:6322/14065 loss：0.038233
【train】 epoch：2 step:6323/14065 loss：0.185441
【train】 epoch：2 step:6324/14065 loss：0.068177
【train】 epoch：2 step:6325/14065 loss：0.036703
【train】 epoch：2 step:6326/14065 loss：0.156770
【train】 epoch：2 step:6327/14065 loss：0.015945
【train】 epoch：2 step:6328/14065 loss：0.190775
【train】 epoch：2 step:6329/14065 loss：0.132253
【train】 epoch：2 step:6330/14065 loss：0.013956
【train】 epoch：2 step:6331/14065 loss：0.031352
【train】 epoch：2 step:6332/14065 loss：0.189058
【train】 epoch：2 step:6333/14065 loss：0.059706
【train】 epoch：2 step:6334/14065 loss：0.020446
【train】 epoch：2 step:6335/14065 loss：0.149416
【train】 epoch：2 step:6336/14065 loss：0.060862
【train】 epoch：2 step:6337/14065 loss：0.091827
【train】 epoch：2 step:6338/14065 loss：0.058347
【train】 epoch：2 step:6339/14065 loss：0.187770
【train】 epoch：2 step:6340/14065 loss：0.218821
【train】 epoch：2 step:6341/14065 loss：0.084390
【train】 epoch：2 step:6342/14065 loss：0.024622
【train】 epoch：2 step:6343/14065 loss：0.166582
【train】 epoch：2 step:6344/14065 loss：0.083223
【train】 epoch：2 step:6345/14065 loss：0.031967
【train】 epoch：2 step:6346/14065 loss：0.111054
【train】 epoch：2 step:6347/14065 loss：0.087005
【train】 epoch：2 step:6348/14065 loss：0.201120
【train】 epoch：2 step:6349/14065 loss：0.026155
【train】 epoch：2 step:6350/14065 loss：0.089105
【train】 epoch：2 step:6351/14065 loss：0.072151
【train】 epoch：2 step:6352/14065 loss：0.037752
【train】 epoch：2 step:6353/14065 loss：0.077191
【train】 epoch：2 step:6354/14065 loss：0.105864
【train】 epoch：2 step:6355/14065 loss：0.040959
【train】 epoch：2 step:6356/14065 loss：0.046276
【train】 epoch：2 step:6357/14065 loss：0.047271
【train】 epoch：2 step:6358/14065 loss：0.037962
【train】 epoch：2 step:6359/14065 loss：0.158026
【train】 epoch：2 step:6360/14065 loss：0.169974
【train】 epoch：2 step:6361/14065 loss：0.141962
【train】 epoch：2 step:6362/14065 loss：0.022462
【train】 epoch：2 step:6363/14065 loss：0.161736
【train】 epoch：2 step:6364/14065 loss：0.058822
【train】 epoch：2 step:6365/14065 loss：0.084065
【train】 epoch：2 step:6366/14065 loss：0.020985
【train】 epoch：2 step:6367/14065 loss：0.088320
【train】 epoch：2 step:6368/14065 loss：0.165788
【train】 epoch：2 step:6369/14065 loss：0.164822
【train】 epoch：2 step:6370/14065 loss：0.065245
【train】 epoch：2 step:6371/14065 loss：0.081912
【train】 epoch：2 step:6372/14065 loss：0.055787
【train】 epoch：2 step:6373/14065 loss：0.171501
【train】 epoch：2 step:6374/14065 loss：0.155065
【train】 epoch：2 step:6375/14065 loss：0.134460
【train】 epoch：2 step:6376/14065 loss：0.023813
【train】 epoch：2 step:6377/14065 loss：0.157050
【train】 epoch：2 step:6378/14065 loss：0.018531
【train】 epoch：2 step:6379/14065 loss：0.109979
【train】 epoch：2 step:6380/14065 loss：0.078884
【train】 epoch：2 step:6381/14065 loss：0.048297
【train】 epoch：2 step:6382/14065 loss：0.157707
【train】 epoch：2 step:6383/14065 loss：0.060513
【train】 epoch：2 step:6384/14065 loss：0.077343
【train】 epoch：2 step:6385/14065 loss：0.061110
【train】 epoch：2 step:6386/14065 loss：0.094193
【train】 epoch：2 step:6387/14065 loss：0.127646
【train】 epoch：2 step:6388/14065 loss：0.050967
【train】 epoch：2 step:6389/14065 loss：0.140819
【train】 epoch：2 step:6390/14065 loss：0.083443
【train】 epoch：2 step:6391/14065 loss：0.161559
【train】 epoch：2 step:6392/14065 loss：0.291266
【train】 epoch：2 step:6393/14065 loss：0.185547
【train】 epoch：2 step:6394/14065 loss：0.125679
【train】 epoch：2 step:6395/14065 loss：0.065790
【train】 epoch：2 step:6396/14065 loss：0.021502
【train】 epoch：2 step:6397/14065 loss：0.071307
【train】 epoch：2 step:6398/14065 loss：0.177297
【train】 epoch：2 step:6399/14065 loss：0.050621
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：196.268176 accuracy：0.9772 precision：0.9772 recall：0.9772 f1：0.9772
【train】 epoch：2 step:6400/14065 loss：0.150549
【train】 epoch：2 step:6401/14065 loss：0.166415
【train】 epoch：2 step:6402/14065 loss：0.097732
【train】 epoch：2 step:6403/14065 loss：0.045145
【train】 epoch：2 step:6404/14065 loss：0.122904
【train】 epoch：2 step:6405/14065 loss：0.087265
【train】 epoch：2 step:6406/14065 loss：0.109458
【train】 epoch：2 step:6407/14065 loss：0.091709
【train】 epoch：2 step:6408/14065 loss：0.091999
【train】 epoch：2 step:6409/14065 loss：0.150361
【train】 epoch：2 step:6410/14065 loss：0.143056
【train】 epoch：2 step:6411/14065 loss：0.060662
【train】 epoch：2 step:6412/14065 loss：0.087700
【train】 epoch：2 step:6413/14065 loss：0.016832
【train】 epoch：2 step:6414/14065 loss：0.234901
【train】 epoch：2 step:6415/14065 loss：0.072183
【train】 epoch：2 step:6416/14065 loss：0.040561
【train】 epoch：2 step:6417/14065 loss：0.054705
【train】 epoch：2 step:6418/14065 loss：0.153830
【train】 epoch：2 step:6419/14065 loss：0.080733
【train】 epoch：2 step:6420/14065 loss：0.050930
【train】 epoch：2 step:6421/14065 loss：0.056531
【train】 epoch：2 step:6422/14065 loss：0.029941
【train】 epoch：2 step:6423/14065 loss：0.146338
【train】 epoch：2 step:6424/14065 loss：0.046020
【train】 epoch：2 step:6425/14065 loss：0.040025
【train】 epoch：2 step:6426/14065 loss：0.158537
【train】 epoch：2 step:6427/14065 loss：0.173457
【train】 epoch：2 step:6428/14065 loss：0.311529
【train】 epoch：2 step:6429/14065 loss：0.171535
【train】 epoch：2 step:6430/14065 loss：0.254021
【train】 epoch：2 step:6431/14065 loss：0.040534
【train】 epoch：2 step:6432/14065 loss：0.210070
【train】 epoch：2 step:6433/14065 loss：0.085503
【train】 epoch：2 step:6434/14065 loss：0.032444
【train】 epoch：2 step:6435/14065 loss：0.042108
【train】 epoch：2 step:6436/14065 loss：0.143912
【train】 epoch：2 step:6437/14065 loss：0.179702
【train】 epoch：2 step:6438/14065 loss：0.204362
【train】 epoch：2 step:6439/14065 loss：0.025941
【train】 epoch：2 step:6440/14065 loss：0.073826
【train】 epoch：2 step:6441/14065 loss：0.211322
【train】 epoch：2 step:6442/14065 loss：0.178298
【train】 epoch：2 step:6443/14065 loss：0.109689
【train】 epoch：2 step:6444/14065 loss：0.035316
【train】 epoch：2 step:6445/14065 loss：0.154040
【train】 epoch：2 step:6446/14065 loss：0.076325
【train】 epoch：2 step:6447/14065 loss：0.043976
【train】 epoch：2 step:6448/14065 loss：0.103674
【train】 epoch：2 step:6449/14065 loss：0.036619
【train】 epoch：2 step:6450/14065 loss：0.063747
【train】 epoch：2 step:6451/14065 loss：0.078154
【train】 epoch：2 step:6452/14065 loss：0.100059
【train】 epoch：2 step:6453/14065 loss：0.098142
【train】 epoch：2 step:6454/14065 loss：0.016063
【train】 epoch：2 step:6455/14065 loss：0.009196
【train】 epoch：2 step:6456/14065 loss：0.107840
【train】 epoch：2 step:6457/14065 loss：0.091486
【train】 epoch：2 step:6458/14065 loss：0.119901
【train】 epoch：2 step:6459/14065 loss：0.114812
【train】 epoch：2 step:6460/14065 loss：0.028167
【train】 epoch：2 step:6461/14065 loss：0.033603
【train】 epoch：2 step:6462/14065 loss：0.165879
【train】 epoch：2 step:6463/14065 loss：0.116898
【train】 epoch：2 step:6464/14065 loss：0.020873
【train】 epoch：2 step:6465/14065 loss：0.106016
【train】 epoch：2 step:6466/14065 loss：0.204569
【train】 epoch：2 step:6467/14065 loss：0.053408
【train】 epoch：2 step:6468/14065 loss：0.117667
【train】 epoch：2 step:6469/14065 loss：0.023273
【train】 epoch：2 step:6470/14065 loss：0.174929
【train】 epoch：2 step:6471/14065 loss：0.136057
【train】 epoch：2 step:6472/14065 loss：0.032478
【train】 epoch：2 step:6473/14065 loss：0.184784
【train】 epoch：2 step:6474/14065 loss：0.120359
【train】 epoch：2 step:6475/14065 loss：0.034829
【train】 epoch：2 step:6476/14065 loss：0.098036
【train】 epoch：2 step:6477/14065 loss：0.097958
【train】 epoch：2 step:6478/14065 loss：0.111390
【train】 epoch：2 step:6479/14065 loss：0.068065
【train】 epoch：2 step:6480/14065 loss：0.085074
【train】 epoch：2 step:6481/14065 loss：0.193297
【train】 epoch：2 step:6482/14065 loss：0.100030
【train】 epoch：2 step:6483/14065 loss：0.033608
【train】 epoch：2 step:6484/14065 loss：0.043068
【train】 epoch：2 step:6485/14065 loss：0.059525
【train】 epoch：2 step:6486/14065 loss：0.072892
【train】 epoch：2 step:6487/14065 loss：0.207534
【train】 epoch：2 step:6488/14065 loss：0.095287
【train】 epoch：2 step:6489/14065 loss：0.008937
【train】 epoch：2 step:6490/14065 loss：0.217843
【train】 epoch：2 step:6491/14065 loss：0.021988
【train】 epoch：2 step:6492/14065 loss：0.077429
【train】 epoch：2 step:6493/14065 loss：0.094790
【train】 epoch：2 step:6494/14065 loss：0.036422
【train】 epoch：2 step:6495/14065 loss：0.185804
【train】 epoch：2 step:6496/14065 loss：0.062710
【train】 epoch：2 step:6497/14065 loss：0.083509
【train】 epoch：2 step:6498/14065 loss：0.025984
【train】 epoch：2 step:6499/14065 loss：0.170211
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：186.927080 accuracy：0.9784 precision：0.9784 recall：0.9784 f1：0.9784
------------>保存当前最好的模型
【train】 epoch：2 step:6500/14065 loss：0.169222
【train】 epoch：2 step:6501/14065 loss：0.089850
【train】 epoch：2 step:6502/14065 loss：0.096974
【train】 epoch：2 step:6503/14065 loss：0.059196
【train】 epoch：2 step:6504/14065 loss：0.029797
【train】 epoch：2 step:6505/14065 loss：0.115424
【train】 epoch：2 step:6506/14065 loss：0.102352
【train】 epoch：2 step:6507/14065 loss：0.014773
【train】 epoch：2 step:6508/14065 loss：0.070232
【train】 epoch：2 step:6509/14065 loss：0.030309
【train】 epoch：2 step:6510/14065 loss：0.093345
【train】 epoch：2 step:6511/14065 loss：0.017593
【train】 epoch：2 step:6512/14065 loss：0.304243
【train】 epoch：2 step:6513/14065 loss：0.057698
【train】 epoch：2 step:6514/14065 loss：0.079649
【train】 epoch：2 step:6515/14065 loss：0.041809
【train】 epoch：2 step:6516/14065 loss：0.105184
【train】 epoch：2 step:6517/14065 loss：0.032909
【train】 epoch：2 step:6518/14065 loss：0.059523
【train】 epoch：2 step:6519/14065 loss：0.087927
【train】 epoch：2 step:6520/14065 loss：0.116564
【train】 epoch：2 step:6521/14065 loss：0.121929
【train】 epoch：2 step:6522/14065 loss：0.060464
【train】 epoch：2 step:6523/14065 loss：0.065512
【train】 epoch：2 step:6524/14065 loss：0.145099
【train】 epoch：2 step:6525/14065 loss：0.098937
【train】 epoch：2 step:6526/14065 loss：0.146381
【train】 epoch：2 step:6527/14065 loss：0.009405
【train】 epoch：2 step:6528/14065 loss：0.019109
【train】 epoch：2 step:6529/14065 loss：0.041403
【train】 epoch：2 step:6530/14065 loss：0.139888
【train】 epoch：2 step:6531/14065 loss：0.017847
【train】 epoch：2 step:6532/14065 loss：0.100437
【train】 epoch：2 step:6533/14065 loss：0.134598
【train】 epoch：2 step:6534/14065 loss：0.275896
【train】 epoch：2 step:6535/14065 loss：0.035338
【train】 epoch：2 step:6536/14065 loss：0.099913
【train】 epoch：2 step:6537/14065 loss：0.180071
【train】 epoch：2 step:6538/14065 loss：0.096112
【train】 epoch：2 step:6539/14065 loss：0.053810
【train】 epoch：2 step:6540/14065 loss：0.097201
【train】 epoch：2 step:6541/14065 loss：0.006437
【train】 epoch：2 step:6542/14065 loss：0.108007
【train】 epoch：2 step:6543/14065 loss：0.126855
【train】 epoch：2 step:6544/14065 loss：0.083106
【train】 epoch：2 step:6545/14065 loss：0.126562
【train】 epoch：2 step:6546/14065 loss：0.081522
【train】 epoch：2 step:6547/14065 loss：0.121329
【train】 epoch：2 step:6548/14065 loss：0.057532
【train】 epoch：2 step:6549/14065 loss：0.079214
【train】 epoch：2 step:6550/14065 loss：0.120098
【train】 epoch：2 step:6551/14065 loss：0.064777
【train】 epoch：2 step:6552/14065 loss：0.074476
【train】 epoch：2 step:6553/14065 loss：0.106477
【train】 epoch：2 step:6554/14065 loss：0.016687
【train】 epoch：2 step:6555/14065 loss：0.073343
【train】 epoch：2 step:6556/14065 loss：0.054564
【train】 epoch：2 step:6557/14065 loss：0.063797
【train】 epoch：2 step:6558/14065 loss：0.076751
【train】 epoch：2 step:6559/14065 loss：0.046228
【train】 epoch：2 step:6560/14065 loss：0.150078
【train】 epoch：2 step:6561/14065 loss：0.188450
【train】 epoch：2 step:6562/14065 loss：0.099465
【train】 epoch：2 step:6563/14065 loss：0.030533
【train】 epoch：2 step:6564/14065 loss：0.033105
【train】 epoch：2 step:6565/14065 loss：0.093217
【train】 epoch：2 step:6566/14065 loss：0.114022
【train】 epoch：2 step:6567/14065 loss：0.034400
【train】 epoch：2 step:6568/14065 loss：0.125894
【train】 epoch：2 step:6569/14065 loss：0.062931
【train】 epoch：2 step:6570/14065 loss：0.056939
【train】 epoch：2 step:6571/14065 loss：0.086692
【train】 epoch：2 step:6572/14065 loss：0.042560
【train】 epoch：2 step:6573/14065 loss：0.195668
【train】 epoch：2 step:6574/14065 loss：0.105226
【train】 epoch：2 step:6575/14065 loss：0.142856
【train】 epoch：2 step:6576/14065 loss：0.024814
【train】 epoch：2 step:6577/14065 loss：0.072238
【train】 epoch：2 step:6578/14065 loss：0.055944
【train】 epoch：2 step:6579/14065 loss：0.064392
【train】 epoch：2 step:6580/14065 loss：0.156707
【train】 epoch：2 step:6581/14065 loss：0.072486
【train】 epoch：2 step:6582/14065 loss：0.135743
【train】 epoch：2 step:6583/14065 loss：0.126614
【train】 epoch：2 step:6584/14065 loss：0.031221
【train】 epoch：2 step:6585/14065 loss：0.092841
【train】 epoch：2 step:6586/14065 loss：0.086465
【train】 epoch：2 step:6587/14065 loss：0.039977
【train】 epoch：2 step:6588/14065 loss：0.065835
【train】 epoch：2 step:6589/14065 loss：0.150983
【train】 epoch：2 step:6590/14065 loss：0.043823
【train】 epoch：2 step:6591/14065 loss：0.136632
【train】 epoch：2 step:6592/14065 loss：0.035984
【train】 epoch：2 step:6593/14065 loss：0.108055
【train】 epoch：2 step:6594/14065 loss：0.036162
【train】 epoch：2 step:6595/14065 loss：0.045195
【train】 epoch：2 step:6596/14065 loss：0.124985
【train】 epoch：2 step:6597/14065 loss：0.102960
【train】 epoch：2 step:6598/14065 loss：0.088800
【train】 epoch：2 step:6599/14065 loss：0.120551
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：175.687899 accuracy：0.9796 precision：0.9796 recall：0.9796 f1：0.9796
------------>保存当前最好的模型
【train】 epoch：2 step:6600/14065 loss：0.062765
【train】 epoch：2 step:6601/14065 loss：0.162061
【train】 epoch：2 step:6602/14065 loss：0.081143
【train】 epoch：2 step:6603/14065 loss：0.033592
【train】 epoch：2 step:6604/14065 loss：0.096331
【train】 epoch：2 step:6605/14065 loss：0.113845
【train】 epoch：2 step:6606/14065 loss：0.036120
【train】 epoch：2 step:6607/14065 loss：0.090309
【train】 epoch：2 step:6608/14065 loss：0.066474
【train】 epoch：2 step:6609/14065 loss：0.113002
【train】 epoch：2 step:6610/14065 loss：0.244213
【train】 epoch：2 step:6611/14065 loss：0.147951
【train】 epoch：2 step:6612/14065 loss：0.158351
【train】 epoch：2 step:6613/14065 loss：0.119333
【train】 epoch：2 step:6614/14065 loss：0.222393
【train】 epoch：2 step:6615/14065 loss：0.037212
【train】 epoch：2 step:6616/14065 loss：0.026884
【train】 epoch：2 step:6617/14065 loss：0.044082
【train】 epoch：2 step:6618/14065 loss：0.141078
【train】 epoch：2 step:6619/14065 loss：0.099887
【train】 epoch：2 step:6620/14065 loss：0.042001
【train】 epoch：2 step:6621/14065 loss：0.176118
【train】 epoch：2 step:6622/14065 loss：0.139168
【train】 epoch：2 step:6623/14065 loss：0.107269
【train】 epoch：2 step:6624/14065 loss：0.026678
【train】 epoch：2 step:6625/14065 loss：0.129718
【train】 epoch：2 step:6626/14065 loss：0.038973
【train】 epoch：2 step:6627/14065 loss：0.200788
【train】 epoch：2 step:6628/14065 loss：0.124777
【train】 epoch：2 step:6629/14065 loss：0.040285
【train】 epoch：2 step:6630/14065 loss：0.034181
【train】 epoch：2 step:6631/14065 loss：0.048561
【train】 epoch：2 step:6632/14065 loss：0.119154
【train】 epoch：2 step:6633/14065 loss：0.072620
【train】 epoch：2 step:6634/14065 loss：0.036928
【train】 epoch：2 step:6635/14065 loss：0.107429
【train】 epoch：2 step:6636/14065 loss：0.049567
【train】 epoch：2 step:6637/14065 loss：0.067161
【train】 epoch：2 step:6638/14065 loss：0.091555
【train】 epoch：2 step:6639/14065 loss：0.012903
【train】 epoch：2 step:6640/14065 loss：0.141505
【train】 epoch：2 step:6641/14065 loss：0.079049
【train】 epoch：2 step:6642/14065 loss：0.159626
【train】 epoch：2 step:6643/14065 loss：0.015487
【train】 epoch：2 step:6644/14065 loss：0.050178
【train】 epoch：2 step:6645/14065 loss：0.146821
【train】 epoch：2 step:6646/14065 loss：0.048952
【train】 epoch：2 step:6647/14065 loss：0.142728
【train】 epoch：2 step:6648/14065 loss：0.071083
【train】 epoch：2 step:6649/14065 loss：0.068197
【train】 epoch：2 step:6650/14065 loss：0.038525
【train】 epoch：2 step:6651/14065 loss：0.014576
【train】 epoch：2 step:6652/14065 loss：0.060040
【train】 epoch：2 step:6653/14065 loss：0.023773
【train】 epoch：2 step:6654/14065 loss：0.090047
【train】 epoch：2 step:6655/14065 loss：0.097505
【train】 epoch：2 step:6656/14065 loss：0.056027
【train】 epoch：2 step:6657/14065 loss：0.038001
【train】 epoch：2 step:6658/14065 loss：0.022247
【train】 epoch：2 step:6659/14065 loss：0.258494
【train】 epoch：2 step:6660/14065 loss：0.227074
【train】 epoch：2 step:6661/14065 loss：0.187715
【train】 epoch：2 step:6662/14065 loss：0.035889
【train】 epoch：2 step:6663/14065 loss：0.089434
【train】 epoch：2 step:6664/14065 loss：0.023060
【train】 epoch：2 step:6665/14065 loss：0.060970
【train】 epoch：2 step:6666/14065 loss：0.058971
【train】 epoch：2 step:6667/14065 loss：0.071037
【train】 epoch：2 step:6668/14065 loss：0.112183
【train】 epoch：2 step:6669/14065 loss：0.096058
【train】 epoch：2 step:6670/14065 loss：0.071553
【train】 epoch：2 step:6671/14065 loss：0.090856
【train】 epoch：2 step:6672/14065 loss：0.319214
【train】 epoch：2 step:6673/14065 loss：0.079578
【train】 epoch：2 step:6674/14065 loss：0.058632
【train】 epoch：2 step:6675/14065 loss：0.242503
【train】 epoch：2 step:6676/14065 loss：0.084595
【train】 epoch：2 step:6677/14065 loss：0.047601
【train】 epoch：2 step:6678/14065 loss：0.090939
【train】 epoch：2 step:6679/14065 loss：0.126423
【train】 epoch：2 step:6680/14065 loss：0.129735
【train】 epoch：2 step:6681/14065 loss：0.102961
【train】 epoch：2 step:6682/14065 loss：0.155856
【train】 epoch：2 step:6683/14065 loss：0.097814
【train】 epoch：2 step:6684/14065 loss：0.097356
【train】 epoch：2 step:6685/14065 loss：0.183254
【train】 epoch：2 step:6686/14065 loss：0.065920
【train】 epoch：2 step:6687/14065 loss：0.137512
【train】 epoch：2 step:6688/14065 loss：0.209626
【train】 epoch：2 step:6689/14065 loss：0.029880
【train】 epoch：2 step:6690/14065 loss：0.068903
【train】 epoch：2 step:6691/14065 loss：0.181129
【train】 epoch：2 step:6692/14065 loss：0.094034
【train】 epoch：2 step:6693/14065 loss：0.088414
【train】 epoch：2 step:6694/14065 loss：0.081987
【train】 epoch：2 step:6695/14065 loss：0.123875
【train】 epoch：2 step:6696/14065 loss：0.020209
【train】 epoch：2 step:6697/14065 loss：0.046901
【train】 epoch：2 step:6698/14065 loss：0.039204
【train】 epoch：2 step:6699/14065 loss：0.138509
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：172.542069 accuracy：0.9804 precision：0.9804 recall：0.9804 f1：0.9804
------------>保存当前最好的模型
【train】 epoch：2 step:6700/14065 loss：0.097303
【train】 epoch：2 step:6701/14065 loss：0.040747
【train】 epoch：2 step:6702/14065 loss：0.119464
【train】 epoch：2 step:6703/14065 loss：0.079784
【train】 epoch：2 step:6704/14065 loss：0.078214
【train】 epoch：2 step:6705/14065 loss：0.031108
【train】 epoch：2 step:6706/14065 loss：0.072477
【train】 epoch：2 step:6707/14065 loss：0.067752
【train】 epoch：2 step:6708/14065 loss：0.063022
【train】 epoch：2 step:6709/14065 loss：0.104240
【train】 epoch：2 step:6710/14065 loss：0.028529
【train】 epoch：2 step:6711/14065 loss：0.107510
【train】 epoch：2 step:6712/14065 loss：0.057076
【train】 epoch：2 step:6713/14065 loss：0.277250
【train】 epoch：2 step:6714/14065 loss：0.059585
【train】 epoch：2 step:6715/14065 loss：0.124565
【train】 epoch：2 step:6716/14065 loss：0.109364
【train】 epoch：2 step:6717/14065 loss：0.050444
【train】 epoch：2 step:6718/14065 loss：0.037708
【train】 epoch：2 step:6719/14065 loss：0.110012
【train】 epoch：2 step:6720/14065 loss：0.104553
【train】 epoch：2 step:6721/14065 loss：0.025017
【train】 epoch：2 step:6722/14065 loss：0.057410
【train】 epoch：2 step:6723/14065 loss：0.191797
【train】 epoch：2 step:6724/14065 loss：0.030939
【train】 epoch：2 step:6725/14065 loss：0.139234
【train】 epoch：2 step:6726/14065 loss：0.048109
【train】 epoch：2 step:6727/14065 loss：0.030333
【train】 epoch：2 step:6728/14065 loss：0.113519
【train】 epoch：2 step:6729/14065 loss：0.018873
【train】 epoch：2 step:6730/14065 loss：0.063951
【train】 epoch：2 step:6731/14065 loss：0.021342
【train】 epoch：2 step:6732/14065 loss：0.197233
【train】 epoch：2 step:6733/14065 loss：0.119292
【train】 epoch：2 step:6734/14065 loss：0.113858
【train】 epoch：2 step:6735/14065 loss：0.074084
【train】 epoch：2 step:6736/14065 loss：0.016362
【train】 epoch：2 step:6737/14065 loss：0.056955
【train】 epoch：2 step:6738/14065 loss：0.031065
【train】 epoch：2 step:6739/14065 loss：0.168197
【train】 epoch：2 step:6740/14065 loss：0.040117
【train】 epoch：2 step:6741/14065 loss：0.250203
【train】 epoch：2 step:6742/14065 loss：0.184386
【train】 epoch：2 step:6743/14065 loss：0.035964
【train】 epoch：2 step:6744/14065 loss：0.088769
【train】 epoch：2 step:6745/14065 loss：0.098710
【train】 epoch：2 step:6746/14065 loss：0.014867
【train】 epoch：2 step:6747/14065 loss：0.042994
【train】 epoch：2 step:6748/14065 loss：0.288136
【train】 epoch：2 step:6749/14065 loss：0.089138
【train】 epoch：2 step:6750/14065 loss：0.021362
【train】 epoch：2 step:6751/14065 loss：0.173542
【train】 epoch：2 step:6752/14065 loss：0.034012
【train】 epoch：2 step:6753/14065 loss：0.117390
【train】 epoch：2 step:6754/14065 loss：0.228676
【train】 epoch：2 step:6755/14065 loss：0.132359
【train】 epoch：2 step:6756/14065 loss：0.099163
【train】 epoch：2 step:6757/14065 loss：0.158542
【train】 epoch：2 step:6758/14065 loss：0.208655
【train】 epoch：2 step:6759/14065 loss：0.129488
【train】 epoch：2 step:6760/14065 loss：0.094119
【train】 epoch：2 step:6761/14065 loss：0.080032
【train】 epoch：2 step:6762/14065 loss：0.079751
【train】 epoch：2 step:6763/14065 loss：0.023106
【train】 epoch：2 step:6764/14065 loss：0.041067
【train】 epoch：2 step:6765/14065 loss：0.144598
【train】 epoch：2 step:6766/14065 loss：0.174027
【train】 epoch：2 step:6767/14065 loss：0.066259
【train】 epoch：2 step:6768/14065 loss：0.143397
【train】 epoch：2 step:6769/14065 loss：0.144594
【train】 epoch：2 step:6770/14065 loss：0.056688
【train】 epoch：2 step:6771/14065 loss：0.134557
【train】 epoch：2 step:6772/14065 loss：0.032099
【train】 epoch：2 step:6773/14065 loss：0.137984
【train】 epoch：2 step:6774/14065 loss：0.205421
【train】 epoch：2 step:6775/14065 loss：0.111980
【train】 epoch：2 step:6776/14065 loss：0.102356
【train】 epoch：2 step:6777/14065 loss：0.029533
【train】 epoch：2 step:6778/14065 loss：0.054233
【train】 epoch：2 step:6779/14065 loss：0.081243
【train】 epoch：2 step:6780/14065 loss：0.048742
【train】 epoch：2 step:6781/14065 loss：0.224565
【train】 epoch：2 step:6782/14065 loss：0.098870
【train】 epoch：2 step:6783/14065 loss：0.049465
【train】 epoch：2 step:6784/14065 loss：0.030235
【train】 epoch：2 step:6785/14065 loss：0.073473
【train】 epoch：2 step:6786/14065 loss：0.063274
【train】 epoch：2 step:6787/14065 loss：0.140443
【train】 epoch：2 step:6788/14065 loss：0.038084
【train】 epoch：2 step:6789/14065 loss：0.071806
【train】 epoch：2 step:6790/14065 loss：0.043950
【train】 epoch：2 step:6791/14065 loss：0.254557
【train】 epoch：2 step:6792/14065 loss：0.110684
【train】 epoch：2 step:6793/14065 loss：0.047327
【train】 epoch：2 step:6794/14065 loss：0.107407
【train】 epoch：2 step:6795/14065 loss：0.115612
【train】 epoch：2 step:6796/14065 loss：0.032910
【train】 epoch：2 step:6797/14065 loss：0.118821
【train】 epoch：2 step:6798/14065 loss：0.118276
【train】 epoch：2 step:6799/14065 loss：0.205079
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：193.427532 accuracy：0.9774 precision：0.9774 recall：0.9774 f1：0.9774
【train】 epoch：2 step:6800/14065 loss：0.031726
【train】 epoch：2 step:6801/14065 loss：0.064748
【train】 epoch：2 step:6802/14065 loss：0.179053
【train】 epoch：2 step:6803/14065 loss：0.229215
【train】 epoch：2 step:6804/14065 loss：0.147506
【train】 epoch：2 step:6805/14065 loss：0.028069
【train】 epoch：2 step:6806/14065 loss：0.080019
【train】 epoch：2 step:6807/14065 loss：0.019878
【train】 epoch：2 step:6808/14065 loss：0.203629
【train】 epoch：2 step:6809/14065 loss：0.223995
【train】 epoch：2 step:6810/14065 loss：0.136721
【train】 epoch：2 step:6811/14065 loss：0.055813
【train】 epoch：2 step:6812/14065 loss：0.296880
【train】 epoch：2 step:6813/14065 loss：0.040514
【train】 epoch：2 step:6814/14065 loss：0.036298
【train】 epoch：2 step:6815/14065 loss：0.041523
【train】 epoch：2 step:6816/14065 loss：0.085488
【train】 epoch：2 step:6817/14065 loss：0.055965
【train】 epoch：2 step:6818/14065 loss：0.046267
【train】 epoch：2 step:6819/14065 loss：0.115398
【train】 epoch：2 step:6820/14065 loss：0.075714
【train】 epoch：2 step:6821/14065 loss：0.075487
【train】 epoch：2 step:6822/14065 loss：0.084139
【train】 epoch：2 step:6823/14065 loss：0.052401
【train】 epoch：2 step:6824/14065 loss：0.103521
【train】 epoch：2 step:6825/14065 loss：0.082658
【train】 epoch：2 step:6826/14065 loss：0.073850
【train】 epoch：2 step:6827/14065 loss：0.050743
【train】 epoch：2 step:6828/14065 loss：0.094412
【train】 epoch：2 step:6829/14065 loss：0.104896
【train】 epoch：2 step:6830/14065 loss：0.283812
【train】 epoch：2 step:6831/14065 loss：0.081721
【train】 epoch：2 step:6832/14065 loss：0.083472
【train】 epoch：2 step:6833/14065 loss：0.108924
【train】 epoch：2 step:6834/14065 loss：0.049439
【train】 epoch：2 step:6835/14065 loss：0.115142
【train】 epoch：2 step:6836/14065 loss：0.215569
【train】 epoch：2 step:6837/14065 loss：0.023125
【train】 epoch：2 step:6838/14065 loss：0.166034
【train】 epoch：2 step:6839/14065 loss：0.193089
【train】 epoch：2 step:6840/14065 loss：0.161248
【train】 epoch：2 step:6841/14065 loss：0.126954
【train】 epoch：2 step:6842/14065 loss：0.187053
【train】 epoch：2 step:6843/14065 loss：0.128744
【train】 epoch：2 step:6844/14065 loss：0.096870
【train】 epoch：2 step:6845/14065 loss：0.048836
【train】 epoch：2 step:6846/14065 loss：0.152100
【train】 epoch：2 step:6847/14065 loss：0.045340
【train】 epoch：2 step:6848/14065 loss：0.021945
【train】 epoch：2 step:6849/14065 loss：0.075553
【train】 epoch：2 step:6850/14065 loss：0.114819
【train】 epoch：2 step:6851/14065 loss：0.062433
【train】 epoch：2 step:6852/14065 loss：0.025419
【train】 epoch：2 step:6853/14065 loss：0.126100
【train】 epoch：2 step:6854/14065 loss：0.086769
【train】 epoch：2 step:6855/14065 loss：0.049465
【train】 epoch：2 step:6856/14065 loss：0.029928
【train】 epoch：2 step:6857/14065 loss：0.180279
【train】 epoch：2 step:6858/14065 loss：0.110444
【train】 epoch：2 step:6859/14065 loss：0.159247
【train】 epoch：2 step:6860/14065 loss：0.029854
【train】 epoch：2 step:6861/14065 loss：0.035546
【train】 epoch：2 step:6862/14065 loss：0.065985
【train】 epoch：2 step:6863/14065 loss：0.149743
【train】 epoch：2 step:6864/14065 loss：0.039819
【train】 epoch：2 step:6865/14065 loss：0.131793
【train】 epoch：2 step:6866/14065 loss：0.050579
【train】 epoch：2 step:6867/14065 loss：0.146867
【train】 epoch：2 step:6868/14065 loss：0.177310
【train】 epoch：2 step:6869/14065 loss：0.028489
【train】 epoch：2 step:6870/14065 loss：0.026458
【train】 epoch：2 step:6871/14065 loss：0.054039
【train】 epoch：2 step:6872/14065 loss：0.103842
【train】 epoch：2 step:6873/14065 loss：0.112585
【train】 epoch：2 step:6874/14065 loss：0.115612
【train】 epoch：2 step:6875/14065 loss：0.073770
【train】 epoch：2 step:6876/14065 loss：0.206830
【train】 epoch：2 step:6877/14065 loss：0.053598
【train】 epoch：2 step:6878/14065 loss：0.135452
【train】 epoch：2 step:6879/14065 loss：0.044392
【train】 epoch：2 step:6880/14065 loss：0.086356
【train】 epoch：2 step:6881/14065 loss：0.113119
【train】 epoch：2 step:6882/14065 loss：0.112299
【train】 epoch：2 step:6883/14065 loss：0.115276
【train】 epoch：2 step:6884/14065 loss：0.096666
【train】 epoch：2 step:6885/14065 loss：0.100033
【train】 epoch：2 step:6886/14065 loss：0.078247
【train】 epoch：2 step:6887/14065 loss：0.114260
【train】 epoch：2 step:6888/14065 loss：0.159952
【train】 epoch：2 step:6889/14065 loss：0.064386
【train】 epoch：2 step:6890/14065 loss：0.043343
【train】 epoch：2 step:6891/14065 loss：0.128347
【train】 epoch：2 step:6892/14065 loss：0.159724
【train】 epoch：2 step:6893/14065 loss：0.073914
【train】 epoch：2 step:6894/14065 loss：0.045411
【train】 epoch：2 step:6895/14065 loss：0.111461
【train】 epoch：2 step:6896/14065 loss：0.092008
【train】 epoch：2 step:6897/14065 loss：0.145209
【train】 epoch：2 step:6898/14065 loss：0.179285
【train】 epoch：2 step:6899/14065 loss：0.104615
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：185.190275 accuracy：0.9780 precision：0.9780 recall：0.9780 f1：0.9780
【train】 epoch：2 step:6900/14065 loss：0.145518
【train】 epoch：2 step:6901/14065 loss：0.087192
【train】 epoch：2 step:6902/14065 loss：0.195977
【train】 epoch：2 step:6903/14065 loss：0.044328
【train】 epoch：2 step:6904/14065 loss：0.066217
【train】 epoch：2 step:6905/14065 loss：0.067793
【train】 epoch：2 step:6906/14065 loss：0.102316
【train】 epoch：2 step:6907/14065 loss：0.101173
【train】 epoch：2 step:6908/14065 loss：0.151685
【train】 epoch：2 step:6909/14065 loss：0.063663
【train】 epoch：2 step:6910/14065 loss：0.190779
【train】 epoch：2 step:6911/14065 loss：0.015408
【train】 epoch：2 step:6912/14065 loss：0.097809
【train】 epoch：2 step:6913/14065 loss：0.133092
【train】 epoch：2 step:6914/14065 loss：0.035818
【train】 epoch：2 step:6915/14065 loss：0.096495
【train】 epoch：2 step:6916/14065 loss：0.126196
【train】 epoch：2 step:6917/14065 loss：0.185404
【train】 epoch：2 step:6918/14065 loss：0.052990
【train】 epoch：2 step:6919/14065 loss：0.082403
【train】 epoch：2 step:6920/14065 loss：0.027313
【train】 epoch：2 step:6921/14065 loss：0.227119
【train】 epoch：2 step:6922/14065 loss：0.088283
【train】 epoch：2 step:6923/14065 loss：0.121747
【train】 epoch：2 step:6924/14065 loss：0.066044
【train】 epoch：2 step:6925/14065 loss：0.065195
【train】 epoch：2 step:6926/14065 loss：0.090830
【train】 epoch：2 step:6927/14065 loss：0.074881
【train】 epoch：2 step:6928/14065 loss：0.070034
【train】 epoch：2 step:6929/14065 loss：0.097360
【train】 epoch：2 step:6930/14065 loss：0.058246
【train】 epoch：2 step:6931/14065 loss：0.040096
【train】 epoch：2 step:6932/14065 loss：0.051452
【train】 epoch：2 step:6933/14065 loss：0.071589
【train】 epoch：2 step:6934/14065 loss：0.217366
【train】 epoch：2 step:6935/14065 loss：0.198329
【train】 epoch：2 step:6936/14065 loss：0.054529
【train】 epoch：2 step:6937/14065 loss：0.064415
【train】 epoch：2 step:6938/14065 loss：0.049006
【train】 epoch：2 step:6939/14065 loss：0.106195
【train】 epoch：2 step:6940/14065 loss：0.057502
【train】 epoch：2 step:6941/14065 loss：0.110338
【train】 epoch：2 step:6942/14065 loss：0.044349
【train】 epoch：2 step:6943/14065 loss：0.049712
【train】 epoch：2 step:6944/14065 loss：0.119587
【train】 epoch：2 step:6945/14065 loss：0.084127
【train】 epoch：2 step:6946/14065 loss：0.034689
【train】 epoch：2 step:6947/14065 loss：0.117849
【train】 epoch：2 step:6948/14065 loss：0.107679
【train】 epoch：2 step:6949/14065 loss：0.115068
【train】 epoch：2 step:6950/14065 loss：0.046672
【train】 epoch：2 step:6951/14065 loss：0.096727
【train】 epoch：2 step:6952/14065 loss：0.088316
【train】 epoch：2 step:6953/14065 loss：0.052344
【train】 epoch：2 step:6954/14065 loss：0.121004
【train】 epoch：2 step:6955/14065 loss：0.141967
【train】 epoch：2 step:6956/14065 loss：0.198968
【train】 epoch：2 step:6957/14065 loss：0.079257
【train】 epoch：2 step:6958/14065 loss：0.075491
【train】 epoch：2 step:6959/14065 loss：0.072736
【train】 epoch：2 step:6960/14065 loss：0.116224
【train】 epoch：2 step:6961/14065 loss：0.028101
【train】 epoch：2 step:6962/14065 loss：0.099397
【train】 epoch：2 step:6963/14065 loss：0.125602
【train】 epoch：2 step:6964/14065 loss：0.111334
【train】 epoch：2 step:6965/14065 loss：0.144668
【train】 epoch：2 step:6966/14065 loss：0.043432
【train】 epoch：2 step:6967/14065 loss：0.113985
【train】 epoch：2 step:6968/14065 loss：0.031002
【train】 epoch：2 step:6969/14065 loss：0.042973
【train】 epoch：2 step:6970/14065 loss：0.046628
【train】 epoch：2 step:6971/14065 loss：0.067615
【train】 epoch：2 step:6972/14065 loss：0.101432
【train】 epoch：2 step:6973/14065 loss：0.076131
【train】 epoch：2 step:6974/14065 loss：0.084041
【train】 epoch：2 step:6975/14065 loss：0.083475
【train】 epoch：2 step:6976/14065 loss：0.060379
【train】 epoch：2 step:6977/14065 loss：0.087326
【train】 epoch：2 step:6978/14065 loss：0.081561
【train】 epoch：2 step:6979/14065 loss：0.124562
【train】 epoch：2 step:6980/14065 loss：0.100898
【train】 epoch：2 step:6981/14065 loss：0.063491
【train】 epoch：2 step:6982/14065 loss：0.178964
【train】 epoch：2 step:6983/14065 loss：0.066183
【train】 epoch：2 step:6984/14065 loss：0.037362
【train】 epoch：2 step:6985/14065 loss：0.090695
【train】 epoch：2 step:6986/14065 loss：0.008380
【train】 epoch：2 step:6987/14065 loss：0.108283
【train】 epoch：2 step:6988/14065 loss：0.081546
【train】 epoch：2 step:6989/14065 loss：0.034627
【train】 epoch：2 step:6990/14065 loss：0.052996
【train】 epoch：2 step:6991/14065 loss：0.052539
【train】 epoch：2 step:6992/14065 loss：0.029821
【train】 epoch：2 step:6993/14065 loss：0.062967
【train】 epoch：2 step:6994/14065 loss：0.074623
【train】 epoch：2 step:6995/14065 loss：0.130099
【train】 epoch：2 step:6996/14065 loss：0.108171
【train】 epoch：2 step:6997/14065 loss：0.138187
【train】 epoch：2 step:6998/14065 loss：0.100527
【train】 epoch：2 step:6999/14065 loss：0.041713
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：181.382827 accuracy：0.9788 precision：0.9788 recall：0.9788 f1：0.9788
【train】 epoch：2 step:7000/14065 loss：0.060497
【train】 epoch：2 step:7001/14065 loss：0.064408
【train】 epoch：2 step:7002/14065 loss：0.046445
【train】 epoch：2 step:7003/14065 loss：0.155502
【train】 epoch：2 step:7004/14065 loss：0.066965
【train】 epoch：2 step:7005/14065 loss：0.174173
【train】 epoch：2 step:7006/14065 loss：0.206474
【train】 epoch：2 step:7007/14065 loss：0.096146
【train】 epoch：2 step:7008/14065 loss：0.040309
【train】 epoch：2 step:7009/14065 loss：0.048299
【train】 epoch：2 step:7010/14065 loss：0.058758
【train】 epoch：2 step:7011/14065 loss：0.039785
【train】 epoch：2 step:7012/14065 loss：0.075738
【train】 epoch：2 step:7013/14065 loss：0.024300
【train】 epoch：2 step:7014/14065 loss：0.041618
【train】 epoch：2 step:7015/14065 loss：0.073947
【train】 epoch：2 step:7016/14065 loss：0.191562
【train】 epoch：2 step:7017/14065 loss：0.033616
【train】 epoch：2 step:7018/14065 loss：0.148238
【train】 epoch：2 step:7019/14065 loss：0.086703
【train】 epoch：2 step:7020/14065 loss：0.047167
【train】 epoch：2 step:7021/14065 loss：0.115566
【train】 epoch：2 step:7022/14065 loss：0.149138
【train】 epoch：2 step:7023/14065 loss：0.032819
【train】 epoch：2 step:7024/14065 loss：0.143730
【train】 epoch：2 step:7025/14065 loss：0.061767
【train】 epoch：2 step:7026/14065 loss：0.063104
【train】 epoch：2 step:7027/14065 loss：0.035759
【train】 epoch：2 step:7028/14065 loss：0.242272
【train】 epoch：2 step:7029/14065 loss：0.081032
【train】 epoch：2 step:7030/14065 loss：0.088374
【train】 epoch：2 step:7031/14065 loss：0.091338
【train】 epoch：2 step:7032/14065 loss：0.038979
【train】 epoch：2 step:7033/14065 loss：0.085199
【train】 epoch：2 step:7034/14065 loss：0.024156
【train】 epoch：2 step:7035/14065 loss：0.044729
【train】 epoch：2 step:7036/14065 loss：0.082076
【train】 epoch：2 step:7037/14065 loss：0.079230
【train】 epoch：2 step:7038/14065 loss：0.006074
【train】 epoch：2 step:7039/14065 loss：0.036466
【train】 epoch：2 step:7040/14065 loss：0.037215
【train】 epoch：2 step:7041/14065 loss：0.099563
【train】 epoch：2 step:7042/14065 loss：0.022729
【train】 epoch：2 step:7043/14065 loss：0.189671
【train】 epoch：2 step:7044/14065 loss：0.079730
【train】 epoch：2 step:7045/14065 loss：0.189345
【train】 epoch：2 step:7046/14065 loss：0.061127
【train】 epoch：2 step:7047/14065 loss：0.056549
【train】 epoch：2 step:7048/14065 loss：0.046252
【train】 epoch：2 step:7049/14065 loss：0.106134
【train】 epoch：2 step:7050/14065 loss：0.132599
【train】 epoch：2 step:7051/14065 loss：0.016343
【train】 epoch：2 step:7052/14065 loss：0.172516
【train】 epoch：2 step:7053/14065 loss：0.064065
【train】 epoch：2 step:7054/14065 loss：0.006905
【train】 epoch：2 step:7055/14065 loss：0.031903
【train】 epoch：2 step:7056/14065 loss：0.116160
【train】 epoch：2 step:7057/14065 loss：0.107193
【train】 epoch：2 step:7058/14065 loss：0.024732
【train】 epoch：2 step:7059/14065 loss：0.194142
【train】 epoch：2 step:7060/14065 loss：0.266425
【train】 epoch：2 step:7061/14065 loss：0.049531
【train】 epoch：2 step:7062/14065 loss：0.204664
【train】 epoch：2 step:7063/14065 loss：0.072145
【train】 epoch：2 step:7064/14065 loss：0.193044
【train】 epoch：2 step:7065/14065 loss：0.048196
【train】 epoch：2 step:7066/14065 loss：0.067420
【train】 epoch：2 step:7067/14065 loss：0.130511
【train】 epoch：2 step:7068/14065 loss：0.073079
【train】 epoch：2 step:7069/14065 loss：0.056440
【train】 epoch：2 step:7070/14065 loss：0.040563
【train】 epoch：2 step:7071/14065 loss：0.006473
【train】 epoch：2 step:7072/14065 loss：0.050067
【train】 epoch：2 step:7073/14065 loss：0.175048
【train】 epoch：2 step:7074/14065 loss：0.159316
【train】 epoch：2 step:7075/14065 loss：0.161418
【train】 epoch：2 step:7076/14065 loss：0.073865
【train】 epoch：2 step:7077/14065 loss：0.050663
【train】 epoch：2 step:7078/14065 loss：0.223095
【train】 epoch：2 step:7079/14065 loss：0.034161
【train】 epoch：2 step:7080/14065 loss：0.336072
【train】 epoch：2 step:7081/14065 loss：0.098435
【train】 epoch：2 step:7082/14065 loss：0.083628
【train】 epoch：2 step:7083/14065 loss：0.161200
【train】 epoch：2 step:7084/14065 loss：0.096022
【train】 epoch：2 step:7085/14065 loss：0.157528
【train】 epoch：2 step:7086/14065 loss：0.077471
【train】 epoch：2 step:7087/14065 loss：0.171509
【train】 epoch：2 step:7088/14065 loss：0.051375
【train】 epoch：2 step:7089/14065 loss：0.075368
【train】 epoch：2 step:7090/14065 loss：0.020435
【train】 epoch：2 step:7091/14065 loss：0.068988
【train】 epoch：2 step:7092/14065 loss：0.128366
【train】 epoch：2 step:7093/14065 loss：0.263969
【train】 epoch：2 step:7094/14065 loss：0.103609
【train】 epoch：2 step:7095/14065 loss：0.077268
【train】 epoch：2 step:7096/14065 loss：0.130182
【train】 epoch：2 step:7097/14065 loss：0.151914
【train】 epoch：2 step:7098/14065 loss：0.120888
【train】 epoch：2 step:7099/14065 loss：0.031925
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：197.244675 accuracy：0.9769 precision：0.9769 recall：0.9769 f1：0.9769
【train】 epoch：2 step:7100/14065 loss：0.169253
【train】 epoch：2 step:7101/14065 loss：0.077415
【train】 epoch：2 step:7102/14065 loss：0.073011
【train】 epoch：2 step:7103/14065 loss：0.088876
【train】 epoch：2 step:7104/14065 loss：0.016852
【train】 epoch：2 step:7105/14065 loss：0.196547
【train】 epoch：2 step:7106/14065 loss：0.183002
【train】 epoch：2 step:7107/14065 loss：0.200289
【train】 epoch：2 step:7108/14065 loss：0.130747
【train】 epoch：2 step:7109/14065 loss：0.039041
【train】 epoch：2 step:7110/14065 loss：0.199960
【train】 epoch：2 step:7111/14065 loss：0.082305
【train】 epoch：2 step:7112/14065 loss：0.044479
【train】 epoch：2 step:7113/14065 loss：0.101813
【train】 epoch：2 step:7114/14065 loss：0.247319
【train】 epoch：2 step:7115/14065 loss：0.079309
【train】 epoch：2 step:7116/14065 loss：0.073980
【train】 epoch：2 step:7117/14065 loss：0.047575
【train】 epoch：2 step:7118/14065 loss：0.139097
【train】 epoch：2 step:7119/14065 loss：0.122452
【train】 epoch：2 step:7120/14065 loss：0.075422
【train】 epoch：2 step:7121/14065 loss：0.073036
【train】 epoch：2 step:7122/14065 loss：0.128769
【train】 epoch：2 step:7123/14065 loss：0.118396
【train】 epoch：2 step:7124/14065 loss：0.055489
【train】 epoch：2 step:7125/14065 loss：0.114604
【train】 epoch：2 step:7126/14065 loss：0.123644
【train】 epoch：2 step:7127/14065 loss：0.067052
【train】 epoch：2 step:7128/14065 loss：0.099681
【train】 epoch：2 step:7129/14065 loss：0.049922
【train】 epoch：2 step:7130/14065 loss：0.089130
【train】 epoch：2 step:7131/14065 loss：0.048362
【train】 epoch：2 step:7132/14065 loss：0.074342
【train】 epoch：2 step:7133/14065 loss：0.057461
【train】 epoch：2 step:7134/14065 loss：0.064908
【train】 epoch：2 step:7135/14065 loss：0.094521
【train】 epoch：2 step:7136/14065 loss：0.075906
【train】 epoch：2 step:7137/14065 loss：0.096463
【train】 epoch：2 step:7138/14065 loss：0.056968
【train】 epoch：2 step:7139/14065 loss：0.097747
【train】 epoch：2 step:7140/14065 loss：0.033929
【train】 epoch：2 step:7141/14065 loss：0.102224
【train】 epoch：2 step:7142/14065 loss：0.163733
【train】 epoch：2 step:7143/14065 loss：0.164001
【train】 epoch：2 step:7144/14065 loss：0.115590
【train】 epoch：2 step:7145/14065 loss：0.082265
【train】 epoch：2 step:7146/14065 loss：0.061167
【train】 epoch：2 step:7147/14065 loss：0.135246
【train】 epoch：2 step:7148/14065 loss：0.178456
【train】 epoch：2 step:7149/14065 loss：0.023547
【train】 epoch：2 step:7150/14065 loss：0.065151
【train】 epoch：2 step:7151/14065 loss：0.082326
【train】 epoch：2 step:7152/14065 loss：0.029224
【train】 epoch：2 step:7153/14065 loss：0.131537
【train】 epoch：2 step:7154/14065 loss：0.035713
【train】 epoch：2 step:7155/14065 loss：0.091985
【train】 epoch：2 step:7156/14065 loss：0.098287
【train】 epoch：2 step:7157/14065 loss：0.194686
【train】 epoch：2 step:7158/14065 loss：0.147348
【train】 epoch：2 step:7159/14065 loss：0.260700
【train】 epoch：2 step:7160/14065 loss：0.125635
【train】 epoch：2 step:7161/14065 loss：0.065384
【train】 epoch：2 step:7162/14065 loss：0.107190
【train】 epoch：2 step:7163/14065 loss：0.073096
【train】 epoch：2 step:7164/14065 loss：0.081559
【train】 epoch：2 step:7165/14065 loss：0.044528
【train】 epoch：2 step:7166/14065 loss：0.030394
【train】 epoch：2 step:7167/14065 loss：0.048943
【train】 epoch：2 step:7168/14065 loss：0.060905
【train】 epoch：2 step:7169/14065 loss：0.056371
【train】 epoch：2 step:7170/14065 loss：0.109261
【train】 epoch：2 step:7171/14065 loss：0.134745
【train】 epoch：2 step:7172/14065 loss：0.017170
【train】 epoch：2 step:7173/14065 loss：0.052676
【train】 epoch：2 step:7174/14065 loss：0.094967
【train】 epoch：2 step:7175/14065 loss：0.080250
【train】 epoch：2 step:7176/14065 loss：0.128449
【train】 epoch：2 step:7177/14065 loss：0.024174
【train】 epoch：2 step:7178/14065 loss：0.088972
【train】 epoch：2 step:7179/14065 loss：0.126719
【train】 epoch：2 step:7180/14065 loss：0.050227
【train】 epoch：2 step:7181/14065 loss：0.041411
【train】 epoch：2 step:7182/14065 loss：0.117075
【train】 epoch：2 step:7183/14065 loss：0.044142
【train】 epoch：2 step:7184/14065 loss：0.166622
【train】 epoch：2 step:7185/14065 loss：0.050893
【train】 epoch：2 step:7186/14065 loss：0.223172
【train】 epoch：2 step:7187/14065 loss：0.079099
【train】 epoch：2 step:7188/14065 loss：0.037690
【train】 epoch：2 step:7189/14065 loss：0.010500
【train】 epoch：2 step:7190/14065 loss：0.074237
【train】 epoch：2 step:7191/14065 loss：0.206790
【train】 epoch：2 step:7192/14065 loss：0.030975
【train】 epoch：2 step:7193/14065 loss：0.042821
【train】 epoch：2 step:7194/14065 loss：0.184230
【train】 epoch：2 step:7195/14065 loss：0.060210
【train】 epoch：2 step:7196/14065 loss：0.041580
【train】 epoch：2 step:7197/14065 loss：0.072648
【train】 epoch：2 step:7198/14065 loss：0.014653
【train】 epoch：2 step:7199/14065 loss：0.045314
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：172.341241 accuracy：0.9801 precision：0.9801 recall：0.9801 f1：0.9801
【train】 epoch：2 step:7200/14065 loss：0.151407
【train】 epoch：2 step:7201/14065 loss：0.091154
【train】 epoch：2 step:7202/14065 loss：0.012609
【train】 epoch：2 step:7203/14065 loss：0.049475
【train】 epoch：2 step:7204/14065 loss：0.086943
【train】 epoch：2 step:7205/14065 loss：0.067823
【train】 epoch：2 step:7206/14065 loss：0.030648
【train】 epoch：2 step:7207/14065 loss：0.110892
【train】 epoch：2 step:7208/14065 loss：0.136168
【train】 epoch：2 step:7209/14065 loss：0.065631
【train】 epoch：2 step:7210/14065 loss：0.049271
【train】 epoch：2 step:7211/14065 loss：0.096404
【train】 epoch：2 step:7212/14065 loss：0.018414
【train】 epoch：2 step:7213/14065 loss：0.044435
【train】 epoch：2 step:7214/14065 loss：0.016747
【train】 epoch：2 step:7215/14065 loss：0.015449
【train】 epoch：2 step:7216/14065 loss：0.141645
【train】 epoch：2 step:7217/14065 loss：0.015242
【train】 epoch：2 step:7218/14065 loss：0.090257
【train】 epoch：2 step:7219/14065 loss：0.065462
【train】 epoch：2 step:7220/14065 loss：0.072394
【train】 epoch：2 step:7221/14065 loss：0.040699
【train】 epoch：2 step:7222/14065 loss：0.121786
【train】 epoch：2 step:7223/14065 loss：0.013819
【train】 epoch：2 step:7224/14065 loss：0.045190
【train】 epoch：2 step:7225/14065 loss：0.155143
【train】 epoch：2 step:7226/14065 loss：0.230872
【train】 epoch：2 step:7227/14065 loss：0.048630
【train】 epoch：2 step:7228/14065 loss：0.107717
【train】 epoch：2 step:7229/14065 loss：0.063299
【train】 epoch：2 step:7230/14065 loss：0.281407
【train】 epoch：2 step:7231/14065 loss：0.089694
【train】 epoch：2 step:7232/14065 loss：0.025417
【train】 epoch：2 step:7233/14065 loss：0.041841
【train】 epoch：2 step:7234/14065 loss：0.144404
【train】 epoch：2 step:7235/14065 loss：0.094524
【train】 epoch：2 step:7236/14065 loss：0.082609
【train】 epoch：2 step:7237/14065 loss：0.072897
【train】 epoch：2 step:7238/14065 loss：0.221678
【train】 epoch：2 step:7239/14065 loss：0.105170
【train】 epoch：2 step:7240/14065 loss：0.256951
【train】 epoch：2 step:7241/14065 loss：0.197658
【train】 epoch：2 step:7242/14065 loss：0.169232
【train】 epoch：2 step:7243/14065 loss：0.045622
【train】 epoch：2 step:7244/14065 loss：0.088435
【train】 epoch：2 step:7245/14065 loss：0.164696
【train】 epoch：2 step:7246/14065 loss：0.091826
【train】 epoch：2 step:7247/14065 loss：0.067755
【train】 epoch：2 step:7248/14065 loss：0.117735
【train】 epoch：2 step:7249/14065 loss：0.037958
【train】 epoch：2 step:7250/14065 loss：0.275722
【train】 epoch：2 step:7251/14065 loss：0.150837
【train】 epoch：2 step:7252/14065 loss：0.110344
【train】 epoch：2 step:7253/14065 loss：0.037570
【train】 epoch：2 step:7254/14065 loss：0.261191
【train】 epoch：2 step:7255/14065 loss：0.102318
【train】 epoch：2 step:7256/14065 loss：0.069375
【train】 epoch：2 step:7257/14065 loss：0.248947
【train】 epoch：2 step:7258/14065 loss：0.158917
【train】 epoch：2 step:7259/14065 loss：0.022065
【train】 epoch：2 step:7260/14065 loss：0.073640
【train】 epoch：2 step:7261/14065 loss：0.098840
【train】 epoch：2 step:7262/14065 loss：0.017416
【train】 epoch：2 step:7263/14065 loss：0.107103
【train】 epoch：2 step:7264/14065 loss：0.051356
【train】 epoch：2 step:7265/14065 loss：0.164614
【train】 epoch：2 step:7266/14065 loss：0.026500
【train】 epoch：2 step:7267/14065 loss：0.116094
【train】 epoch：2 step:7268/14065 loss：0.102733
【train】 epoch：2 step:7269/14065 loss：0.099839
【train】 epoch：2 step:7270/14065 loss：0.271092
【train】 epoch：2 step:7271/14065 loss：0.095525
【train】 epoch：2 step:7272/14065 loss：0.150689
【train】 epoch：2 step:7273/14065 loss：0.059321
【train】 epoch：2 step:7274/14065 loss：0.095355
【train】 epoch：2 step:7275/14065 loss：0.038263
【train】 epoch：2 step:7276/14065 loss：0.025825
【train】 epoch：2 step:7277/14065 loss：0.084950
【train】 epoch：2 step:7278/14065 loss：0.030785
【train】 epoch：2 step:7279/14065 loss：0.037677
【train】 epoch：2 step:7280/14065 loss：0.067623
【train】 epoch：2 step:7281/14065 loss：0.073731
【train】 epoch：2 step:7282/14065 loss：0.175848
【train】 epoch：2 step:7283/14065 loss：0.026864
【train】 epoch：2 step:7284/14065 loss：0.057474
【train】 epoch：2 step:7285/14065 loss：0.125782
【train】 epoch：2 step:7286/14065 loss：0.070269
【train】 epoch：2 step:7287/14065 loss：0.057137
【train】 epoch：2 step:7288/14065 loss：0.105170
【train】 epoch：2 step:7289/14065 loss：0.049572
【train】 epoch：2 step:7290/14065 loss：0.018638
【train】 epoch：2 step:7291/14065 loss：0.056037
【train】 epoch：2 step:7292/14065 loss：0.143443
【train】 epoch：2 step:7293/14065 loss：0.114241
【train】 epoch：2 step:7294/14065 loss：0.122431
【train】 epoch：2 step:7295/14065 loss：0.066682
【train】 epoch：2 step:7296/14065 loss：0.146984
【train】 epoch：2 step:7297/14065 loss：0.065042
【train】 epoch：2 step:7298/14065 loss：0.032023
【train】 epoch：2 step:7299/14065 loss：0.086478
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：177.085997 accuracy：0.9790 precision：0.9790 recall：0.9790 f1：0.9790
【train】 epoch：2 step:7300/14065 loss：0.086855
【train】 epoch：2 step:7301/14065 loss：0.279643
【train】 epoch：2 step:7302/14065 loss：0.152483
【train】 epoch：2 step:7303/14065 loss：0.135799
【train】 epoch：2 step:7304/14065 loss：0.114637
【train】 epoch：2 step:7305/14065 loss：0.017837
【train】 epoch：2 step:7306/14065 loss：0.121181
【train】 epoch：2 step:7307/14065 loss：0.250962
【train】 epoch：2 step:7308/14065 loss：0.059036
【train】 epoch：2 step:7309/14065 loss：0.115086
【train】 epoch：2 step:7310/14065 loss：0.064289
【train】 epoch：2 step:7311/14065 loss：0.080072
【train】 epoch：2 step:7312/14065 loss：0.148034
【train】 epoch：2 step:7313/14065 loss：0.018076
【train】 epoch：2 step:7314/14065 loss：0.054295
【train】 epoch：2 step:7315/14065 loss：0.105470
【train】 epoch：2 step:7316/14065 loss：0.008796
【train】 epoch：2 step:7317/14065 loss：0.318259
【train】 epoch：2 step:7318/14065 loss：0.056284
【train】 epoch：2 step:7319/14065 loss：0.044237
【train】 epoch：2 step:7320/14065 loss：0.033873
【train】 epoch：2 step:7321/14065 loss：0.133092
【train】 epoch：2 step:7322/14065 loss：0.055464
【train】 epoch：2 step:7323/14065 loss：0.040008
【train】 epoch：2 step:7324/14065 loss：0.051438
【train】 epoch：2 step:7325/14065 loss：0.190430
【train】 epoch：2 step:7326/14065 loss：0.041231
【train】 epoch：2 step:7327/14065 loss：0.160484
【train】 epoch：2 step:7328/14065 loss：0.046447
【train】 epoch：2 step:7329/14065 loss：0.173104
【train】 epoch：2 step:7330/14065 loss：0.122989
【train】 epoch：2 step:7331/14065 loss：0.213632
【train】 epoch：2 step:7332/14065 loss：0.118888
【train】 epoch：2 step:7333/14065 loss：0.157757
【train】 epoch：2 step:7334/14065 loss：0.029647
【train】 epoch：2 step:7335/14065 loss：0.021716
【train】 epoch：2 step:7336/14065 loss：0.151679
【train】 epoch：2 step:7337/14065 loss：0.020397
【train】 epoch：2 step:7338/14065 loss：0.038223
【train】 epoch：2 step:7339/14065 loss：0.108086
【train】 epoch：2 step:7340/14065 loss：0.117131
【train】 epoch：2 step:7341/14065 loss：0.078060
【train】 epoch：2 step:7342/14065 loss：0.107212
【train】 epoch：2 step:7343/14065 loss：0.118621
【train】 epoch：2 step:7344/14065 loss：0.047967
【train】 epoch：2 step:7345/14065 loss：0.061479
【train】 epoch：2 step:7346/14065 loss：0.021467
【train】 epoch：2 step:7347/14065 loss：0.144403
【train】 epoch：2 step:7348/14065 loss：0.037290
【train】 epoch：2 step:7349/14065 loss：0.127429
【train】 epoch：2 step:7350/14065 loss：0.082396
【train】 epoch：2 step:7351/14065 loss：0.068986
【train】 epoch：2 step:7352/14065 loss：0.068976
【train】 epoch：2 step:7353/14065 loss：0.102843
【train】 epoch：2 step:7354/14065 loss：0.067026
【train】 epoch：2 step:7355/14065 loss：0.039700
【train】 epoch：2 step:7356/14065 loss：0.019704
【train】 epoch：2 step:7357/14065 loss：0.097770
【train】 epoch：2 step:7358/14065 loss：0.118694
【train】 epoch：2 step:7359/14065 loss：0.148486
【train】 epoch：2 step:7360/14065 loss：0.096410
【train】 epoch：2 step:7361/14065 loss：0.038216
【train】 epoch：2 step:7362/14065 loss：0.112824
【train】 epoch：2 step:7363/14065 loss：0.046278
【train】 epoch：2 step:7364/14065 loss：0.015222
【train】 epoch：2 step:7365/14065 loss：0.130769
【train】 epoch：2 step:7366/14065 loss：0.227600
【train】 epoch：2 step:7367/14065 loss：0.091604
【train】 epoch：2 step:7368/14065 loss：0.159382
【train】 epoch：2 step:7369/14065 loss：0.078288
【train】 epoch：2 step:7370/14065 loss：0.104052
【train】 epoch：2 step:7371/14065 loss：0.056052
【train】 epoch：2 step:7372/14065 loss：0.111101
【train】 epoch：2 step:7373/14065 loss：0.167340
【train】 epoch：2 step:7374/14065 loss：0.073023
【train】 epoch：2 step:7375/14065 loss：0.096373
【train】 epoch：2 step:7376/14065 loss：0.079512
【train】 epoch：2 step:7377/14065 loss：0.033001
【train】 epoch：2 step:7378/14065 loss：0.186608
【train】 epoch：2 step:7379/14065 loss：0.099267
【train】 epoch：2 step:7380/14065 loss：0.108353
【train】 epoch：2 step:7381/14065 loss：0.080588
【train】 epoch：2 step:7382/14065 loss：0.207764
【train】 epoch：2 step:7383/14065 loss：0.037638
【train】 epoch：2 step:7384/14065 loss：0.091331
【train】 epoch：2 step:7385/14065 loss：0.045590
【train】 epoch：2 step:7386/14065 loss：0.118860
【train】 epoch：2 step:7387/14065 loss：0.128438
【train】 epoch：2 step:7388/14065 loss：0.056380
【train】 epoch：2 step:7389/14065 loss：0.036703
【train】 epoch：2 step:7390/14065 loss：0.084296
【train】 epoch：2 step:7391/14065 loss：0.153308
【train】 epoch：2 step:7392/14065 loss：0.181677
【train】 epoch：2 step:7393/14065 loss：0.110804
【train】 epoch：2 step:7394/14065 loss：0.177281
【train】 epoch：2 step:7395/14065 loss：0.015179
【train】 epoch：2 step:7396/14065 loss：0.043927
【train】 epoch：2 step:7397/14065 loss：0.163602
【train】 epoch：2 step:7398/14065 loss：0.088770
【train】 epoch：2 step:7399/14065 loss：0.151652
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：164.157805 accuracy：0.9817 precision：0.9817 recall：0.9817 f1：0.9817
------------>保存当前最好的模型
【train】 epoch：2 step:7400/14065 loss：0.063990
【train】 epoch：2 step:7401/14065 loss：0.209083
【train】 epoch：2 step:7402/14065 loss：0.088651
【train】 epoch：2 step:7403/14065 loss：0.065243
【train】 epoch：2 step:7404/14065 loss：0.103865
【train】 epoch：2 step:7405/14065 loss：0.060551
【train】 epoch：2 step:7406/14065 loss：0.109107
【train】 epoch：2 step:7407/14065 loss：0.075365
【train】 epoch：2 step:7408/14065 loss：0.185015
【train】 epoch：2 step:7409/14065 loss：0.166924
【train】 epoch：2 step:7410/14065 loss：0.067565
【train】 epoch：2 step:7411/14065 loss：0.090873
【train】 epoch：2 step:7412/14065 loss：0.073292
【train】 epoch：2 step:7413/14065 loss：0.080179
【train】 epoch：2 step:7414/14065 loss：0.034493
【train】 epoch：2 step:7415/14065 loss：0.075895
【train】 epoch：2 step:7416/14065 loss：0.078403
【train】 epoch：2 step:7417/14065 loss：0.137855
【train】 epoch：2 step:7418/14065 loss：0.047570
【train】 epoch：2 step:7419/14065 loss：0.141437
【train】 epoch：2 step:7420/14065 loss：0.243052
【train】 epoch：2 step:7421/14065 loss：0.037729
【train】 epoch：2 step:7422/14065 loss：0.148717
【train】 epoch：2 step:7423/14065 loss：0.051424
【train】 epoch：2 step:7424/14065 loss：0.117368
【train】 epoch：2 step:7425/14065 loss：0.175970
【train】 epoch：2 step:7426/14065 loss：0.052966
【train】 epoch：2 step:7427/14065 loss：0.185454
【train】 epoch：2 step:7428/14065 loss：0.060200
【train】 epoch：2 step:7429/14065 loss：0.042561
【train】 epoch：2 step:7430/14065 loss：0.124467
【train】 epoch：2 step:7431/14065 loss：0.074601
【train】 epoch：2 step:7432/14065 loss：0.086215
【train】 epoch：2 step:7433/14065 loss：0.170795
【train】 epoch：2 step:7434/14065 loss：0.108377
【train】 epoch：2 step:7435/14065 loss：0.041384
【train】 epoch：2 step:7436/14065 loss：0.095725
【train】 epoch：2 step:7437/14065 loss：0.052790
【train】 epoch：2 step:7438/14065 loss：0.166852
【train】 epoch：2 step:7439/14065 loss：0.090823
【train】 epoch：2 step:7440/14065 loss：0.070726
【train】 epoch：2 step:7441/14065 loss：0.320557
【train】 epoch：2 step:7442/14065 loss：0.077933
【train】 epoch：2 step:7443/14065 loss：0.149180
【train】 epoch：2 step:7444/14065 loss：0.054380
【train】 epoch：2 step:7445/14065 loss：0.150458
【train】 epoch：2 step:7446/14065 loss：0.041200
【train】 epoch：2 step:7447/14065 loss：0.132155
【train】 epoch：2 step:7448/14065 loss：0.143958
【train】 epoch：2 step:7449/14065 loss：0.089051
【train】 epoch：2 step:7450/14065 loss：0.056970
【train】 epoch：2 step:7451/14065 loss：0.055027
【train】 epoch：2 step:7452/14065 loss：0.041210
【train】 epoch：2 step:7453/14065 loss：0.094070
【train】 epoch：2 step:7454/14065 loss：0.065012
【train】 epoch：2 step:7455/14065 loss：0.116328
【train】 epoch：2 step:7456/14065 loss：0.082616
【train】 epoch：2 step:7457/14065 loss：0.124109
【train】 epoch：2 step:7458/14065 loss：0.074369
【train】 epoch：2 step:7459/14065 loss：0.086550
【train】 epoch：2 step:7460/14065 loss：0.071776
【train】 epoch：2 step:7461/14065 loss：0.089443
【train】 epoch：2 step:7462/14065 loss：0.207039
【train】 epoch：2 step:7463/14065 loss：0.168589
【train】 epoch：2 step:7464/14065 loss：0.125528
【train】 epoch：2 step:7465/14065 loss：0.226811
【train】 epoch：2 step:7466/14065 loss：0.140460
【train】 epoch：2 step:7467/14065 loss：0.134163
【train】 epoch：2 step:7468/14065 loss：0.077196
【train】 epoch：2 step:7469/14065 loss：0.054998
【train】 epoch：2 step:7470/14065 loss：0.069479
【train】 epoch：2 step:7471/14065 loss：0.033799
【train】 epoch：2 step:7472/14065 loss：0.114352
【train】 epoch：2 step:7473/14065 loss：0.098431
【train】 epoch：2 step:7474/14065 loss：0.056270
【train】 epoch：2 step:7475/14065 loss：0.039097
【train】 epoch：2 step:7476/14065 loss：0.116856
【train】 epoch：2 step:7477/14065 loss：0.141794
【train】 epoch：2 step:7478/14065 loss：0.096047
【train】 epoch：2 step:7479/14065 loss：0.051765
【train】 epoch：2 step:7480/14065 loss：0.063128
【train】 epoch：2 step:7481/14065 loss：0.067696
【train】 epoch：2 step:7482/14065 loss：0.031499
【train】 epoch：2 step:7483/14065 loss：0.053075
【train】 epoch：2 step:7484/14065 loss：0.062872
【train】 epoch：2 step:7485/14065 loss：0.067802
【train】 epoch：2 step:7486/14065 loss：0.179647
【train】 epoch：2 step:7487/14065 loss：0.083235
【train】 epoch：2 step:7488/14065 loss：0.228599
【train】 epoch：2 step:7489/14065 loss：0.039853
【train】 epoch：2 step:7490/14065 loss：0.180999
【train】 epoch：2 step:7491/14065 loss：0.067615
【train】 epoch：2 step:7492/14065 loss：0.082200
【train】 epoch：2 step:7493/14065 loss：0.159678
【train】 epoch：2 step:7494/14065 loss：0.228323
【train】 epoch：2 step:7495/14065 loss：0.009123
【train】 epoch：2 step:7496/14065 loss：0.146117
【train】 epoch：2 step:7497/14065 loss：0.082937
【train】 epoch：2 step:7498/14065 loss：0.260763
【train】 epoch：2 step:7499/14065 loss：0.228783
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：175.089691 accuracy：0.9796 precision：0.9796 recall：0.9796 f1：0.9796
【train】 epoch：2 step:7500/14065 loss：0.173620
【train】 epoch：2 step:7501/14065 loss：0.122234
【train】 epoch：2 step:7502/14065 loss：0.223340
【train】 epoch：2 step:7503/14065 loss：0.065692
【train】 epoch：2 step:7504/14065 loss：0.065397
【train】 epoch：2 step:7505/14065 loss：0.098197
【train】 epoch：2 step:7506/14065 loss：0.095574
【train】 epoch：2 step:7507/14065 loss：0.088990
【train】 epoch：2 step:7508/14065 loss：0.097865
【train】 epoch：2 step:7509/14065 loss：0.047230
【train】 epoch：2 step:7510/14065 loss：0.137242
【train】 epoch：2 step:7511/14065 loss：0.042436
【train】 epoch：2 step:7512/14065 loss：0.109243
【train】 epoch：2 step:7513/14065 loss：0.020202
【train】 epoch：2 step:7514/14065 loss：0.172508
【train】 epoch：2 step:7515/14065 loss：0.241115
【train】 epoch：2 step:7516/14065 loss：0.242504
【train】 epoch：2 step:7517/14065 loss：0.108071
【train】 epoch：2 step:7518/14065 loss：0.190407
【train】 epoch：2 step:7519/14065 loss：0.175516
【train】 epoch：2 step:7520/14065 loss：0.016337
【train】 epoch：2 step:7521/14065 loss：0.045734
【train】 epoch：2 step:7522/14065 loss：0.024020
【train】 epoch：2 step:7523/14065 loss：0.065861
【train】 epoch：2 step:7524/14065 loss：0.035945
【train】 epoch：2 step:7525/14065 loss：0.040710
【train】 epoch：2 step:7526/14065 loss：0.036008
【train】 epoch：2 step:7527/14065 loss：0.110726
【train】 epoch：2 step:7528/14065 loss：0.150086
【train】 epoch：2 step:7529/14065 loss：0.157296
【train】 epoch：2 step:7530/14065 loss：0.136175
【train】 epoch：2 step:7531/14065 loss：0.031891
【train】 epoch：2 step:7532/14065 loss：0.275612
【train】 epoch：2 step:7533/14065 loss：0.075716
【train】 epoch：2 step:7534/14065 loss：0.160213
【train】 epoch：2 step:7535/14065 loss：0.211030
【train】 epoch：2 step:7536/14065 loss：0.051847
【train】 epoch：2 step:7537/14065 loss：0.038530
【train】 epoch：2 step:7538/14065 loss：0.069047
【train】 epoch：2 step:7539/14065 loss：0.088543
【train】 epoch：2 step:7540/14065 loss：0.037358
【train】 epoch：2 step:7541/14065 loss：0.050683
【train】 epoch：2 step:7542/14065 loss：0.123855
【train】 epoch：2 step:7543/14065 loss：0.054300
【train】 epoch：2 step:7544/14065 loss：0.152390
【train】 epoch：2 step:7545/14065 loss：0.020487
【train】 epoch：2 step:7546/14065 loss：0.111585
【train】 epoch：2 step:7547/14065 loss：0.061789
【train】 epoch：2 step:7548/14065 loss：0.184153
【train】 epoch：2 step:7549/14065 loss：0.247314
【train】 epoch：2 step:7550/14065 loss：0.153984
【train】 epoch：2 step:7551/14065 loss：0.091976
【train】 epoch：2 step:7552/14065 loss：0.018025
【train】 epoch：2 step:7553/14065 loss：0.015604
【train】 epoch：2 step:7554/14065 loss：0.178033
【train】 epoch：2 step:7555/14065 loss：0.083781
【train】 epoch：2 step:7556/14065 loss：0.059004
【train】 epoch：2 step:7557/14065 loss：0.014017
【train】 epoch：2 step:7558/14065 loss：0.038917
【train】 epoch：2 step:7559/14065 loss：0.197717
【train】 epoch：2 step:7560/14065 loss：0.162074
【train】 epoch：2 step:7561/14065 loss：0.125096
【train】 epoch：2 step:7562/14065 loss：0.061613
【train】 epoch：2 step:7563/14065 loss：0.011512
【train】 epoch：2 step:7564/14065 loss：0.058050
【train】 epoch：2 step:7565/14065 loss：0.187217
【train】 epoch：2 step:7566/14065 loss：0.120004
【train】 epoch：2 step:7567/14065 loss：0.043632
【train】 epoch：2 step:7568/14065 loss：0.170414
【train】 epoch：2 step:7569/14065 loss：0.078324
【train】 epoch：2 step:7570/14065 loss：0.034974
【train】 epoch：2 step:7571/14065 loss：0.197829
【train】 epoch：2 step:7572/14065 loss：0.081721
【train】 epoch：2 step:7573/14065 loss：0.024504
【train】 epoch：2 step:7574/14065 loss：0.100379
【train】 epoch：2 step:7575/14065 loss：0.141593
【train】 epoch：2 step:7576/14065 loss：0.054710
【train】 epoch：2 step:7577/14065 loss：0.059314
【train】 epoch：2 step:7578/14065 loss：0.072227
【train】 epoch：2 step:7579/14065 loss：0.100647
【train】 epoch：2 step:7580/14065 loss：0.201990
【train】 epoch：2 step:7581/14065 loss：0.041638
【train】 epoch：2 step:7582/14065 loss：0.096837
【train】 epoch：2 step:7583/14065 loss：0.146804
【train】 epoch：2 step:7584/14065 loss：0.083691
【train】 epoch：2 step:7585/14065 loss：0.063679
【train】 epoch：2 step:7586/14065 loss：0.059909
【train】 epoch：2 step:7587/14065 loss：0.191915
【train】 epoch：2 step:7588/14065 loss：0.142892
【train】 epoch：2 step:7589/14065 loss：0.137990
【train】 epoch：2 step:7590/14065 loss：0.158114
【train】 epoch：2 step:7591/14065 loss：0.038815
【train】 epoch：2 step:7592/14065 loss：0.034876
【train】 epoch：2 step:7593/14065 loss：0.113075
【train】 epoch：2 step:7594/14065 loss：0.072139
【train】 epoch：2 step:7595/14065 loss：0.119498
【train】 epoch：2 step:7596/14065 loss：0.183202
【train】 epoch：2 step:7597/14065 loss：0.190091
【train】 epoch：2 step:7598/14065 loss：0.055741
【train】 epoch：2 step:7599/14065 loss：0.170907
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：162.922269 accuracy：0.9814 precision：0.9814 recall：0.9814 f1：0.9814
【train】 epoch：2 step:7600/14065 loss：0.069712
【train】 epoch：2 step:7601/14065 loss：0.167688
【train】 epoch：2 step:7602/14065 loss：0.093289
【train】 epoch：2 step:7603/14065 loss：0.105278
【train】 epoch：2 step:7604/14065 loss：0.114260
【train】 epoch：2 step:7605/14065 loss：0.104659
【train】 epoch：2 step:7606/14065 loss：0.188853
【train】 epoch：2 step:7607/14065 loss：0.084108
【train】 epoch：2 step:7608/14065 loss：0.119960
【train】 epoch：2 step:7609/14065 loss：0.075389
【train】 epoch：2 step:7610/14065 loss：0.130676
【train】 epoch：2 step:7611/14065 loss：0.027147
【train】 epoch：2 step:7612/14065 loss：0.207312
【train】 epoch：2 step:7613/14065 loss：0.095257
【train】 epoch：2 step:7614/14065 loss：0.098228
【train】 epoch：2 step:7615/14065 loss：0.210257
【train】 epoch：2 step:7616/14065 loss：0.039071
【train】 epoch：2 step:7617/14065 loss：0.099228
【train】 epoch：2 step:7618/14065 loss：0.074455
【train】 epoch：2 step:7619/14065 loss：0.134476
【train】 epoch：2 step:7620/14065 loss：0.195814
【train】 epoch：2 step:7621/14065 loss：0.146788
【train】 epoch：2 step:7622/14065 loss：0.132782
【train】 epoch：2 step:7623/14065 loss：0.032228
【train】 epoch：2 step:7624/14065 loss：0.026137
【train】 epoch：2 step:7625/14065 loss：0.103179
【train】 epoch：2 step:7626/14065 loss：0.082879
【train】 epoch：2 step:7627/14065 loss：0.102760
【train】 epoch：2 step:7628/14065 loss：0.046829
【train】 epoch：2 step:7629/14065 loss：0.190500
【train】 epoch：2 step:7630/14065 loss：0.114983
【train】 epoch：2 step:7631/14065 loss：0.092935
【train】 epoch：2 step:7632/14065 loss：0.059074
【train】 epoch：2 step:7633/14065 loss：0.051385
【train】 epoch：2 step:7634/14065 loss：0.086243
【train】 epoch：2 step:7635/14065 loss：0.103961
【train】 epoch：2 step:7636/14065 loss：0.182363
【train】 epoch：2 step:7637/14065 loss：0.051699
【train】 epoch：2 step:7638/14065 loss：0.055114
【train】 epoch：2 step:7639/14065 loss：0.022370
【train】 epoch：2 step:7640/14065 loss：0.079749
【train】 epoch：2 step:7641/14065 loss：0.190875
【train】 epoch：2 step:7642/14065 loss：0.073593
【train】 epoch：2 step:7643/14065 loss：0.027228
【train】 epoch：2 step:7644/14065 loss：0.035651
【train】 epoch：2 step:7645/14065 loss：0.131337
【train】 epoch：2 step:7646/14065 loss：0.060417
【train】 epoch：2 step:7647/14065 loss：0.177694
【train】 epoch：2 step:7648/14065 loss：0.030037
【train】 epoch：2 step:7649/14065 loss：0.039217
【train】 epoch：2 step:7650/14065 loss：0.257961
【train】 epoch：2 step:7651/14065 loss：0.057741
【train】 epoch：2 step:7652/14065 loss：0.022868
【train】 epoch：2 step:7653/14065 loss：0.056352
【train】 epoch：2 step:7654/14065 loss：0.169087
【train】 epoch：2 step:7655/14065 loss：0.101725
【train】 epoch：2 step:7656/14065 loss：0.087491
【train】 epoch：2 step:7657/14065 loss：0.015394
【train】 epoch：2 step:7658/14065 loss：0.230952
【train】 epoch：2 step:7659/14065 loss：0.125977
【train】 epoch：2 step:7660/14065 loss：0.192620
【train】 epoch：2 step:7661/14065 loss：0.056149
【train】 epoch：2 step:7662/14065 loss：0.050018
【train】 epoch：2 step:7663/14065 loss：0.111463
【train】 epoch：2 step:7664/14065 loss：0.156259
【train】 epoch：2 step:7665/14065 loss：0.045692
【train】 epoch：2 step:7666/14065 loss：0.023380
【train】 epoch：2 step:7667/14065 loss：0.126743
【train】 epoch：2 step:7668/14065 loss：0.050374
【train】 epoch：2 step:7669/14065 loss：0.050064
【train】 epoch：2 step:7670/14065 loss：0.084443
【train】 epoch：2 step:7671/14065 loss：0.058998
【train】 epoch：2 step:7672/14065 loss：0.020308
【train】 epoch：2 step:7673/14065 loss：0.102869
【train】 epoch：2 step:7674/14065 loss：0.186611
【train】 epoch：2 step:7675/14065 loss：0.119283
【train】 epoch：2 step:7676/14065 loss：0.137701
【train】 epoch：2 step:7677/14065 loss：0.151245
【train】 epoch：2 step:7678/14065 loss：0.079407
【train】 epoch：2 step:7679/14065 loss：0.023772
【train】 epoch：2 step:7680/14065 loss：0.152696
【train】 epoch：2 step:7681/14065 loss：0.189250
【train】 epoch：2 step:7682/14065 loss：0.035227
【train】 epoch：2 step:7683/14065 loss：0.057061
【train】 epoch：2 step:7684/14065 loss：0.036741
【train】 epoch：2 step:7685/14065 loss：0.139821
【train】 epoch：2 step:7686/14065 loss：0.072245
【train】 epoch：2 step:7687/14065 loss：0.069243
【train】 epoch：2 step:7688/14065 loss：0.141678
【train】 epoch：2 step:7689/14065 loss：0.126512
【train】 epoch：2 step:7690/14065 loss：0.130206
【train】 epoch：2 step:7691/14065 loss：0.172296
【train】 epoch：2 step:7692/14065 loss：0.103579
【train】 epoch：2 step:7693/14065 loss：0.169804
【train】 epoch：2 step:7694/14065 loss：0.080201
【train】 epoch：2 step:7695/14065 loss：0.053897
【train】 epoch：2 step:7696/14065 loss：0.044714
【train】 epoch：2 step:7697/14065 loss：0.136452
【train】 epoch：2 step:7698/14065 loss：0.043564
【train】 epoch：2 step:7699/14065 loss：0.150188
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：176.970792 accuracy：0.9800 precision：0.9800 recall：0.9800 f1：0.9800
【train】 epoch：2 step:7700/14065 loss：0.064788
【train】 epoch：2 step:7701/14065 loss：0.067182
【train】 epoch：2 step:7702/14065 loss：0.215177
【train】 epoch：2 step:7703/14065 loss：0.132866
【train】 epoch：2 step:7704/14065 loss：0.087339
【train】 epoch：2 step:7705/14065 loss：0.125014
【train】 epoch：2 step:7706/14065 loss：0.196077
【train】 epoch：2 step:7707/14065 loss：0.073633
【train】 epoch：2 step:7708/14065 loss：0.212736
【train】 epoch：2 step:7709/14065 loss：0.094800
【train】 epoch：2 step:7710/14065 loss：0.132024
【train】 epoch：2 step:7711/14065 loss：0.132438
【train】 epoch：2 step:7712/14065 loss：0.033089
【train】 epoch：2 step:7713/14065 loss：0.133092
【train】 epoch：2 step:7714/14065 loss：0.064246
【train】 epoch：2 step:7715/14065 loss：0.044272
【train】 epoch：2 step:7716/14065 loss：0.037038
【train】 epoch：2 step:7717/14065 loss：0.068473
【train】 epoch：2 step:7718/14065 loss：0.116339
【train】 epoch：2 step:7719/14065 loss：0.050474
【train】 epoch：2 step:7720/14065 loss：0.225637
【train】 epoch：2 step:7721/14065 loss：0.010943
【train】 epoch：2 step:7722/14065 loss：0.042334
【train】 epoch：2 step:7723/14065 loss：0.203329
【train】 epoch：2 step:7724/14065 loss：0.154912
【train】 epoch：2 step:7725/14065 loss：0.082640
【train】 epoch：2 step:7726/14065 loss：0.075019
【train】 epoch：2 step:7727/14065 loss：0.044482
【train】 epoch：2 step:7728/14065 loss：0.021027
【train】 epoch：2 step:7729/14065 loss：0.058296
【train】 epoch：2 step:7730/14065 loss：0.151109
【train】 epoch：2 step:7731/14065 loss：0.093284
【train】 epoch：2 step:7732/14065 loss：0.051481
【train】 epoch：2 step:7733/14065 loss：0.025949
【train】 epoch：2 step:7734/14065 loss：0.115246
【train】 epoch：2 step:7735/14065 loss：0.110945
【train】 epoch：2 step:7736/14065 loss：0.150532
【train】 epoch：2 step:7737/14065 loss：0.180253
【train】 epoch：2 step:7738/14065 loss：0.130225
【train】 epoch：2 step:7739/14065 loss：0.076480
【train】 epoch：2 step:7740/14065 loss：0.087478
【train】 epoch：2 step:7741/14065 loss：0.110591
【train】 epoch：2 step:7742/14065 loss：0.094087
【train】 epoch：2 step:7743/14065 loss：0.048799
【train】 epoch：2 step:7744/14065 loss：0.125950
【train】 epoch：2 step:7745/14065 loss：0.081217
【train】 epoch：2 step:7746/14065 loss：0.201181
【train】 epoch：2 step:7747/14065 loss：0.060816
【train】 epoch：2 step:7748/14065 loss：0.133234
【train】 epoch：2 step:7749/14065 loss：0.111970
【train】 epoch：2 step:7750/14065 loss：0.020840
【train】 epoch：2 step:7751/14065 loss：0.063722
【train】 epoch：2 step:7752/14065 loss：0.028326
【train】 epoch：2 step:7753/14065 loss：0.057656
【train】 epoch：2 step:7754/14065 loss：0.072939
【train】 epoch：2 step:7755/14065 loss：0.072136
【train】 epoch：2 step:7756/14065 loss：0.058343
【train】 epoch：2 step:7757/14065 loss：0.074414
【train】 epoch：2 step:7758/14065 loss：0.060963
【train】 epoch：2 step:7759/14065 loss：0.091189
【train】 epoch：2 step:7760/14065 loss：0.124768
【train】 epoch：2 step:7761/14065 loss：0.121220
【train】 epoch：2 step:7762/14065 loss：0.037190
【train】 epoch：2 step:7763/14065 loss：0.092413
【train】 epoch：2 step:7764/14065 loss：0.069531
【train】 epoch：2 step:7765/14065 loss：0.100472
【train】 epoch：2 step:7766/14065 loss：0.158414
【train】 epoch：2 step:7767/14065 loss：0.069085
【train】 epoch：2 step:7768/14065 loss：0.083166
【train】 epoch：2 step:7769/14065 loss：0.224948
【train】 epoch：2 step:7770/14065 loss：0.045547
【train】 epoch：2 step:7771/14065 loss：0.127008
【train】 epoch：2 step:7772/14065 loss：0.107019
【train】 epoch：2 step:7773/14065 loss：0.132334
【train】 epoch：2 step:7774/14065 loss：0.067847
【train】 epoch：2 step:7775/14065 loss：0.201182
【train】 epoch：2 step:7776/14065 loss：0.083161
【train】 epoch：2 step:7777/14065 loss：0.072044
【train】 epoch：2 step:7778/14065 loss：0.016795
【train】 epoch：2 step:7779/14065 loss：0.099541
【train】 epoch：2 step:7780/14065 loss：0.216299
【train】 epoch：2 step:7781/14065 loss：0.048398
【train】 epoch：2 step:7782/14065 loss：0.105431
【train】 epoch：2 step:7783/14065 loss：0.115666
【train】 epoch：2 step:7784/14065 loss：0.115536
【train】 epoch：2 step:7785/14065 loss：0.089906
【train】 epoch：2 step:7786/14065 loss：0.227436
【train】 epoch：2 step:7787/14065 loss：0.093704
【train】 epoch：2 step:7788/14065 loss：0.104262
【train】 epoch：2 step:7789/14065 loss：0.065151
【train】 epoch：2 step:7790/14065 loss：0.053787
【train】 epoch：2 step:7791/14065 loss：0.026198
【train】 epoch：2 step:7792/14065 loss：0.040281
【train】 epoch：2 step:7793/14065 loss：0.127403
【train】 epoch：2 step:7794/14065 loss：0.133573
【train】 epoch：2 step:7795/14065 loss：0.037892
【train】 epoch：2 step:7796/14065 loss：0.119617
【train】 epoch：2 step:7797/14065 loss：0.079969
【train】 epoch：2 step:7798/14065 loss：0.012641
【train】 epoch：2 step:7799/14065 loss：0.078876
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：165.810263 accuracy：0.9810 precision：0.9810 recall：0.9810 f1：0.9810
【train】 epoch：2 step:7800/14065 loss：0.180334
【train】 epoch：2 step:7801/14065 loss：0.069283
【train】 epoch：2 step:7802/14065 loss：0.117498
【train】 epoch：2 step:7803/14065 loss：0.121525
【train】 epoch：2 step:7804/14065 loss：0.080349
【train】 epoch：2 step:7805/14065 loss：0.093186
【train】 epoch：2 step:7806/14065 loss：0.084606
【train】 epoch：2 step:7807/14065 loss：0.131498
【train】 epoch：2 step:7808/14065 loss：0.018788
【train】 epoch：2 step:7809/14065 loss：0.083190
【train】 epoch：2 step:7810/14065 loss：0.117834
【train】 epoch：2 step:7811/14065 loss：0.100198
【train】 epoch：2 step:7812/14065 loss：0.089031
【train】 epoch：2 step:7813/14065 loss：0.042463
【train】 epoch：2 step:7814/14065 loss：0.094806
【train】 epoch：2 step:7815/14065 loss：0.100904
【train】 epoch：2 step:7816/14065 loss：0.151624
【train】 epoch：2 step:7817/14065 loss：0.096049
【train】 epoch：2 step:7818/14065 loss：0.133635
【train】 epoch：2 step:7819/14065 loss：0.054646
【train】 epoch：2 step:7820/14065 loss：0.052562
【train】 epoch：2 step:7821/14065 loss：0.105309
【train】 epoch：2 step:7822/14065 loss：0.098460
【train】 epoch：2 step:7823/14065 loss：0.113542
【train】 epoch：2 step:7824/14065 loss：0.135165
【train】 epoch：2 step:7825/14065 loss：0.111167
【train】 epoch：2 step:7826/14065 loss：0.100691
【train】 epoch：2 step:7827/14065 loss：0.063066
【train】 epoch：2 step:7828/14065 loss：0.124797
【train】 epoch：2 step:7829/14065 loss：0.089605
【train】 epoch：2 step:7830/14065 loss：0.054718
【train】 epoch：2 step:7831/14065 loss：0.169288
【train】 epoch：2 step:7832/14065 loss：0.136354
【train】 epoch：2 step:7833/14065 loss：0.064906
【train】 epoch：2 step:7834/14065 loss：0.152778
【train】 epoch：2 step:7835/14065 loss：0.030068
【train】 epoch：2 step:7836/14065 loss：0.116124
【train】 epoch：2 step:7837/14065 loss：0.132949
【train】 epoch：2 step:7838/14065 loss：0.085450
【train】 epoch：2 step:7839/14065 loss：0.105784
【train】 epoch：2 step:7840/14065 loss：0.046191
【train】 epoch：2 step:7841/14065 loss：0.017292
【train】 epoch：2 step:7842/14065 loss：0.072391
【train】 epoch：2 step:7843/14065 loss：0.122020
【train】 epoch：2 step:7844/14065 loss：0.098873
【train】 epoch：2 step:7845/14065 loss：0.040206
【train】 epoch：2 step:7846/14065 loss：0.161777
【train】 epoch：2 step:7847/14065 loss：0.096651
【train】 epoch：2 step:7848/14065 loss：0.114565
【train】 epoch：2 step:7849/14065 loss：0.124647
【train】 epoch：2 step:7850/14065 loss：0.152202
【train】 epoch：2 step:7851/14065 loss：0.047277
【train】 epoch：2 step:7852/14065 loss：0.039905
【train】 epoch：2 step:7853/14065 loss：0.091099
【train】 epoch：2 step:7854/14065 loss：0.151040
【train】 epoch：2 step:7855/14065 loss：0.064686
【train】 epoch：2 step:7856/14065 loss：0.078756
【train】 epoch：2 step:7857/14065 loss：0.034511
【train】 epoch：2 step:7858/14065 loss：0.097252
【train】 epoch：2 step:7859/14065 loss：0.023702
【train】 epoch：2 step:7860/14065 loss：0.092069
【train】 epoch：2 step:7861/14065 loss：0.045777
【train】 epoch：2 step:7862/14065 loss：0.039844
【train】 epoch：2 step:7863/14065 loss：0.151854
【train】 epoch：2 step:7864/14065 loss：0.058293
【train】 epoch：2 step:7865/14065 loss：0.114504
【train】 epoch：2 step:7866/14065 loss：0.077782
【train】 epoch：2 step:7867/14065 loss：0.034153
【train】 epoch：2 step:7868/14065 loss：0.125892
【train】 epoch：2 step:7869/14065 loss：0.076266
【train】 epoch：2 step:7870/14065 loss：0.096609
【train】 epoch：2 step:7871/14065 loss：0.027911
【train】 epoch：2 step:7872/14065 loss：0.011952
【train】 epoch：2 step:7873/14065 loss：0.091207
【train】 epoch：2 step:7874/14065 loss：0.087949
【train】 epoch：2 step:7875/14065 loss：0.159909
【train】 epoch：2 step:7876/14065 loss：0.087998
【train】 epoch：2 step:7877/14065 loss：0.032684
【train】 epoch：2 step:7878/14065 loss：0.151681
【train】 epoch：2 step:7879/14065 loss：0.104440
【train】 epoch：2 step:7880/14065 loss：0.026433
【train】 epoch：2 step:7881/14065 loss：0.126604
【train】 epoch：2 step:7882/14065 loss：0.062791
【train】 epoch：2 step:7883/14065 loss：0.046369
【train】 epoch：2 step:7884/14065 loss：0.221092
【train】 epoch：2 step:7885/14065 loss：0.037708
【train】 epoch：2 step:7886/14065 loss：0.040193
【train】 epoch：2 step:7887/14065 loss：0.037367
【train】 epoch：2 step:7888/14065 loss：0.026723
【train】 epoch：2 step:7889/14065 loss：0.175696
【train】 epoch：2 step:7890/14065 loss：0.101483
【train】 epoch：2 step:7891/14065 loss：0.106433
【train】 epoch：2 step:7892/14065 loss：0.047789
【train】 epoch：2 step:7893/14065 loss：0.080745
【train】 epoch：2 step:7894/14065 loss：0.142935
【train】 epoch：2 step:7895/14065 loss：0.191575
【train】 epoch：2 step:7896/14065 loss：0.139132
【train】 epoch：2 step:7897/14065 loss：0.053817
【train】 epoch：2 step:7898/14065 loss：0.148666
【train】 epoch：2 step:7899/14065 loss：0.042794
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：151.140066 accuracy：0.9831 precision：0.9831 recall：0.9831 f1：0.9831
------------>保存当前最好的模型
【train】 epoch：2 step:7900/14065 loss：0.194318
【train】 epoch：2 step:7901/14065 loss：0.059238
【train】 epoch：2 step:7902/14065 loss：0.070526
【train】 epoch：2 step:7903/14065 loss：0.060386
【train】 epoch：2 step:7904/14065 loss：0.314856
【train】 epoch：2 step:7905/14065 loss：0.026248
【train】 epoch：2 step:7906/14065 loss：0.330762
【train】 epoch：2 step:7907/14065 loss：0.109785
【train】 epoch：2 step:7908/14065 loss：0.074593
【train】 epoch：2 step:7909/14065 loss：0.125657
【train】 epoch：2 step:7910/14065 loss：0.021814
【train】 epoch：2 step:7911/14065 loss：0.109445
【train】 epoch：2 step:7912/14065 loss：0.105128
【train】 epoch：2 step:7913/14065 loss：0.116084
【train】 epoch：2 step:7914/14065 loss：0.055141
【train】 epoch：2 step:7915/14065 loss：0.185764
【train】 epoch：2 step:7916/14065 loss：0.163407
【train】 epoch：2 step:7917/14065 loss：0.234075
【train】 epoch：2 step:7918/14065 loss：0.215568
【train】 epoch：2 step:7919/14065 loss：0.027796
【train】 epoch：2 step:7920/14065 loss：0.097510
【train】 epoch：2 step:7921/14065 loss：0.033829
【train】 epoch：2 step:7922/14065 loss：0.067973
【train】 epoch：2 step:7923/14065 loss：0.052443
【train】 epoch：2 step:7924/14065 loss：0.142471
【train】 epoch：2 step:7925/14065 loss：0.030793
【train】 epoch：2 step:7926/14065 loss：0.149434
【train】 epoch：2 step:7927/14065 loss：0.181769
【train】 epoch：2 step:7928/14065 loss：0.075634
【train】 epoch：2 step:7929/14065 loss：0.071412
【train】 epoch：2 step:7930/14065 loss：0.171578
【train】 epoch：2 step:7931/14065 loss：0.020372
【train】 epoch：2 step:7932/14065 loss：0.100526
【train】 epoch：2 step:7933/14065 loss：0.087134
【train】 epoch：2 step:7934/14065 loss：0.134597
【train】 epoch：2 step:7935/14065 loss：0.227840
【train】 epoch：2 step:7936/14065 loss：0.128745
【train】 epoch：2 step:7937/14065 loss：0.140316
【train】 epoch：2 step:7938/14065 loss：0.107519
【train】 epoch：2 step:7939/14065 loss：0.069862
【train】 epoch：2 step:7940/14065 loss：0.269077
【train】 epoch：2 step:7941/14065 loss：0.184784
【train】 epoch：2 step:7942/14065 loss：0.164615
【train】 epoch：2 step:7943/14065 loss：0.054726
【train】 epoch：2 step:7944/14065 loss：0.151609
【train】 epoch：2 step:7945/14065 loss：0.043114
【train】 epoch：2 step:7946/14065 loss：0.207700
【train】 epoch：2 step:7947/14065 loss：0.045006
【train】 epoch：2 step:7948/14065 loss：0.071557
【train】 epoch：2 step:7949/14065 loss：0.025105
【train】 epoch：2 step:7950/14065 loss：0.223536
【train】 epoch：2 step:7951/14065 loss：0.178605
【train】 epoch：2 step:7952/14065 loss：0.058845
【train】 epoch：2 step:7953/14065 loss：0.208022
【train】 epoch：2 step:7954/14065 loss：0.081903
【train】 epoch：2 step:7955/14065 loss：0.189213
【train】 epoch：2 step:7956/14065 loss：0.095771
【train】 epoch：2 step:7957/14065 loss：0.116091
【train】 epoch：2 step:7958/14065 loss：0.071142
【train】 epoch：2 step:7959/14065 loss：0.124771
【train】 epoch：2 step:7960/14065 loss：0.023561
【train】 epoch：2 step:7961/14065 loss：0.204262
【train】 epoch：2 step:7962/14065 loss：0.319200
【train】 epoch：2 step:7963/14065 loss：0.124586
【train】 epoch：2 step:7964/14065 loss：0.099658
【train】 epoch：2 step:7965/14065 loss：0.033634
【train】 epoch：2 step:7966/14065 loss：0.054418
【train】 epoch：2 step:7967/14065 loss：0.033774
【train】 epoch：2 step:7968/14065 loss：0.158943
【train】 epoch：2 step:7969/14065 loss：0.043286
【train】 epoch：2 step:7970/14065 loss：0.034738
【train】 epoch：2 step:7971/14065 loss：0.029960
【train】 epoch：2 step:7972/14065 loss：0.038982
【train】 epoch：2 step:7973/14065 loss：0.089894
【train】 epoch：2 step:7974/14065 loss：0.077129
【train】 epoch：2 step:7975/14065 loss：0.044460
【train】 epoch：2 step:7976/14065 loss：0.072246
【train】 epoch：2 step:7977/14065 loss：0.170578
【train】 epoch：2 step:7978/14065 loss：0.086403
【train】 epoch：2 step:7979/14065 loss：0.099198
【train】 epoch：2 step:7980/14065 loss：0.157982
【train】 epoch：2 step:7981/14065 loss：0.073832
【train】 epoch：2 step:7982/14065 loss：0.071953
【train】 epoch：2 step:7983/14065 loss：0.105165
【train】 epoch：2 step:7984/14065 loss：0.146468
【train】 epoch：2 step:7985/14065 loss：0.099001
【train】 epoch：2 step:7986/14065 loss：0.079529
【train】 epoch：2 step:7987/14065 loss：0.106109
【train】 epoch：2 step:7988/14065 loss：0.081682
【train】 epoch：2 step:7989/14065 loss：0.243490
【train】 epoch：2 step:7990/14065 loss：0.120612
【train】 epoch：2 step:7991/14065 loss：0.096718
【train】 epoch：2 step:7992/14065 loss：0.065353
【train】 epoch：2 step:7993/14065 loss：0.064902
【train】 epoch：2 step:7994/14065 loss：0.151747
【train】 epoch：2 step:7995/14065 loss：0.152368
【train】 epoch：2 step:7996/14065 loss：0.029510
【train】 epoch：2 step:7997/14065 loss：0.082957
【train】 epoch：2 step:7998/14065 loss：0.158297
【train】 epoch：2 step:7999/14065 loss：0.019181
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：168.500233 accuracy：0.9804 precision：0.9804 recall：0.9804 f1：0.9804
【train】 epoch：2 step:8000/14065 loss：0.183138
【train】 epoch：2 step:8001/14065 loss：0.099339
【train】 epoch：2 step:8002/14065 loss：0.042179
【train】 epoch：2 step:8003/14065 loss：0.106833
【train】 epoch：2 step:8004/14065 loss：0.162959
【train】 epoch：2 step:8005/14065 loss：0.048213
【train】 epoch：2 step:8006/14065 loss：0.094852
【train】 epoch：2 step:8007/14065 loss：0.109132
【train】 epoch：2 step:8008/14065 loss：0.052614
【train】 epoch：2 step:8009/14065 loss：0.031354
【train】 epoch：2 step:8010/14065 loss：0.133333
【train】 epoch：2 step:8011/14065 loss：0.215430
【train】 epoch：2 step:8012/14065 loss：0.178598
【train】 epoch：2 step:8013/14065 loss：0.113627
【train】 epoch：2 step:8014/14065 loss：0.049321
【train】 epoch：2 step:8015/14065 loss：0.063548
【train】 epoch：2 step:8016/14065 loss：0.341217
【train】 epoch：2 step:8017/14065 loss：0.132267
【train】 epoch：2 step:8018/14065 loss：0.035941
【train】 epoch：2 step:8019/14065 loss：0.119295
【train】 epoch：2 step:8020/14065 loss：0.081532
【train】 epoch：2 step:8021/14065 loss：0.016188
【train】 epoch：2 step:8022/14065 loss：0.031119
【train】 epoch：2 step:8023/14065 loss：0.143228
【train】 epoch：2 step:8024/14065 loss：0.028742
【train】 epoch：2 step:8025/14065 loss：0.077020
【train】 epoch：2 step:8026/14065 loss：0.117175
【train】 epoch：2 step:8027/14065 loss：0.114271
【train】 epoch：2 step:8028/14065 loss：0.023623
【train】 epoch：2 step:8029/14065 loss：0.033472
【train】 epoch：2 step:8030/14065 loss：0.035362
【train】 epoch：2 step:8031/14065 loss：0.184447
【train】 epoch：2 step:8032/14065 loss：0.116114
【train】 epoch：2 step:8033/14065 loss：0.060657
【train】 epoch：2 step:8034/14065 loss：0.052421
【train】 epoch：2 step:8035/14065 loss：0.020916
【train】 epoch：2 step:8036/14065 loss：0.073919
【train】 epoch：2 step:8037/14065 loss：0.095930
【train】 epoch：2 step:8038/14065 loss：0.020642
【train】 epoch：2 step:8039/14065 loss：0.058817
【train】 epoch：2 step:8040/14065 loss：0.130489
【train】 epoch：2 step:8041/14065 loss：0.162260
【train】 epoch：2 step:8042/14065 loss：0.064232
【train】 epoch：2 step:8043/14065 loss：0.166887
【train】 epoch：2 step:8044/14065 loss：0.147684
【train】 epoch：2 step:8045/14065 loss：0.205463
【train】 epoch：2 step:8046/14065 loss：0.040866
【train】 epoch：2 step:8047/14065 loss：0.104215
【train】 epoch：2 step:8048/14065 loss：0.061981
【train】 epoch：2 step:8049/14065 loss：0.161595
【train】 epoch：2 step:8050/14065 loss：0.063221
【train】 epoch：2 step:8051/14065 loss：0.015157
【train】 epoch：2 step:8052/14065 loss：0.188766
【train】 epoch：2 step:8053/14065 loss：0.029710
【train】 epoch：2 step:8054/14065 loss：0.068150
【train】 epoch：2 step:8055/14065 loss：0.128274
【train】 epoch：2 step:8056/14065 loss：0.083489
【train】 epoch：2 step:8057/14065 loss：0.081452
【train】 epoch：2 step:8058/14065 loss：0.035888
【train】 epoch：2 step:8059/14065 loss：0.051965
【train】 epoch：2 step:8060/14065 loss：0.178168
【train】 epoch：2 step:8061/14065 loss：0.177942
【train】 epoch：2 step:8062/14065 loss：0.042116
【train】 epoch：2 step:8063/14065 loss：0.176961
【train】 epoch：2 step:8064/14065 loss：0.362683
【train】 epoch：2 step:8065/14065 loss：0.040819
【train】 epoch：2 step:8066/14065 loss：0.151786
【train】 epoch：2 step:8067/14065 loss：0.248144
【train】 epoch：2 step:8068/14065 loss：0.103849
【train】 epoch：2 step:8069/14065 loss：0.201021
【train】 epoch：2 step:8070/14065 loss：0.150085
【train】 epoch：2 step:8071/14065 loss：0.125169
【train】 epoch：2 step:8072/14065 loss：0.145932
【train】 epoch：2 step:8073/14065 loss：0.073612
【train】 epoch：2 step:8074/14065 loss：0.033692
【train】 epoch：2 step:8075/14065 loss：0.078300
【train】 epoch：2 step:8076/14065 loss：0.028748
【train】 epoch：2 step:8077/14065 loss：0.056772
【train】 epoch：2 step:8078/14065 loss：0.031966
【train】 epoch：2 step:8079/14065 loss：0.263251
【train】 epoch：2 step:8080/14065 loss：0.132080
【train】 epoch：2 step:8081/14065 loss：0.204177
【train】 epoch：2 step:8082/14065 loss：0.147483
【train】 epoch：2 step:8083/14065 loss：0.123529
【train】 epoch：2 step:8084/14065 loss：0.147682
【train】 epoch：2 step:8085/14065 loss：0.107595
【train】 epoch：2 step:8086/14065 loss：0.120681
【train】 epoch：2 step:8087/14065 loss：0.122704
【train】 epoch：2 step:8088/14065 loss：0.038738
【train】 epoch：2 step:8089/14065 loss：0.037348
【train】 epoch：2 step:8090/14065 loss：0.164950
【train】 epoch：2 step:8091/14065 loss：0.163030
【train】 epoch：2 step:8092/14065 loss：0.095442
【train】 epoch：2 step:8093/14065 loss：0.201676
【train】 epoch：2 step:8094/14065 loss：0.060900
【train】 epoch：2 step:8095/14065 loss：0.066567
【train】 epoch：2 step:8096/14065 loss：0.087144
【train】 epoch：2 step:8097/14065 loss：0.065443
【train】 epoch：2 step:8098/14065 loss：0.117686
【train】 epoch：2 step:8099/14065 loss：0.020499
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：152.046357 accuracy：0.9831 precision：0.9831 recall：0.9831 f1：0.9831
【train】 epoch：2 step:8100/14065 loss：0.077060
【train】 epoch：2 step:8101/14065 loss：0.171230
【train】 epoch：2 step:8102/14065 loss：0.063346
【train】 epoch：2 step:8103/14065 loss：0.152426
【train】 epoch：2 step:8104/14065 loss：0.166556
【train】 epoch：2 step:8105/14065 loss：0.048788
【train】 epoch：2 step:8106/14065 loss：0.070663
【train】 epoch：2 step:8107/14065 loss：0.207053
【train】 epoch：2 step:8108/14065 loss：0.058651
【train】 epoch：2 step:8109/14065 loss：0.147166
【train】 epoch：2 step:8110/14065 loss：0.138765
【train】 epoch：2 step:8111/14065 loss：0.075011
【train】 epoch：2 step:8112/14065 loss：0.095017
【train】 epoch：2 step:8113/14065 loss：0.145962
【train】 epoch：2 step:8114/14065 loss：0.133381
【train】 epoch：2 step:8115/14065 loss：0.136573
【train】 epoch：2 step:8116/14065 loss：0.053546
【train】 epoch：2 step:8117/14065 loss：0.218162
【train】 epoch：2 step:8118/14065 loss：0.123235
【train】 epoch：2 step:8119/14065 loss：0.071868
【train】 epoch：2 step:8120/14065 loss：0.038051
【train】 epoch：2 step:8121/14065 loss：0.019487
【train】 epoch：2 step:8122/14065 loss：0.123362
【train】 epoch：2 step:8123/14065 loss：0.225699
【train】 epoch：2 step:8124/14065 loss：0.093303
【train】 epoch：2 step:8125/14065 loss：0.090124
【train】 epoch：2 step:8126/14065 loss：0.085545
【train】 epoch：2 step:8127/14065 loss：0.180467
【train】 epoch：2 step:8128/14065 loss：0.138807
【train】 epoch：2 step:8129/14065 loss：0.088102
【train】 epoch：2 step:8130/14065 loss：0.082241
【train】 epoch：2 step:8131/14065 loss：0.020120
【train】 epoch：2 step:8132/14065 loss：0.077470
【train】 epoch：2 step:8133/14065 loss：0.134866
【train】 epoch：2 step:8134/14065 loss：0.068226
【train】 epoch：2 step:8135/14065 loss：0.101943
【train】 epoch：2 step:8136/14065 loss：0.052530
【train】 epoch：2 step:8137/14065 loss：0.204351
【train】 epoch：2 step:8138/14065 loss：0.120721
【train】 epoch：2 step:8139/14065 loss：0.050074
【train】 epoch：2 step:8140/14065 loss：0.056591
【train】 epoch：2 step:8141/14065 loss：0.087599
【train】 epoch：2 step:8142/14065 loss：0.081730
【train】 epoch：2 step:8143/14065 loss：0.058303
【train】 epoch：2 step:8144/14065 loss：0.020789
【train】 epoch：2 step:8145/14065 loss：0.161655
【train】 epoch：2 step:8146/14065 loss：0.112114
【train】 epoch：2 step:8147/14065 loss：0.118274
【train】 epoch：2 step:8148/14065 loss：0.167636
【train】 epoch：2 step:8149/14065 loss：0.148472
【train】 epoch：2 step:8150/14065 loss：0.155619
【train】 epoch：2 step:8151/14065 loss：0.239732
【train】 epoch：2 step:8152/14065 loss：0.103742
【train】 epoch：2 step:8153/14065 loss：0.043751
【train】 epoch：2 step:8154/14065 loss：0.129160
【train】 epoch：2 step:8155/14065 loss：0.128713
【train】 epoch：2 step:8156/14065 loss：0.085481
【train】 epoch：2 step:8157/14065 loss：0.057652
【train】 epoch：2 step:8158/14065 loss：0.099443
【train】 epoch：2 step:8159/14065 loss：0.157862
【train】 epoch：2 step:8160/14065 loss：0.097051
【train】 epoch：2 step:8161/14065 loss：0.038914
【train】 epoch：2 step:8162/14065 loss：0.153838
【train】 epoch：2 step:8163/14065 loss：0.064152
【train】 epoch：2 step:8164/14065 loss：0.085711
【train】 epoch：2 step:8165/14065 loss：0.068321
【train】 epoch：2 step:8166/14065 loss：0.064526
【train】 epoch：2 step:8167/14065 loss：0.083495
【train】 epoch：2 step:8168/14065 loss：0.216189
【train】 epoch：2 step:8169/14065 loss：0.098510
【train】 epoch：2 step:8170/14065 loss：0.172546
【train】 epoch：2 step:8171/14065 loss：0.114958
【train】 epoch：2 step:8172/14065 loss：0.065022
【train】 epoch：2 step:8173/14065 loss：0.172501
【train】 epoch：2 step:8174/14065 loss：0.095730
【train】 epoch：2 step:8175/14065 loss：0.185467
【train】 epoch：2 step:8176/14065 loss：0.190481
【train】 epoch：2 step:8177/14065 loss：0.151922
【train】 epoch：2 step:8178/14065 loss：0.155012
【train】 epoch：2 step:8179/14065 loss：0.075794
【train】 epoch：2 step:8180/14065 loss：0.059909
【train】 epoch：2 step:8181/14065 loss：0.063599
【train】 epoch：2 step:8182/14065 loss：0.085854
【train】 epoch：2 step:8183/14065 loss：0.052208
【train】 epoch：2 step:8184/14065 loss：0.060287
【train】 epoch：2 step:8185/14065 loss：0.202456
【train】 epoch：2 step:8186/14065 loss：0.223656
【train】 epoch：2 step:8187/14065 loss：0.208242
【train】 epoch：2 step:8188/14065 loss：0.051145
【train】 epoch：2 step:8189/14065 loss：0.231227
【train】 epoch：2 step:8190/14065 loss：0.079050
【train】 epoch：2 step:8191/14065 loss：0.085476
【train】 epoch：2 step:8192/14065 loss：0.031242
【train】 epoch：2 step:8193/14065 loss：0.162498
【train】 epoch：2 step:8194/14065 loss：0.033883
【train】 epoch：2 step:8195/14065 loss：0.103153
【train】 epoch：2 step:8196/14065 loss：0.041923
【train】 epoch：2 step:8197/14065 loss：0.111034
【train】 epoch：2 step:8198/14065 loss：0.080693
【train】 epoch：2 step:8199/14065 loss：0.094363
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：162.487592 accuracy：0.9820 precision：0.9820 recall：0.9820 f1：0.9820
【train】 epoch：2 step:8200/14065 loss：0.221280
【train】 epoch：2 step:8201/14065 loss：0.293221
【train】 epoch：2 step:8202/14065 loss：0.246817
【train】 epoch：2 step:8203/14065 loss：0.028461
【train】 epoch：2 step:8204/14065 loss：0.126141
【train】 epoch：2 step:8205/14065 loss：0.038476
【train】 epoch：2 step:8206/14065 loss：0.131581
【train】 epoch：2 step:8207/14065 loss：0.067847
【train】 epoch：2 step:8208/14065 loss：0.035728
【train】 epoch：2 step:8209/14065 loss：0.054157
【train】 epoch：2 step:8210/14065 loss：0.084134
【train】 epoch：2 step:8211/14065 loss：0.103631
【train】 epoch：2 step:8212/14065 loss：0.010885
【train】 epoch：2 step:8213/14065 loss：0.080241
【train】 epoch：2 step:8214/14065 loss：0.247799
【train】 epoch：2 step:8215/14065 loss：0.201877
【train】 epoch：2 step:8216/14065 loss：0.110092
【train】 epoch：2 step:8217/14065 loss：0.059784
【train】 epoch：2 step:8218/14065 loss：0.055815
【train】 epoch：2 step:8219/14065 loss：0.020701
【train】 epoch：2 step:8220/14065 loss：0.123632
【train】 epoch：2 step:8221/14065 loss：0.137671
【train】 epoch：2 step:8222/14065 loss：0.023285
【train】 epoch：2 step:8223/14065 loss：0.083305
【train】 epoch：2 step:8224/14065 loss：0.051815
【train】 epoch：2 step:8225/14065 loss：0.112851
【train】 epoch：2 step:8226/14065 loss：0.111613
【train】 epoch：2 step:8227/14065 loss：0.138420
【train】 epoch：2 step:8228/14065 loss：0.035889
【train】 epoch：2 step:8229/14065 loss：0.047762
【train】 epoch：2 step:8230/14065 loss：0.080591
【train】 epoch：2 step:8231/14065 loss：0.185717
【train】 epoch：2 step:8232/14065 loss：0.265199
【train】 epoch：2 step:8233/14065 loss：0.173740
【train】 epoch：2 step:8234/14065 loss：0.088545
【train】 epoch：2 step:8235/14065 loss：0.068142
【train】 epoch：2 step:8236/14065 loss：0.016370
【train】 epoch：2 step:8237/14065 loss：0.042321
【train】 epoch：2 step:8238/14065 loss：0.100406
【train】 epoch：2 step:8239/14065 loss：0.055302
【train】 epoch：2 step:8240/14065 loss：0.008688
【train】 epoch：2 step:8241/14065 loss：0.067280
【train】 epoch：2 step:8242/14065 loss：0.149062
【train】 epoch：2 step:8243/14065 loss：0.146643
【train】 epoch：2 step:8244/14065 loss：0.153470
【train】 epoch：2 step:8245/14065 loss：0.077852
【train】 epoch：2 step:8246/14065 loss：0.035792
【train】 epoch：2 step:8247/14065 loss：0.022355
【train】 epoch：2 step:8248/14065 loss：0.060439
【train】 epoch：2 step:8249/14065 loss：0.114529
【train】 epoch：2 step:8250/14065 loss：0.111593
【train】 epoch：2 step:8251/14065 loss：0.107480
【train】 epoch：2 step:8252/14065 loss：0.168590
【train】 epoch：2 step:8253/14065 loss：0.121001
【train】 epoch：2 step:8254/14065 loss：0.070237
【train】 epoch：2 step:8255/14065 loss：0.033308
【train】 epoch：2 step:8256/14065 loss：0.172034
【train】 epoch：2 step:8257/14065 loss：0.075032
【train】 epoch：2 step:8258/14065 loss：0.054842
【train】 epoch：2 step:8259/14065 loss：0.161000
【train】 epoch：2 step:8260/14065 loss：0.152073
【train】 epoch：2 step:8261/14065 loss：0.049569
【train】 epoch：2 step:8262/14065 loss：0.072940
【train】 epoch：2 step:8263/14065 loss：0.189139
【train】 epoch：2 step:8264/14065 loss：0.141883
【train】 epoch：2 step:8265/14065 loss：0.197960
【train】 epoch：2 step:8266/14065 loss：0.097184
【train】 epoch：2 step:8267/14065 loss：0.138849
【train】 epoch：2 step:8268/14065 loss：0.204997
【train】 epoch：2 step:8269/14065 loss：0.096827
【train】 epoch：2 step:8270/14065 loss：0.192739
【train】 epoch：2 step:8271/14065 loss：0.210543
【train】 epoch：2 step:8272/14065 loss：0.033733
【train】 epoch：2 step:8273/14065 loss：0.183418
【train】 epoch：2 step:8274/14065 loss：0.198479
【train】 epoch：2 step:8275/14065 loss：0.088272
【train】 epoch：2 step:8276/14065 loss：0.064528
【train】 epoch：2 step:8277/14065 loss：0.187910
【train】 epoch：2 step:8278/14065 loss：0.035646
【train】 epoch：2 step:8279/14065 loss：0.103321
【train】 epoch：2 step:8280/14065 loss：0.189812
【train】 epoch：2 step:8281/14065 loss：0.064103
【train】 epoch：2 step:8282/14065 loss：0.193965
【train】 epoch：2 step:8283/14065 loss：0.109724
【train】 epoch：2 step:8284/14065 loss：0.130503
【train】 epoch：2 step:8285/14065 loss：0.084277
【train】 epoch：2 step:8286/14065 loss：0.040722
【train】 epoch：2 step:8287/14065 loss：0.091421
【train】 epoch：2 step:8288/14065 loss：0.089645
【train】 epoch：2 step:8289/14065 loss：0.080511
【train】 epoch：2 step:8290/14065 loss：0.080577
【train】 epoch：2 step:8291/14065 loss：0.205786
【train】 epoch：2 step:8292/14065 loss：0.131635
【train】 epoch：2 step:8293/14065 loss：0.059972
【train】 epoch：2 step:8294/14065 loss：0.028300
【train】 epoch：2 step:8295/14065 loss：0.059145
【train】 epoch：2 step:8296/14065 loss：0.094739
【train】 epoch：2 step:8297/14065 loss：0.075964
【train】 epoch：2 step:8298/14065 loss：0.028772
【train】 epoch：2 step:8299/14065 loss：0.309956
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：159.933746 accuracy：0.9818 precision：0.9818 recall：0.9818 f1：0.9818
【train】 epoch：2 step:8300/14065 loss：0.146519
【train】 epoch：2 step:8301/14065 loss：0.072883
【train】 epoch：2 step:8302/14065 loss：0.072926
【train】 epoch：2 step:8303/14065 loss：0.181433
【train】 epoch：2 step:8304/14065 loss：0.124911
【train】 epoch：2 step:8305/14065 loss：0.128646
【train】 epoch：2 step:8306/14065 loss：0.035733
【train】 epoch：2 step:8307/14065 loss：0.282748
【train】 epoch：2 step:8308/14065 loss：0.088514
【train】 epoch：2 step:8309/14065 loss：0.028390
【train】 epoch：2 step:8310/14065 loss：0.151585
【train】 epoch：2 step:8311/14065 loss：0.173341
【train】 epoch：2 step:8312/14065 loss：0.116821
【train】 epoch：2 step:8313/14065 loss：0.264632
【train】 epoch：2 step:8314/14065 loss：0.073948
【train】 epoch：2 step:8315/14065 loss：0.090236
【train】 epoch：2 step:8316/14065 loss：0.183051
【train】 epoch：2 step:8317/14065 loss：0.090609
【train】 epoch：2 step:8318/14065 loss：0.119407
【train】 epoch：2 step:8319/14065 loss：0.052007
【train】 epoch：2 step:8320/14065 loss：0.137165
【train】 epoch：2 step:8321/14065 loss：0.259467
【train】 epoch：2 step:8322/14065 loss：0.140569
【train】 epoch：2 step:8323/14065 loss：0.006948
【train】 epoch：2 step:8324/14065 loss：0.099657
【train】 epoch：2 step:8325/14065 loss：0.143758
【train】 epoch：2 step:8326/14065 loss：0.212769
【train】 epoch：2 step:8327/14065 loss：0.116019
【train】 epoch：2 step:8328/14065 loss：0.082791
【train】 epoch：2 step:8329/14065 loss：0.076751
【train】 epoch：2 step:8330/14065 loss：0.074462
【train】 epoch：2 step:8331/14065 loss：0.118100
【train】 epoch：2 step:8332/14065 loss：0.087534
【train】 epoch：2 step:8333/14065 loss：0.049667
【train】 epoch：2 step:8334/14065 loss：0.017127
【train】 epoch：2 step:8335/14065 loss：0.099952
【train】 epoch：2 step:8336/14065 loss：0.068421
【train】 epoch：2 step:8337/14065 loss：0.032839
【train】 epoch：2 step:8338/14065 loss：0.029976
【train】 epoch：2 step:8339/14065 loss：0.098966
【train】 epoch：2 step:8340/14065 loss：0.100767
【train】 epoch：2 step:8341/14065 loss：0.200921
【train】 epoch：2 step:8342/14065 loss：0.125740
【train】 epoch：2 step:8343/14065 loss：0.123590
【train】 epoch：2 step:8344/14065 loss：0.214869
【train】 epoch：2 step:8345/14065 loss：0.241189
【train】 epoch：2 step:8346/14065 loss：0.139449
【train】 epoch：2 step:8347/14065 loss：0.116603
【train】 epoch：2 step:8348/14065 loss：0.048011
【train】 epoch：2 step:8349/14065 loss：0.045095
【train】 epoch：2 step:8350/14065 loss：0.026133
【train】 epoch：2 step:8351/14065 loss：0.068105
【train】 epoch：2 step:8352/14065 loss：0.079567
【train】 epoch：2 step:8353/14065 loss：0.108742
【train】 epoch：2 step:8354/14065 loss：0.133543
【train】 epoch：2 step:8355/14065 loss：0.084218
【train】 epoch：2 step:8356/14065 loss：0.134466
【train】 epoch：2 step:8357/14065 loss：0.165541
【train】 epoch：2 step:8358/14065 loss：0.053122
【train】 epoch：2 step:8359/14065 loss：0.051164
【train】 epoch：2 step:8360/14065 loss：0.147197
【train】 epoch：2 step:8361/14065 loss：0.229730
【train】 epoch：2 step:8362/14065 loss：0.087209
【train】 epoch：2 step:8363/14065 loss：0.134876
【train】 epoch：2 step:8364/14065 loss：0.110572
【train】 epoch：2 step:8365/14065 loss：0.209081
【train】 epoch：2 step:8366/14065 loss：0.105671
【train】 epoch：2 step:8367/14065 loss：0.040859
【train】 epoch：2 step:8368/14065 loss：0.069378
【train】 epoch：2 step:8369/14065 loss：0.073811
【train】 epoch：2 step:8370/14065 loss：0.146977
【train】 epoch：2 step:8371/14065 loss：0.136224
【train】 epoch：2 step:8372/14065 loss：0.237057
【train】 epoch：2 step:8373/14065 loss：0.134663
【train】 epoch：2 step:8374/14065 loss：0.054706
【train】 epoch：2 step:8375/14065 loss：0.119046
【train】 epoch：2 step:8376/14065 loss：0.049885
【train】 epoch：2 step:8377/14065 loss：0.171196
【train】 epoch：2 step:8378/14065 loss：0.065639
【train】 epoch：2 step:8379/14065 loss：0.068876
【train】 epoch：2 step:8380/14065 loss：0.115026
【train】 epoch：2 step:8381/14065 loss：0.071103
【train】 epoch：2 step:8382/14065 loss：0.054978
【train】 epoch：2 step:8383/14065 loss：0.027693
【train】 epoch：2 step:8384/14065 loss：0.145463
【train】 epoch：2 step:8385/14065 loss：0.007819
【train】 epoch：2 step:8386/14065 loss：0.132388
【train】 epoch：2 step:8387/14065 loss：0.161538
【train】 epoch：2 step:8388/14065 loss：0.204230
【train】 epoch：2 step:8389/14065 loss：0.183113
【train】 epoch：2 step:8390/14065 loss：0.038933
【train】 epoch：2 step:8391/14065 loss：0.176442
【train】 epoch：2 step:8392/14065 loss：0.079011
【train】 epoch：2 step:8393/14065 loss：0.039540
【train】 epoch：2 step:8394/14065 loss：0.132139
【train】 epoch：2 step:8395/14065 loss：0.083244
【train】 epoch：2 step:8396/14065 loss：0.052457
【train】 epoch：2 step:8397/14065 loss：0.138493
【train】 epoch：2 step:8398/14065 loss：0.300769
【train】 epoch：2 step:8399/14065 loss：0.114098
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：153.734251 accuracy：0.9828 precision：0.9828 recall：0.9828 f1：0.9828
【train】 epoch：2 step:8400/14065 loss：0.132537
【train】 epoch：2 step:8401/14065 loss：0.026052
【train】 epoch：2 step:8402/14065 loss：0.101146
【train】 epoch：2 step:8403/14065 loss：0.170590
【train】 epoch：2 step:8404/14065 loss：0.258059
【train】 epoch：2 step:8405/14065 loss：0.068046
【train】 epoch：2 step:8406/14065 loss：0.078082
【train】 epoch：2 step:8407/14065 loss：0.099072
【train】 epoch：2 step:8408/14065 loss：0.066199
【train】 epoch：2 step:8409/14065 loss：0.072304
【train】 epoch：2 step:8410/14065 loss：0.158745
【train】 epoch：2 step:8411/14065 loss：0.197064
【train】 epoch：2 step:8412/14065 loss：0.082890
【train】 epoch：2 step:8413/14065 loss：0.073788
【train】 epoch：2 step:8414/14065 loss：0.165081
【train】 epoch：2 step:8415/14065 loss：0.058115
【train】 epoch：2 step:8416/14065 loss：0.137307
【train】 epoch：2 step:8417/14065 loss：0.024578
【train】 epoch：2 step:8418/14065 loss：0.077318
【train】 epoch：2 step:8419/14065 loss：0.070483
【train】 epoch：2 step:8420/14065 loss：0.056317
【train】 epoch：2 step:8421/14065 loss：0.045412
【train】 epoch：2 step:8422/14065 loss：0.050575
【train】 epoch：2 step:8423/14065 loss：0.110915
【train】 epoch：2 step:8424/14065 loss：0.062714
【train】 epoch：2 step:8425/14065 loss：0.043318
【train】 epoch：2 step:8426/14065 loss：0.089417
【train】 epoch：2 step:8427/14065 loss：0.058949
【train】 epoch：2 step:8428/14065 loss：0.105059
【train】 epoch：2 step:8429/14065 loss：0.045763
【train】 epoch：2 step:8430/14065 loss：0.030979
【train】 epoch：2 step:8431/14065 loss：0.192411
【train】 epoch：2 step:8432/14065 loss：0.073127
【train】 epoch：2 step:8433/14065 loss：0.095471
【train】 epoch：2 step:8434/14065 loss：0.190326
【train】 epoch：2 step:8435/14065 loss：0.212310
【train】 epoch：2 step:8436/14065 loss：0.125622
【train】 epoch：2 step:8437/14065 loss：0.024305
【train】 epoch：2 step:8438/14065 loss：0.014397
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【train】 epoch：3 step:8439/14065 loss：0.035739
【train】 epoch：3 step:8440/14065 loss：0.040686
【train】 epoch：3 step:8441/14065 loss：0.087456
【train】 epoch：3 step:8442/14065 loss：0.035777
【train】 epoch：3 step:8443/14065 loss：0.013621
【train】 epoch：3 step:8444/14065 loss：0.067637
【train】 epoch：3 step:8445/14065 loss：0.021181
【train】 epoch：3 step:8446/14065 loss：0.112185
【train】 epoch：3 step:8447/14065 loss：0.065892
【train】 epoch：3 step:8448/14065 loss：0.064947
【train】 epoch：3 step:8449/14065 loss：0.051175
【train】 epoch：3 step:8450/14065 loss：0.197204
【train】 epoch：3 step:8451/14065 loss：0.035294
【train】 epoch：3 step:8452/14065 loss：0.022250
【train】 epoch：3 step:8453/14065 loss：0.024509
【train】 epoch：3 step:8454/14065 loss：0.043710
【train】 epoch：3 step:8455/14065 loss：0.064593
【train】 epoch：3 step:8456/14065 loss：0.019455
【train】 epoch：3 step:8457/14065 loss：0.101979
【train】 epoch：3 step:8458/14065 loss：0.057010
【train】 epoch：3 step:8459/14065 loss：0.135535
【train】 epoch：3 step:8460/14065 loss：0.022634
【train】 epoch：3 step:8461/14065 loss：0.145606
【train】 epoch：3 step:8462/14065 loss：0.044527
【train】 epoch：3 step:8463/14065 loss：0.093891
【train】 epoch：3 step:8464/14065 loss：0.049965
【train】 epoch：3 step:8465/14065 loss：0.028806
【train】 epoch：3 step:8466/14065 loss：0.024853
【train】 epoch：3 step:8467/14065 loss：0.045258
【train】 epoch：3 step:8468/14065 loss：0.042064
【train】 epoch：3 step:8469/14065 loss：0.054466
【train】 epoch：3 step:8470/14065 loss：0.071058
【train】 epoch：3 step:8471/14065 loss：0.040323
【train】 epoch：3 step:8472/14065 loss：0.133278
【train】 epoch：3 step:8473/14065 loss：0.039486
【train】 epoch：3 step:8474/14065 loss：0.024000
【train】 epoch：3 step:8475/14065 loss：0.021714
【train】 epoch：3 step:8476/14065 loss：0.165396
【train】 epoch：3 step:8477/14065 loss：0.116548
【train】 epoch：3 step:8478/14065 loss：0.101786
【train】 epoch：3 step:8479/14065 loss：0.086486
【train】 epoch：3 step:8480/14065 loss：0.028745
【train】 epoch：3 step:8481/14065 loss：0.058573
【train】 epoch：3 step:8482/14065 loss：0.052035
【train】 epoch：3 step:8483/14065 loss：0.008491
【train】 epoch：3 step:8484/14065 loss：0.179107
【train】 epoch：3 step:8485/14065 loss：0.031472
【train】 epoch：3 step:8486/14065 loss：0.049916
【train】 epoch：3 step:8487/14065 loss：0.023344
【train】 epoch：3 step:8488/14065 loss：0.043940
【train】 epoch：3 step:8489/14065 loss：0.138572
【train】 epoch：3 step:8490/14065 loss：0.174627
【train】 epoch：3 step:8491/14065 loss：0.119899
【train】 epoch：3 step:8492/14065 loss：0.135795
【train】 epoch：3 step:8493/14065 loss：0.050504
【train】 epoch：3 step:8494/14065 loss：0.097313
【train】 epoch：3 step:8495/14065 loss：0.054916
【train】 epoch：3 step:8496/14065 loss：0.112959
【train】 epoch：3 step:8497/14065 loss：0.058494
【train】 epoch：3 step:8498/14065 loss：0.012680
【train】 epoch：3 step:8499/14065 loss：0.039691
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：140.387076 accuracy：0.9841 precision：0.9841 recall：0.9841 f1：0.9841
------------>保存当前最好的模型
【train】 epoch：3 step:8500/14065 loss：0.136901
【train】 epoch：3 step:8501/14065 loss：0.127358
【train】 epoch：3 step:8502/14065 loss：0.061614
【train】 epoch：3 step:8503/14065 loss：0.026518
【train】 epoch：3 step:8504/14065 loss：0.105695
【train】 epoch：3 step:8505/14065 loss：0.034849
【train】 epoch：3 step:8506/14065 loss：0.043145
【train】 epoch：3 step:8507/14065 loss：0.118911
【train】 epoch：3 step:8508/14065 loss：0.064208
【train】 epoch：3 step:8509/14065 loss：0.050674
【train】 epoch：3 step:8510/14065 loss：0.078091
【train】 epoch：3 step:8511/14065 loss：0.015906
【train】 epoch：3 step:8512/14065 loss：0.127927
【train】 epoch：3 step:8513/14065 loss：0.088272
【train】 epoch：3 step:8514/14065 loss：0.024336
【train】 epoch：3 step:8515/14065 loss：0.025353
【train】 epoch：3 step:8516/14065 loss：0.087532
【train】 epoch：3 step:8517/14065 loss：0.019181
【train】 epoch：3 step:8518/14065 loss：0.181760
【train】 epoch：3 step:8519/14065 loss：0.106073
【train】 epoch：3 step:8520/14065 loss：0.019695
【train】 epoch：3 step:8521/14065 loss：0.087838
【train】 epoch：3 step:8522/14065 loss：0.104670
【train】 epoch：3 step:8523/14065 loss：0.093492
【train】 epoch：3 step:8524/14065 loss：0.171645
【train】 epoch：3 step:8525/14065 loss：0.070139
【train】 epoch：3 step:8526/14065 loss：0.050971
【train】 epoch：3 step:8527/14065 loss：0.092925
【train】 epoch：3 step:8528/14065 loss：0.122052
【train】 epoch：3 step:8529/14065 loss：0.039519
【train】 epoch：3 step:8530/14065 loss：0.031605
【train】 epoch：3 step:8531/14065 loss：0.105305
【train】 epoch：3 step:8532/14065 loss：0.020488
【train】 epoch：3 step:8533/14065 loss：0.063350
【train】 epoch：3 step:8534/14065 loss：0.030103
【train】 epoch：3 step:8535/14065 loss：0.102813
【train】 epoch：3 step:8536/14065 loss：0.078419
【train】 epoch：3 step:8537/14065 loss：0.076385
【train】 epoch：3 step:8538/14065 loss：0.041316
【train】 epoch：3 step:8539/14065 loss：0.140345
【train】 epoch：3 step:8540/14065 loss：0.057845
【train】 epoch：3 step:8541/14065 loss：0.055864
【train】 epoch：3 step:8542/14065 loss：0.032120
【train】 epoch：3 step:8543/14065 loss：0.071587
【train】 epoch：3 step:8544/14065 loss：0.121983
【train】 epoch：3 step:8545/14065 loss：0.054277
【train】 epoch：3 step:8546/14065 loss：0.142057
【train】 epoch：3 step:8547/14065 loss：0.016731
【train】 epoch：3 step:8548/14065 loss：0.062527
【train】 epoch：3 step:8549/14065 loss：0.047300
【train】 epoch：3 step:8550/14065 loss：0.142996
【train】 epoch：3 step:8551/14065 loss：0.017886
【train】 epoch：3 step:8552/14065 loss：0.020706
【train】 epoch：3 step:8553/14065 loss：0.027889
【train】 epoch：3 step:8554/14065 loss：0.043588
【train】 epoch：3 step:8555/14065 loss：0.142754
【train】 epoch：3 step:8556/14065 loss：0.055404
【train】 epoch：3 step:8557/14065 loss：0.082048
【train】 epoch：3 step:8558/14065 loss：0.121601
【train】 epoch：3 step:8559/14065 loss：0.117574
【train】 epoch：3 step:8560/14065 loss：0.102798
【train】 epoch：3 step:8561/14065 loss：0.052414
【train】 epoch：3 step:8562/14065 loss：0.019064
【train】 epoch：3 step:8563/14065 loss：0.029784
【train】 epoch：3 step:8564/14065 loss：0.015111
【train】 epoch：3 step:8565/14065 loss：0.022786
【train】 epoch：3 step:8566/14065 loss：0.031899
【train】 epoch：3 step:8567/14065 loss：0.092432
【train】 epoch：3 step:8568/14065 loss：0.032226
【train】 epoch：3 step:8569/14065 loss：0.027836
【train】 epoch：3 step:8570/14065 loss：0.199201
【train】 epoch：3 step:8571/14065 loss：0.072939
【train】 epoch：3 step:8572/14065 loss：0.134022
【train】 epoch：3 step:8573/14065 loss：0.092193
【train】 epoch：3 step:8574/14065 loss：0.035381
【train】 epoch：3 step:8575/14065 loss：0.043279
【train】 epoch：3 step:8576/14065 loss：0.024820
【train】 epoch：3 step:8577/14065 loss：0.050866
【train】 epoch：3 step:8578/14065 loss：0.026146
【train】 epoch：3 step:8579/14065 loss：0.035323
【train】 epoch：3 step:8580/14065 loss：0.023500
【train】 epoch：3 step:8581/14065 loss：0.054055
【train】 epoch：3 step:8582/14065 loss：0.010829
【train】 epoch：3 step:8583/14065 loss：0.059535
【train】 epoch：3 step:8584/14065 loss：0.093962
【train】 epoch：3 step:8585/14065 loss：0.117071
【train】 epoch：3 step:8586/14065 loss：0.046362
【train】 epoch：3 step:8587/14065 loss：0.008154
【train】 epoch：3 step:8588/14065 loss：0.056193
【train】 epoch：3 step:8589/14065 loss：0.109424
【train】 epoch：3 step:8590/14065 loss：0.090345
【train】 epoch：3 step:8591/14065 loss：0.036436
【train】 epoch：3 step:8592/14065 loss：0.047756
【train】 epoch：3 step:8593/14065 loss：0.043249
【train】 epoch：3 step:8594/14065 loss：0.022962
【train】 epoch：3 step:8595/14065 loss：0.016162
【train】 epoch：3 step:8596/14065 loss：0.176563
【train】 epoch：3 step:8597/14065 loss：0.022062
【train】 epoch：3 step:8598/14065 loss：0.012076
【train】 epoch：3 step:8599/14065 loss：0.116327
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：145.764358 accuracy：0.9823 precision：0.9823 recall：0.9823 f1：0.9823
【train】 epoch：3 step:8600/14065 loss：0.074665
【train】 epoch：3 step:8601/14065 loss：0.032204
【train】 epoch：3 step:8602/14065 loss：0.025103
【train】 epoch：3 step:8603/14065 loss：0.059296
【train】 epoch：3 step:8604/14065 loss：0.042403
【train】 epoch：3 step:8605/14065 loss：0.081721
【train】 epoch：3 step:8606/14065 loss：0.042838
【train】 epoch：3 step:8607/14065 loss：0.068747
【train】 epoch：3 step:8608/14065 loss：0.055256
【train】 epoch：3 step:8609/14065 loss：0.006467
【train】 epoch：3 step:8610/14065 loss：0.009119
【train】 epoch：3 step:8611/14065 loss：0.080821
【train】 epoch：3 step:8612/14065 loss：0.076407
【train】 epoch：3 step:8613/14065 loss：0.024120
【train】 epoch：3 step:8614/14065 loss：0.030635
【train】 epoch：3 step:8615/14065 loss：0.011562
【train】 epoch：3 step:8616/14065 loss：0.011619
【train】 epoch：3 step:8617/14065 loss：0.037441
【train】 epoch：3 step:8618/14065 loss：0.163007
【train】 epoch：3 step:8619/14065 loss：0.031866
【train】 epoch：3 step:8620/14065 loss：0.090639
【train】 epoch：3 step:8621/14065 loss：0.026419
【train】 epoch：3 step:8622/14065 loss：0.130821
【train】 epoch：3 step:8623/14065 loss：0.083070
【train】 epoch：3 step:8624/14065 loss：0.034031
【train】 epoch：3 step:8625/14065 loss：0.014955
【train】 epoch：3 step:8626/14065 loss：0.152993
【train】 epoch：3 step:8627/14065 loss：0.141620
【train】 epoch：3 step:8628/14065 loss：0.072762
【train】 epoch：3 step:8629/14065 loss：0.019247
【train】 epoch：3 step:8630/14065 loss：0.039953
【train】 epoch：3 step:8631/14065 loss：0.031803
【train】 epoch：3 step:8632/14065 loss：0.112465
【train】 epoch：3 step:8633/14065 loss：0.060973
【train】 epoch：3 step:8634/14065 loss：0.033817
【train】 epoch：3 step:8635/14065 loss：0.050158
【train】 epoch：3 step:8636/14065 loss：0.151575
【train】 epoch：3 step:8637/14065 loss：0.004401
【train】 epoch：3 step:8638/14065 loss：0.009673
【train】 epoch：3 step:8639/14065 loss：0.076683
【train】 epoch：3 step:8640/14065 loss：0.072726
【train】 epoch：3 step:8641/14065 loss：0.015736
【train】 epoch：3 step:8642/14065 loss：0.057047
【train】 epoch：3 step:8643/14065 loss：0.051775
【train】 epoch：3 step:8644/14065 loss：0.104693
【train】 epoch：3 step:8645/14065 loss：0.121347
【train】 epoch：3 step:8646/14065 loss：0.012454
【train】 epoch：3 step:8647/14065 loss：0.079819
【train】 epoch：3 step:8648/14065 loss：0.077006
【train】 epoch：3 step:8649/14065 loss：0.031863
【train】 epoch：3 step:8650/14065 loss：0.076511
【train】 epoch：3 step:8651/14065 loss：0.039830
【train】 epoch：3 step:8652/14065 loss：0.122712
【train】 epoch：3 step:8653/14065 loss：0.050643
【train】 epoch：3 step:8654/14065 loss：0.024887
【train】 epoch：3 step:8655/14065 loss：0.124737
【train】 epoch：3 step:8656/14065 loss：0.051552
【train】 epoch：3 step:8657/14065 loss：0.026220
【train】 epoch：3 step:8658/14065 loss：0.119178
【train】 epoch：3 step:8659/14065 loss：0.026747
【train】 epoch：3 step:8660/14065 loss：0.067375
【train】 epoch：3 step:8661/14065 loss：0.022180
【train】 epoch：3 step:8662/14065 loss：0.157128
【train】 epoch：3 step:8663/14065 loss：0.013269
【train】 epoch：3 step:8664/14065 loss：0.095125
【train】 epoch：3 step:8665/14065 loss：0.083581
【train】 epoch：3 step:8666/14065 loss：0.076249
【train】 epoch：3 step:8667/14065 loss：0.051851
【train】 epoch：3 step:8668/14065 loss：0.011795
【train】 epoch：3 step:8669/14065 loss：0.036359
【train】 epoch：3 step:8670/14065 loss：0.055556
【train】 epoch：3 step:8671/14065 loss：0.041212
【train】 epoch：3 step:8672/14065 loss：0.047319
【train】 epoch：3 step:8673/14065 loss：0.057087
【train】 epoch：3 step:8674/14065 loss：0.032665
【train】 epoch：3 step:8675/14065 loss：0.017269
【train】 epoch：3 step:8676/14065 loss：0.037525
【train】 epoch：3 step:8677/14065 loss：0.098060
【train】 epoch：3 step:8678/14065 loss：0.118325
【train】 epoch：3 step:8679/14065 loss：0.130143
【train】 epoch：3 step:8680/14065 loss：0.043455
【train】 epoch：3 step:8681/14065 loss：0.055171
【train】 epoch：3 step:8682/14065 loss：0.067745
【train】 epoch：3 step:8683/14065 loss：0.032148
【train】 epoch：3 step:8684/14065 loss：0.058727
【train】 epoch：3 step:8685/14065 loss：0.029219
【train】 epoch：3 step:8686/14065 loss：0.047076
【train】 epoch：3 step:8687/14065 loss：0.014943
【train】 epoch：3 step:8688/14065 loss：0.119207
【train】 epoch：3 step:8689/14065 loss：0.071612
【train】 epoch：3 step:8690/14065 loss：0.014131
【train】 epoch：3 step:8691/14065 loss：0.020144
【train】 epoch：3 step:8692/14065 loss：0.088527
【train】 epoch：3 step:8693/14065 loss：0.045230
【train】 epoch：3 step:8694/14065 loss：0.045634
【train】 epoch：3 step:8695/14065 loss：0.096581
【train】 epoch：3 step:8696/14065 loss：0.105867
【train】 epoch：3 step:8697/14065 loss：0.062259
【train】 epoch：3 step:8698/14065 loss：0.181347
【train】 epoch：3 step:8699/14065 loss：0.061581
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：123.492491 accuracy：0.9854 precision：0.9854 recall：0.9854 f1：0.9854
------------>保存当前最好的模型
【train】 epoch：3 step:8700/14065 loss：0.017731
【train】 epoch：3 step:8701/14065 loss：0.157196
【train】 epoch：3 step:8702/14065 loss：0.018230
【train】 epoch：3 step:8703/14065 loss：0.107588
【train】 epoch：3 step:8704/14065 loss：0.079933
【train】 epoch：3 step:8705/14065 loss：0.061514
【train】 epoch：3 step:8706/14065 loss：0.060809
【train】 epoch：3 step:8707/14065 loss：0.073500
【train】 epoch：3 step:8708/14065 loss：0.084309
【train】 epoch：3 step:8709/14065 loss：0.025197
【train】 epoch：3 step:8710/14065 loss：0.104063
【train】 epoch：3 step:8711/14065 loss：0.023628
【train】 epoch：3 step:8712/14065 loss：0.003033
【train】 epoch：3 step:8713/14065 loss：0.086737
【train】 epoch：3 step:8714/14065 loss：0.068772
【train】 epoch：3 step:8715/14065 loss：0.020580
【train】 epoch：3 step:8716/14065 loss：0.031823
【train】 epoch：3 step:8717/14065 loss：0.017847
【train】 epoch：3 step:8718/14065 loss：0.026588
【train】 epoch：3 step:8719/14065 loss：0.019010
【train】 epoch：3 step:8720/14065 loss：0.134098
【train】 epoch：3 step:8721/14065 loss：0.056370
【train】 epoch：3 step:8722/14065 loss：0.018935
【train】 epoch：3 step:8723/14065 loss：0.057270
【train】 epoch：3 step:8724/14065 loss：0.038669
【train】 epoch：3 step:8725/14065 loss：0.024902
【train】 epoch：3 step:8726/14065 loss：0.044404
【train】 epoch：3 step:8727/14065 loss：0.120571
【train】 epoch：3 step:8728/14065 loss：0.118209
【train】 epoch：3 step:8729/14065 loss：0.031724
【train】 epoch：3 step:8730/14065 loss：0.044645
【train】 epoch：3 step:8731/14065 loss：0.123784
【train】 epoch：3 step:8732/14065 loss：0.034598
【train】 epoch：3 step:8733/14065 loss：0.087438
【train】 epoch：3 step:8734/14065 loss：0.019852
【train】 epoch：3 step:8735/14065 loss：0.018614
【train】 epoch：3 step:8736/14065 loss：0.018356
【train】 epoch：3 step:8737/14065 loss：0.135629
【train】 epoch：3 step:8738/14065 loss：0.144255
【train】 epoch：3 step:8739/14065 loss：0.017634
【train】 epoch：3 step:8740/14065 loss：0.148702
【train】 epoch：3 step:8741/14065 loss：0.031660
【train】 epoch：3 step:8742/14065 loss：0.063698
【train】 epoch：3 step:8743/14065 loss：0.054536
【train】 epoch：3 step:8744/14065 loss：0.159028
【train】 epoch：3 step:8745/14065 loss：0.063167
【train】 epoch：3 step:8746/14065 loss：0.024953
【train】 epoch：3 step:8747/14065 loss：0.097072
【train】 epoch：3 step:8748/14065 loss：0.100895
【train】 epoch：3 step:8749/14065 loss：0.027729
【train】 epoch：3 step:8750/14065 loss：0.080131
【train】 epoch：3 step:8751/14065 loss：0.007062
【train】 epoch：3 step:8752/14065 loss：0.103839
【train】 epoch：3 step:8753/14065 loss：0.009293
【train】 epoch：3 step:8754/14065 loss：0.088621
【train】 epoch：3 step:8755/14065 loss：0.057121
【train】 epoch：3 step:8756/14065 loss：0.061505
【train】 epoch：3 step:8757/14065 loss：0.037656
【train】 epoch：3 step:8758/14065 loss：0.021439
【train】 epoch：3 step:8759/14065 loss：0.020523
【train】 epoch：3 step:8760/14065 loss：0.020453
【train】 epoch：3 step:8761/14065 loss：0.099717
【train】 epoch：3 step:8762/14065 loss：0.049542
【train】 epoch：3 step:8763/14065 loss：0.045094
【train】 epoch：3 step:8764/14065 loss：0.021868
【train】 epoch：3 step:8765/14065 loss：0.025904
【train】 epoch：3 step:8766/14065 loss：0.146469
【train】 epoch：3 step:8767/14065 loss：0.018610
【train】 epoch：3 step:8768/14065 loss：0.065208
【train】 epoch：3 step:8769/14065 loss：0.105348
【train】 epoch：3 step:8770/14065 loss：0.097243
【train】 epoch：3 step:8771/14065 loss：0.024814
【train】 epoch：3 step:8772/14065 loss：0.102892
【train】 epoch：3 step:8773/14065 loss：0.037972
【train】 epoch：3 step:8774/14065 loss：0.027095
【train】 epoch：3 step:8775/14065 loss：0.030628
【train】 epoch：3 step:8776/14065 loss：0.106655
【train】 epoch：3 step:8777/14065 loss：0.050763
【train】 epoch：3 step:8778/14065 loss：0.032833
【train】 epoch：3 step:8779/14065 loss：0.039127
【train】 epoch：3 step:8780/14065 loss：0.005202
【train】 epoch：3 step:8781/14065 loss：0.005260
【train】 epoch：3 step:8782/14065 loss：0.100184
【train】 epoch：3 step:8783/14065 loss：0.012869
【train】 epoch：3 step:8784/14065 loss：0.041989
【train】 epoch：3 step:8785/14065 loss：0.038446
【train】 epoch：3 step:8786/14065 loss：0.055789
【train】 epoch：3 step:8787/14065 loss：0.066490
【train】 epoch：3 step:8788/14065 loss：0.066310
【train】 epoch：3 step:8789/14065 loss：0.075514
【train】 epoch：3 step:8790/14065 loss：0.144507
【train】 epoch：3 step:8791/14065 loss：0.045314
【train】 epoch：3 step:8792/14065 loss：0.015393
【train】 epoch：3 step:8793/14065 loss：0.010599
【train】 epoch：3 step:8794/14065 loss：0.041143
【train】 epoch：3 step:8795/14065 loss：0.032644
【train】 epoch：3 step:8796/14065 loss：0.017242
【train】 epoch：3 step:8797/14065 loss：0.064203
【train】 epoch：3 step:8798/14065 loss：0.018217
【train】 epoch：3 step:8799/14065 loss：0.140513
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：140.407080 accuracy：0.9834 precision：0.9834 recall：0.9834 f1：0.9834
【train】 epoch：3 step:8800/14065 loss：0.062283
【train】 epoch：3 step:8801/14065 loss：0.017250
【train】 epoch：3 step:8802/14065 loss：0.011116
【train】 epoch：3 step:8803/14065 loss：0.060037
【train】 epoch：3 step:8804/14065 loss：0.005767
【train】 epoch：3 step:8805/14065 loss：0.050370
【train】 epoch：3 step:8806/14065 loss：0.048230
【train】 epoch：3 step:8807/14065 loss：0.073318
【train】 epoch：3 step:8808/14065 loss：0.025861
【train】 epoch：3 step:8809/14065 loss：0.054892
【train】 epoch：3 step:8810/14065 loss：0.023491
【train】 epoch：3 step:8811/14065 loss：0.097728
【train】 epoch：3 step:8812/14065 loss：0.049563
【train】 epoch：3 step:8813/14065 loss：0.035508
【train】 epoch：3 step:8814/14065 loss：0.017892
【train】 epoch：3 step:8815/14065 loss：0.051674
【train】 epoch：3 step:8816/14065 loss：0.159676
【train】 epoch：3 step:8817/14065 loss：0.077523
【train】 epoch：3 step:8818/14065 loss：0.132147
【train】 epoch：3 step:8819/14065 loss：0.059132
【train】 epoch：3 step:8820/14065 loss：0.028603
【train】 epoch：3 step:8821/14065 loss：0.056927
【train】 epoch：3 step:8822/14065 loss：0.089233
【train】 epoch：3 step:8823/14065 loss：0.086367
【train】 epoch：3 step:8824/14065 loss：0.032232
【train】 epoch：3 step:8825/14065 loss：0.132474
【train】 epoch：3 step:8826/14065 loss：0.054881
【train】 epoch：3 step:8827/14065 loss：0.083530
【train】 epoch：3 step:8828/14065 loss：0.011442
【train】 epoch：3 step:8829/14065 loss：0.055219
【train】 epoch：3 step:8830/14065 loss：0.035159
【train】 epoch：3 step:8831/14065 loss：0.038478
【train】 epoch：3 step:8832/14065 loss：0.143373
【train】 epoch：3 step:8833/14065 loss：0.026247
【train】 epoch：3 step:8834/14065 loss：0.052150
【train】 epoch：3 step:8835/14065 loss：0.016893
【train】 epoch：3 step:8836/14065 loss：0.083649
【train】 epoch：3 step:8837/14065 loss：0.037385
【train】 epoch：3 step:8838/14065 loss：0.005930
【train】 epoch：3 step:8839/14065 loss：0.052894
【train】 epoch：3 step:8840/14065 loss：0.162442
【train】 epoch：3 step:8841/14065 loss：0.032820
【train】 epoch：3 step:8842/14065 loss：0.100709
【train】 epoch：3 step:8843/14065 loss：0.156704
【train】 epoch：3 step:8844/14065 loss：0.058822
【train】 epoch：3 step:8845/14065 loss：0.072568
【train】 epoch：3 step:8846/14065 loss：0.256022
【train】 epoch：3 step:8847/14065 loss：0.062563
【train】 epoch：3 step:8848/14065 loss：0.031594
【train】 epoch：3 step:8849/14065 loss：0.022571
【train】 epoch：3 step:8850/14065 loss：0.094213
【train】 epoch：3 step:8851/14065 loss：0.113385
【train】 epoch：3 step:8852/14065 loss：0.035641
【train】 epoch：3 step:8853/14065 loss：0.103824
【train】 epoch：3 step:8854/14065 loss：0.056080
【train】 epoch：3 step:8855/14065 loss：0.025484
【train】 epoch：3 step:8856/14065 loss：0.003938
【train】 epoch：3 step:8857/14065 loss：0.075777
【train】 epoch：3 step:8858/14065 loss：0.101532
【train】 epoch：3 step:8859/14065 loss：0.112476
【train】 epoch：3 step:8860/14065 loss：0.047088
【train】 epoch：3 step:8861/14065 loss：0.133222
【train】 epoch：3 step:8862/14065 loss：0.119660
【train】 epoch：3 step:8863/14065 loss：0.160653
【train】 epoch：3 step:8864/14065 loss：0.058357
【train】 epoch：3 step:8865/14065 loss：0.013873
【train】 epoch：3 step:8866/14065 loss：0.060509
【train】 epoch：3 step:8867/14065 loss：0.035816
【train】 epoch：3 step:8868/14065 loss：0.143553
【train】 epoch：3 step:8869/14065 loss：0.038855
【train】 epoch：3 step:8870/14065 loss：0.013060
【train】 epoch：3 step:8871/14065 loss：0.122672
【train】 epoch：3 step:8872/14065 loss：0.049117
【train】 epoch：3 step:8873/14065 loss：0.110220
【train】 epoch：3 step:8874/14065 loss：0.024220
【train】 epoch：3 step:8875/14065 loss：0.014026
【train】 epoch：3 step:8876/14065 loss：0.086455
【train】 epoch：3 step:8877/14065 loss：0.013752
【train】 epoch：3 step:8878/14065 loss：0.149664
【train】 epoch：3 step:8879/14065 loss：0.077274
【train】 epoch：3 step:8880/14065 loss：0.054408
【train】 epoch：3 step:8881/14065 loss：0.031694
【train】 epoch：3 step:8882/14065 loss：0.047469
【train】 epoch：3 step:8883/14065 loss：0.005430
【train】 epoch：3 step:8884/14065 loss：0.017976
【train】 epoch：3 step:8885/14065 loss：0.039385
【train】 epoch：3 step:8886/14065 loss：0.100318
【train】 epoch：3 step:8887/14065 loss：0.091033
【train】 epoch：3 step:8888/14065 loss：0.206055
【train】 epoch：3 step:8889/14065 loss：0.055107
【train】 epoch：3 step:8890/14065 loss：0.062579
【train】 epoch：3 step:8891/14065 loss：0.184391
【train】 epoch：3 step:8892/14065 loss：0.073789
【train】 epoch：3 step:8893/14065 loss：0.024497
【train】 epoch：3 step:8894/14065 loss：0.137395
【train】 epoch：3 step:8895/14065 loss：0.045866
【train】 epoch：3 step:8896/14065 loss：0.012821
【train】 epoch：3 step:8897/14065 loss：0.086271
【train】 epoch：3 step:8898/14065 loss：0.091381
【train】 epoch：3 step:8899/14065 loss：0.078843
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：151.356087 accuracy：0.9822 precision：0.9822 recall：0.9822 f1：0.9822
【train】 epoch：3 step:8900/14065 loss：0.098546
【train】 epoch：3 step:8901/14065 loss：0.106173
【train】 epoch：3 step:8902/14065 loss：0.038324
【train】 epoch：3 step:8903/14065 loss：0.106489
【train】 epoch：3 step:8904/14065 loss：0.127381
【train】 epoch：3 step:8905/14065 loss：0.017296
【train】 epoch：3 step:8906/14065 loss：0.083782
【train】 epoch：3 step:8907/14065 loss：0.037844
【train】 epoch：3 step:8908/14065 loss：0.016064
【train】 epoch：3 step:8909/14065 loss：0.188740
【train】 epoch：3 step:8910/14065 loss：0.124675
【train】 epoch：3 step:8911/14065 loss：0.050529
【train】 epoch：3 step:8912/14065 loss：0.116714
【train】 epoch：3 step:8913/14065 loss：0.052277
【train】 epoch：3 step:8914/14065 loss：0.023357
【train】 epoch：3 step:8915/14065 loss：0.025702
【train】 epoch：3 step:8916/14065 loss：0.015879
【train】 epoch：3 step:8917/14065 loss：0.145044
【train】 epoch：3 step:8918/14065 loss：0.050283
【train】 epoch：3 step:8919/14065 loss：0.010033
【train】 epoch：3 step:8920/14065 loss：0.036158
【train】 epoch：3 step:8921/14065 loss：0.135535
【train】 epoch：3 step:8922/14065 loss：0.040218
【train】 epoch：3 step:8923/14065 loss：0.063595
【train】 epoch：3 step:8924/14065 loss：0.015510
【train】 epoch：3 step:8925/14065 loss：0.017039
【train】 epoch：3 step:8926/14065 loss：0.039223
【train】 epoch：3 step:8927/14065 loss：0.027173
【train】 epoch：3 step:8928/14065 loss：0.113566
【train】 epoch：3 step:8929/14065 loss：0.030565
【train】 epoch：3 step:8930/14065 loss：0.089969
【train】 epoch：3 step:8931/14065 loss：0.007867
【train】 epoch：3 step:8932/14065 loss：0.062891
【train】 epoch：3 step:8933/14065 loss：0.038108
【train】 epoch：3 step:8934/14065 loss：0.110609
【train】 epoch：3 step:8935/14065 loss：0.047316
【train】 epoch：3 step:8936/14065 loss：0.017506
【train】 epoch：3 step:8937/14065 loss：0.006591
【train】 epoch：3 step:8938/14065 loss：0.091365
【train】 epoch：3 step:8939/14065 loss：0.136116
【train】 epoch：3 step:8940/14065 loss：0.012642
【train】 epoch：3 step:8941/14065 loss：0.133815
【train】 epoch：3 step:8942/14065 loss：0.024816
【train】 epoch：3 step:8943/14065 loss：0.016239
【train】 epoch：3 step:8944/14065 loss：0.027337
【train】 epoch：3 step:8945/14065 loss：0.024200
【train】 epoch：3 step:8946/14065 loss：0.013239
【train】 epoch：3 step:8947/14065 loss：0.082413
【train】 epoch：3 step:8948/14065 loss：0.068865
【train】 epoch：3 step:8949/14065 loss：0.197860
【train】 epoch：3 step:8950/14065 loss：0.119060
【train】 epoch：3 step:8951/14065 loss：0.005507
【train】 epoch：3 step:8952/14065 loss：0.036293
【train】 epoch：3 step:8953/14065 loss：0.178706
【train】 epoch：3 step:8954/14065 loss：0.061991
【train】 epoch：3 step:8955/14065 loss：0.035926
【train】 epoch：3 step:8956/14065 loss：0.038122
【train】 epoch：3 step:8957/14065 loss：0.047505
【train】 epoch：3 step:8958/14065 loss：0.012509
【train】 epoch：3 step:8959/14065 loss：0.088855
【train】 epoch：3 step:8960/14065 loss：0.110629
【train】 epoch：3 step:8961/14065 loss：0.039058
【train】 epoch：3 step:8962/14065 loss：0.050754
【train】 epoch：3 step:8963/14065 loss：0.018029
【train】 epoch：3 step:8964/14065 loss：0.024064
【train】 epoch：3 step:8965/14065 loss：0.015112
【train】 epoch：3 step:8966/14065 loss：0.066333
【train】 epoch：3 step:8967/14065 loss：0.110040
【train】 epoch：3 step:8968/14065 loss：0.147133
【train】 epoch：3 step:8969/14065 loss：0.030470
【train】 epoch：3 step:8970/14065 loss：0.243535
【train】 epoch：3 step:8971/14065 loss：0.129098
【train】 epoch：3 step:8972/14065 loss：0.083052
【train】 epoch：3 step:8973/14065 loss：0.118211
【train】 epoch：3 step:8974/14065 loss：0.079316
【train】 epoch：3 step:8975/14065 loss：0.020402
【train】 epoch：3 step:8976/14065 loss：0.021256
【train】 epoch：3 step:8977/14065 loss：0.056332
【train】 epoch：3 step:8978/14065 loss：0.046661
【train】 epoch：3 step:8979/14065 loss：0.009351
【train】 epoch：3 step:8980/14065 loss：0.021786
【train】 epoch：3 step:8981/14065 loss：0.161569
【train】 epoch：3 step:8982/14065 loss：0.050189
【train】 epoch：3 step:8983/14065 loss：0.040289
【train】 epoch：3 step:8984/14065 loss：0.028052
【train】 epoch：3 step:8985/14065 loss：0.032373
【train】 epoch：3 step:8986/14065 loss：0.013065
【train】 epoch：3 step:8987/14065 loss：0.035394
【train】 epoch：3 step:8988/14065 loss：0.036079
【train】 epoch：3 step:8989/14065 loss：0.102670
【train】 epoch：3 step:8990/14065 loss：0.083835
【train】 epoch：3 step:8991/14065 loss：0.065171
【train】 epoch：3 step:8992/14065 loss：0.202337
【train】 epoch：3 step:8993/14065 loss：0.057145
【train】 epoch：3 step:8994/14065 loss：0.106935
【train】 epoch：3 step:8995/14065 loss：0.085830
【train】 epoch：3 step:8996/14065 loss：0.042223
【train】 epoch：3 step:8997/14065 loss：0.026663
【train】 epoch：3 step:8998/14065 loss：0.006111
【train】 epoch：3 step:8999/14065 loss：0.050903
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：137.486232 accuracy：0.9835 precision：0.9835 recall：0.9835 f1：0.9835
【train】 epoch：3 step:9000/14065 loss：0.138092
【train】 epoch：3 step:9001/14065 loss：0.093654
【train】 epoch：3 step:9002/14065 loss：0.028651
【train】 epoch：3 step:9003/14065 loss：0.035215
【train】 epoch：3 step:9004/14065 loss：0.022271
【train】 epoch：3 step:9005/14065 loss：0.049068
【train】 epoch：3 step:9006/14065 loss：0.125410
【train】 epoch：3 step:9007/14065 loss：0.146869
【train】 epoch：3 step:9008/14065 loss：0.018887
【train】 epoch：3 step:9009/14065 loss：0.013021
【train】 epoch：3 step:9010/14065 loss：0.046040
【train】 epoch：3 step:9011/14065 loss：0.096179
【train】 epoch：3 step:9012/14065 loss：0.009777
【train】 epoch：3 step:9013/14065 loss：0.038686
【train】 epoch：3 step:9014/14065 loss：0.184097
【train】 epoch：3 step:9015/14065 loss：0.037081
【train】 epoch：3 step:9016/14065 loss：0.064402
【train】 epoch：3 step:9017/14065 loss：0.007832
【train】 epoch：3 step:9018/14065 loss：0.079739
【train】 epoch：3 step:9019/14065 loss：0.089102
【train】 epoch：3 step:9020/14065 loss：0.040790
【train】 epoch：3 step:9021/14065 loss：0.067292
【train】 epoch：3 step:9022/14065 loss：0.061730
【train】 epoch：3 step:9023/14065 loss：0.037476
【train】 epoch：3 step:9024/14065 loss：0.037875
【train】 epoch：3 step:9025/14065 loss：0.177843
【train】 epoch：3 step:9026/14065 loss：0.084227
【train】 epoch：3 step:9027/14065 loss：0.037104
【train】 epoch：3 step:9028/14065 loss：0.022948
【train】 epoch：3 step:9029/14065 loss：0.046121
【train】 epoch：3 step:9030/14065 loss：0.036298
【train】 epoch：3 step:9031/14065 loss：0.107745
【train】 epoch：3 step:9032/14065 loss：0.104690
【train】 epoch：3 step:9033/14065 loss：0.010064
【train】 epoch：3 step:9034/14065 loss：0.063710
【train】 epoch：3 step:9035/14065 loss：0.089294
【train】 epoch：3 step:9036/14065 loss：0.044011
【train】 epoch：3 step:9037/14065 loss：0.074044
【train】 epoch：3 step:9038/14065 loss：0.025689
【train】 epoch：3 step:9039/14065 loss：0.046702
【train】 epoch：3 step:9040/14065 loss：0.142575
【train】 epoch：3 step:9041/14065 loss：0.027572
【train】 epoch：3 step:9042/14065 loss：0.109676
【train】 epoch：3 step:9043/14065 loss：0.009694
【train】 epoch：3 step:9044/14065 loss：0.069999
【train】 epoch：3 step:9045/14065 loss：0.036841
【train】 epoch：3 step:9046/14065 loss：0.034081
【train】 epoch：3 step:9047/14065 loss：0.223124
【train】 epoch：3 step:9048/14065 loss：0.026129
【train】 epoch：3 step:9049/14065 loss：0.044240
【train】 epoch：3 step:9050/14065 loss：0.165660
【train】 epoch：3 step:9051/14065 loss：0.101280
【train】 epoch：3 step:9052/14065 loss：0.080747
【train】 epoch：3 step:9053/14065 loss：0.070300
【train】 epoch：3 step:9054/14065 loss：0.006765
【train】 epoch：3 step:9055/14065 loss：0.036460
【train】 epoch：3 step:9056/14065 loss：0.071809
【train】 epoch：3 step:9057/14065 loss：0.013578
【train】 epoch：3 step:9058/14065 loss：0.039179
【train】 epoch：3 step:9059/14065 loss：0.088112
【train】 epoch：3 step:9060/14065 loss：0.127127
【train】 epoch：3 step:9061/14065 loss：0.013775
【train】 epoch：3 step:9062/14065 loss：0.079359
【train】 epoch：3 step:9063/14065 loss：0.058894
【train】 epoch：3 step:9064/14065 loss：0.036709
【train】 epoch：3 step:9065/14065 loss：0.010146
【train】 epoch：3 step:9066/14065 loss：0.059951
【train】 epoch：3 step:9067/14065 loss：0.037960
【train】 epoch：3 step:9068/14065 loss：0.007529
【train】 epoch：3 step:9069/14065 loss：0.064218
【train】 epoch：3 step:9070/14065 loss：0.017757
【train】 epoch：3 step:9071/14065 loss：0.075157
【train】 epoch：3 step:9072/14065 loss：0.103137
【train】 epoch：3 step:9073/14065 loss：0.120419
【train】 epoch：3 step:9074/14065 loss：0.082186
【train】 epoch：3 step:9075/14065 loss：0.116233
【train】 epoch：3 step:9076/14065 loss：0.058488
【train】 epoch：3 step:9077/14065 loss：0.024731
【train】 epoch：3 step:9078/14065 loss：0.021033
【train】 epoch：3 step:9079/14065 loss：0.227430
【train】 epoch：3 step:9080/14065 loss：0.044433
【train】 epoch：3 step:9081/14065 loss：0.126507
【train】 epoch：3 step:9082/14065 loss：0.127294
【train】 epoch：3 step:9083/14065 loss：0.141188
【train】 epoch：3 step:9084/14065 loss：0.102740
【train】 epoch：3 step:9085/14065 loss：0.111907
【train】 epoch：3 step:9086/14065 loss：0.051928
【train】 epoch：3 step:9087/14065 loss：0.032344
【train】 epoch：3 step:9088/14065 loss：0.049614
【train】 epoch：3 step:9089/14065 loss：0.067941
【train】 epoch：3 step:9090/14065 loss：0.029544
【train】 epoch：3 step:9091/14065 loss：0.013944
【train】 epoch：3 step:9092/14065 loss：0.083620
【train】 epoch：3 step:9093/14065 loss：0.021320
【train】 epoch：3 step:9094/14065 loss：0.029235
【train】 epoch：3 step:9095/14065 loss：0.007486
【train】 epoch：3 step:9096/14065 loss：0.103030
【train】 epoch：3 step:9097/14065 loss：0.053631
【train】 epoch：3 step:9098/14065 loss：0.044294
【train】 epoch：3 step:9099/14065 loss：0.072271
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：125.227220 accuracy：0.9856 precision：0.9856 recall：0.9856 f1：0.9856
------------>保存当前最好的模型
【train】 epoch：3 step:9100/14065 loss：0.074960
【train】 epoch：3 step:9101/14065 loss：0.053078
【train】 epoch：3 step:9102/14065 loss：0.090170
【train】 epoch：3 step:9103/14065 loss：0.050996
【train】 epoch：3 step:9104/14065 loss：0.045187
【train】 epoch：3 step:9105/14065 loss：0.075425
【train】 epoch：3 step:9106/14065 loss：0.003864
【train】 epoch：3 step:9107/14065 loss：0.044854
【train】 epoch：3 step:9108/14065 loss：0.056475
【train】 epoch：3 step:9109/14065 loss：0.016362
【train】 epoch：3 step:9110/14065 loss：0.014134
【train】 epoch：3 step:9111/14065 loss：0.089154
【train】 epoch：3 step:9112/14065 loss：0.110906
【train】 epoch：3 step:9113/14065 loss：0.109613
【train】 epoch：3 step:9114/14065 loss：0.072454
【train】 epoch：3 step:9115/14065 loss：0.039233
【train】 epoch：3 step:9116/14065 loss：0.008636
【train】 epoch：3 step:9117/14065 loss：0.036452
【train】 epoch：3 step:9118/14065 loss：0.036217
【train】 epoch：3 step:9119/14065 loss：0.056268
【train】 epoch：3 step:9120/14065 loss：0.043108
【train】 epoch：3 step:9121/14065 loss：0.067036
【train】 epoch：3 step:9122/14065 loss：0.033199
【train】 epoch：3 step:9123/14065 loss：0.202476
【train】 epoch：3 step:9124/14065 loss：0.044988
【train】 epoch：3 step:9125/14065 loss：0.019699
【train】 epoch：3 step:9126/14065 loss：0.076367
【train】 epoch：3 step:9127/14065 loss：0.007209
【train】 epoch：3 step:9128/14065 loss：0.044096
【train】 epoch：3 step:9129/14065 loss：0.137690
【train】 epoch：3 step:9130/14065 loss：0.098264
【train】 epoch：3 step:9131/14065 loss：0.167338
【train】 epoch：3 step:9132/14065 loss：0.079994
【train】 epoch：3 step:9133/14065 loss：0.065228
【train】 epoch：3 step:9134/14065 loss：0.034682
【train】 epoch：3 step:9135/14065 loss：0.050341
【train】 epoch：3 step:9136/14065 loss：0.196897
【train】 epoch：3 step:9137/14065 loss：0.088017
【train】 epoch：3 step:9138/14065 loss：0.055769
【train】 epoch：3 step:9139/14065 loss：0.066487
【train】 epoch：3 step:9140/14065 loss：0.154526
【train】 epoch：3 step:9141/14065 loss：0.028076
【train】 epoch：3 step:9142/14065 loss：0.009071
【train】 epoch：3 step:9143/14065 loss：0.025510
【train】 epoch：3 step:9144/14065 loss：0.087567
【train】 epoch：3 step:9145/14065 loss：0.097030
【train】 epoch：3 step:9146/14065 loss：0.066581
【train】 epoch：3 step:9147/14065 loss：0.038456
【train】 epoch：3 step:9148/14065 loss：0.066357
【train】 epoch：3 step:9149/14065 loss：0.113984
【train】 epoch：3 step:9150/14065 loss：0.017823
【train】 epoch：3 step:9151/14065 loss：0.019797
【train】 epoch：3 step:9152/14065 loss：0.016877
【train】 epoch：3 step:9153/14065 loss：0.005845
【train】 epoch：3 step:9154/14065 loss：0.025660
【train】 epoch：3 step:9155/14065 loss：0.073386
【train】 epoch：3 step:9156/14065 loss：0.085507
【train】 epoch：3 step:9157/14065 loss：0.081659
【train】 epoch：3 step:9158/14065 loss：0.016732
【train】 epoch：3 step:9159/14065 loss：0.069783
【train】 epoch：3 step:9160/14065 loss：0.148079
【train】 epoch：3 step:9161/14065 loss：0.097629
【train】 epoch：3 step:9162/14065 loss：0.023507
【train】 epoch：3 step:9163/14065 loss：0.027296
【train】 epoch：3 step:9164/14065 loss：0.014608
【train】 epoch：3 step:9165/14065 loss：0.036514
【train】 epoch：3 step:9166/14065 loss：0.024725
【train】 epoch：3 step:9167/14065 loss：0.139708
【train】 epoch：3 step:9168/14065 loss：0.046046
【train】 epoch：3 step:9169/14065 loss：0.030668
【train】 epoch：3 step:9170/14065 loss：0.059641
【train】 epoch：3 step:9171/14065 loss：0.012419
【train】 epoch：3 step:9172/14065 loss：0.024047
【train】 epoch：3 step:9173/14065 loss：0.073300
【train】 epoch：3 step:9174/14065 loss：0.088624
【train】 epoch：3 step:9175/14065 loss：0.034951
【train】 epoch：3 step:9176/14065 loss：0.091268
【train】 epoch：3 step:9177/14065 loss：0.142976
【train】 epoch：3 step:9178/14065 loss：0.049652
【train】 epoch：3 step:9179/14065 loss：0.010542
【train】 epoch：3 step:9180/14065 loss：0.007638
【train】 epoch：3 step:9181/14065 loss：0.058613
【train】 epoch：3 step:9182/14065 loss：0.010634
【train】 epoch：3 step:9183/14065 loss：0.008913
【train】 epoch：3 step:9184/14065 loss：0.141557
【train】 epoch：3 step:9185/14065 loss：0.045310
【train】 epoch：3 step:9186/14065 loss：0.005110
【train】 epoch：3 step:9187/14065 loss：0.061401
【train】 epoch：3 step:9188/14065 loss：0.053039
【train】 epoch：3 step:9189/14065 loss：0.028575
【train】 epoch：3 step:9190/14065 loss：0.005975
【train】 epoch：3 step:9191/14065 loss：0.030437
【train】 epoch：3 step:9192/14065 loss：0.064398
【train】 epoch：3 step:9193/14065 loss：0.078613
【train】 epoch：3 step:9194/14065 loss：0.048044
【train】 epoch：3 step:9195/14065 loss：0.048225
【train】 epoch：3 step:9196/14065 loss：0.042861
【train】 epoch：3 step:9197/14065 loss：0.122148
【train】 epoch：3 step:9198/14065 loss：0.031191
【train】 epoch：3 step:9199/14065 loss：0.018808
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：112.934896 accuracy：0.9869 precision：0.9869 recall：0.9869 f1：0.9869
------------>保存当前最好的模型
【train】 epoch：3 step:9200/14065 loss：0.040774
【train】 epoch：3 step:9201/14065 loss：0.039529
【train】 epoch：3 step:9202/14065 loss：0.042338
【train】 epoch：3 step:9203/14065 loss：0.033644
【train】 epoch：3 step:9204/14065 loss：0.007042
【train】 epoch：3 step:9205/14065 loss：0.179288
【train】 epoch：3 step:9206/14065 loss：0.099711
【train】 epoch：3 step:9207/14065 loss：0.056959
【train】 epoch：3 step:9208/14065 loss：0.062143
【train】 epoch：3 step:9209/14065 loss：0.005540
【train】 epoch：3 step:9210/14065 loss：0.127278
【train】 epoch：3 step:9211/14065 loss：0.123561
【train】 epoch：3 step:9212/14065 loss：0.042224
【train】 epoch：3 step:9213/14065 loss：0.151569
【train】 epoch：3 step:9214/14065 loss：0.051860
【train】 epoch：3 step:9215/14065 loss：0.058391
【train】 epoch：3 step:9216/14065 loss：0.007510
【train】 epoch：3 step:9217/14065 loss：0.039410
【train】 epoch：3 step:9218/14065 loss：0.037406
【train】 epoch：3 step:9219/14065 loss：0.069842
【train】 epoch：3 step:9220/14065 loss：0.063430
【train】 epoch：3 step:9221/14065 loss：0.209889
【train】 epoch：3 step:9222/14065 loss：0.041829
【train】 epoch：3 step:9223/14065 loss：0.141293
【train】 epoch：3 step:9224/14065 loss：0.067376
【train】 epoch：3 step:9225/14065 loss：0.096180
【train】 epoch：3 step:9226/14065 loss：0.057820
【train】 epoch：3 step:9227/14065 loss：0.065699
【train】 epoch：3 step:9228/14065 loss：0.011389
【train】 epoch：3 step:9229/14065 loss：0.032325
【train】 epoch：3 step:9230/14065 loss：0.064829
【train】 epoch：3 step:9231/14065 loss：0.059600
【train】 epoch：3 step:9232/14065 loss：0.060671
【train】 epoch：3 step:9233/14065 loss：0.052139
【train】 epoch：3 step:9234/14065 loss：0.036305
【train】 epoch：3 step:9235/14065 loss：0.016349
【train】 epoch：3 step:9236/14065 loss：0.064552
【train】 epoch：3 step:9237/14065 loss：0.041807
【train】 epoch：3 step:9238/14065 loss：0.037207
【train】 epoch：3 step:9239/14065 loss：0.011059
【train】 epoch：3 step:9240/14065 loss：0.036282
【train】 epoch：3 step:9241/14065 loss：0.188924
【train】 epoch：3 step:9242/14065 loss：0.060750
【train】 epoch：3 step:9243/14065 loss：0.053095
【train】 epoch：3 step:9244/14065 loss：0.030761
【train】 epoch：3 step:9245/14065 loss：0.033805
【train】 epoch：3 step:9246/14065 loss：0.035080
【train】 epoch：3 step:9247/14065 loss：0.003129
【train】 epoch：3 step:9248/14065 loss：0.080868
【train】 epoch：3 step:9249/14065 loss：0.066479
【train】 epoch：3 step:9250/14065 loss：0.042968
【train】 epoch：3 step:9251/14065 loss：0.083101
【train】 epoch：3 step:9252/14065 loss：0.041476
【train】 epoch：3 step:9253/14065 loss：0.106930
【train】 epoch：3 step:9254/14065 loss：0.042902
【train】 epoch：3 step:9255/14065 loss：0.060936
【train】 epoch：3 step:9256/14065 loss：0.013724
【train】 epoch：3 step:9257/14065 loss：0.062594
【train】 epoch：3 step:9258/14065 loss：0.039741
【train】 epoch：3 step:9259/14065 loss：0.049242
【train】 epoch：3 step:9260/14065 loss：0.068924
【train】 epoch：3 step:9261/14065 loss：0.081815
【train】 epoch：3 step:9262/14065 loss：0.013712
【train】 epoch：3 step:9263/14065 loss：0.092348
【train】 epoch：3 step:9264/14065 loss：0.030125
【train】 epoch：3 step:9265/14065 loss：0.063933
【train】 epoch：3 step:9266/14065 loss：0.057194
【train】 epoch：3 step:9267/14065 loss：0.123153
【train】 epoch：3 step:9268/14065 loss：0.042555
【train】 epoch：3 step:9269/14065 loss：0.009034
【train】 epoch：3 step:9270/14065 loss：0.098938
【train】 epoch：3 step:9271/14065 loss：0.080826
【train】 epoch：3 step:9272/14065 loss：0.038893
【train】 epoch：3 step:9273/14065 loss：0.143988
【train】 epoch：3 step:9274/14065 loss：0.033797
【train】 epoch：3 step:9275/14065 loss：0.196831
【train】 epoch：3 step:9276/14065 loss：0.014150
【train】 epoch：3 step:9277/14065 loss：0.043193
【train】 epoch：3 step:9278/14065 loss：0.045312
【train】 epoch：3 step:9279/14065 loss：0.006726
【train】 epoch：3 step:9280/14065 loss：0.014412
【train】 epoch：3 step:9281/14065 loss：0.111439
【train】 epoch：3 step:9282/14065 loss：0.067275
【train】 epoch：3 step:9283/14065 loss：0.010228
【train】 epoch：3 step:9284/14065 loss：0.207312
【train】 epoch：3 step:9285/14065 loss：0.130753
【train】 epoch：3 step:9286/14065 loss：0.105325
【train】 epoch：3 step:9287/14065 loss：0.009216
【train】 epoch：3 step:9288/14065 loss：0.054580
【train】 epoch：3 step:9289/14065 loss：0.011379
【train】 epoch：3 step:9290/14065 loss：0.023227
【train】 epoch：3 step:9291/14065 loss：0.049435
【train】 epoch：3 step:9292/14065 loss：0.014343
【train】 epoch：3 step:9293/14065 loss：0.166674
【train】 epoch：3 step:9294/14065 loss：0.013071
【train】 epoch：3 step:9295/14065 loss：0.058031
【train】 epoch：3 step:9296/14065 loss：0.049633
【train】 epoch：3 step:9297/14065 loss：0.014349
【train】 epoch：3 step:9298/14065 loss：0.087280
【train】 epoch：3 step:9299/14065 loss：0.058895
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：125.661869 accuracy：0.9851 precision：0.9851 recall：0.9851 f1：0.9851
【train】 epoch：3 step:9300/14065 loss：0.116184
【train】 epoch：3 step:9301/14065 loss：0.051401
【train】 epoch：3 step:9302/14065 loss：0.055165
【train】 epoch：3 step:9303/14065 loss：0.043184
【train】 epoch：3 step:9304/14065 loss：0.027723
【train】 epoch：3 step:9305/14065 loss：0.022859
【train】 epoch：3 step:9306/14065 loss：0.029338
【train】 epoch：3 step:9307/14065 loss：0.116412
【train】 epoch：3 step:9308/14065 loss：0.031883
【train】 epoch：3 step:9309/14065 loss：0.133731
【train】 epoch：3 step:9310/14065 loss：0.013983
【train】 epoch：3 step:9311/14065 loss：0.049388
【train】 epoch：3 step:9312/14065 loss：0.016107
【train】 epoch：3 step:9313/14065 loss：0.058680
【train】 epoch：3 step:9314/14065 loss：0.091495
【train】 epoch：3 step:9315/14065 loss：0.162172
【train】 epoch：3 step:9316/14065 loss：0.018684
【train】 epoch：3 step:9317/14065 loss：0.028269
【train】 epoch：3 step:9318/14065 loss：0.183277
【train】 epoch：3 step:9319/14065 loss：0.040060
【train】 epoch：3 step:9320/14065 loss：0.135104
【train】 epoch：3 step:9321/14065 loss：0.041201
【train】 epoch：3 step:9322/14065 loss：0.042993
【train】 epoch：3 step:9323/14065 loss：0.044624
【train】 epoch：3 step:9324/14065 loss：0.106163
【train】 epoch：3 step:9325/14065 loss：0.086048
【train】 epoch：3 step:9326/14065 loss：0.058081
【train】 epoch：3 step:9327/14065 loss：0.035865
【train】 epoch：3 step:9328/14065 loss：0.024555
【train】 epoch：3 step:9329/14065 loss：0.123910
【train】 epoch：3 step:9330/14065 loss：0.044430
【train】 epoch：3 step:9331/14065 loss：0.009716
【train】 epoch：3 step:9332/14065 loss：0.043657
【train】 epoch：3 step:9333/14065 loss：0.082362
【train】 epoch：3 step:9334/14065 loss：0.159913
【train】 epoch：3 step:9335/14065 loss：0.114671
【train】 epoch：3 step:9336/14065 loss：0.035265
【train】 epoch：3 step:9337/14065 loss：0.122657
【train】 epoch：3 step:9338/14065 loss：0.055800
【train】 epoch：3 step:9339/14065 loss：0.025293
【train】 epoch：3 step:9340/14065 loss：0.207265
【train】 epoch：3 step:9341/14065 loss：0.059632
【train】 epoch：3 step:9342/14065 loss：0.108087
【train】 epoch：3 step:9343/14065 loss：0.113464
【train】 epoch：3 step:9344/14065 loss：0.121128
【train】 epoch：3 step:9345/14065 loss：0.053780
【train】 epoch：3 step:9346/14065 loss：0.089503
【train】 epoch：3 step:9347/14065 loss：0.120165
【train】 epoch：3 step:9348/14065 loss：0.050190
【train】 epoch：3 step:9349/14065 loss：0.009758
【train】 epoch：3 step:9350/14065 loss：0.057041
【train】 epoch：3 step:9351/14065 loss：0.050252
【train】 epoch：3 step:9352/14065 loss：0.191261
【train】 epoch：3 step:9353/14065 loss：0.057155
【train】 epoch：3 step:9354/14065 loss：0.087264
【train】 epoch：3 step:9355/14065 loss：0.045945
【train】 epoch：3 step:9356/14065 loss：0.026428
【train】 epoch：3 step:9357/14065 loss：0.082034
【train】 epoch：3 step:9358/14065 loss：0.069745
【train】 epoch：3 step:9359/14065 loss：0.058480
【train】 epoch：3 step:9360/14065 loss：0.037662
【train】 epoch：3 step:9361/14065 loss：0.108610
【train】 epoch：3 step:9362/14065 loss：0.117048
【train】 epoch：3 step:9363/14065 loss：0.097158
【train】 epoch：3 step:9364/14065 loss：0.089190
【train】 epoch：3 step:9365/14065 loss：0.237327
【train】 epoch：3 step:9366/14065 loss：0.272155
【train】 epoch：3 step:9367/14065 loss：0.011838
【train】 epoch：3 step:9368/14065 loss：0.227639
【train】 epoch：3 step:9369/14065 loss：0.043607
【train】 epoch：3 step:9370/14065 loss：0.033485
【train】 epoch：3 step:9371/14065 loss：0.011867
【train】 epoch：3 step:9372/14065 loss：0.083857
【train】 epoch：3 step:9373/14065 loss：0.230995
【train】 epoch：3 step:9374/14065 loss：0.027743
【train】 epoch：3 step:9375/14065 loss：0.216549
【train】 epoch：3 step:9376/14065 loss：0.033483
【train】 epoch：3 step:9377/14065 loss：0.029465
【train】 epoch：3 step:9378/14065 loss：0.131885
【train】 epoch：3 step:9379/14065 loss：0.122859
【train】 epoch：3 step:9380/14065 loss：0.053260
【train】 epoch：3 step:9381/14065 loss：0.025313
【train】 epoch：3 step:9382/14065 loss：0.231950
【train】 epoch：3 step:9383/14065 loss：0.076605
【train】 epoch：3 step:9384/14065 loss：0.033540
【train】 epoch：3 step:9385/14065 loss：0.042494
【train】 epoch：3 step:9386/14065 loss：0.082707
【train】 epoch：3 step:9387/14065 loss：0.115705
【train】 epoch：3 step:9388/14065 loss：0.009874
【train】 epoch：3 step:9389/14065 loss：0.185183
【train】 epoch：3 step:9390/14065 loss：0.049113
【train】 epoch：3 step:9391/14065 loss：0.105693
【train】 epoch：3 step:9392/14065 loss：0.029472
【train】 epoch：3 step:9393/14065 loss：0.067868
【train】 epoch：3 step:9394/14065 loss：0.027848
【train】 epoch：3 step:9395/14065 loss：0.213102
【train】 epoch：3 step:9396/14065 loss：0.021933
【train】 epoch：3 step:9397/14065 loss：0.025897
【train】 epoch：3 step:9398/14065 loss：0.030377
【train】 epoch：3 step:9399/14065 loss：0.078690
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：126.851053 accuracy：0.9857 precision：0.9857 recall：0.9857 f1：0.9857
【train】 epoch：3 step:9400/14065 loss：0.106739
【train】 epoch：3 step:9401/14065 loss：0.115659
【train】 epoch：3 step:9402/14065 loss：0.021576
【train】 epoch：3 step:9403/14065 loss：0.146396
【train】 epoch：3 step:9404/14065 loss：0.096496
【train】 epoch：3 step:9405/14065 loss：0.021259
【train】 epoch：3 step:9406/14065 loss：0.054526
【train】 epoch：3 step:9407/14065 loss：0.125920
【train】 epoch：3 step:9408/14065 loss：0.010120
【train】 epoch：3 step:9409/14065 loss：0.107013
【train】 epoch：3 step:9410/14065 loss：0.030129
【train】 epoch：3 step:9411/14065 loss：0.070411
【train】 epoch：3 step:9412/14065 loss：0.040125
【train】 epoch：3 step:9413/14065 loss：0.061429
【train】 epoch：3 step:9414/14065 loss：0.189666
【train】 epoch：3 step:9415/14065 loss：0.035566
【train】 epoch：3 step:9416/14065 loss：0.074279
【train】 epoch：3 step:9417/14065 loss：0.060410
【train】 epoch：3 step:9418/14065 loss：0.239750
【train】 epoch：3 step:9419/14065 loss：0.089645
【train】 epoch：3 step:9420/14065 loss：0.064642
【train】 epoch：3 step:9421/14065 loss：0.090162
【train】 epoch：3 step:9422/14065 loss：0.043361
【train】 epoch：3 step:9423/14065 loss：0.066948
【train】 epoch：3 step:9424/14065 loss：0.014729
【train】 epoch：3 step:9425/14065 loss：0.058499
【train】 epoch：3 step:9426/14065 loss：0.043886
【train】 epoch：3 step:9427/14065 loss：0.013826
【train】 epoch：3 step:9428/14065 loss：0.037557
【train】 epoch：3 step:9429/14065 loss：0.019098
【train】 epoch：3 step:9430/14065 loss：0.037618
【train】 epoch：3 step:9431/14065 loss：0.045646
【train】 epoch：3 step:9432/14065 loss：0.105854
【train】 epoch：3 step:9433/14065 loss：0.114123
【train】 epoch：3 step:9434/14065 loss：0.042094
【train】 epoch：3 step:9435/14065 loss：0.050765
【train】 epoch：3 step:9436/14065 loss：0.096770
【train】 epoch：3 step:9437/14065 loss：0.130181
【train】 epoch：3 step:9438/14065 loss：0.022068
【train】 epoch：3 step:9439/14065 loss：0.158847
【train】 epoch：3 step:9440/14065 loss：0.057005
【train】 epoch：3 step:9441/14065 loss：0.085559
【train】 epoch：3 step:9442/14065 loss：0.054722
【train】 epoch：3 step:9443/14065 loss：0.043799
【train】 epoch：3 step:9444/14065 loss：0.085175
【train】 epoch：3 step:9445/14065 loss：0.017959
【train】 epoch：3 step:9446/14065 loss：0.015217
【train】 epoch：3 step:9447/14065 loss：0.094133
【train】 epoch：3 step:9448/14065 loss：0.096418
【train】 epoch：3 step:9449/14065 loss：0.006573
【train】 epoch：3 step:9450/14065 loss：0.073998
【train】 epoch：3 step:9451/14065 loss：0.071284
【train】 epoch：3 step:9452/14065 loss：0.019108
【train】 epoch：3 step:9453/14065 loss：0.035953
【train】 epoch：3 step:9454/14065 loss：0.021724
【train】 epoch：3 step:9455/14065 loss：0.048493
【train】 epoch：3 step:9456/14065 loss：0.059100
【train】 epoch：3 step:9457/14065 loss：0.029410
【train】 epoch：3 step:9458/14065 loss：0.040841
【train】 epoch：3 step:9459/14065 loss：0.070165
【train】 epoch：3 step:9460/14065 loss：0.047934
【train】 epoch：3 step:9461/14065 loss：0.073379
【train】 epoch：3 step:9462/14065 loss：0.022832
【train】 epoch：3 step:9463/14065 loss：0.050591
【train】 epoch：3 step:9464/14065 loss：0.021790
【train】 epoch：3 step:9465/14065 loss：0.142631
【train】 epoch：3 step:9466/14065 loss：0.022686
【train】 epoch：3 step:9467/14065 loss：0.060702
【train】 epoch：3 step:9468/14065 loss：0.105502
【train】 epoch：3 step:9469/14065 loss：0.073841
【train】 epoch：3 step:9470/14065 loss：0.098626
【train】 epoch：3 step:9471/14065 loss：0.058123
【train】 epoch：3 step:9472/14065 loss：0.034878
【train】 epoch：3 step:9473/14065 loss：0.058368
【train】 epoch：3 step:9474/14065 loss：0.048215
【train】 epoch：3 step:9475/14065 loss：0.071042
【train】 epoch：3 step:9476/14065 loss：0.015514
【train】 epoch：3 step:9477/14065 loss：0.164060
【train】 epoch：3 step:9478/14065 loss：0.064938
【train】 epoch：3 step:9479/14065 loss：0.108272
【train】 epoch：3 step:9480/14065 loss：0.036529
【train】 epoch：3 step:9481/14065 loss：0.107268
【train】 epoch：3 step:9482/14065 loss：0.078561
【train】 epoch：3 step:9483/14065 loss：0.048668
【train】 epoch：3 step:9484/14065 loss：0.027984
【train】 epoch：3 step:9485/14065 loss：0.053562
【train】 epoch：3 step:9486/14065 loss：0.019080
【train】 epoch：3 step:9487/14065 loss：0.188256
【train】 epoch：3 step:9488/14065 loss：0.104801
【train】 epoch：3 step:9489/14065 loss：0.016505
【train】 epoch：3 step:9490/14065 loss：0.014021
【train】 epoch：3 step:9491/14065 loss：0.075138
【train】 epoch：3 step:9492/14065 loss：0.040798
【train】 epoch：3 step:9493/14065 loss：0.046897
【train】 epoch：3 step:9494/14065 loss：0.054004
【train】 epoch：3 step:9495/14065 loss：0.007629
【train】 epoch：3 step:9496/14065 loss：0.068521
【train】 epoch：3 step:9497/14065 loss：0.072323
【train】 epoch：3 step:9498/14065 loss：0.067186
【train】 epoch：3 step:9499/14065 loss：0.142665
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：118.315813 accuracy：0.9864 precision：0.9864 recall：0.9864 f1：0.9864
【train】 epoch：3 step:9500/14065 loss：0.074600
【train】 epoch：3 step:9501/14065 loss：0.074291
【train】 epoch：3 step:9502/14065 loss：0.067167
【train】 epoch：3 step:9503/14065 loss：0.068482
【train】 epoch：3 step:9504/14065 loss：0.036368
【train】 epoch：3 step:9505/14065 loss：0.053628
【train】 epoch：3 step:9506/14065 loss：0.017209
【train】 epoch：3 step:9507/14065 loss：0.117675
【train】 epoch：3 step:9508/14065 loss：0.042980
【train】 epoch：3 step:9509/14065 loss：0.019376
【train】 epoch：3 step:9510/14065 loss：0.054894
【train】 epoch：3 step:9511/14065 loss：0.087939
【train】 epoch：3 step:9512/14065 loss：0.034715
【train】 epoch：3 step:9513/14065 loss：0.037897
【train】 epoch：3 step:9514/14065 loss：0.057205
【train】 epoch：3 step:9515/14065 loss：0.027233
【train】 epoch：3 step:9516/14065 loss：0.072545
【train】 epoch：3 step:9517/14065 loss：0.028910
【train】 epoch：3 step:9518/14065 loss：0.033617
【train】 epoch：3 step:9519/14065 loss：0.020868
【train】 epoch：3 step:9520/14065 loss：0.062048
【train】 epoch：3 step:9521/14065 loss：0.043990
【train】 epoch：3 step:9522/14065 loss：0.041607
【train】 epoch：3 step:9523/14065 loss：0.032653
【train】 epoch：3 step:9524/14065 loss：0.005664
【train】 epoch：3 step:9525/14065 loss：0.051798
【train】 epoch：3 step:9526/14065 loss：0.092004
【train】 epoch：3 step:9527/14065 loss：0.155230
【train】 epoch：3 step:9528/14065 loss：0.059570
【train】 epoch：3 step:9529/14065 loss：0.059603
【train】 epoch：3 step:9530/14065 loss：0.007865
【train】 epoch：3 step:9531/14065 loss：0.069058
【train】 epoch：3 step:9532/14065 loss：0.032385
【train】 epoch：3 step:9533/14065 loss：0.057187
【train】 epoch：3 step:9534/14065 loss：0.193976
【train】 epoch：3 step:9535/14065 loss：0.038436
【train】 epoch：3 step:9536/14065 loss：0.076068
【train】 epoch：3 step:9537/14065 loss：0.119191
【train】 epoch：3 step:9538/14065 loss：0.098324
【train】 epoch：3 step:9539/14065 loss：0.111455
【train】 epoch：3 step:9540/14065 loss：0.124194
【train】 epoch：3 step:9541/14065 loss：0.038539
【train】 epoch：3 step:9542/14065 loss：0.032991
【train】 epoch：3 step:9543/14065 loss：0.084732
【train】 epoch：3 step:9544/14065 loss：0.067395
【train】 epoch：3 step:9545/14065 loss：0.165389
【train】 epoch：3 step:9546/14065 loss：0.160638
【train】 epoch：3 step:9547/14065 loss：0.045577
【train】 epoch：3 step:9548/14065 loss：0.045251
【train】 epoch：3 step:9549/14065 loss：0.094541
【train】 epoch：3 step:9550/14065 loss：0.038403
【train】 epoch：3 step:9551/14065 loss：0.034805
【train】 epoch：3 step:9552/14065 loss：0.155702
【train】 epoch：3 step:9553/14065 loss：0.072780
【train】 epoch：3 step:9554/14065 loss：0.143348
【train】 epoch：3 step:9555/14065 loss：0.082855
【train】 epoch：3 step:9556/14065 loss：0.019435
【train】 epoch：3 step:9557/14065 loss：0.093808
【train】 epoch：3 step:9558/14065 loss：0.131177
【train】 epoch：3 step:9559/14065 loss：0.074695
【train】 epoch：3 step:9560/14065 loss：0.092238
【train】 epoch：3 step:9561/14065 loss：0.057492
【train】 epoch：3 step:9562/14065 loss：0.097424
【train】 epoch：3 step:9563/14065 loss：0.159873
【train】 epoch：3 step:9564/14065 loss：0.076205
【train】 epoch：3 step:9565/14065 loss：0.072205
【train】 epoch：3 step:9566/14065 loss：0.012786
【train】 epoch：3 step:9567/14065 loss：0.132861
【train】 epoch：3 step:9568/14065 loss：0.095232
【train】 epoch：3 step:9569/14065 loss：0.092528
【train】 epoch：3 step:9570/14065 loss：0.029811
【train】 epoch：3 step:9571/14065 loss：0.118896
【train】 epoch：3 step:9572/14065 loss：0.014015
【train】 epoch：3 step:9573/14065 loss：0.027517
【train】 epoch：3 step:9574/14065 loss：0.022802
【train】 epoch：3 step:9575/14065 loss：0.043448
【train】 epoch：3 step:9576/14065 loss：0.109367
【train】 epoch：3 step:9577/14065 loss：0.105741
【train】 epoch：3 step:9578/14065 loss：0.262605
【train】 epoch：3 step:9579/14065 loss：0.203591
【train】 epoch：3 step:9580/14065 loss：0.055561
【train】 epoch：3 step:9581/14065 loss：0.072043
【train】 epoch：3 step:9582/14065 loss：0.023552
【train】 epoch：3 step:9583/14065 loss：0.029054
【train】 epoch：3 step:9584/14065 loss：0.059434
【train】 epoch：3 step:9585/14065 loss：0.097265
【train】 epoch：3 step:9586/14065 loss：0.109417
【train】 epoch：3 step:9587/14065 loss：0.017326
【train】 epoch：3 step:9588/14065 loss：0.085892
【train】 epoch：3 step:9589/14065 loss：0.018380
【train】 epoch：3 step:9590/14065 loss：0.038554
【train】 epoch：3 step:9591/14065 loss：0.029211
【train】 epoch：3 step:9592/14065 loss：0.040857
【train】 epoch：3 step:9593/14065 loss：0.091849
【train】 epoch：3 step:9594/14065 loss：0.099354
【train】 epoch：3 step:9595/14065 loss：0.049501
【train】 epoch：3 step:9596/14065 loss：0.040467
【train】 epoch：3 step:9597/14065 loss：0.068971
【train】 epoch：3 step:9598/14065 loss：0.109997
【train】 epoch：3 step:9599/14065 loss：0.024644
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：113.533119 accuracy：0.9872 precision：0.9872 recall：0.9872 f1：0.9872
------------>保存当前最好的模型
【train】 epoch：3 step:9600/14065 loss：0.020614
【train】 epoch：3 step:9601/14065 loss：0.075026
【train】 epoch：3 step:9602/14065 loss：0.094386
【train】 epoch：3 step:9603/14065 loss：0.010058
【train】 epoch：3 step:9604/14065 loss：0.120025
【train】 epoch：3 step:9605/14065 loss：0.070951
【train】 epoch：3 step:9606/14065 loss：0.046039
【train】 epoch：3 step:9607/14065 loss：0.137740
【train】 epoch：3 step:9608/14065 loss：0.092107
【train】 epoch：3 step:9609/14065 loss：0.045047
【train】 epoch：3 step:9610/14065 loss：0.078691
【train】 epoch：3 step:9611/14065 loss：0.037125
【train】 epoch：3 step:9612/14065 loss：0.023624
【train】 epoch：3 step:9613/14065 loss：0.094034
【train】 epoch：3 step:9614/14065 loss：0.042865
【train】 epoch：3 step:9615/14065 loss：0.030036
【train】 epoch：3 step:9616/14065 loss：0.103775
【train】 epoch：3 step:9617/14065 loss：0.011001
【train】 epoch：3 step:9618/14065 loss：0.090282
【train】 epoch：3 step:9619/14065 loss：0.020460
【train】 epoch：3 step:9620/14065 loss：0.102934
【train】 epoch：3 step:9621/14065 loss：0.034314
【train】 epoch：3 step:9622/14065 loss：0.061986
【train】 epoch：3 step:9623/14065 loss：0.088774
【train】 epoch：3 step:9624/14065 loss：0.095999
【train】 epoch：3 step:9625/14065 loss：0.027251
【train】 epoch：3 step:9626/14065 loss：0.173409
【train】 epoch：3 step:9627/14065 loss：0.047096
【train】 epoch：3 step:9628/14065 loss：0.114372
【train】 epoch：3 step:9629/14065 loss：0.130285
【train】 epoch：3 step:9630/14065 loss：0.007574
【train】 epoch：3 step:9631/14065 loss：0.049554
【train】 epoch：3 step:9632/14065 loss：0.084303
【train】 epoch：3 step:9633/14065 loss：0.058608
【train】 epoch：3 step:9634/14065 loss：0.109619
【train】 epoch：3 step:9635/14065 loss：0.030135
【train】 epoch：3 step:9636/14065 loss：0.040603
【train】 epoch：3 step:9637/14065 loss：0.105871
【train】 epoch：3 step:9638/14065 loss：0.129043
【train】 epoch：3 step:9639/14065 loss：0.036931
【train】 epoch：3 step:9640/14065 loss：0.032464
【train】 epoch：3 step:9641/14065 loss：0.011510
【train】 epoch：3 step:9642/14065 loss：0.030273
【train】 epoch：3 step:9643/14065 loss：0.061890
【train】 epoch：3 step:9644/14065 loss：0.141239
【train】 epoch：3 step:9645/14065 loss：0.121239
【train】 epoch：3 step:9646/14065 loss：0.178187
【train】 epoch：3 step:9647/14065 loss：0.015999
【train】 epoch：3 step:9648/14065 loss：0.071880
【train】 epoch：3 step:9649/14065 loss：0.028770
【train】 epoch：3 step:9650/14065 loss：0.013306
【train】 epoch：3 step:9651/14065 loss：0.061495
【train】 epoch：3 step:9652/14065 loss：0.063124
【train】 epoch：3 step:9653/14065 loss：0.126579
【train】 epoch：3 step:9654/14065 loss：0.094032
【train】 epoch：3 step:9655/14065 loss：0.129657
【train】 epoch：3 step:9656/14065 loss：0.056379
【train】 epoch：3 step:9657/14065 loss：0.066563
【train】 epoch：3 step:9658/14065 loss：0.045303
【train】 epoch：3 step:9659/14065 loss：0.055208
【train】 epoch：3 step:9660/14065 loss：0.041235
【train】 epoch：3 step:9661/14065 loss：0.123625
【train】 epoch：3 step:9662/14065 loss：0.065065
【train】 epoch：3 step:9663/14065 loss：0.044206
【train】 epoch：3 step:9664/14065 loss：0.021489
【train】 epoch：3 step:9665/14065 loss：0.074034
【train】 epoch：3 step:9666/14065 loss：0.028137
【train】 epoch：3 step:9667/14065 loss：0.139901
【train】 epoch：3 step:9668/14065 loss：0.076566
【train】 epoch：3 step:9669/14065 loss：0.286279
【train】 epoch：3 step:9670/14065 loss：0.130523
【train】 epoch：3 step:9671/14065 loss：0.055219
【train】 epoch：3 step:9672/14065 loss：0.059925
【train】 epoch：3 step:9673/14065 loss：0.081660
【train】 epoch：3 step:9674/14065 loss：0.066561
【train】 epoch：3 step:9675/14065 loss：0.033559
【train】 epoch：3 step:9676/14065 loss：0.093780
【train】 epoch：3 step:9677/14065 loss：0.009895
【train】 epoch：3 step:9678/14065 loss：0.030471
【train】 epoch：3 step:9679/14065 loss：0.111816
【train】 epoch：3 step:9680/14065 loss：0.042655
【train】 epoch：3 step:9681/14065 loss：0.036767
【train】 epoch：3 step:9682/14065 loss：0.025036
【train】 epoch：3 step:9683/14065 loss：0.061448
【train】 epoch：3 step:9684/14065 loss：0.021349
【train】 epoch：3 step:9685/14065 loss：0.018657
【train】 epoch：3 step:9686/14065 loss：0.178790
【train】 epoch：3 step:9687/14065 loss：0.010170
【train】 epoch：3 step:9688/14065 loss：0.023035
【train】 epoch：3 step:9689/14065 loss：0.112337
【train】 epoch：3 step:9690/14065 loss：0.009506
【train】 epoch：3 step:9691/14065 loss：0.032170
【train】 epoch：3 step:9692/14065 loss：0.010960
【train】 epoch：3 step:9693/14065 loss：0.130566
【train】 epoch：3 step:9694/14065 loss：0.107065
【train】 epoch：3 step:9695/14065 loss：0.030612
【train】 epoch：3 step:9696/14065 loss：0.235412
【train】 epoch：3 step:9697/14065 loss：0.014599
【train】 epoch：3 step:9698/14065 loss：0.086882
【train】 epoch：3 step:9699/14065 loss：0.092714
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：104.877119 accuracy：0.9887 precision：0.9887 recall：0.9887 f1：0.9887
------------>保存当前最好的模型
【train】 epoch：3 step:9700/14065 loss：0.149084
【train】 epoch：3 step:9701/14065 loss：0.093945
【train】 epoch：3 step:9702/14065 loss：0.062317
【train】 epoch：3 step:9703/14065 loss：0.023179
【train】 epoch：3 step:9704/14065 loss：0.149585
【train】 epoch：3 step:9705/14065 loss：0.051013
【train】 epoch：3 step:9706/14065 loss：0.069737
【train】 epoch：3 step:9707/14065 loss：0.085305
【train】 epoch：3 step:9708/14065 loss：0.040362
【train】 epoch：3 step:9709/14065 loss：0.015458
【train】 epoch：3 step:9710/14065 loss：0.067348
【train】 epoch：3 step:9711/14065 loss：0.041578
【train】 epoch：3 step:9712/14065 loss：0.104073
【train】 epoch：3 step:9713/14065 loss：0.053170
【train】 epoch：3 step:9714/14065 loss：0.114520
【train】 epoch：3 step:9715/14065 loss：0.094041
【train】 epoch：3 step:9716/14065 loss：0.186954
【train】 epoch：3 step:9717/14065 loss：0.016954
【train】 epoch：3 step:9718/14065 loss：0.019596
【train】 epoch：3 step:9719/14065 loss：0.094608
【train】 epoch：3 step:9720/14065 loss：0.222678
【train】 epoch：3 step:9721/14065 loss：0.048077
【train】 epoch：3 step:9722/14065 loss：0.009814
【train】 epoch：3 step:9723/14065 loss：0.057001
【train】 epoch：3 step:9724/14065 loss：0.007431
【train】 epoch：3 step:9725/14065 loss：0.072033
【train】 epoch：3 step:9726/14065 loss：0.111135
【train】 epoch：3 step:9727/14065 loss：0.070451
【train】 epoch：3 step:9728/14065 loss：0.053844
【train】 epoch：3 step:9729/14065 loss：0.048335
【train】 epoch：3 step:9730/14065 loss：0.028762
【train】 epoch：3 step:9731/14065 loss：0.044901
【train】 epoch：3 step:9732/14065 loss：0.026973
【train】 epoch：3 step:9733/14065 loss：0.076139
【train】 epoch：3 step:9734/14065 loss：0.087290
【train】 epoch：3 step:9735/14065 loss：0.114508
【train】 epoch：3 step:9736/14065 loss：0.012287
【train】 epoch：3 step:9737/14065 loss：0.062597
【train】 epoch：3 step:9738/14065 loss：0.009129
【train】 epoch：3 step:9739/14065 loss：0.046786
【train】 epoch：3 step:9740/14065 loss：0.031195
【train】 epoch：3 step:9741/14065 loss：0.048651
【train】 epoch：3 step:9742/14065 loss：0.201677
【train】 epoch：3 step:9743/14065 loss：0.084489
【train】 epoch：3 step:9744/14065 loss：0.054693
【train】 epoch：3 step:9745/14065 loss：0.059800
【train】 epoch：3 step:9746/14065 loss：0.092601
【train】 epoch：3 step:9747/14065 loss：0.099629
【train】 epoch：3 step:9748/14065 loss：0.010240
【train】 epoch：3 step:9749/14065 loss：0.030264
【train】 epoch：3 step:9750/14065 loss：0.040657
【train】 epoch：3 step:9751/14065 loss：0.034249
【train】 epoch：3 step:9752/14065 loss：0.023598
【train】 epoch：3 step:9753/14065 loss：0.046568
【train】 epoch：3 step:9754/14065 loss：0.068373
【train】 epoch：3 step:9755/14065 loss：0.024634
【train】 epoch：3 step:9756/14065 loss：0.028992
【train】 epoch：3 step:9757/14065 loss：0.100182
【train】 epoch：3 step:9758/14065 loss：0.097817
【train】 epoch：3 step:9759/14065 loss：0.049478
【train】 epoch：3 step:9760/14065 loss：0.131951
【train】 epoch：3 step:9761/14065 loss：0.057862
【train】 epoch：3 step:9762/14065 loss：0.034821
【train】 epoch：3 step:9763/14065 loss：0.010704
【train】 epoch：3 step:9764/14065 loss：0.153361
【train】 epoch：3 step:9765/14065 loss：0.144899
【train】 epoch：3 step:9766/14065 loss：0.061812
【train】 epoch：3 step:9767/14065 loss：0.016172
【train】 epoch：3 step:9768/14065 loss：0.110197
【train】 epoch：3 step:9769/14065 loss：0.011903
【train】 epoch：3 step:9770/14065 loss：0.117386
【train】 epoch：3 step:9771/14065 loss：0.048127
【train】 epoch：3 step:9772/14065 loss：0.053314
【train】 epoch：3 step:9773/14065 loss：0.018508
【train】 epoch：3 step:9774/14065 loss：0.005098
【train】 epoch：3 step:9775/14065 loss：0.075909
【train】 epoch：3 step:9776/14065 loss：0.166186
【train】 epoch：3 step:9777/14065 loss：0.037608
【train】 epoch：3 step:9778/14065 loss：0.040467
【train】 epoch：3 step:9779/14065 loss：0.083045
【train】 epoch：3 step:9780/14065 loss：0.089862
【train】 epoch：3 step:9781/14065 loss：0.078713
【train】 epoch：3 step:9782/14065 loss：0.137696
【train】 epoch：3 step:9783/14065 loss：0.022329
【train】 epoch：3 step:9784/14065 loss：0.144248
【train】 epoch：3 step:9785/14065 loss：0.132138
【train】 epoch：3 step:9786/14065 loss：0.087114
【train】 epoch：3 step:9787/14065 loss：0.147367
【train】 epoch：3 step:9788/14065 loss：0.025565
【train】 epoch：3 step:9789/14065 loss：0.029077
【train】 epoch：3 step:9790/14065 loss：0.063072
【train】 epoch：3 step:9791/14065 loss：0.092337
【train】 epoch：3 step:9792/14065 loss：0.174292
【train】 epoch：3 step:9793/14065 loss：0.052045
【train】 epoch：3 step:9794/14065 loss：0.068122
【train】 epoch：3 step:9795/14065 loss：0.010385
【train】 epoch：3 step:9796/14065 loss：0.038912
【train】 epoch：3 step:9797/14065 loss：0.039563
【train】 epoch：3 step:9798/14065 loss：0.171835
【train】 epoch：3 step:9799/14065 loss：0.027090
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：106.284471 accuracy：0.9884 precision：0.9884 recall：0.9884 f1：0.9884
【train】 epoch：3 step:9800/14065 loss：0.180550
【train】 epoch：3 step:9801/14065 loss：0.007766
【train】 epoch：3 step:9802/14065 loss：0.009028
【train】 epoch：3 step:9803/14065 loss：0.070981
【train】 epoch：3 step:9804/14065 loss：0.025603
【train】 epoch：3 step:9805/14065 loss：0.103638
【train】 epoch：3 step:9806/14065 loss：0.072550
【train】 epoch：3 step:9807/14065 loss：0.044526
【train】 epoch：3 step:9808/14065 loss：0.072816
【train】 epoch：3 step:9809/14065 loss：0.084635
【train】 epoch：3 step:9810/14065 loss：0.163441
【train】 epoch：3 step:9811/14065 loss：0.086191
【train】 epoch：3 step:9812/14065 loss：0.010010
【train】 epoch：3 step:9813/14065 loss：0.052761
【train】 epoch：3 step:9814/14065 loss：0.043536
【train】 epoch：3 step:9815/14065 loss：0.063457
【train】 epoch：3 step:9816/14065 loss：0.108065
【train】 epoch：3 step:9817/14065 loss：0.064338
【train】 epoch：3 step:9818/14065 loss：0.106064
【train】 epoch：3 step:9819/14065 loss：0.015298
【train】 epoch：3 step:9820/14065 loss：0.154911
【train】 epoch：3 step:9821/14065 loss：0.082766
【train】 epoch：3 step:9822/14065 loss：0.013512
【train】 epoch：3 step:9823/14065 loss：0.084821
【train】 epoch：3 step:9824/14065 loss：0.024350
【train】 epoch：3 step:9825/14065 loss：0.023436
【train】 epoch：3 step:9826/14065 loss：0.041686
【train】 epoch：3 step:9827/14065 loss：0.059856
【train】 epoch：3 step:9828/14065 loss：0.007595
【train】 epoch：3 step:9829/14065 loss：0.016797
【train】 epoch：3 step:9830/14065 loss：0.043843
【train】 epoch：3 step:9831/14065 loss：0.037688
【train】 epoch：3 step:9832/14065 loss：0.093208
【train】 epoch：3 step:9833/14065 loss：0.074810
【train】 epoch：3 step:9834/14065 loss：0.103338
【train】 epoch：3 step:9835/14065 loss：0.058633
【train】 epoch：3 step:9836/14065 loss：0.056301
【train】 epoch：3 step:9837/14065 loss：0.162357
【train】 epoch：3 step:9838/14065 loss：0.069248
【train】 epoch：3 step:9839/14065 loss：0.048751
【train】 epoch：3 step:9840/14065 loss：0.067008
【train】 epoch：3 step:9841/14065 loss：0.094777
【train】 epoch：3 step:9842/14065 loss：0.067073
【train】 epoch：3 step:9843/14065 loss：0.128112
【train】 epoch：3 step:9844/14065 loss：0.019516
【train】 epoch：3 step:9845/14065 loss：0.055855
【train】 epoch：3 step:9846/14065 loss：0.058279
【train】 epoch：3 step:9847/14065 loss：0.162826
【train】 epoch：3 step:9848/14065 loss：0.029916
【train】 epoch：3 step:9849/14065 loss：0.042352
【train】 epoch：3 step:9850/14065 loss：0.063349
【train】 epoch：3 step:9851/14065 loss：0.032831
【train】 epoch：3 step:9852/14065 loss：0.049308
【train】 epoch：3 step:9853/14065 loss：0.104623
【train】 epoch：3 step:9854/14065 loss：0.010454
【train】 epoch：3 step:9855/14065 loss：0.230195
【train】 epoch：3 step:9856/14065 loss：0.012187
【train】 epoch：3 step:9857/14065 loss：0.053096
【train】 epoch：3 step:9858/14065 loss：0.021764
【train】 epoch：3 step:9859/14065 loss：0.088077
【train】 epoch：3 step:9860/14065 loss：0.068968
【train】 epoch：3 step:9861/14065 loss：0.192466
【train】 epoch：3 step:9862/14065 loss：0.103388
【train】 epoch：3 step:9863/14065 loss：0.097965
【train】 epoch：3 step:9864/14065 loss：0.135473
【train】 epoch：3 step:9865/14065 loss：0.216486
【train】 epoch：3 step:9866/14065 loss：0.125587
【train】 epoch：3 step:9867/14065 loss：0.017616
【train】 epoch：3 step:9868/14065 loss：0.031201
【train】 epoch：3 step:9869/14065 loss：0.036523
【train】 epoch：3 step:9870/14065 loss：0.066530
【train】 epoch：3 step:9871/14065 loss：0.050855
【train】 epoch：3 step:9872/14065 loss：0.026037
【train】 epoch：3 step:9873/14065 loss：0.046460
【train】 epoch：3 step:9874/14065 loss：0.112586
【train】 epoch：3 step:9875/14065 loss：0.082040
【train】 epoch：3 step:9876/14065 loss：0.056634
【train】 epoch：3 step:9877/14065 loss：0.035500
【train】 epoch：3 step:9878/14065 loss：0.181622
【train】 epoch：3 step:9879/14065 loss：0.006863
【train】 epoch：3 step:9880/14065 loss：0.014667
【train】 epoch：3 step:9881/14065 loss：0.182303
【train】 epoch：3 step:9882/14065 loss：0.089948
【train】 epoch：3 step:9883/14065 loss：0.049485
【train】 epoch：3 step:9884/14065 loss：0.092491
【train】 epoch：3 step:9885/14065 loss：0.106863
【train】 epoch：3 step:9886/14065 loss：0.024494
【train】 epoch：3 step:9887/14065 loss：0.034740
【train】 epoch：3 step:9888/14065 loss：0.047433
【train】 epoch：3 step:9889/14065 loss：0.083790
【train】 epoch：3 step:9890/14065 loss：0.093568
【train】 epoch：3 step:9891/14065 loss：0.047814
【train】 epoch：3 step:9892/14065 loss：0.195555
【train】 epoch：3 step:9893/14065 loss：0.067649
【train】 epoch：3 step:9894/14065 loss：0.122072
【train】 epoch：3 step:9895/14065 loss：0.020049
【train】 epoch：3 step:9896/14065 loss：0.043426
【train】 epoch：3 step:9897/14065 loss：0.031948
【train】 epoch：3 step:9898/14065 loss：0.057932
【train】 epoch：3 step:9899/14065 loss：0.031810
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：107.454090 accuracy：0.9882 precision：0.9882 recall：0.9882 f1：0.9882
【train】 epoch：3 step:9900/14065 loss：0.069239
【train】 epoch：3 step:9901/14065 loss：0.098607
【train】 epoch：3 step:9902/14065 loss：0.093185
【train】 epoch：3 step:9903/14065 loss：0.048942
【train】 epoch：3 step:9904/14065 loss：0.117176
【train】 epoch：3 step:9905/14065 loss：0.119342
【train】 epoch：3 step:9906/14065 loss：0.032831
【train】 epoch：3 step:9907/14065 loss：0.032121
【train】 epoch：3 step:9908/14065 loss：0.066537
【train】 epoch：3 step:9909/14065 loss：0.005337
【train】 epoch：3 step:9910/14065 loss：0.036012
【train】 epoch：3 step:9911/14065 loss：0.022601
【train】 epoch：3 step:9912/14065 loss：0.086634
【train】 epoch：3 step:9913/14065 loss：0.038547
【train】 epoch：3 step:9914/14065 loss：0.040244
【train】 epoch：3 step:9915/14065 loss：0.055812
【train】 epoch：3 step:9916/14065 loss：0.015129
【train】 epoch：3 step:9917/14065 loss：0.038956
【train】 epoch：3 step:9918/14065 loss：0.056455
【train】 epoch：3 step:9919/14065 loss：0.018096
【train】 epoch：3 step:9920/14065 loss：0.064711
【train】 epoch：3 step:9921/14065 loss：0.049466
【train】 epoch：3 step:9922/14065 loss：0.039630
【train】 epoch：3 step:9923/14065 loss：0.045491
【train】 epoch：3 step:9924/14065 loss：0.026501
【train】 epoch：3 step:9925/14065 loss：0.051269
【train】 epoch：3 step:9926/14065 loss：0.015360
【train】 epoch：3 step:9927/14065 loss：0.038945
【train】 epoch：3 step:9928/14065 loss：0.036293
【train】 epoch：3 step:9929/14065 loss：0.014974
【train】 epoch：3 step:9930/14065 loss：0.055633
【train】 epoch：3 step:9931/14065 loss：0.069377
【train】 epoch：3 step:9932/14065 loss：0.030052
【train】 epoch：3 step:9933/14065 loss：0.174581
【train】 epoch：3 step:9934/14065 loss：0.031026
【train】 epoch：3 step:9935/14065 loss：0.033300
【train】 epoch：3 step:9936/14065 loss：0.029540
【train】 epoch：3 step:9937/14065 loss：0.016355
【train】 epoch：3 step:9938/14065 loss：0.088766
【train】 epoch：3 step:9939/14065 loss：0.120735
【train】 epoch：3 step:9940/14065 loss：0.013383
【train】 epoch：3 step:9941/14065 loss：0.063734
【train】 epoch：3 step:9942/14065 loss：0.063991
【train】 epoch：3 step:9943/14065 loss：0.075586
【train】 epoch：3 step:9944/14065 loss：0.068998
【train】 epoch：3 step:9945/14065 loss：0.091507
【train】 epoch：3 step:9946/14065 loss：0.033107
【train】 epoch：3 step:9947/14065 loss：0.197581
【train】 epoch：3 step:9948/14065 loss：0.014789
【train】 epoch：3 step:9949/14065 loss：0.060638
【train】 epoch：3 step:9950/14065 loss：0.009335
【train】 epoch：3 step:9951/14065 loss：0.017882
【train】 epoch：3 step:9952/14065 loss：0.071692
【train】 epoch：3 step:9953/14065 loss：0.079479
【train】 epoch：3 step:9954/14065 loss：0.092807
【train】 epoch：3 step:9955/14065 loss：0.014219
【train】 epoch：3 step:9956/14065 loss：0.044057
【train】 epoch：3 step:9957/14065 loss：0.208321
【train】 epoch：3 step:9958/14065 loss：0.019032
【train】 epoch：3 step:9959/14065 loss：0.062194
【train】 epoch：3 step:9960/14065 loss：0.141666
【train】 epoch：3 step:9961/14065 loss：0.069321
【train】 epoch：3 step:9962/14065 loss：0.093992
【train】 epoch：3 step:9963/14065 loss：0.107674
【train】 epoch：3 step:9964/14065 loss：0.050694
【train】 epoch：3 step:9965/14065 loss：0.094073
【train】 epoch：3 step:9966/14065 loss：0.070597
【train】 epoch：3 step:9967/14065 loss：0.142340
【train】 epoch：3 step:9968/14065 loss：0.100283
【train】 epoch：3 step:9969/14065 loss：0.059578
【train】 epoch：3 step:9970/14065 loss：0.033106
【train】 epoch：3 step:9971/14065 loss：0.028978
【train】 epoch：3 step:9972/14065 loss：0.085306
【train】 epoch：3 step:9973/14065 loss：0.055758
【train】 epoch：3 step:9974/14065 loss：0.071656
【train】 epoch：3 step:9975/14065 loss：0.088817
【train】 epoch：3 step:9976/14065 loss：0.052289
【train】 epoch：3 step:9977/14065 loss：0.132582
【train】 epoch：3 step:9978/14065 loss：0.049228
【train】 epoch：3 step:9979/14065 loss：0.025692
【train】 epoch：3 step:9980/14065 loss：0.042153
【train】 epoch：3 step:9981/14065 loss：0.151524
【train】 epoch：3 step:9982/14065 loss：0.055434
【train】 epoch：3 step:9983/14065 loss：0.105012
【train】 epoch：3 step:9984/14065 loss：0.223968
【train】 epoch：3 step:9985/14065 loss：0.057820
【train】 epoch：3 step:9986/14065 loss：0.121618
【train】 epoch：3 step:9987/14065 loss：0.099945
【train】 epoch：3 step:9988/14065 loss：0.114368
【train】 epoch：3 step:9989/14065 loss：0.045244
【train】 epoch：3 step:9990/14065 loss：0.205966
【train】 epoch：3 step:9991/14065 loss：0.064900
【train】 epoch：3 step:9992/14065 loss：0.046428
【train】 epoch：3 step:9993/14065 loss：0.060324
【train】 epoch：3 step:9994/14065 loss：0.195849
【train】 epoch：3 step:9995/14065 loss：0.043402
【train】 epoch：3 step:9996/14065 loss：0.082753
【train】 epoch：3 step:9997/14065 loss：0.057669
【train】 epoch：3 step:9998/14065 loss：0.032115
【train】 epoch：3 step:9999/14065 loss：0.047971
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：118.584962 accuracy：0.9870 precision：0.9870 recall：0.9870 f1：0.9870
【train】 epoch：3 step:10000/14065 loss：0.092049
【train】 epoch：3 step:10001/14065 loss：0.025594
【train】 epoch：3 step:10002/14065 loss：0.069596
【train】 epoch：3 step:10003/14065 loss：0.153891
【train】 epoch：3 step:10004/14065 loss：0.044720
【train】 epoch：3 step:10005/14065 loss：0.027705
【train】 epoch：3 step:10006/14065 loss：0.026641
【train】 epoch：3 step:10007/14065 loss：0.034555
【train】 epoch：3 step:10008/14065 loss：0.026665
【train】 epoch：3 step:10009/14065 loss：0.051594
【train】 epoch：3 step:10010/14065 loss：0.071300
【train】 epoch：3 step:10011/14065 loss：0.099195
【train】 epoch：3 step:10012/14065 loss：0.008822
【train】 epoch：3 step:10013/14065 loss：0.107920
【train】 epoch：3 step:10014/14065 loss：0.055272
【train】 epoch：3 step:10015/14065 loss：0.017446
【train】 epoch：3 step:10016/14065 loss：0.045695
【train】 epoch：3 step:10017/14065 loss：0.023498
【train】 epoch：3 step:10018/14065 loss：0.016330
【train】 epoch：3 step:10019/14065 loss：0.081218
【train】 epoch：3 step:10020/14065 loss：0.094914
【train】 epoch：3 step:10021/14065 loss：0.049365
【train】 epoch：3 step:10022/14065 loss：0.171099
【train】 epoch：3 step:10023/14065 loss：0.082960
【train】 epoch：3 step:10024/14065 loss：0.087370
【train】 epoch：3 step:10025/14065 loss：0.033838
【train】 epoch：3 step:10026/14065 loss：0.107828
【train】 epoch：3 step:10027/14065 loss：0.040914
【train】 epoch：3 step:10028/14065 loss：0.115033
【train】 epoch：3 step:10029/14065 loss：0.030411
【train】 epoch：3 step:10030/14065 loss：0.088170
【train】 epoch：3 step:10031/14065 loss：0.105437
【train】 epoch：3 step:10032/14065 loss：0.095855
【train】 epoch：3 step:10033/14065 loss：0.056843
【train】 epoch：3 step:10034/14065 loss：0.214932
【train】 epoch：3 step:10035/14065 loss：0.031689
【train】 epoch：3 step:10036/14065 loss：0.026028
【train】 epoch：3 step:10037/14065 loss：0.026039
【train】 epoch：3 step:10038/14065 loss：0.081076
【train】 epoch：3 step:10039/14065 loss：0.016863
【train】 epoch：3 step:10040/14065 loss：0.171575
【train】 epoch：3 step:10041/14065 loss：0.090367
【train】 epoch：3 step:10042/14065 loss：0.064649
【train】 epoch：3 step:10043/14065 loss：0.068709
【train】 epoch：3 step:10044/14065 loss：0.085837
【train】 epoch：3 step:10045/14065 loss：0.050920
【train】 epoch：3 step:10046/14065 loss：0.012476
【train】 epoch：3 step:10047/14065 loss：0.035183
【train】 epoch：3 step:10048/14065 loss：0.040849
【train】 epoch：3 step:10049/14065 loss：0.033938
【train】 epoch：3 step:10050/14065 loss：0.066905
【train】 epoch：3 step:10051/14065 loss：0.053332
【train】 epoch：3 step:10052/14065 loss：0.035993
【train】 epoch：3 step:10053/14065 loss：0.051499
【train】 epoch：3 step:10054/14065 loss：0.058048
【train】 epoch：3 step:10055/14065 loss：0.050711
【train】 epoch：3 step:10056/14065 loss：0.089021
【train】 epoch：3 step:10057/14065 loss：0.151095
【train】 epoch：3 step:10058/14065 loss：0.027499
【train】 epoch：3 step:10059/14065 loss：0.085657
【train】 epoch：3 step:10060/14065 loss：0.041993
【train】 epoch：3 step:10061/14065 loss：0.082723
【train】 epoch：3 step:10062/14065 loss：0.037086
【train】 epoch：3 step:10063/14065 loss：0.141469
【train】 epoch：3 step:10064/14065 loss：0.004719
【train】 epoch：3 step:10065/14065 loss：0.028906
【train】 epoch：3 step:10066/14065 loss：0.092334
【train】 epoch：3 step:10067/14065 loss：0.039292
【train】 epoch：3 step:10068/14065 loss：0.042794
【train】 epoch：3 step:10069/14065 loss：0.029843
【train】 epoch：3 step:10070/14065 loss：0.065585
【train】 epoch：3 step:10071/14065 loss：0.004090
【train】 epoch：3 step:10072/14065 loss：0.051905
【train】 epoch：3 step:10073/14065 loss：0.004551
【train】 epoch：3 step:10074/14065 loss：0.096790
【train】 epoch：3 step:10075/14065 loss：0.059433
【train】 epoch：3 step:10076/14065 loss：0.031809
【train】 epoch：3 step:10077/14065 loss：0.140296
【train】 epoch：3 step:10078/14065 loss：0.076613
【train】 epoch：3 step:10079/14065 loss：0.167522
【train】 epoch：3 step:10080/14065 loss：0.059696
【train】 epoch：3 step:10081/14065 loss：0.023325
【train】 epoch：3 step:10082/14065 loss：0.056026
【train】 epoch：3 step:10083/14065 loss：0.029789
【train】 epoch：3 step:10084/14065 loss：0.046613
【train】 epoch：3 step:10085/14065 loss：0.019659
【train】 epoch：3 step:10086/14065 loss：0.031585
【train】 epoch：3 step:10087/14065 loss：0.047941
【train】 epoch：3 step:10088/14065 loss：0.187965
【train】 epoch：3 step:10089/14065 loss：0.063480
【train】 epoch：3 step:10090/14065 loss：0.045743
【train】 epoch：3 step:10091/14065 loss：0.035336
【train】 epoch：3 step:10092/14065 loss：0.071138
【train】 epoch：3 step:10093/14065 loss：0.016378
【train】 epoch：3 step:10094/14065 loss：0.059167
【train】 epoch：3 step:10095/14065 loss：0.136279
【train】 epoch：3 step:10096/14065 loss：0.166507
【train】 epoch：3 step:10097/14065 loss：0.090692
【train】 epoch：3 step:10098/14065 loss：0.062749
【train】 epoch：3 step:10099/14065 loss：0.035193
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：105.923785 accuracy：0.9877 precision：0.9877 recall：0.9877 f1：0.9877
【train】 epoch：3 step:10100/14065 loss：0.040970
【train】 epoch：3 step:10101/14065 loss：0.028947
【train】 epoch：3 step:10102/14065 loss：0.119488
【train】 epoch：3 step:10103/14065 loss：0.092792
【train】 epoch：3 step:10104/14065 loss：0.027914
【train】 epoch：3 step:10105/14065 loss：0.080206
【train】 epoch：3 step:10106/14065 loss：0.087372
【train】 epoch：3 step:10107/14065 loss：0.020750
【train】 epoch：3 step:10108/14065 loss：0.075457
【train】 epoch：3 step:10109/14065 loss：0.100556
【train】 epoch：3 step:10110/14065 loss：0.078496
【train】 epoch：3 step:10111/14065 loss：0.016877
【train】 epoch：3 step:10112/14065 loss：0.097514
【train】 epoch：3 step:10113/14065 loss：0.026293
【train】 epoch：3 step:10114/14065 loss：0.036084
【train】 epoch：3 step:10115/14065 loss：0.038232
【train】 epoch：3 step:10116/14065 loss：0.035230
【train】 epoch：3 step:10117/14065 loss：0.022498
【train】 epoch：3 step:10118/14065 loss：0.067489
【train】 epoch：3 step:10119/14065 loss：0.036301
【train】 epoch：3 step:10120/14065 loss：0.057139
【train】 epoch：3 step:10121/14065 loss：0.138202
【train】 epoch：3 step:10122/14065 loss：0.010239
【train】 epoch：3 step:10123/14065 loss：0.071357
【train】 epoch：3 step:10124/14065 loss：0.006549
【train】 epoch：3 step:10125/14065 loss：0.043541
【train】 epoch：3 step:10126/14065 loss：0.081090
【train】 epoch：3 step:10127/14065 loss：0.012531
【train】 epoch：3 step:10128/14065 loss：0.181543
【train】 epoch：3 step:10129/14065 loss：0.081583
【train】 epoch：3 step:10130/14065 loss：0.011201
【train】 epoch：3 step:10131/14065 loss：0.006350
【train】 epoch：3 step:10132/14065 loss：0.038345
【train】 epoch：3 step:10133/14065 loss：0.073962
【train】 epoch：3 step:10134/14065 loss：0.037713
【train】 epoch：3 step:10135/14065 loss：0.017574
【train】 epoch：3 step:10136/14065 loss：0.045654
【train】 epoch：3 step:10137/14065 loss：0.255056
【train】 epoch：3 step:10138/14065 loss：0.007370
【train】 epoch：3 step:10139/14065 loss：0.044174
【train】 epoch：3 step:10140/14065 loss：0.011975
【train】 epoch：3 step:10141/14065 loss：0.082751
【train】 epoch：3 step:10142/14065 loss：0.014558
【train】 epoch：3 step:10143/14065 loss：0.118201
【train】 epoch：3 step:10144/14065 loss：0.010136
【train】 epoch：3 step:10145/14065 loss：0.049276
【train】 epoch：3 step:10146/14065 loss：0.089788
【train】 epoch：3 step:10147/14065 loss：0.185026
【train】 epoch：3 step:10148/14065 loss：0.041185
【train】 epoch：3 step:10149/14065 loss：0.005473
【train】 epoch：3 step:10150/14065 loss：0.054038
【train】 epoch：3 step:10151/14065 loss：0.052781
【train】 epoch：3 step:10152/14065 loss：0.009604
【train】 epoch：3 step:10153/14065 loss：0.029187
【train】 epoch：3 step:10154/14065 loss：0.105627
【train】 epoch：3 step:10155/14065 loss：0.089566
【train】 epoch：3 step:10156/14065 loss：0.058504
【train】 epoch：3 step:10157/14065 loss：0.036982
【train】 epoch：3 step:10158/14065 loss：0.014776
【train】 epoch：3 step:10159/14065 loss：0.110801
【train】 epoch：3 step:10160/14065 loss：0.079005
【train】 epoch：3 step:10161/14065 loss：0.137928
【train】 epoch：3 step:10162/14065 loss：0.053923
【train】 epoch：3 step:10163/14065 loss：0.053103
【train】 epoch：3 step:10164/14065 loss：0.211115
【train】 epoch：3 step:10165/14065 loss：0.033587
【train】 epoch：3 step:10166/14065 loss：0.125563
【train】 epoch：3 step:10167/14065 loss：0.062413
【train】 epoch：3 step:10168/14065 loss：0.018750
【train】 epoch：3 step:10169/14065 loss：0.071643
【train】 epoch：3 step:10170/14065 loss：0.049662
【train】 epoch：3 step:10171/14065 loss：0.028334
【train】 epoch：3 step:10172/14065 loss：0.015654
【train】 epoch：3 step:10173/14065 loss：0.166779
【train】 epoch：3 step:10174/14065 loss：0.109337
【train】 epoch：3 step:10175/14065 loss：0.017871
【train】 epoch：3 step:10176/14065 loss：0.108039
【train】 epoch：3 step:10177/14065 loss：0.094941
【train】 epoch：3 step:10178/14065 loss：0.031934
【train】 epoch：3 step:10179/14065 loss：0.019932
【train】 epoch：3 step:10180/14065 loss：0.042494
【train】 epoch：3 step:10181/14065 loss：0.152567
【train】 epoch：3 step:10182/14065 loss：0.198564
【train】 epoch：3 step:10183/14065 loss：0.098547
【train】 epoch：3 step:10184/14065 loss：0.097766
【train】 epoch：3 step:10185/14065 loss：0.048812
【train】 epoch：3 step:10186/14065 loss：0.020275
【train】 epoch：3 step:10187/14065 loss：0.032674
【train】 epoch：3 step:10188/14065 loss：0.021046
【train】 epoch：3 step:10189/14065 loss：0.104786
【train】 epoch：3 step:10190/14065 loss：0.048758
【train】 epoch：3 step:10191/14065 loss：0.055995
【train】 epoch：3 step:10192/14065 loss：0.122917
【train】 epoch：3 step:10193/14065 loss：0.039553
【train】 epoch：3 step:10194/14065 loss：0.029098
【train】 epoch：3 step:10195/14065 loss：0.028942
【train】 epoch：3 step:10196/14065 loss：0.150376
【train】 epoch：3 step:10197/14065 loss：0.017400
【train】 epoch：3 step:10198/14065 loss：0.142153
【train】 epoch：3 step:10199/14065 loss：0.051722
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：103.502276 accuracy：0.9885 precision：0.9885 recall：0.9885 f1：0.9885
【train】 epoch：3 step:10200/14065 loss：0.044985
【train】 epoch：3 step:10201/14065 loss：0.094692
【train】 epoch：3 step:10202/14065 loss：0.121373
【train】 epoch：3 step:10203/14065 loss：0.161625
【train】 epoch：3 step:10204/14065 loss：0.081239
【train】 epoch：3 step:10205/14065 loss：0.032890
【train】 epoch：3 step:10206/14065 loss：0.096522
【train】 epoch：3 step:10207/14065 loss：0.012090
【train】 epoch：3 step:10208/14065 loss：0.156658
【train】 epoch：3 step:10209/14065 loss：0.104778
【train】 epoch：3 step:10210/14065 loss：0.027070
【train】 epoch：3 step:10211/14065 loss：0.053549
【train】 epoch：3 step:10212/14065 loss：0.051404
【train】 epoch：3 step:10213/14065 loss：0.037674
【train】 epoch：3 step:10214/14065 loss：0.031232
【train】 epoch：3 step:10215/14065 loss：0.032340
【train】 epoch：3 step:10216/14065 loss：0.011983
【train】 epoch：3 step:10217/14065 loss：0.029732
【train】 epoch：3 step:10218/14065 loss：0.028548
【train】 epoch：3 step:10219/14065 loss：0.041755
【train】 epoch：3 step:10220/14065 loss：0.043406
【train】 epoch：3 step:10221/14065 loss：0.066045
【train】 epoch：3 step:10222/14065 loss：0.038390
【train】 epoch：3 step:10223/14065 loss：0.014389
【train】 epoch：3 step:10224/14065 loss：0.110959
【train】 epoch：3 step:10225/14065 loss：0.036334
【train】 epoch：3 step:10226/14065 loss：0.098891
【train】 epoch：3 step:10227/14065 loss：0.024361
【train】 epoch：3 step:10228/14065 loss：0.064446
【train】 epoch：3 step:10229/14065 loss：0.124561
【train】 epoch：3 step:10230/14065 loss：0.052803
【train】 epoch：3 step:10231/14065 loss：0.088220
【train】 epoch：3 step:10232/14065 loss：0.089226
【train】 epoch：3 step:10233/14065 loss：0.015728
【train】 epoch：3 step:10234/14065 loss：0.055616
【train】 epoch：3 step:10235/14065 loss：0.023606
【train】 epoch：3 step:10236/14065 loss：0.074207
【train】 epoch：3 step:10237/14065 loss：0.035651
【train】 epoch：3 step:10238/14065 loss：0.049970
【train】 epoch：3 step:10239/14065 loss：0.093619
【train】 epoch：3 step:10240/14065 loss：0.160544
【train】 epoch：3 step:10241/14065 loss：0.046703
【train】 epoch：3 step:10242/14065 loss：0.071436
【train】 epoch：3 step:10243/14065 loss：0.054580
【train】 epoch：3 step:10244/14065 loss：0.027988
【train】 epoch：3 step:10245/14065 loss：0.141467
【train】 epoch：3 step:10246/14065 loss：0.007517
【train】 epoch：3 step:10247/14065 loss：0.040080
【train】 epoch：3 step:10248/14065 loss：0.047863
【train】 epoch：3 step:10249/14065 loss：0.008081
【train】 epoch：3 step:10250/14065 loss：0.125841
【train】 epoch：3 step:10251/14065 loss：0.139592
【train】 epoch：3 step:10252/14065 loss：0.038993
【train】 epoch：3 step:10253/14065 loss：0.314237
【train】 epoch：3 step:10254/14065 loss：0.037214
【train】 epoch：3 step:10255/14065 loss：0.033256
【train】 epoch：3 step:10256/14065 loss：0.045411
【train】 epoch：3 step:10257/14065 loss：0.174622
【train】 epoch：3 step:10258/14065 loss：0.072411
【train】 epoch：3 step:10259/14065 loss：0.053680
【train】 epoch：3 step:10260/14065 loss：0.055803
【train】 epoch：3 step:10261/14065 loss：0.069303
【train】 epoch：3 step:10262/14065 loss：0.052500
【train】 epoch：3 step:10263/14065 loss：0.096891
【train】 epoch：3 step:10264/14065 loss：0.077539
【train】 epoch：3 step:10265/14065 loss：0.007158
【train】 epoch：3 step:10266/14065 loss：0.037934
【train】 epoch：3 step:10267/14065 loss：0.152073
【train】 epoch：3 step:10268/14065 loss：0.022125
【train】 epoch：3 step:10269/14065 loss：0.094415
【train】 epoch：3 step:10270/14065 loss：0.020442
【train】 epoch：3 step:10271/14065 loss：0.023593
【train】 epoch：3 step:10272/14065 loss：0.178593
【train】 epoch：3 step:10273/14065 loss：0.011245
【train】 epoch：3 step:10274/14065 loss：0.068411
【train】 epoch：3 step:10275/14065 loss：0.167320
【train】 epoch：3 step:10276/14065 loss：0.126285
【train】 epoch：3 step:10277/14065 loss：0.027512
【train】 epoch：3 step:10278/14065 loss：0.045774
【train】 epoch：3 step:10279/14065 loss：0.006370
【train】 epoch：3 step:10280/14065 loss：0.099699
【train】 epoch：3 step:10281/14065 loss：0.074152
【train】 epoch：3 step:10282/14065 loss：0.036421
【train】 epoch：3 step:10283/14065 loss：0.069223
【train】 epoch：3 step:10284/14065 loss：0.057153
【train】 epoch：3 step:10285/14065 loss：0.070880
【train】 epoch：3 step:10286/14065 loss：0.005469
【train】 epoch：3 step:10287/14065 loss：0.020520
【train】 epoch：3 step:10288/14065 loss：0.048031
【train】 epoch：3 step:10289/14065 loss：0.050827
【train】 epoch：3 step:10290/14065 loss：0.032664
【train】 epoch：3 step:10291/14065 loss：0.036505
【train】 epoch：3 step:10292/14065 loss：0.007487
【train】 epoch：3 step:10293/14065 loss：0.050931
【train】 epoch：3 step:10294/14065 loss：0.027156
【train】 epoch：3 step:10295/14065 loss：0.030019
【train】 epoch：3 step:10296/14065 loss：0.045733
【train】 epoch：3 step:10297/14065 loss：0.026032
【train】 epoch：3 step:10298/14065 loss：0.075022
【train】 epoch：3 step:10299/14065 loss：0.032506
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：111.500145 accuracy：0.9870 precision：0.9870 recall：0.9870 f1：0.9870
【train】 epoch：3 step:10300/14065 loss：0.080925
【train】 epoch：3 step:10301/14065 loss：0.053962
【train】 epoch：3 step:10302/14065 loss：0.071948
【train】 epoch：3 step:10303/14065 loss：0.059004
【train】 epoch：3 step:10304/14065 loss：0.040556
【train】 epoch：3 step:10305/14065 loss：0.046659
【train】 epoch：3 step:10306/14065 loss：0.120280
【train】 epoch：3 step:10307/14065 loss：0.065739
【train】 epoch：3 step:10308/14065 loss：0.086703
【train】 epoch：3 step:10309/14065 loss：0.063859
【train】 epoch：3 step:10310/14065 loss：0.003195
【train】 epoch：3 step:10311/14065 loss：0.108403
【train】 epoch：3 step:10312/14065 loss：0.026077
【train】 epoch：3 step:10313/14065 loss：0.073231
【train】 epoch：3 step:10314/14065 loss：0.034859
【train】 epoch：3 step:10315/14065 loss：0.033513
【train】 epoch：3 step:10316/14065 loss：0.034785
【train】 epoch：3 step:10317/14065 loss：0.016644
【train】 epoch：3 step:10318/14065 loss：0.149939
【train】 epoch：3 step:10319/14065 loss：0.086046
【train】 epoch：3 step:10320/14065 loss：0.049209
【train】 epoch：3 step:10321/14065 loss：0.057056
【train】 epoch：3 step:10322/14065 loss：0.022303
【train】 epoch：3 step:10323/14065 loss：0.037473
【train】 epoch：3 step:10324/14065 loss：0.176162
【train】 epoch：3 step:10325/14065 loss：0.092576
【train】 epoch：3 step:10326/14065 loss：0.154111
【train】 epoch：3 step:10327/14065 loss：0.063884
【train】 epoch：3 step:10328/14065 loss：0.114273
【train】 epoch：3 step:10329/14065 loss：0.099135
【train】 epoch：3 step:10330/14065 loss：0.127420
【train】 epoch：3 step:10331/14065 loss：0.151063
【train】 epoch：3 step:10332/14065 loss：0.070235
【train】 epoch：3 step:10333/14065 loss：0.062291
【train】 epoch：3 step:10334/14065 loss：0.153971
【train】 epoch：3 step:10335/14065 loss：0.036545
【train】 epoch：3 step:10336/14065 loss：0.014607
【train】 epoch：3 step:10337/14065 loss：0.072394
【train】 epoch：3 step:10338/14065 loss：0.069274
【train】 epoch：3 step:10339/14065 loss：0.020244
【train】 epoch：3 step:10340/14065 loss：0.071510
【train】 epoch：3 step:10341/14065 loss：0.017532
【train】 epoch：3 step:10342/14065 loss：0.022851
【train】 epoch：3 step:10343/14065 loss：0.038249
【train】 epoch：3 step:10344/14065 loss：0.145864
【train】 epoch：3 step:10345/14065 loss：0.018569
【train】 epoch：3 step:10346/14065 loss：0.027666
【train】 epoch：3 step:10347/14065 loss：0.136064
【train】 epoch：3 step:10348/14065 loss：0.190284
【train】 epoch：3 step:10349/14065 loss：0.269174
【train】 epoch：3 step:10350/14065 loss：0.082544
【train】 epoch：3 step:10351/14065 loss：0.065033
【train】 epoch：3 step:10352/14065 loss：0.051596
【train】 epoch：3 step:10353/14065 loss：0.063010
【train】 epoch：3 step:10354/14065 loss：0.015048
【train】 epoch：3 step:10355/14065 loss：0.193692
【train】 epoch：3 step:10356/14065 loss：0.091079
【train】 epoch：3 step:10357/14065 loss：0.029834
【train】 epoch：3 step:10358/14065 loss：0.021719
【train】 epoch：3 step:10359/14065 loss：0.146159
【train】 epoch：3 step:10360/14065 loss：0.071378
【train】 epoch：3 step:10361/14065 loss：0.047378
【train】 epoch：3 step:10362/14065 loss：0.072624
【train】 epoch：3 step:10363/14065 loss：0.089852
【train】 epoch：3 step:10364/14065 loss：0.004810
【train】 epoch：3 step:10365/14065 loss：0.109640
【train】 epoch：3 step:10366/14065 loss：0.083132
【train】 epoch：3 step:10367/14065 loss：0.238552
【train】 epoch：3 step:10368/14065 loss：0.118568
【train】 epoch：3 step:10369/14065 loss：0.028687
【train】 epoch：3 step:10370/14065 loss：0.197789
【train】 epoch：3 step:10371/14065 loss：0.101029
【train】 epoch：3 step:10372/14065 loss：0.059251
【train】 epoch：3 step:10373/14065 loss：0.064365
【train】 epoch：3 step:10374/14065 loss：0.077919
【train】 epoch：3 step:10375/14065 loss：0.060001
【train】 epoch：3 step:10376/14065 loss：0.049114
【train】 epoch：3 step:10377/14065 loss：0.079299
【train】 epoch：3 step:10378/14065 loss：0.051330
【train】 epoch：3 step:10379/14065 loss：0.020039
【train】 epoch：3 step:10380/14065 loss：0.056749
【train】 epoch：3 step:10381/14065 loss：0.094280
【train】 epoch：3 step:10382/14065 loss：0.028602
【train】 epoch：3 step:10383/14065 loss：0.046198
【train】 epoch：3 step:10384/14065 loss：0.039155
【train】 epoch：3 step:10385/14065 loss：0.057082
【train】 epoch：3 step:10386/14065 loss：0.065436
【train】 epoch：3 step:10387/14065 loss：0.087039
【train】 epoch：3 step:10388/14065 loss：0.056389
【train】 epoch：3 step:10389/14065 loss：0.079834
【train】 epoch：3 step:10390/14065 loss：0.063646
【train】 epoch：3 step:10391/14065 loss：0.133589
【train】 epoch：3 step:10392/14065 loss：0.208978
【train】 epoch：3 step:10393/14065 loss：0.023800
【train】 epoch：3 step:10394/14065 loss：0.017335
【train】 epoch：3 step:10395/14065 loss：0.084636
【train】 epoch：3 step:10396/14065 loss：0.152738
【train】 epoch：3 step:10397/14065 loss：0.006004
【train】 epoch：3 step:10398/14065 loss：0.023517
【train】 epoch：3 step:10399/14065 loss：0.038737
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：99.211065 accuracy：0.9892 precision：0.9892 recall：0.9892 f1：0.9892
------------>保存当前最好的模型
【train】 epoch：3 step:10400/14065 loss：0.033884
【train】 epoch：3 step:10401/14065 loss：0.019124
【train】 epoch：3 step:10402/14065 loss：0.010218
【train】 epoch：3 step:10403/14065 loss：0.068542
【train】 epoch：3 step:10404/14065 loss：0.026422
【train】 epoch：3 step:10405/14065 loss：0.035720
【train】 epoch：3 step:10406/14065 loss：0.015762
【train】 epoch：3 step:10407/14065 loss：0.077540
【train】 epoch：3 step:10408/14065 loss：0.139830
【train】 epoch：3 step:10409/14065 loss：0.013151
【train】 epoch：3 step:10410/14065 loss：0.017398
【train】 epoch：3 step:10411/14065 loss：0.110296
【train】 epoch：3 step:10412/14065 loss：0.041197
【train】 epoch：3 step:10413/14065 loss：0.203665
【train】 epoch：3 step:10414/14065 loss：0.038592
【train】 epoch：3 step:10415/14065 loss：0.168838
【train】 epoch：3 step:10416/14065 loss：0.072524
【train】 epoch：3 step:10417/14065 loss：0.019034
【train】 epoch：3 step:10418/14065 loss：0.073851
【train】 epoch：3 step:10419/14065 loss：0.076407
【train】 epoch：3 step:10420/14065 loss：0.067927
【train】 epoch：3 step:10421/14065 loss：0.062150
【train】 epoch：3 step:10422/14065 loss：0.028243
【train】 epoch：3 step:10423/14065 loss：0.065598
【train】 epoch：3 step:10424/14065 loss：0.042484
【train】 epoch：3 step:10425/14065 loss：0.069277
【train】 epoch：3 step:10426/14065 loss：0.021475
【train】 epoch：3 step:10427/14065 loss：0.076683
【train】 epoch：3 step:10428/14065 loss：0.074975
【train】 epoch：3 step:10429/14065 loss：0.054778
【train】 epoch：3 step:10430/14065 loss：0.034072
【train】 epoch：3 step:10431/14065 loss：0.033075
【train】 epoch：3 step:10432/14065 loss：0.106748
【train】 epoch：3 step:10433/14065 loss：0.010625
【train】 epoch：3 step:10434/14065 loss：0.059457
【train】 epoch：3 step:10435/14065 loss：0.046069
【train】 epoch：3 step:10436/14065 loss：0.094599
【train】 epoch：3 step:10437/14065 loss：0.048474
【train】 epoch：3 step:10438/14065 loss：0.069653
【train】 epoch：3 step:10439/14065 loss：0.045197
【train】 epoch：3 step:10440/14065 loss：0.164691
【train】 epoch：3 step:10441/14065 loss：0.176970
【train】 epoch：3 step:10442/14065 loss：0.236833
【train】 epoch：3 step:10443/14065 loss：0.004924
【train】 epoch：3 step:10444/14065 loss：0.048054
【train】 epoch：3 step:10445/14065 loss：0.007336
【train】 epoch：3 step:10446/14065 loss：0.018486
【train】 epoch：3 step:10447/14065 loss：0.026611
【train】 epoch：3 step:10448/14065 loss：0.097541
【train】 epoch：3 step:10449/14065 loss：0.072983
【train】 epoch：3 step:10450/14065 loss：0.049559
【train】 epoch：3 step:10451/14065 loss：0.073581
【train】 epoch：3 step:10452/14065 loss：0.030193
【train】 epoch：3 step:10453/14065 loss：0.117448
【train】 epoch：3 step:10454/14065 loss：0.056163
【train】 epoch：3 step:10455/14065 loss：0.025426
【train】 epoch：3 step:10456/14065 loss：0.105438
【train】 epoch：3 step:10457/14065 loss：0.013995
【train】 epoch：3 step:10458/14065 loss：0.034204
【train】 epoch：3 step:10459/14065 loss：0.130098
【train】 epoch：3 step:10460/14065 loss：0.033158
【train】 epoch：3 step:10461/14065 loss：0.038111
【train】 epoch：3 step:10462/14065 loss：0.125717
【train】 epoch：3 step:10463/14065 loss：0.007915
【train】 epoch：3 step:10464/14065 loss：0.046473
【train】 epoch：3 step:10465/14065 loss：0.222560
【train】 epoch：3 step:10466/14065 loss：0.168100
【train】 epoch：3 step:10467/14065 loss：0.044778
【train】 epoch：3 step:10468/14065 loss：0.009881
【train】 epoch：3 step:10469/14065 loss：0.067853
【train】 epoch：3 step:10470/14065 loss：0.169589
【train】 epoch：3 step:10471/14065 loss：0.130537
【train】 epoch：3 step:10472/14065 loss：0.201493
【train】 epoch：3 step:10473/14065 loss：0.147729
【train】 epoch：3 step:10474/14065 loss：0.055407
【train】 epoch：3 step:10475/14065 loss：0.037669
【train】 epoch：3 step:10476/14065 loss：0.162865
【train】 epoch：3 step:10477/14065 loss：0.071738
【train】 epoch：3 step:10478/14065 loss：0.058624
【train】 epoch：3 step:10479/14065 loss：0.135108
【train】 epoch：3 step:10480/14065 loss：0.041620
【train】 epoch：3 step:10481/14065 loss：0.044183
【train】 epoch：3 step:10482/14065 loss：0.061190
【train】 epoch：3 step:10483/14065 loss：0.094160
【train】 epoch：3 step:10484/14065 loss：0.034484
【train】 epoch：3 step:10485/14065 loss：0.043188
【train】 epoch：3 step:10486/14065 loss：0.107068
【train】 epoch：3 step:10487/14065 loss：0.052543
【train】 epoch：3 step:10488/14065 loss：0.022357
【train】 epoch：3 step:10489/14065 loss：0.123585
【train】 epoch：3 step:10490/14065 loss：0.107342
【train】 epoch：3 step:10491/14065 loss：0.046654
【train】 epoch：3 step:10492/14065 loss：0.012755
【train】 epoch：3 step:10493/14065 loss：0.057032
【train】 epoch：3 step:10494/14065 loss：0.022618
【train】 epoch：3 step:10495/14065 loss：0.039503
【train】 epoch：3 step:10496/14065 loss：0.010496
【train】 epoch：3 step:10497/14065 loss：0.088278
【train】 epoch：3 step:10498/14065 loss：0.128175
【train】 epoch：3 step:10499/14065 loss：0.114248
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：110.584012 accuracy：0.9874 precision：0.9874 recall：0.9874 f1：0.9874
【train】 epoch：3 step:10500/14065 loss：0.124988
【train】 epoch：3 step:10501/14065 loss：0.118088
【train】 epoch：3 step:10502/14065 loss：0.121446
【train】 epoch：3 step:10503/14065 loss：0.022838
【train】 epoch：3 step:10504/14065 loss：0.063269
【train】 epoch：3 step:10505/14065 loss：0.083739
【train】 epoch：3 step:10506/14065 loss：0.159375
【train】 epoch：3 step:10507/14065 loss：0.041233
【train】 epoch：3 step:10508/14065 loss：0.046997
【train】 epoch：3 step:10509/14065 loss：0.006999
【train】 epoch：3 step:10510/14065 loss：0.109614
【train】 epoch：3 step:10511/14065 loss：0.101345
【train】 epoch：3 step:10512/14065 loss：0.040230
【train】 epoch：3 step:10513/14065 loss：0.044473
【train】 epoch：3 step:10514/14065 loss：0.057875
【train】 epoch：3 step:10515/14065 loss：0.025844
【train】 epoch：3 step:10516/14065 loss：0.044076
【train】 epoch：3 step:10517/14065 loss：0.115419
【train】 epoch：3 step:10518/14065 loss：0.024523
【train】 epoch：3 step:10519/14065 loss：0.136539
【train】 epoch：3 step:10520/14065 loss：0.050763
【train】 epoch：3 step:10521/14065 loss：0.112701
【train】 epoch：3 step:10522/14065 loss：0.104001
【train】 epoch：3 step:10523/14065 loss：0.106706
【train】 epoch：3 step:10524/14065 loss：0.117511
【train】 epoch：3 step:10525/14065 loss：0.024117
【train】 epoch：3 step:10526/14065 loss：0.066621
【train】 epoch：3 step:10527/14065 loss：0.025661
【train】 epoch：3 step:10528/14065 loss：0.016183
【train】 epoch：3 step:10529/14065 loss：0.084488
【train】 epoch：3 step:10530/14065 loss：0.018959
【train】 epoch：3 step:10531/14065 loss：0.031903
【train】 epoch：3 step:10532/14065 loss：0.018824
【train】 epoch：3 step:10533/14065 loss：0.066907
【train】 epoch：3 step:10534/14065 loss：0.016924
【train】 epoch：3 step:10535/14065 loss：0.013889
【train】 epoch：3 step:10536/14065 loss：0.045545
【train】 epoch：3 step:10537/14065 loss：0.109079
【train】 epoch：3 step:10538/14065 loss：0.094637
【train】 epoch：3 step:10539/14065 loss：0.036720
【train】 epoch：3 step:10540/14065 loss：0.107325
【train】 epoch：3 step:10541/14065 loss：0.020031
【train】 epoch：3 step:10542/14065 loss：0.114526
【train】 epoch：3 step:10543/14065 loss：0.172288
【train】 epoch：3 step:10544/14065 loss：0.009572
【train】 epoch：3 step:10545/14065 loss：0.033098
【train】 epoch：3 step:10546/14065 loss：0.113433
【train】 epoch：3 step:10547/14065 loss：0.006797
【train】 epoch：3 step:10548/14065 loss：0.088664
【train】 epoch：3 step:10549/14065 loss：0.134092
【train】 epoch：3 step:10550/14065 loss：0.033672
【train】 epoch：3 step:10551/14065 loss：0.069894
【train】 epoch：3 step:10552/14065 loss：0.017276
【train】 epoch：3 step:10553/14065 loss：0.102828
【train】 epoch：3 step:10554/14065 loss：0.082026
【train】 epoch：3 step:10555/14065 loss：0.066283
【train】 epoch：3 step:10556/14065 loss：0.006828
【train】 epoch：3 step:10557/14065 loss：0.021637
【train】 epoch：3 step:10558/14065 loss：0.048642
【train】 epoch：3 step:10559/14065 loss：0.112302
【train】 epoch：3 step:10560/14065 loss：0.064435
【train】 epoch：3 step:10561/14065 loss：0.121654
【train】 epoch：3 step:10562/14065 loss：0.078541
【train】 epoch：3 step:10563/14065 loss：0.086576
【train】 epoch：3 step:10564/14065 loss：0.089592
【train】 epoch：3 step:10565/14065 loss：0.016388
【train】 epoch：3 step:10566/14065 loss：0.059677
【train】 epoch：3 step:10567/14065 loss：0.042234
【train】 epoch：3 step:10568/14065 loss：0.027873
【train】 epoch：3 step:10569/14065 loss：0.046274
【train】 epoch：3 step:10570/14065 loss：0.056986
【train】 epoch：3 step:10571/14065 loss：0.021862
【train】 epoch：3 step:10572/14065 loss：0.035340
【train】 epoch：3 step:10573/14065 loss：0.037026
【train】 epoch：3 step:10574/14065 loss：0.037793
【train】 epoch：3 step:10575/14065 loss：0.054805
【train】 epoch：3 step:10576/14065 loss：0.052817
【train】 epoch：3 step:10577/14065 loss：0.028736
【train】 epoch：3 step:10578/14065 loss：0.036301
【train】 epoch：3 step:10579/14065 loss：0.040606
【train】 epoch：3 step:10580/14065 loss：0.066931
【train】 epoch：3 step:10581/14065 loss：0.104585
【train】 epoch：3 step:10582/14065 loss：0.090123
【train】 epoch：3 step:10583/14065 loss：0.024660
【train】 epoch：3 step:10584/14065 loss：0.052882
【train】 epoch：3 step:10585/14065 loss：0.089036
【train】 epoch：3 step:10586/14065 loss：0.089462
【train】 epoch：3 step:10587/14065 loss：0.099718
【train】 epoch：3 step:10588/14065 loss：0.146687
【train】 epoch：3 step:10589/14065 loss：0.104941
【train】 epoch：3 step:10590/14065 loss：0.104391
【train】 epoch：3 step:10591/14065 loss：0.005220
【train】 epoch：3 step:10592/14065 loss：0.115375
【train】 epoch：3 step:10593/14065 loss：0.008714
【train】 epoch：3 step:10594/14065 loss：0.019211
【train】 epoch：3 step:10595/14065 loss：0.067221
【train】 epoch：3 step:10596/14065 loss：0.005366
【train】 epoch：3 step:10597/14065 loss：0.167356
【train】 epoch：3 step:10598/14065 loss：0.038897
【train】 epoch：3 step:10599/14065 loss：0.094561
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：96.518336 accuracy：0.9889 precision：0.9889 recall：0.9889 f1：0.9889
【train】 epoch：3 step:10600/14065 loss：0.047466
【train】 epoch：3 step:10601/14065 loss：0.055582
【train】 epoch：3 step:10602/14065 loss：0.037425
【train】 epoch：3 step:10603/14065 loss：0.029762
【train】 epoch：3 step:10604/14065 loss：0.044328
【train】 epoch：3 step:10605/14065 loss：0.016552
【train】 epoch：3 step:10606/14065 loss：0.153442
【train】 epoch：3 step:10607/14065 loss：0.060030
【train】 epoch：3 step:10608/14065 loss：0.077544
【train】 epoch：3 step:10609/14065 loss：0.046638
【train】 epoch：3 step:10610/14065 loss：0.016587
【train】 epoch：3 step:10611/14065 loss：0.014688
【train】 epoch：3 step:10612/14065 loss：0.076128
【train】 epoch：3 step:10613/14065 loss：0.073001
【train】 epoch：3 step:10614/14065 loss：0.066173
【train】 epoch：3 step:10615/14065 loss：0.023415
【train】 epoch：3 step:10616/14065 loss：0.068079
【train】 epoch：3 step:10617/14065 loss：0.072609
【train】 epoch：3 step:10618/14065 loss：0.042535
【train】 epoch：3 step:10619/14065 loss：0.093240
【train】 epoch：3 step:10620/14065 loss：0.029927
【train】 epoch：3 step:10621/14065 loss：0.008505
【train】 epoch：3 step:10622/14065 loss：0.063240
【train】 epoch：3 step:10623/14065 loss：0.052526
【train】 epoch：3 step:10624/14065 loss：0.047478
【train】 epoch：3 step:10625/14065 loss：0.040650
【train】 epoch：3 step:10626/14065 loss：0.089577
【train】 epoch：3 step:10627/14065 loss：0.053855
【train】 epoch：3 step:10628/14065 loss：0.151516
【train】 epoch：3 step:10629/14065 loss：0.031193
【train】 epoch：3 step:10630/14065 loss：0.008060
【train】 epoch：3 step:10631/14065 loss：0.051282
【train】 epoch：3 step:10632/14065 loss：0.099408
【train】 epoch：3 step:10633/14065 loss：0.049004
【train】 epoch：3 step:10634/14065 loss：0.031999
【train】 epoch：3 step:10635/14065 loss：0.081453
【train】 epoch：3 step:10636/14065 loss：0.058269
【train】 epoch：3 step:10637/14065 loss：0.016115
【train】 epoch：3 step:10638/14065 loss：0.067095
【train】 epoch：3 step:10639/14065 loss：0.005620
【train】 epoch：3 step:10640/14065 loss：0.022497
【train】 epoch：3 step:10641/14065 loss：0.166459
【train】 epoch：3 step:10642/14065 loss：0.013519
【train】 epoch：3 step:10643/14065 loss：0.035351
【train】 epoch：3 step:10644/14065 loss：0.005949
【train】 epoch：3 step:10645/14065 loss：0.061095
【train】 epoch：3 step:10646/14065 loss：0.084408
【train】 epoch：3 step:10647/14065 loss：0.072692
【train】 epoch：3 step:10648/14065 loss：0.019260
【train】 epoch：3 step:10649/14065 loss：0.033642
【train】 epoch：3 step:10650/14065 loss：0.053686
【train】 epoch：3 step:10651/14065 loss：0.018285
【train】 epoch：3 step:10652/14065 loss：0.072412
【train】 epoch：3 step:10653/14065 loss：0.096581
【train】 epoch：3 step:10654/14065 loss：0.005320
【train】 epoch：3 step:10655/14065 loss：0.103919
【train】 epoch：3 step:10656/14065 loss：0.157359
【train】 epoch：3 step:10657/14065 loss：0.082739
【train】 epoch：3 step:10658/14065 loss：0.032117
【train】 epoch：3 step:10659/14065 loss：0.038202
【train】 epoch：3 step:10660/14065 loss：0.017030
【train】 epoch：3 step:10661/14065 loss：0.019176
【train】 epoch：3 step:10662/14065 loss：0.220107
【train】 epoch：3 step:10663/14065 loss：0.040676
【train】 epoch：3 step:10664/14065 loss：0.157578
【train】 epoch：3 step:10665/14065 loss：0.017915
【train】 epoch：3 step:10666/14065 loss：0.038244
【train】 epoch：3 step:10667/14065 loss：0.094533
【train】 epoch：3 step:10668/14065 loss：0.063535
【train】 epoch：3 step:10669/14065 loss：0.163353
【train】 epoch：3 step:10670/14065 loss：0.077467
【train】 epoch：3 step:10671/14065 loss：0.025245
【train】 epoch：3 step:10672/14065 loss：0.013725
【train】 epoch：3 step:10673/14065 loss：0.004068
【train】 epoch：3 step:10674/14065 loss：0.008564
【train】 epoch：3 step:10675/14065 loss：0.102299
【train】 epoch：3 step:10676/14065 loss：0.100058
【train】 epoch：3 step:10677/14065 loss：0.103257
【train】 epoch：3 step:10678/14065 loss：0.041123
【train】 epoch：3 step:10679/14065 loss：0.147189
【train】 epoch：3 step:10680/14065 loss：0.130365
【train】 epoch：3 step:10681/14065 loss：0.068331
【train】 epoch：3 step:10682/14065 loss：0.019864
【train】 epoch：3 step:10683/14065 loss：0.028527
【train】 epoch：3 step:10684/14065 loss：0.077743
【train】 epoch：3 step:10685/14065 loss：0.058259
【train】 epoch：3 step:10686/14065 loss：0.067841
【train】 epoch：3 step:10687/14065 loss：0.116735
【train】 epoch：3 step:10688/14065 loss：0.085606
【train】 epoch：3 step:10689/14065 loss：0.011145
【train】 epoch：3 step:10690/14065 loss：0.038462
【train】 epoch：3 step:10691/14065 loss：0.028675
【train】 epoch：3 step:10692/14065 loss：0.042313
【train】 epoch：3 step:10693/14065 loss：0.070749
【train】 epoch：3 step:10694/14065 loss：0.051785
【train】 epoch：3 step:10695/14065 loss：0.081357
【train】 epoch：3 step:10696/14065 loss：0.137070
【train】 epoch：3 step:10697/14065 loss：0.064823
【train】 epoch：3 step:10698/14065 loss：0.106987
【train】 epoch：3 step:10699/14065 loss：0.034617
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：96.634186 accuracy：0.9891 precision：0.9891 recall：0.9891 f1：0.9891
【train】 epoch：3 step:10700/14065 loss：0.028639
【train】 epoch：3 step:10701/14065 loss：0.022459
【train】 epoch：3 step:10702/14065 loss：0.038174
【train】 epoch：3 step:10703/14065 loss：0.014103
【train】 epoch：3 step:10704/14065 loss：0.025734
【train】 epoch：3 step:10705/14065 loss：0.105814
【train】 epoch：3 step:10706/14065 loss：0.045838
【train】 epoch：3 step:10707/14065 loss：0.007579
【train】 epoch：3 step:10708/14065 loss：0.040374
【train】 epoch：3 step:10709/14065 loss：0.043252
【train】 epoch：3 step:10710/14065 loss：0.109852
【train】 epoch：3 step:10711/14065 loss：0.040587
【train】 epoch：3 step:10712/14065 loss：0.070995
【train】 epoch：3 step:10713/14065 loss：0.149532
【train】 epoch：3 step:10714/14065 loss：0.053510
【train】 epoch：3 step:10715/14065 loss：0.259944
【train】 epoch：3 step:10716/14065 loss：0.005912
【train】 epoch：3 step:10717/14065 loss：0.136713
【train】 epoch：3 step:10718/14065 loss：0.094947
【train】 epoch：3 step:10719/14065 loss：0.014007
【train】 epoch：3 step:10720/14065 loss：0.021324
【train】 epoch：3 step:10721/14065 loss：0.116980
【train】 epoch：3 step:10722/14065 loss：0.030637
【train】 epoch：3 step:10723/14065 loss：0.025181
【train】 epoch：3 step:10724/14065 loss：0.064557
【train】 epoch：3 step:10725/14065 loss：0.051000
【train】 epoch：3 step:10726/14065 loss：0.061081
【train】 epoch：3 step:10727/14065 loss：0.253882
【train】 epoch：3 step:10728/14065 loss：0.082913
【train】 epoch：3 step:10729/14065 loss：0.064518
【train】 epoch：3 step:10730/14065 loss：0.125055
【train】 epoch：3 step:10731/14065 loss：0.009340
【train】 epoch：3 step:10732/14065 loss：0.016296
【train】 epoch：3 step:10733/14065 loss：0.113883
【train】 epoch：3 step:10734/14065 loss：0.077586
【train】 epoch：3 step:10735/14065 loss：0.028484
【train】 epoch：3 step:10736/14065 loss：0.144278
【train】 epoch：3 step:10737/14065 loss：0.116040
【train】 epoch：3 step:10738/14065 loss：0.031449
【train】 epoch：3 step:10739/14065 loss：0.071701
【train】 epoch：3 step:10740/14065 loss：0.113563
【train】 epoch：3 step:10741/14065 loss：0.125128
【train】 epoch：3 step:10742/14065 loss：0.070214
【train】 epoch：3 step:10743/14065 loss：0.023942
【train】 epoch：3 step:10744/14065 loss：0.092699
【train】 epoch：3 step:10745/14065 loss：0.207798
【train】 epoch：3 step:10746/14065 loss：0.025508
【train】 epoch：3 step:10747/14065 loss：0.008806
【train】 epoch：3 step:10748/14065 loss：0.012617
【train】 epoch：3 step:10749/14065 loss：0.031471
【train】 epoch：3 step:10750/14065 loss：0.124272
【train】 epoch：3 step:10751/14065 loss：0.026767
【train】 epoch：3 step:10752/14065 loss：0.048306
【train】 epoch：3 step:10753/14065 loss：0.050767
【train】 epoch：3 step:10754/14065 loss：0.152293
【train】 epoch：3 step:10755/14065 loss：0.086753
【train】 epoch：3 step:10756/14065 loss：0.028651
【train】 epoch：3 step:10757/14065 loss：0.049864
【train】 epoch：3 step:10758/14065 loss：0.202870
【train】 epoch：3 step:10759/14065 loss：0.014313
【train】 epoch：3 step:10760/14065 loss：0.017894
【train】 epoch：3 step:10761/14065 loss：0.044926
【train】 epoch：3 step:10762/14065 loss：0.156899
【train】 epoch：3 step:10763/14065 loss：0.039196
【train】 epoch：3 step:10764/14065 loss：0.129646
【train】 epoch：3 step:10765/14065 loss：0.074667
【train】 epoch：3 step:10766/14065 loss：0.028925
【train】 epoch：3 step:10767/14065 loss：0.075562
【train】 epoch：3 step:10768/14065 loss：0.081175
【train】 epoch：3 step:10769/14065 loss：0.027538
【train】 epoch：3 step:10770/14065 loss：0.039829
【train】 epoch：3 step:10771/14065 loss：0.106986
【train】 epoch：3 step:10772/14065 loss：0.063471
【train】 epoch：3 step:10773/14065 loss：0.014465
【train】 epoch：3 step:10774/14065 loss：0.091666
【train】 epoch：3 step:10775/14065 loss：0.045839
【train】 epoch：3 step:10776/14065 loss：0.122739
【train】 epoch：3 step:10777/14065 loss：0.054104
【train】 epoch：3 step:10778/14065 loss：0.014950
【train】 epoch：3 step:10779/14065 loss：0.011199
【train】 epoch：3 step:10780/14065 loss：0.068975
【train】 epoch：3 step:10781/14065 loss：0.010502
【train】 epoch：3 step:10782/14065 loss：0.016887
【train】 epoch：3 step:10783/14065 loss：0.120614
【train】 epoch：3 step:10784/14065 loss：0.039126
【train】 epoch：3 step:10785/14065 loss：0.069402
【train】 epoch：3 step:10786/14065 loss：0.162985
【train】 epoch：3 step:10787/14065 loss：0.102671
【train】 epoch：3 step:10788/14065 loss：0.043568
【train】 epoch：3 step:10789/14065 loss：0.036472
【train】 epoch：3 step:10790/14065 loss：0.068027
【train】 epoch：3 step:10791/14065 loss：0.040323
【train】 epoch：3 step:10792/14065 loss：0.054305
【train】 epoch：3 step:10793/14065 loss：0.122091
【train】 epoch：3 step:10794/14065 loss：0.046027
【train】 epoch：3 step:10795/14065 loss：0.045576
【train】 epoch：3 step:10796/14065 loss：0.027818
【train】 epoch：3 step:10797/14065 loss：0.016419
【train】 epoch：3 step:10798/14065 loss：0.149602
【train】 epoch：3 step:10799/14065 loss：0.021558
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：96.610670 accuracy：0.9890 precision：0.9890 recall：0.9890 f1：0.9890
【train】 epoch：3 step:10800/14065 loss：0.020318
【train】 epoch：3 step:10801/14065 loss：0.160159
【train】 epoch：3 step:10802/14065 loss：0.163448
【train】 epoch：3 step:10803/14065 loss：0.078464
【train】 epoch：3 step:10804/14065 loss：0.043605
【train】 epoch：3 step:10805/14065 loss：0.034588
【train】 epoch：3 step:10806/14065 loss：0.038130
【train】 epoch：3 step:10807/14065 loss：0.028204
【train】 epoch：3 step:10808/14065 loss：0.038495
【train】 epoch：3 step:10809/14065 loss：0.083139
【train】 epoch：3 step:10810/14065 loss：0.078150
【train】 epoch：3 step:10811/14065 loss：0.014545
【train】 epoch：3 step:10812/14065 loss：0.090372
【train】 epoch：3 step:10813/14065 loss：0.026120
【train】 epoch：3 step:10814/14065 loss：0.005265
【train】 epoch：3 step:10815/14065 loss：0.016348
【train】 epoch：3 step:10816/14065 loss：0.007760
【train】 epoch：3 step:10817/14065 loss：0.016149
【train】 epoch：3 step:10818/14065 loss：0.200217
【train】 epoch：3 step:10819/14065 loss：0.182723
【train】 epoch：3 step:10820/14065 loss：0.041403
【train】 epoch：3 step:10821/14065 loss：0.082764
【train】 epoch：3 step:10822/14065 loss：0.154538
【train】 epoch：3 step:10823/14065 loss：0.054089
【train】 epoch：3 step:10824/14065 loss：0.033272
【train】 epoch：3 step:10825/14065 loss：0.161770
【train】 epoch：3 step:10826/14065 loss：0.041399
【train】 epoch：3 step:10827/14065 loss：0.025236
【train】 epoch：3 step:10828/14065 loss：0.122082
【train】 epoch：3 step:10829/14065 loss：0.085504
【train】 epoch：3 step:10830/14065 loss：0.112911
【train】 epoch：3 step:10831/14065 loss：0.047089
【train】 epoch：3 step:10832/14065 loss：0.018964
【train】 epoch：3 step:10833/14065 loss：0.024312
【train】 epoch：3 step:10834/14065 loss：0.073254
【train】 epoch：3 step:10835/14065 loss：0.285405
【train】 epoch：3 step:10836/14065 loss：0.016482
【train】 epoch：3 step:10837/14065 loss：0.024004
【train】 epoch：3 step:10838/14065 loss：0.162292
【train】 epoch：3 step:10839/14065 loss：0.033997
【train】 epoch：3 step:10840/14065 loss：0.101038
【train】 epoch：3 step:10841/14065 loss：0.093946
【train】 epoch：3 step:10842/14065 loss：0.042007
【train】 epoch：3 step:10843/14065 loss：0.047456
【train】 epoch：3 step:10844/14065 loss：0.084696
【train】 epoch：3 step:10845/14065 loss：0.065215
【train】 epoch：3 step:10846/14065 loss：0.101503
【train】 epoch：3 step:10847/14065 loss：0.007924
【train】 epoch：3 step:10848/14065 loss：0.050045
【train】 epoch：3 step:10849/14065 loss：0.014876
【train】 epoch：3 step:10850/14065 loss：0.138194
【train】 epoch：3 step:10851/14065 loss：0.083497
【train】 epoch：3 step:10852/14065 loss：0.053730
【train】 epoch：3 step:10853/14065 loss：0.125314
【train】 epoch：3 step:10854/14065 loss：0.157859
【train】 epoch：3 step:10855/14065 loss：0.065555
【train】 epoch：3 step:10856/14065 loss：0.025912
【train】 epoch：3 step:10857/14065 loss：0.066483
【train】 epoch：3 step:10858/14065 loss：0.096462
【train】 epoch：3 step:10859/14065 loss：0.005518
【train】 epoch：3 step:10860/14065 loss：0.112017
【train】 epoch：3 step:10861/14065 loss：0.036705
【train】 epoch：3 step:10862/14065 loss：0.035128
【train】 epoch：3 step:10863/14065 loss：0.100599
【train】 epoch：3 step:10864/14065 loss：0.122182
【train】 epoch：3 step:10865/14065 loss：0.022776
【train】 epoch：3 step:10866/14065 loss：0.007949
【train】 epoch：3 step:10867/14065 loss：0.151460
【train】 epoch：3 step:10868/14065 loss：0.007807
【train】 epoch：3 step:10869/14065 loss：0.006819
【train】 epoch：3 step:10870/14065 loss：0.063860
【train】 epoch：3 step:10871/14065 loss：0.040082
【train】 epoch：3 step:10872/14065 loss：0.028614
【train】 epoch：3 step:10873/14065 loss：0.057482
【train】 epoch：3 step:10874/14065 loss：0.124186
【train】 epoch：3 step:10875/14065 loss：0.059228
【train】 epoch：3 step:10876/14065 loss：0.038482
【train】 epoch：3 step:10877/14065 loss：0.076707
【train】 epoch：3 step:10878/14065 loss：0.051303
【train】 epoch：3 step:10879/14065 loss：0.124213
【train】 epoch：3 step:10880/14065 loss：0.007310
【train】 epoch：3 step:10881/14065 loss：0.019191
【train】 epoch：3 step:10882/14065 loss：0.061050
【train】 epoch：3 step:10883/14065 loss：0.074178
【train】 epoch：3 step:10884/14065 loss：0.157460
【train】 epoch：3 step:10885/14065 loss：0.085354
【train】 epoch：3 step:10886/14065 loss：0.120064
【train】 epoch：3 step:10887/14065 loss：0.051256
【train】 epoch：3 step:10888/14065 loss：0.120730
【train】 epoch：3 step:10889/14065 loss：0.007541
【train】 epoch：3 step:10890/14065 loss：0.116119
【train】 epoch：3 step:10891/14065 loss：0.048503
【train】 epoch：3 step:10892/14065 loss：0.040358
【train】 epoch：3 step:10893/14065 loss：0.055940
【train】 epoch：3 step:10894/14065 loss：0.011993
【train】 epoch：3 step:10895/14065 loss：0.130137
【train】 epoch：3 step:10896/14065 loss：0.050943
【train】 epoch：3 step:10897/14065 loss：0.031624
【train】 epoch：3 step:10898/14065 loss：0.055019
【train】 epoch：3 step:10899/14065 loss：0.044468
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：102.384018 accuracy：0.9885 precision：0.9885 recall：0.9885 f1：0.9885
【train】 epoch：3 step:10900/14065 loss：0.087364
【train】 epoch：3 step:10901/14065 loss：0.028872
【train】 epoch：3 step:10902/14065 loss：0.109379
【train】 epoch：3 step:10903/14065 loss：0.148327
【train】 epoch：3 step:10904/14065 loss：0.146906
【train】 epoch：3 step:10905/14065 loss：0.038050
【train】 epoch：3 step:10906/14065 loss：0.113742
【train】 epoch：3 step:10907/14065 loss：0.113832
【train】 epoch：3 step:10908/14065 loss：0.114029
【train】 epoch：3 step:10909/14065 loss：0.063214
【train】 epoch：3 step:10910/14065 loss：0.100806
【train】 epoch：3 step:10911/14065 loss：0.100684
【train】 epoch：3 step:10912/14065 loss：0.032052
【train】 epoch：3 step:10913/14065 loss：0.167584
【train】 epoch：3 step:10914/14065 loss：0.156816
【train】 epoch：3 step:10915/14065 loss：0.051655
【train】 epoch：3 step:10916/14065 loss：0.095248
【train】 epoch：3 step:10917/14065 loss：0.061026
【train】 epoch：3 step:10918/14065 loss：0.107288
【train】 epoch：3 step:10919/14065 loss：0.028912
【train】 epoch：3 step:10920/14065 loss：0.118820
【train】 epoch：3 step:10921/14065 loss：0.017087
【train】 epoch：3 step:10922/14065 loss：0.067081
【train】 epoch：3 step:10923/14065 loss：0.103867
【train】 epoch：3 step:10924/14065 loss：0.112350
【train】 epoch：3 step:10925/14065 loss：0.083115
【train】 epoch：3 step:10926/14065 loss：0.051147
【train】 epoch：3 step:10927/14065 loss：0.046439
【train】 epoch：3 step:10928/14065 loss：0.138659
【train】 epoch：3 step:10929/14065 loss：0.041928
【train】 epoch：3 step:10930/14065 loss：0.022948
【train】 epoch：3 step:10931/14065 loss：0.004227
【train】 epoch：3 step:10932/14065 loss：0.018217
【train】 epoch：3 step:10933/14065 loss：0.100205
【train】 epoch：3 step:10934/14065 loss：0.132773
【train】 epoch：3 step:10935/14065 loss：0.010135
【train】 epoch：3 step:10936/14065 loss：0.028931
【train】 epoch：3 step:10937/14065 loss：0.009906
【train】 epoch：3 step:10938/14065 loss：0.007739
【train】 epoch：3 step:10939/14065 loss：0.036733
【train】 epoch：3 step:10940/14065 loss：0.044741
【train】 epoch：3 step:10941/14065 loss：0.020943
【train】 epoch：3 step:10942/14065 loss：0.020550
【train】 epoch：3 step:10943/14065 loss：0.004733
【train】 epoch：3 step:10944/14065 loss：0.064538
【train】 epoch：3 step:10945/14065 loss：0.021517
【train】 epoch：3 step:10946/14065 loss：0.082141
【train】 epoch：3 step:10947/14065 loss：0.135605
【train】 epoch：3 step:10948/14065 loss：0.091923
【train】 epoch：3 step:10949/14065 loss：0.169776
【train】 epoch：3 step:10950/14065 loss：0.044531
【train】 epoch：3 step:10951/14065 loss：0.081197
【train】 epoch：3 step:10952/14065 loss：0.006299
【train】 epoch：3 step:10953/14065 loss：0.031762
【train】 epoch：3 step:10954/14065 loss：0.034321
【train】 epoch：3 step:10955/14065 loss：0.029520
【train】 epoch：3 step:10956/14065 loss：0.017366
【train】 epoch：3 step:10957/14065 loss：0.011582
【train】 epoch：3 step:10958/14065 loss：0.101955
【train】 epoch：3 step:10959/14065 loss：0.037458
【train】 epoch：3 step:10960/14065 loss：0.045110
【train】 epoch：3 step:10961/14065 loss：0.095126
【train】 epoch：3 step:10962/14065 loss：0.018879
【train】 epoch：3 step:10963/14065 loss：0.027819
【train】 epoch：3 step:10964/14065 loss：0.020757
【train】 epoch：3 step:10965/14065 loss：0.129894
【train】 epoch：3 step:10966/14065 loss：0.092161
【train】 epoch：3 step:10967/14065 loss：0.082589
【train】 epoch：3 step:10968/14065 loss：0.144389
【train】 epoch：3 step:10969/14065 loss：0.083678
【train】 epoch：3 step:10970/14065 loss：0.082706
【train】 epoch：3 step:10971/14065 loss：0.160095
【train】 epoch：3 step:10972/14065 loss：0.065284
【train】 epoch：3 step:10973/14065 loss：0.022305
【train】 epoch：3 step:10974/14065 loss：0.079018
【train】 epoch：3 step:10975/14065 loss：0.026407
【train】 epoch：3 step:10976/14065 loss：0.041068
【train】 epoch：3 step:10977/14065 loss：0.098213
【train】 epoch：3 step:10978/14065 loss：0.049048
【train】 epoch：3 step:10979/14065 loss：0.028452
【train】 epoch：3 step:10980/14065 loss：0.066642
【train】 epoch：3 step:10981/14065 loss：0.037187
【train】 epoch：3 step:10982/14065 loss：0.022489
【train】 epoch：3 step:10983/14065 loss：0.171019
【train】 epoch：3 step:10984/14065 loss：0.042346
【train】 epoch：3 step:10985/14065 loss：0.038632
【train】 epoch：3 step:10986/14065 loss：0.148335
【train】 epoch：3 step:10987/14065 loss：0.147622
【train】 epoch：3 step:10988/14065 loss：0.109602
【train】 epoch：3 step:10989/14065 loss：0.009191
【train】 epoch：3 step:10990/14065 loss：0.052111
【train】 epoch：3 step:10991/14065 loss：0.093422
【train】 epoch：3 step:10992/14065 loss：0.122822
【train】 epoch：3 step:10993/14065 loss：0.033084
【train】 epoch：3 step:10994/14065 loss：0.037410
【train】 epoch：3 step:10995/14065 loss：0.032018
【train】 epoch：3 step:10996/14065 loss：0.040001
【train】 epoch：3 step:10997/14065 loss：0.094369
【train】 epoch：3 step:10998/14065 loss：0.021191
【train】 epoch：3 step:10999/14065 loss：0.107487
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：87.958984 accuracy：0.9902 precision：0.9902 recall：0.9902 f1：0.9902
------------>保存当前最好的模型
【train】 epoch：3 step:11000/14065 loss：0.039609
【train】 epoch：3 step:11001/14065 loss：0.018883
【train】 epoch：3 step:11002/14065 loss：0.097380
【train】 epoch：3 step:11003/14065 loss：0.137630
【train】 epoch：3 step:11004/14065 loss：0.154279
【train】 epoch：3 step:11005/14065 loss：0.028481
【train】 epoch：3 step:11006/14065 loss：0.027562
【train】 epoch：3 step:11007/14065 loss：0.034857
【train】 epoch：3 step:11008/14065 loss：0.017016
【train】 epoch：3 step:11009/14065 loss：0.069608
【train】 epoch：3 step:11010/14065 loss：0.073670
【train】 epoch：3 step:11011/14065 loss：0.022021
【train】 epoch：3 step:11012/14065 loss：0.016615
【train】 epoch：3 step:11013/14065 loss：0.043453
【train】 epoch：3 step:11014/14065 loss：0.014083
【train】 epoch：3 step:11015/14065 loss：0.078773
【train】 epoch：3 step:11016/14065 loss：0.042359
【train】 epoch：3 step:11017/14065 loss：0.134233
【train】 epoch：3 step:11018/14065 loss：0.167748
【train】 epoch：3 step:11019/14065 loss：0.111850
【train】 epoch：3 step:11020/14065 loss：0.133810
【train】 epoch：3 step:11021/14065 loss：0.089096
【train】 epoch：3 step:11022/14065 loss：0.099613
【train】 epoch：3 step:11023/14065 loss：0.034119
【train】 epoch：3 step:11024/14065 loss：0.020204
【train】 epoch：3 step:11025/14065 loss：0.036219
【train】 epoch：3 step:11026/14065 loss：0.112519
【train】 epoch：3 step:11027/14065 loss：0.021207
【train】 epoch：3 step:11028/14065 loss：0.030154
【train】 epoch：3 step:11029/14065 loss：0.019574
【train】 epoch：3 step:11030/14065 loss：0.007660
【train】 epoch：3 step:11031/14065 loss：0.090430
【train】 epoch：3 step:11032/14065 loss：0.056914
【train】 epoch：3 step:11033/14065 loss：0.049636
【train】 epoch：3 step:11034/14065 loss：0.101538
【train】 epoch：3 step:11035/14065 loss：0.092347
【train】 epoch：3 step:11036/14065 loss：0.019763
【train】 epoch：3 step:11037/14065 loss：0.009219
【train】 epoch：3 step:11038/14065 loss：0.045628
【train】 epoch：3 step:11039/14065 loss：0.167416
【train】 epoch：3 step:11040/14065 loss：0.059249
【train】 epoch：3 step:11041/14065 loss：0.096876
【train】 epoch：3 step:11042/14065 loss：0.193917
【train】 epoch：3 step:11043/14065 loss：0.066572
【train】 epoch：3 step:11044/14065 loss：0.047307
【train】 epoch：3 step:11045/14065 loss：0.058390
【train】 epoch：3 step:11046/14065 loss：0.057494
【train】 epoch：3 step:11047/14065 loss：0.094520
【train】 epoch：3 step:11048/14065 loss：0.042500
【train】 epoch：3 step:11049/14065 loss：0.031042
【train】 epoch：3 step:11050/14065 loss：0.192023
【train】 epoch：3 step:11051/14065 loss：0.070835
【train】 epoch：3 step:11052/14065 loss：0.034025
【train】 epoch：3 step:11053/14065 loss：0.011905
【train】 epoch：3 step:11054/14065 loss：0.055503
【train】 epoch：3 step:11055/14065 loss：0.050102
【train】 epoch：3 step:11056/14065 loss：0.124149
【train】 epoch：3 step:11057/14065 loss：0.028687
【train】 epoch：3 step:11058/14065 loss：0.149723
【train】 epoch：3 step:11059/14065 loss：0.064653
【train】 epoch：3 step:11060/14065 loss：0.063001
【train】 epoch：3 step:11061/14065 loss：0.018454
【train】 epoch：3 step:11062/14065 loss：0.081543
【train】 epoch：3 step:11063/14065 loss：0.085631
【train】 epoch：3 step:11064/14065 loss：0.024057
【train】 epoch：3 step:11065/14065 loss：0.050148
【train】 epoch：3 step:11066/14065 loss：0.035166
【train】 epoch：3 step:11067/14065 loss：0.034204
【train】 epoch：3 step:11068/14065 loss：0.083842
【train】 epoch：3 step:11069/14065 loss：0.042110
【train】 epoch：3 step:11070/14065 loss：0.062202
【train】 epoch：3 step:11071/14065 loss：0.060857
【train】 epoch：3 step:11072/14065 loss：0.021573
【train】 epoch：3 step:11073/14065 loss：0.053724
【train】 epoch：3 step:11074/14065 loss：0.111179
【train】 epoch：3 step:11075/14065 loss：0.083504
【train】 epoch：3 step:11076/14065 loss：0.086505
【train】 epoch：3 step:11077/14065 loss：0.037388
【train】 epoch：3 step:11078/14065 loss：0.081430
【train】 epoch：3 step:11079/14065 loss：0.021052
【train】 epoch：3 step:11080/14065 loss：0.025100
【train】 epoch：3 step:11081/14065 loss：0.020535
【train】 epoch：3 step:11082/14065 loss：0.014679
【train】 epoch：3 step:11083/14065 loss：0.014287
【train】 epoch：3 step:11084/14065 loss：0.083863
【train】 epoch：3 step:11085/14065 loss：0.238368
【train】 epoch：3 step:11086/14065 loss：0.006761
【train】 epoch：3 step:11087/14065 loss：0.015947
【train】 epoch：3 step:11088/14065 loss：0.105646
【train】 epoch：3 step:11089/14065 loss：0.047413
【train】 epoch：3 step:11090/14065 loss：0.051653
【train】 epoch：3 step:11091/14065 loss：0.024697
【train】 epoch：3 step:11092/14065 loss：0.110035
【train】 epoch：3 step:11093/14065 loss：0.094131
【train】 epoch：3 step:11094/14065 loss：0.118541
【train】 epoch：3 step:11095/14065 loss：0.023815
【train】 epoch：3 step:11096/14065 loss：0.050219
【train】 epoch：3 step:11097/14065 loss：0.004959
【train】 epoch：3 step:11098/14065 loss：0.025907
【train】 epoch：3 step:11099/14065 loss：0.117422
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：85.902603 accuracy：0.9908 precision：0.9908 recall：0.9908 f1：0.9908
------------>保存当前最好的模型
【train】 epoch：3 step:11100/14065 loss：0.032012
【train】 epoch：3 step:11101/14065 loss：0.058880
【train】 epoch：3 step:11102/14065 loss：0.057338
【train】 epoch：3 step:11103/14065 loss：0.075988
【train】 epoch：3 step:11104/14065 loss：0.030335
【train】 epoch：3 step:11105/14065 loss：0.090116
【train】 epoch：3 step:11106/14065 loss：0.068071
【train】 epoch：3 step:11107/14065 loss：0.160799
【train】 epoch：3 step:11108/14065 loss：0.132175
【train】 epoch：3 step:11109/14065 loss：0.183874
【train】 epoch：3 step:11110/14065 loss：0.049007
【train】 epoch：3 step:11111/14065 loss：0.014831
【train】 epoch：3 step:11112/14065 loss：0.095094
【train】 epoch：3 step:11113/14065 loss：0.016212
【train】 epoch：3 step:11114/14065 loss：0.091566
【train】 epoch：3 step:11115/14065 loss：0.072644
【train】 epoch：3 step:11116/14065 loss：0.041605
【train】 epoch：3 step:11117/14065 loss：0.024196
【train】 epoch：3 step:11118/14065 loss：0.077248
【train】 epoch：3 step:11119/14065 loss：0.025978
【train】 epoch：3 step:11120/14065 loss：0.079026
【train】 epoch：3 step:11121/14065 loss：0.031844
【train】 epoch：3 step:11122/14065 loss：0.046630
【train】 epoch：3 step:11123/14065 loss：0.065957
【train】 epoch：3 step:11124/14065 loss：0.034352
【train】 epoch：3 step:11125/14065 loss：0.140946
【train】 epoch：3 step:11126/14065 loss：0.012650
【train】 epoch：3 step:11127/14065 loss：0.084723
【train】 epoch：3 step:11128/14065 loss：0.092180
【train】 epoch：3 step:11129/14065 loss：0.088493
【train】 epoch：3 step:11130/14065 loss：0.024271
【train】 epoch：3 step:11131/14065 loss：0.151874
【train】 epoch：3 step:11132/14065 loss：0.139923
【train】 epoch：3 step:11133/14065 loss：0.036776
【train】 epoch：3 step:11134/14065 loss：0.033003
【train】 epoch：3 step:11135/14065 loss：0.064310
【train】 epoch：3 step:11136/14065 loss：0.039205
【train】 epoch：3 step:11137/14065 loss：0.077098
【train】 epoch：3 step:11138/14065 loss：0.039185
【train】 epoch：3 step:11139/14065 loss：0.066951
【train】 epoch：3 step:11140/14065 loss：0.080895
【train】 epoch：3 step:11141/14065 loss：0.069717
【train】 epoch：3 step:11142/14065 loss：0.039166
【train】 epoch：3 step:11143/14065 loss：0.020044
【train】 epoch：3 step:11144/14065 loss：0.027895
【train】 epoch：3 step:11145/14065 loss：0.078593
【train】 epoch：3 step:11146/14065 loss：0.011569
【train】 epoch：3 step:11147/14065 loss：0.037292
【train】 epoch：3 step:11148/14065 loss：0.014344
【train】 epoch：3 step:11149/14065 loss：0.030401
【train】 epoch：3 step:11150/14065 loss：0.064103
【train】 epoch：3 step:11151/14065 loss：0.038330
【train】 epoch：3 step:11152/14065 loss：0.053175
【train】 epoch：3 step:11153/14065 loss：0.086920
【train】 epoch：3 step:11154/14065 loss：0.170383
【train】 epoch：3 step:11155/14065 loss：0.032231
【train】 epoch：3 step:11156/14065 loss：0.051390
【train】 epoch：3 step:11157/14065 loss：0.022291
【train】 epoch：3 step:11158/14065 loss：0.088515
【train】 epoch：3 step:11159/14065 loss：0.032778
【train】 epoch：3 step:11160/14065 loss：0.048048
【train】 epoch：3 step:11161/14065 loss：0.041789
【train】 epoch：3 step:11162/14065 loss：0.040404
【train】 epoch：3 step:11163/14065 loss：0.074353
【train】 epoch：3 step:11164/14065 loss：0.124176
【train】 epoch：3 step:11165/14065 loss：0.054759
【train】 epoch：3 step:11166/14065 loss：0.015792
【train】 epoch：3 step:11167/14065 loss：0.111379
【train】 epoch：3 step:11168/14065 loss：0.004427
【train】 epoch：3 step:11169/14065 loss：0.040561
【train】 epoch：3 step:11170/14065 loss：0.055223
【train】 epoch：3 step:11171/14065 loss：0.193298
【train】 epoch：3 step:11172/14065 loss：0.172895
【train】 epoch：3 step:11173/14065 loss：0.036777
【train】 epoch：3 step:11174/14065 loss：0.108178
【train】 epoch：3 step:11175/14065 loss：0.084430
【train】 epoch：3 step:11176/14065 loss：0.050176
【train】 epoch：3 step:11177/14065 loss：0.010924
【train】 epoch：3 step:11178/14065 loss：0.145307
【train】 epoch：3 step:11179/14065 loss：0.015345
【train】 epoch：3 step:11180/14065 loss：0.039816
【train】 epoch：3 step:11181/14065 loss：0.037197
【train】 epoch：3 step:11182/14065 loss：0.220674
【train】 epoch：3 step:11183/14065 loss：0.015004
【train】 epoch：3 step:11184/14065 loss：0.169264
【train】 epoch：3 step:11185/14065 loss：0.054573
【train】 epoch：3 step:11186/14065 loss：0.018071
【train】 epoch：3 step:11187/14065 loss：0.009410
【train】 epoch：3 step:11188/14065 loss：0.047811
【train】 epoch：3 step:11189/14065 loss：0.018597
【train】 epoch：3 step:11190/14065 loss：0.008229
【train】 epoch：3 step:11191/14065 loss：0.094981
【train】 epoch：3 step:11192/14065 loss：0.060303
【train】 epoch：3 step:11193/14065 loss：0.028806
【train】 epoch：3 step:11194/14065 loss：0.107273
【train】 epoch：3 step:11195/14065 loss：0.073828
【train】 epoch：3 step:11196/14065 loss：0.020243
【train】 epoch：3 step:11197/14065 loss：0.073363
【train】 epoch：3 step:11198/14065 loss：0.086706
【train】 epoch：3 step:11199/14065 loss：0.026765
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：100.480483 accuracy：0.9883 precision：0.9883 recall：0.9883 f1：0.9883
【train】 epoch：3 step:11200/14065 loss：0.021956
【train】 epoch：3 step:11201/14065 loss：0.101835
【train】 epoch：3 step:11202/14065 loss：0.076029
【train】 epoch：3 step:11203/14065 loss：0.107239
【train】 epoch：3 step:11204/14065 loss：0.059097
【train】 epoch：3 step:11205/14065 loss：0.098738
【train】 epoch：3 step:11206/14065 loss：0.015501
【train】 epoch：3 step:11207/14065 loss：0.039762
【train】 epoch：3 step:11208/14065 loss：0.080873
【train】 epoch：3 step:11209/14065 loss：0.074715
【train】 epoch：3 step:11210/14065 loss：0.034495
【train】 epoch：3 step:11211/14065 loss：0.085502
【train】 epoch：3 step:11212/14065 loss：0.026922
【train】 epoch：3 step:11213/14065 loss：0.152703
【train】 epoch：3 step:11214/14065 loss：0.023291
【train】 epoch：3 step:11215/14065 loss：0.212357
【train】 epoch：3 step:11216/14065 loss：0.067065
【train】 epoch：3 step:11217/14065 loss：0.143964
【train】 epoch：3 step:11218/14065 loss：0.195065
【train】 epoch：3 step:11219/14065 loss：0.121864
【train】 epoch：3 step:11220/14065 loss：0.045054
【train】 epoch：3 step:11221/14065 loss：0.015112
【train】 epoch：3 step:11222/14065 loss：0.051254
【train】 epoch：3 step:11223/14065 loss：0.015821
【train】 epoch：3 step:11224/14065 loss：0.069779
【train】 epoch：3 step:11225/14065 loss：0.071733
【train】 epoch：3 step:11226/14065 loss：0.117148
【train】 epoch：3 step:11227/14065 loss：0.110473
【train】 epoch：3 step:11228/14065 loss：0.011981
【train】 epoch：3 step:11229/14065 loss：0.111758
【train】 epoch：3 step:11230/14065 loss：0.137612
【train】 epoch：3 step:11231/14065 loss：0.039750
【train】 epoch：3 step:11232/14065 loss：0.055188
【train】 epoch：3 step:11233/14065 loss：0.053884
【train】 epoch：3 step:11234/14065 loss：0.107120
【train】 epoch：3 step:11235/14065 loss：0.142199
【train】 epoch：3 step:11236/14065 loss：0.043967
【train】 epoch：3 step:11237/14065 loss：0.074979
【train】 epoch：3 step:11238/14065 loss：0.014876
【train】 epoch：3 step:11239/14065 loss：0.006114
【train】 epoch：3 step:11240/14065 loss：0.032911
【train】 epoch：3 step:11241/14065 loss：0.007692
【train】 epoch：3 step:11242/14065 loss：0.030056
【train】 epoch：3 step:11243/14065 loss：0.037677
【train】 epoch：3 step:11244/14065 loss：0.104144
【train】 epoch：3 step:11245/14065 loss：0.041633
【train】 epoch：3 step:11246/14065 loss：0.147349
【train】 epoch：3 step:11247/14065 loss：0.066350
【train】 epoch：3 step:11248/14065 loss：0.032451
【train】 epoch：3 step:11249/14065 loss：0.067002
【train】 epoch：3 step:11250/14065 loss：0.097809
【train】 epoch：3 step:11251/14065 loss：0.231052
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【train】 epoch：4 step:11252/14065 loss：0.020438
【train】 epoch：4 step:11253/14065 loss：0.129263
【train】 epoch：4 step:11254/14065 loss：0.055846
【train】 epoch：4 step:11255/14065 loss：0.004633
【train】 epoch：4 step:11256/14065 loss：0.033079
【train】 epoch：4 step:11257/14065 loss：0.036036
【train】 epoch：4 step:11258/14065 loss：0.040043
【train】 epoch：4 step:11259/14065 loss：0.016494
【train】 epoch：4 step:11260/14065 loss：0.077772
【train】 epoch：4 step:11261/14065 loss：0.016735
【train】 epoch：4 step:11262/14065 loss：0.056832
【train】 epoch：4 step:11263/14065 loss：0.006028
【train】 epoch：4 step:11264/14065 loss：0.030517
【train】 epoch：4 step:11265/14065 loss：0.018880
【train】 epoch：4 step:11266/14065 loss：0.016914
【train】 epoch：4 step:11267/14065 loss：0.016996
【train】 epoch：4 step:11268/14065 loss：0.085990
【train】 epoch：4 step:11269/14065 loss：0.036871
【train】 epoch：4 step:11270/14065 loss：0.082432
【train】 epoch：4 step:11271/14065 loss：0.165629
【train】 epoch：4 step:11272/14065 loss：0.092431
【train】 epoch：4 step:11273/14065 loss：0.052181
【train】 epoch：4 step:11274/14065 loss：0.017738
【train】 epoch：4 step:11275/14065 loss：0.053567
【train】 epoch：4 step:11276/14065 loss：0.088363
【train】 epoch：4 step:11277/14065 loss：0.060265
【train】 epoch：4 step:11278/14065 loss：0.077481
【train】 epoch：4 step:11279/14065 loss：0.021130
【train】 epoch：4 step:11280/14065 loss：0.031824
【train】 epoch：4 step:11281/14065 loss：0.012739
【train】 epoch：4 step:11282/14065 loss：0.014403
【train】 epoch：4 step:11283/14065 loss：0.011091
【train】 epoch：4 step:11284/14065 loss：0.058877
【train】 epoch：4 step:11285/14065 loss：0.027784
【train】 epoch：4 step:11286/14065 loss：0.045840
【train】 epoch：4 step:11287/14065 loss：0.024977
【train】 epoch：4 step:11288/14065 loss：0.056201
【train】 epoch：4 step:11289/14065 loss：0.010142
【train】 epoch：4 step:11290/14065 loss：0.020926
【train】 epoch：4 step:11291/14065 loss：0.085794
【train】 epoch：4 step:11292/14065 loss：0.016450
【train】 epoch：4 step:11293/14065 loss：0.019285
【train】 epoch：4 step:11294/14065 loss：0.048531
【train】 epoch：4 step:11295/14065 loss：0.026561
【train】 epoch：4 step:11296/14065 loss：0.179324
【train】 epoch：4 step:11297/14065 loss：0.052612
【train】 epoch：4 step:11298/14065 loss：0.042516
【train】 epoch：4 step:11299/14065 loss：0.011978
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：82.684773 accuracy：0.9911 precision：0.9911 recall：0.9911 f1：0.9911
------------>保存当前最好的模型
【train】 epoch：4 step:11300/14065 loss：0.034325
【train】 epoch：4 step:11301/14065 loss：0.018039
【train】 epoch：4 step:11302/14065 loss：0.014370
【train】 epoch：4 step:11303/14065 loss：0.006362
【train】 epoch：4 step:11304/14065 loss：0.005064
【train】 epoch：4 step:11305/14065 loss：0.061906
【train】 epoch：4 step:11306/14065 loss：0.123794
【train】 epoch：4 step:11307/14065 loss：0.032724
【train】 epoch：4 step:11308/14065 loss：0.056762
【train】 epoch：4 step:11309/14065 loss：0.032150
【train】 epoch：4 step:11310/14065 loss：0.016760
【train】 epoch：4 step:11311/14065 loss：0.029556
【train】 epoch：4 step:11312/14065 loss：0.055949
【train】 epoch：4 step:11313/14065 loss：0.049725
【train】 epoch：4 step:11314/14065 loss：0.017181
【train】 epoch：4 step:11315/14065 loss：0.019259
【train】 epoch：4 step:11316/14065 loss：0.012628
【train】 epoch：4 step:11317/14065 loss：0.014071
【train】 epoch：4 step:11318/14065 loss：0.039022
【train】 epoch：4 step:11319/14065 loss：0.046547
【train】 epoch：4 step:11320/14065 loss：0.035721
【train】 epoch：4 step:11321/14065 loss：0.013894
【train】 epoch：4 step:11322/14065 loss：0.086355
【train】 epoch：4 step:11323/14065 loss：0.115260
【train】 epoch：4 step:11324/14065 loss：0.035123
【train】 epoch：4 step:11325/14065 loss：0.023640
【train】 epoch：4 step:11326/14065 loss：0.068674
【train】 epoch：4 step:11327/14065 loss：0.041420
【train】 epoch：4 step:11328/14065 loss：0.039919
【train】 epoch：4 step:11329/14065 loss：0.108365
【train】 epoch：4 step:11330/14065 loss：0.052812
【train】 epoch：4 step:11331/14065 loss：0.009506
【train】 epoch：4 step:11332/14065 loss：0.024923
【train】 epoch：4 step:11333/14065 loss：0.050017
【train】 epoch：4 step:11334/14065 loss：0.121434
【train】 epoch：4 step:11335/14065 loss：0.005473
【train】 epoch：4 step:11336/14065 loss：0.078539
【train】 epoch：4 step:11337/14065 loss：0.057114
【train】 epoch：4 step:11338/14065 loss：0.023522
【train】 epoch：4 step:11339/14065 loss：0.072703
【train】 epoch：4 step:11340/14065 loss：0.004735
【train】 epoch：4 step:11341/14065 loss：0.100428
【train】 epoch：4 step:11342/14065 loss：0.045049
【train】 epoch：4 step:11343/14065 loss：0.063021
【train】 epoch：4 step:11344/14065 loss：0.025942
【train】 epoch：4 step:11345/14065 loss：0.026588
【train】 epoch：4 step:11346/14065 loss：0.036255
【train】 epoch：4 step:11347/14065 loss：0.033458
【train】 epoch：4 step:11348/14065 loss：0.050288
【train】 epoch：4 step:11349/14065 loss：0.002394
【train】 epoch：4 step:11350/14065 loss：0.063088
【train】 epoch：4 step:11351/14065 loss：0.012445
【train】 epoch：4 step:11352/14065 loss：0.030878
【train】 epoch：4 step:11353/14065 loss：0.013073
【train】 epoch：4 step:11354/14065 loss：0.043124
【train】 epoch：4 step:11355/14065 loss：0.099732
【train】 epoch：4 step:11356/14065 loss：0.002029
【train】 epoch：4 step:11357/14065 loss：0.004393
【train】 epoch：4 step:11358/14065 loss：0.020121
【train】 epoch：4 step:11359/14065 loss：0.006731
【train】 epoch：4 step:11360/14065 loss：0.011255
【train】 epoch：4 step:11361/14065 loss：0.018843
【train】 epoch：4 step:11362/14065 loss：0.036913
【train】 epoch：4 step:11363/14065 loss：0.033083
【train】 epoch：4 step:11364/14065 loss：0.056340
【train】 epoch：4 step:11365/14065 loss：0.035883
【train】 epoch：4 step:11366/14065 loss：0.030236
【train】 epoch：4 step:11367/14065 loss：0.026358
【train】 epoch：4 step:11368/14065 loss：0.002674
【train】 epoch：4 step:11369/14065 loss：0.050904
【train】 epoch：4 step:11370/14065 loss：0.210238
【train】 epoch：4 step:11371/14065 loss：0.027711
【train】 epoch：4 step:11372/14065 loss：0.087913
【train】 epoch：4 step:11373/14065 loss：0.005654
【train】 epoch：4 step:11374/14065 loss：0.010786
【train】 epoch：4 step:11375/14065 loss：0.020483
【train】 epoch：4 step:11376/14065 loss：0.012941
【train】 epoch：4 step:11377/14065 loss：0.091479
【train】 epoch：4 step:11378/14065 loss：0.042777
【train】 epoch：4 step:11379/14065 loss：0.005649
【train】 epoch：4 step:11380/14065 loss：0.027790
【train】 epoch：4 step:11381/14065 loss：0.023489
【train】 epoch：4 step:11382/14065 loss：0.029747
【train】 epoch：4 step:11383/14065 loss：0.022037
【train】 epoch：4 step:11384/14065 loss：0.033593
【train】 epoch：4 step:11385/14065 loss：0.004521
【train】 epoch：4 step:11386/14065 loss：0.060719
【train】 epoch：4 step:11387/14065 loss：0.012376
【train】 epoch：4 step:11388/14065 loss：0.018935
【train】 epoch：4 step:11389/14065 loss：0.094485
【train】 epoch：4 step:11390/14065 loss：0.057711
【train】 epoch：4 step:11391/14065 loss：0.027709
【train】 epoch：4 step:11392/14065 loss：0.072492
【train】 epoch：4 step:11393/14065 loss：0.024182
【train】 epoch：4 step:11394/14065 loss：0.036218
【train】 epoch：4 step:11395/14065 loss：0.044224
【train】 epoch：4 step:11396/14065 loss：0.048610
【train】 epoch：4 step:11397/14065 loss：0.037240
【train】 epoch：4 step:11398/14065 loss：0.012747
【train】 epoch：4 step:11399/14065 loss：0.036777
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：91.146778 accuracy：0.9896 precision：0.9896 recall：0.9896 f1：0.9896
【train】 epoch：4 step:11400/14065 loss：0.027429
【train】 epoch：4 step:11401/14065 loss：0.020604
【train】 epoch：4 step:11402/14065 loss：0.033171
【train】 epoch：4 step:11403/14065 loss：0.005368
【train】 epoch：4 step:11404/14065 loss：0.121730
【train】 epoch：4 step:11405/14065 loss：0.121351
【train】 epoch：4 step:11406/14065 loss：0.029535
【train】 epoch：4 step:11407/14065 loss：0.054845
【train】 epoch：4 step:11408/14065 loss：0.029579
【train】 epoch：4 step:11409/14065 loss：0.003862
【train】 epoch：4 step:11410/14065 loss：0.029177
【train】 epoch：4 step:11411/14065 loss：0.103228
【train】 epoch：4 step:11412/14065 loss：0.043968
【train】 epoch：4 step:11413/14065 loss：0.029526
【train】 epoch：4 step:11414/14065 loss：0.019430
【train】 epoch：4 step:11415/14065 loss：0.047499
【train】 epoch：4 step:11416/14065 loss：0.108193
【train】 epoch：4 step:11417/14065 loss：0.010763
【train】 epoch：4 step:11418/14065 loss：0.019289
【train】 epoch：4 step:11419/14065 loss：0.040213
【train】 epoch：4 step:11420/14065 loss：0.042120
【train】 epoch：4 step:11421/14065 loss：0.098646
【train】 epoch：4 step:11422/14065 loss：0.040832
【train】 epoch：4 step:11423/14065 loss：0.028542
【train】 epoch：4 step:11424/14065 loss：0.023718
【train】 epoch：4 step:11425/14065 loss：0.006521
【train】 epoch：4 step:11426/14065 loss：0.074223
【train】 epoch：4 step:11427/14065 loss：0.009572
【train】 epoch：4 step:11428/14065 loss：0.011349
【train】 epoch：4 step:11429/14065 loss：0.037311
【train】 epoch：4 step:11430/14065 loss：0.073812
【train】 epoch：4 step:11431/14065 loss：0.010428
【train】 epoch：4 step:11432/14065 loss：0.045683
【train】 epoch：4 step:11433/14065 loss：0.020243
【train】 epoch：4 step:11434/14065 loss：0.082598
【train】 epoch：4 step:11435/14065 loss：0.067066
【train】 epoch：4 step:11436/14065 loss：0.012059
【train】 epoch：4 step:11437/14065 loss：0.007227
【train】 epoch：4 step:11438/14065 loss：0.021501
【train】 epoch：4 step:11439/14065 loss：0.007734
【train】 epoch：4 step:11440/14065 loss：0.064595
【train】 epoch：4 step:11441/14065 loss：0.012512
【train】 epoch：4 step:11442/14065 loss：0.058208
【train】 epoch：4 step:11443/14065 loss：0.023277
【train】 epoch：4 step:11444/14065 loss：0.032267
【train】 epoch：4 step:11445/14065 loss：0.031265
【train】 epoch：4 step:11446/14065 loss：0.016328
【train】 epoch：4 step:11447/14065 loss：0.025849
【train】 epoch：4 step:11448/14065 loss：0.028692
【train】 epoch：4 step:11449/14065 loss：0.063689
【train】 epoch：4 step:11450/14065 loss：0.009465
【train】 epoch：4 step:11451/14065 loss：0.014416
【train】 epoch：4 step:11452/14065 loss：0.188212
【train】 epoch：4 step:11453/14065 loss：0.044134
【train】 epoch：4 step:11454/14065 loss：0.049049
【train】 epoch：4 step:11455/14065 loss：0.004192
【train】 epoch：4 step:11456/14065 loss：0.054876
【train】 epoch：4 step:11457/14065 loss：0.085495
【train】 epoch：4 step:11458/14065 loss：0.040861
【train】 epoch：4 step:11459/14065 loss：0.067991
【train】 epoch：4 step:11460/14065 loss：0.051823
【train】 epoch：4 step:11461/14065 loss：0.040048
【train】 epoch：4 step:11462/14065 loss：0.008123
【train】 epoch：4 step:11463/14065 loss：0.030829
【train】 epoch：4 step:11464/14065 loss：0.003999
【train】 epoch：4 step:11465/14065 loss：0.020933
【train】 epoch：4 step:11466/14065 loss：0.040119
【train】 epoch：4 step:11467/14065 loss：0.022676
【train】 epoch：4 step:11468/14065 loss：0.012591
【train】 epoch：4 step:11469/14065 loss：0.071098
【train】 epoch：4 step:11470/14065 loss：0.094501
【train】 epoch：4 step:11471/14065 loss：0.019888
【train】 epoch：4 step:11472/14065 loss：0.021503
【train】 epoch：4 step:11473/14065 loss：0.026834
【train】 epoch：4 step:11474/14065 loss：0.018416
【train】 epoch：4 step:11475/14065 loss：0.047346
【train】 epoch：4 step:11476/14065 loss：0.084424
【train】 epoch：4 step:11477/14065 loss：0.192832
【train】 epoch：4 step:11478/14065 loss：0.020758
【train】 epoch：4 step:11479/14065 loss：0.013936
【train】 epoch：4 step:11480/14065 loss：0.097225
【train】 epoch：4 step:11481/14065 loss：0.039401
【train】 epoch：4 step:11482/14065 loss：0.002541
【train】 epoch：4 step:11483/14065 loss：0.028146
【train】 epoch：4 step:11484/14065 loss：0.008425
【train】 epoch：4 step:11485/14065 loss：0.030667
【train】 epoch：4 step:11486/14065 loss：0.015992
【train】 epoch：4 step:11487/14065 loss：0.011631
【train】 epoch：4 step:11488/14065 loss：0.084773
【train】 epoch：4 step:11489/14065 loss：0.021532
【train】 epoch：4 step:11490/14065 loss：0.016572
【train】 epoch：4 step:11491/14065 loss：0.006708
【train】 epoch：4 step:11492/14065 loss：0.008813
【train】 epoch：4 step:11493/14065 loss：0.085658
【train】 epoch：4 step:11494/14065 loss：0.030760
【train】 epoch：4 step:11495/14065 loss：0.011531
【train】 epoch：4 step:11496/14065 loss：0.006777
【train】 epoch：4 step:11497/14065 loss：0.051318
【train】 epoch：4 step:11498/14065 loss：0.026567
【train】 epoch：4 step:11499/14065 loss：0.017834
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：74.110756 accuracy：0.9920 precision：0.9920 recall：0.9920 f1：0.9920
------------>保存当前最好的模型
【train】 epoch：4 step:11500/14065 loss：0.070043
【train】 epoch：4 step:11501/14065 loss：0.014431
【train】 epoch：4 step:11502/14065 loss：0.089817
【train】 epoch：4 step:11503/14065 loss：0.005781
【train】 epoch：4 step:11504/14065 loss：0.164582
【train】 epoch：4 step:11505/14065 loss：0.152503
【train】 epoch：4 step:11506/14065 loss：0.038569
【train】 epoch：4 step:11507/14065 loss：0.062018
【train】 epoch：4 step:11508/14065 loss：0.053685
【train】 epoch：4 step:11509/14065 loss：0.009632
【train】 epoch：4 step:11510/14065 loss：0.068239
【train】 epoch：4 step:11511/14065 loss：0.035738
【train】 epoch：4 step:11512/14065 loss：0.005264
【train】 epoch：4 step:11513/14065 loss：0.159189
【train】 epoch：4 step:11514/14065 loss：0.040454
【train】 epoch：4 step:11515/14065 loss：0.042151
【train】 epoch：4 step:11516/14065 loss：0.040142
【train】 epoch：4 step:11517/14065 loss：0.050170
【train】 epoch：4 step:11518/14065 loss：0.013651
【train】 epoch：4 step:11519/14065 loss：0.033635
【train】 epoch：4 step:11520/14065 loss：0.008674
【train】 epoch：4 step:11521/14065 loss：0.067361
【train】 epoch：4 step:11522/14065 loss：0.018893
【train】 epoch：4 step:11523/14065 loss：0.025616
【train】 epoch：4 step:11524/14065 loss：0.005386
【train】 epoch：4 step:11525/14065 loss：0.039867
【train】 epoch：4 step:11526/14065 loss：0.028489
【train】 epoch：4 step:11527/14065 loss：0.020317
【train】 epoch：4 step:11528/14065 loss：0.004706
【train】 epoch：4 step:11529/14065 loss：0.046141
【train】 epoch：4 step:11530/14065 loss：0.026855
【train】 epoch：4 step:11531/14065 loss：0.011034
【train】 epoch：4 step:11532/14065 loss：0.012831
【train】 epoch：4 step:11533/14065 loss：0.052812
【train】 epoch：4 step:11534/14065 loss：0.060413
【train】 epoch：4 step:11535/14065 loss：0.119492
【train】 epoch：4 step:11536/14065 loss：0.042626
【train】 epoch：4 step:11537/14065 loss：0.109800
【train】 epoch：4 step:11538/14065 loss：0.005744
【train】 epoch：4 step:11539/14065 loss：0.018012
【train】 epoch：4 step:11540/14065 loss：0.100906
【train】 epoch：4 step:11541/14065 loss：0.003789
【train】 epoch：4 step:11542/14065 loss：0.011466
【train】 epoch：4 step:11543/14065 loss：0.030174
【train】 epoch：4 step:11544/14065 loss：0.018837
【train】 epoch：4 step:11545/14065 loss：0.014627
【train】 epoch：4 step:11546/14065 loss：0.043121
【train】 epoch：4 step:11547/14065 loss：0.023994
【train】 epoch：4 step:11548/14065 loss：0.038695
【train】 epoch：4 step:11549/14065 loss：0.010103
【train】 epoch：4 step:11550/14065 loss：0.044519
【train】 epoch：4 step:11551/14065 loss：0.095304
【train】 epoch：4 step:11552/14065 loss：0.177290
【train】 epoch：4 step:11553/14065 loss：0.018409
【train】 epoch：4 step:11554/14065 loss：0.036980
【train】 epoch：4 step:11555/14065 loss：0.015146
【train】 epoch：4 step:11556/14065 loss：0.016250
【train】 epoch：4 step:11557/14065 loss：0.061415
【train】 epoch：4 step:11558/14065 loss：0.069943
【train】 epoch：4 step:11559/14065 loss：0.035761
【train】 epoch：4 step:11560/14065 loss：0.032577
【train】 epoch：4 step:11561/14065 loss：0.014132
【train】 epoch：4 step:11562/14065 loss：0.060465
【train】 epoch：4 step:11563/14065 loss：0.065041
【train】 epoch：4 step:11564/14065 loss：0.019119
【train】 epoch：4 step:11565/14065 loss：0.071111
【train】 epoch：4 step:11566/14065 loss：0.041536
【train】 epoch：4 step:11567/14065 loss：0.023972
【train】 epoch：4 step:11568/14065 loss：0.118306
【train】 epoch：4 step:11569/14065 loss：0.084139
【train】 epoch：4 step:11570/14065 loss：0.059087
【train】 epoch：4 step:11571/14065 loss：0.018691
【train】 epoch：4 step:11572/14065 loss：0.017769
【train】 epoch：4 step:11573/14065 loss：0.018818
【train】 epoch：4 step:11574/14065 loss：0.013028
【train】 epoch：4 step:11575/14065 loss：0.097844
【train】 epoch：4 step:11576/14065 loss：0.010646
【train】 epoch：4 step:11577/14065 loss：0.089495
【train】 epoch：4 step:11578/14065 loss：0.128834
【train】 epoch：4 step:11579/14065 loss：0.070849
【train】 epoch：4 step:11580/14065 loss：0.003427
【train】 epoch：4 step:11581/14065 loss：0.036034
【train】 epoch：4 step:11582/14065 loss：0.099728
【train】 epoch：4 step:11583/14065 loss：0.052573
【train】 epoch：4 step:11584/14065 loss：0.066067
【train】 epoch：4 step:11585/14065 loss：0.138605
【train】 epoch：4 step:11586/14065 loss：0.014144
【train】 epoch：4 step:11587/14065 loss：0.019681
【train】 epoch：4 step:11588/14065 loss：0.096511
【train】 epoch：4 step:11589/14065 loss：0.111500
【train】 epoch：4 step:11590/14065 loss：0.009985
【train】 epoch：4 step:11591/14065 loss：0.048369
【train】 epoch：4 step:11592/14065 loss：0.023680
【train】 epoch：4 step:11593/14065 loss：0.014375
【train】 epoch：4 step:11594/14065 loss：0.013268
【train】 epoch：4 step:11595/14065 loss：0.048659
【train】 epoch：4 step:11596/14065 loss：0.014668
【train】 epoch：4 step:11597/14065 loss：0.095527
【train】 epoch：4 step:11598/14065 loss：0.037138
【train】 epoch：4 step:11599/14065 loss：0.080626
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：82.379432 accuracy：0.9909 precision：0.9909 recall：0.9909 f1：0.9909
【train】 epoch：4 step:11600/14065 loss：0.087989
【train】 epoch：4 step:11601/14065 loss：0.054730
【train】 epoch：4 step:11602/14065 loss：0.077143
【train】 epoch：4 step:11603/14065 loss：0.082729
【train】 epoch：4 step:11604/14065 loss：0.046018
【train】 epoch：4 step:11605/14065 loss：0.030637
【train】 epoch：4 step:11606/14065 loss：0.044822
【train】 epoch：4 step:11607/14065 loss：0.122958
【train】 epoch：4 step:11608/14065 loss：0.077765
【train】 epoch：4 step:11609/14065 loss：0.054173
【train】 epoch：4 step:11610/14065 loss：0.022674
【train】 epoch：4 step:11611/14065 loss：0.006351
【train】 epoch：4 step:11612/14065 loss：0.008624
【train】 epoch：4 step:11613/14065 loss：0.009923
【train】 epoch：4 step:11614/14065 loss：0.015436
【train】 epoch：4 step:11615/14065 loss：0.024519
【train】 epoch：4 step:11616/14065 loss：0.019724
【train】 epoch：4 step:11617/14065 loss：0.014008
【train】 epoch：4 step:11618/14065 loss：0.055011
【train】 epoch：4 step:11619/14065 loss：0.034977
【train】 epoch：4 step:11620/14065 loss：0.051007
【train】 epoch：4 step:11621/14065 loss：0.026947
【train】 epoch：4 step:11622/14065 loss：0.012131
【train】 epoch：4 step:11623/14065 loss：0.106684
【train】 epoch：4 step:11624/14065 loss：0.065002
【train】 epoch：4 step:11625/14065 loss：0.062227
【train】 epoch：4 step:11626/14065 loss：0.023096
【train】 epoch：4 step:11627/14065 loss：0.069459
【train】 epoch：4 step:11628/14065 loss：0.043054
【train】 epoch：4 step:11629/14065 loss：0.038479
【train】 epoch：4 step:11630/14065 loss：0.015902
【train】 epoch：4 step:11631/14065 loss：0.008190
【train】 epoch：4 step:11632/14065 loss：0.039107
【train】 epoch：4 step:11633/14065 loss：0.060490
【train】 epoch：4 step:11634/14065 loss：0.019812
【train】 epoch：4 step:11635/14065 loss：0.019647
【train】 epoch：4 step:11636/14065 loss：0.048566
【train】 epoch：4 step:11637/14065 loss：0.021146
【train】 epoch：4 step:11638/14065 loss：0.056497
【train】 epoch：4 step:11639/14065 loss：0.033192
【train】 epoch：4 step:11640/14065 loss：0.011701
【train】 epoch：4 step:11641/14065 loss：0.025881
【train】 epoch：4 step:11642/14065 loss：0.018252
【train】 epoch：4 step:11643/14065 loss：0.065729
【train】 epoch：4 step:11644/14065 loss：0.011920
【train】 epoch：4 step:11645/14065 loss：0.017306
【train】 epoch：4 step:11646/14065 loss：0.146480
【train】 epoch：4 step:11647/14065 loss：0.096410
【train】 epoch：4 step:11648/14065 loss：0.068090
【train】 epoch：4 step:11649/14065 loss：0.006358
【train】 epoch：4 step:11650/14065 loss：0.103699
【train】 epoch：4 step:11651/14065 loss：0.056910
【train】 epoch：4 step:11652/14065 loss：0.035205
【train】 epoch：4 step:11653/14065 loss：0.002379
【train】 epoch：4 step:11654/14065 loss：0.026739
【train】 epoch：4 step:11655/14065 loss：0.025300
【train】 epoch：4 step:11656/14065 loss：0.048835
【train】 epoch：4 step:11657/14065 loss：0.001912
【train】 epoch：4 step:11658/14065 loss：0.036593
【train】 epoch：4 step:11659/14065 loss：0.074773
【train】 epoch：4 step:11660/14065 loss：0.055751
【train】 epoch：4 step:11661/14065 loss：0.086653
【train】 epoch：4 step:11662/14065 loss：0.027344
【train】 epoch：4 step:11663/14065 loss：0.037607
【train】 epoch：4 step:11664/14065 loss：0.077606
【train】 epoch：4 step:11665/14065 loss：0.016282
【train】 epoch：4 step:11666/14065 loss：0.056995
【train】 epoch：4 step:11667/14065 loss：0.009423
【train】 epoch：4 step:11668/14065 loss：0.104999
【train】 epoch：4 step:11669/14065 loss：0.045539
【train】 epoch：4 step:11670/14065 loss：0.044611
【train】 epoch：4 step:11671/14065 loss：0.031353
【train】 epoch：4 step:11672/14065 loss：0.071272
【train】 epoch：4 step:11673/14065 loss：0.005949
【train】 epoch：4 step:11674/14065 loss：0.036485
【train】 epoch：4 step:11675/14065 loss：0.056805
【train】 epoch：4 step:11676/14065 loss：0.046695
【train】 epoch：4 step:11677/14065 loss：0.077670
【train】 epoch：4 step:11678/14065 loss：0.010963
【train】 epoch：4 step:11679/14065 loss：0.010627
【train】 epoch：4 step:11680/14065 loss：0.127006
【train】 epoch：4 step:11681/14065 loss：0.014959
【train】 epoch：4 step:11682/14065 loss：0.041567
【train】 epoch：4 step:11683/14065 loss：0.065943
【train】 epoch：4 step:11684/14065 loss：0.005493
【train】 epoch：4 step:11685/14065 loss：0.044724
【train】 epoch：4 step:11686/14065 loss：0.143349
【train】 epoch：4 step:11687/14065 loss：0.101950
【train】 epoch：4 step:11688/14065 loss：0.005537
【train】 epoch：4 step:11689/14065 loss：0.110228
【train】 epoch：4 step:11690/14065 loss：0.063793
【train】 epoch：4 step:11691/14065 loss：0.013932
【train】 epoch：4 step:11692/14065 loss：0.007392
【train】 epoch：4 step:11693/14065 loss：0.016114
【train】 epoch：4 step:11694/14065 loss：0.011509
【train】 epoch：4 step:11695/14065 loss：0.048687
【train】 epoch：4 step:11696/14065 loss：0.079055
【train】 epoch：4 step:11697/14065 loss：0.015998
【train】 epoch：4 step:11698/14065 loss：0.044911
【train】 epoch：4 step:11699/14065 loss：0.047463
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：83.369859 accuracy：0.9905 precision：0.9905 recall：0.9905 f1：0.9905
【train】 epoch：4 step:11700/14065 loss：0.083359
【train】 epoch：4 step:11701/14065 loss：0.004332
【train】 epoch：4 step:11702/14065 loss：0.019021
【train】 epoch：4 step:11703/14065 loss：0.072074
【train】 epoch：4 step:11704/14065 loss：0.035777
【train】 epoch：4 step:11705/14065 loss：0.013275
【train】 epoch：4 step:11706/14065 loss：0.016510
【train】 epoch：4 step:11707/14065 loss：0.157835
【train】 epoch：4 step:11708/14065 loss：0.025353
【train】 epoch：4 step:11709/14065 loss：0.034415
【train】 epoch：4 step:11710/14065 loss：0.023016
【train】 epoch：4 step:11711/14065 loss：0.032562
【train】 epoch：4 step:11712/14065 loss：0.220022
【train】 epoch：4 step:11713/14065 loss：0.004355
【train】 epoch：4 step:11714/14065 loss：0.024826
【train】 epoch：4 step:11715/14065 loss：0.045881
【train】 epoch：4 step:11716/14065 loss：0.012593
【train】 epoch：4 step:11717/14065 loss：0.039001
【train】 epoch：4 step:11718/14065 loss：0.067664
【train】 epoch：4 step:11719/14065 loss：0.012597
【train】 epoch：4 step:11720/14065 loss：0.045695
【train】 epoch：4 step:11721/14065 loss：0.097692
【train】 epoch：4 step:11722/14065 loss：0.018370
【train】 epoch：4 step:11723/14065 loss：0.034115
【train】 epoch：4 step:11724/14065 loss：0.014145
【train】 epoch：4 step:11725/14065 loss：0.029357
【train】 epoch：4 step:11726/14065 loss：0.010182
【train】 epoch：4 step:11727/14065 loss：0.096064
【train】 epoch：4 step:11728/14065 loss：0.061060
【train】 epoch：4 step:11729/14065 loss：0.020662
【train】 epoch：4 step:11730/14065 loss：0.008839
【train】 epoch：4 step:11731/14065 loss：0.090651
【train】 epoch：4 step:11732/14065 loss：0.100955
【train】 epoch：4 step:11733/14065 loss：0.210796
【train】 epoch：4 step:11734/14065 loss：0.088575
【train】 epoch：4 step:11735/14065 loss：0.079502
【train】 epoch：4 step:11736/14065 loss：0.033116
【train】 epoch：4 step:11737/14065 loss：0.033163
【train】 epoch：4 step:11738/14065 loss：0.112488
【train】 epoch：4 step:11739/14065 loss：0.008879
【train】 epoch：4 step:11740/14065 loss：0.037548
【train】 epoch：4 step:11741/14065 loss：0.031239
【train】 epoch：4 step:11742/14065 loss：0.009725
【train】 epoch：4 step:11743/14065 loss：0.051445
【train】 epoch：4 step:11744/14065 loss：0.031621
【train】 epoch：4 step:11745/14065 loss：0.073140
【train】 epoch：4 step:11746/14065 loss：0.122958
【train】 epoch：4 step:11747/14065 loss：0.032762
【train】 epoch：4 step:11748/14065 loss：0.005623
【train】 epoch：4 step:11749/14065 loss：0.022338
【train】 epoch：4 step:11750/14065 loss：0.024164
【train】 epoch：4 step:11751/14065 loss：0.015832
【train】 epoch：4 step:11752/14065 loss：0.019175
【train】 epoch：4 step:11753/14065 loss：0.025609
【train】 epoch：4 step:11754/14065 loss：0.033100
【train】 epoch：4 step:11755/14065 loss：0.079269
【train】 epoch：4 step:11756/14065 loss：0.066397
【train】 epoch：4 step:11757/14065 loss：0.032391
【train】 epoch：4 step:11758/14065 loss：0.028998
【train】 epoch：4 step:11759/14065 loss：0.026392
【train】 epoch：4 step:11760/14065 loss：0.033405
【train】 epoch：4 step:11761/14065 loss：0.020904
【train】 epoch：4 step:11762/14065 loss：0.012986
【train】 epoch：4 step:11763/14065 loss：0.074333
【train】 epoch：4 step:11764/14065 loss：0.015141
【train】 epoch：4 step:11765/14065 loss：0.027696
【train】 epoch：4 step:11766/14065 loss：0.046602
【train】 epoch：4 step:11767/14065 loss：0.008143
【train】 epoch：4 step:11768/14065 loss：0.140590
【train】 epoch：4 step:11769/14065 loss：0.042380
【train】 epoch：4 step:11770/14065 loss：0.038348
【train】 epoch：4 step:11771/14065 loss：0.010607
【train】 epoch：4 step:11772/14065 loss：0.011262
【train】 epoch：4 step:11773/14065 loss：0.066060
【train】 epoch：4 step:11774/14065 loss：0.038090
【train】 epoch：4 step:11775/14065 loss：0.006067
【train】 epoch：4 step:11776/14065 loss：0.025786
【train】 epoch：4 step:11777/14065 loss：0.055679
【train】 epoch：4 step:11778/14065 loss：0.012377
【train】 epoch：4 step:11779/14065 loss：0.007856
【train】 epoch：4 step:11780/14065 loss：0.044891
【train】 epoch：4 step:11781/14065 loss：0.099284
【train】 epoch：4 step:11782/14065 loss：0.006912
【train】 epoch：4 step:11783/14065 loss：0.074663
【train】 epoch：4 step:11784/14065 loss：0.009613
【train】 epoch：4 step:11785/14065 loss：0.061970
【train】 epoch：4 step:11786/14065 loss：0.015184
【train】 epoch：4 step:11787/14065 loss：0.072991
【train】 epoch：4 step:11788/14065 loss：0.060262
【train】 epoch：4 step:11789/14065 loss：0.022672
【train】 epoch：4 step:11790/14065 loss：0.002386
【train】 epoch：4 step:11791/14065 loss：0.079812
【train】 epoch：4 step:11792/14065 loss：0.086260
【train】 epoch：4 step:11793/14065 loss：0.053494
【train】 epoch：4 step:11794/14065 loss：0.114959
【train】 epoch：4 step:11795/14065 loss：0.019649
【train】 epoch：4 step:11796/14065 loss：0.075917
【train】 epoch：4 step:11797/14065 loss：0.108635
【train】 epoch：4 step:11798/14065 loss：0.028345
【train】 epoch：4 step:11799/14065 loss：0.065759
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：90.189222 accuracy：0.9896 precision：0.9896 recall：0.9896 f1：0.9896
【train】 epoch：4 step:11800/14065 loss：0.027237
【train】 epoch：4 step:11801/14065 loss：0.089112
【train】 epoch：4 step:11802/14065 loss：0.057928
【train】 epoch：4 step:11803/14065 loss：0.009635
【train】 epoch：4 step:11804/14065 loss：0.075558
【train】 epoch：4 step:11805/14065 loss：0.078149
【train】 epoch：4 step:11806/14065 loss：0.003046
【train】 epoch：4 step:11807/14065 loss：0.024457
【train】 epoch：4 step:11808/14065 loss：0.005441
【train】 epoch：4 step:11809/14065 loss：0.013284
【train】 epoch：4 step:11810/14065 loss：0.094533
【train】 epoch：4 step:11811/14065 loss：0.017794
【train】 epoch：4 step:11812/14065 loss：0.011969
【train】 epoch：4 step:11813/14065 loss：0.057053
【train】 epoch：4 step:11814/14065 loss：0.035889
【train】 epoch：4 step:11815/14065 loss：0.052121
【train】 epoch：4 step:11816/14065 loss：0.031386
【train】 epoch：4 step:11817/14065 loss：0.015812
【train】 epoch：4 step:11818/14065 loss：0.071964
【train】 epoch：4 step:11819/14065 loss：0.041756
【train】 epoch：4 step:11820/14065 loss：0.082467
【train】 epoch：4 step:11821/14065 loss：0.146616
【train】 epoch：4 step:11822/14065 loss：0.136939
【train】 epoch：4 step:11823/14065 loss：0.032580
【train】 epoch：4 step:11824/14065 loss：0.002537
【train】 epoch：4 step:11825/14065 loss：0.136294
【train】 epoch：4 step:11826/14065 loss：0.058446
【train】 epoch：4 step:11827/14065 loss：0.002433
【train】 epoch：4 step:11828/14065 loss：0.051453
【train】 epoch：4 step:11829/14065 loss：0.013325
【train】 epoch：4 step:11830/14065 loss：0.070109
【train】 epoch：4 step:11831/14065 loss：0.048625
【train】 epoch：4 step:11832/14065 loss：0.024014
【train】 epoch：4 step:11833/14065 loss：0.007310
【train】 epoch：4 step:11834/14065 loss：0.028933
【train】 epoch：4 step:11835/14065 loss：0.119089
【train】 epoch：4 step:11836/14065 loss：0.008922
【train】 epoch：4 step:11837/14065 loss：0.005722
【train】 epoch：4 step:11838/14065 loss：0.064448
【train】 epoch：4 step:11839/14065 loss：0.008476
【train】 epoch：4 step:11840/14065 loss：0.042956
【train】 epoch：4 step:11841/14065 loss：0.145519
【train】 epoch：4 step:11842/14065 loss：0.074339
【train】 epoch：4 step:11843/14065 loss：0.006088
【train】 epoch：4 step:11844/14065 loss：0.047473
【train】 epoch：4 step:11845/14065 loss：0.016153
【train】 epoch：4 step:11846/14065 loss：0.032357
【train】 epoch：4 step:11847/14065 loss：0.009783
【train】 epoch：4 step:11848/14065 loss：0.060690
【train】 epoch：4 step:11849/14065 loss：0.057846
【train】 epoch：4 step:11850/14065 loss：0.005379
【train】 epoch：4 step:11851/14065 loss：0.034074
【train】 epoch：4 step:11852/14065 loss：0.005917
【train】 epoch：4 step:11853/14065 loss：0.026403
【train】 epoch：4 step:11854/14065 loss：0.044322
【train】 epoch：4 step:11855/14065 loss：0.076222
【train】 epoch：4 step:11856/14065 loss：0.023403
【train】 epoch：4 step:11857/14065 loss：0.087866
【train】 epoch：4 step:11858/14065 loss：0.040275
【train】 epoch：4 step:11859/14065 loss：0.098813
【train】 epoch：4 step:11860/14065 loss：0.083242
【train】 epoch：4 step:11861/14065 loss：0.029852
【train】 epoch：4 step:11862/14065 loss：0.079630
【train】 epoch：4 step:11863/14065 loss：0.022273
【train】 epoch：4 step:11864/14065 loss：0.007108
【train】 epoch：4 step:11865/14065 loss：0.047345
【train】 epoch：4 step:11866/14065 loss：0.071067
【train】 epoch：4 step:11867/14065 loss：0.044404
【train】 epoch：4 step:11868/14065 loss：0.052855
【train】 epoch：4 step:11869/14065 loss：0.055845
【train】 epoch：4 step:11870/14065 loss：0.082948
【train】 epoch：4 step:11871/14065 loss：0.061132
【train】 epoch：4 step:11872/14065 loss：0.001822
【train】 epoch：4 step:11873/14065 loss：0.027632
【train】 epoch：4 step:11874/14065 loss：0.080012
【train】 epoch：4 step:11875/14065 loss：0.037213
【train】 epoch：4 step:11876/14065 loss：0.023187
【train】 epoch：4 step:11877/14065 loss：0.088035
【train】 epoch：4 step:11878/14065 loss：0.033920
【train】 epoch：4 step:11879/14065 loss：0.007932
【train】 epoch：4 step:11880/14065 loss：0.057880
【train】 epoch：4 step:11881/14065 loss：0.018539
【train】 epoch：4 step:11882/14065 loss：0.002874
【train】 epoch：4 step:11883/14065 loss：0.053437
【train】 epoch：4 step:11884/14065 loss：0.040372
【train】 epoch：4 step:11885/14065 loss：0.089313
【train】 epoch：4 step:11886/14065 loss：0.039405
【train】 epoch：4 step:11887/14065 loss：0.029791
【train】 epoch：4 step:11888/14065 loss：0.154998
【train】 epoch：4 step:11889/14065 loss：0.048107
【train】 epoch：4 step:11890/14065 loss：0.011039
【train】 epoch：4 step:11891/14065 loss：0.036396
【train】 epoch：4 step:11892/14065 loss：0.019783
【train】 epoch：4 step:11893/14065 loss：0.088858
【train】 epoch：4 step:11894/14065 loss：0.025096
【train】 epoch：4 step:11895/14065 loss：0.057807
【train】 epoch：4 step:11896/14065 loss：0.049812
【train】 epoch：4 step:11897/14065 loss：0.005436
【train】 epoch：4 step:11898/14065 loss：0.013800
【train】 epoch：4 step:11899/14065 loss：0.010417
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：86.576633 accuracy：0.9902 precision：0.9902 recall：0.9902 f1：0.9902
【train】 epoch：4 step:11900/14065 loss：0.053768
【train】 epoch：4 step:11901/14065 loss：0.001857
【train】 epoch：4 step:11902/14065 loss：0.026570
【train】 epoch：4 step:11903/14065 loss：0.013202
【train】 epoch：4 step:11904/14065 loss：0.189740
【train】 epoch：4 step:11905/14065 loss：0.005992
【train】 epoch：4 step:11906/14065 loss：0.011862
【train】 epoch：4 step:11907/14065 loss：0.050602
【train】 epoch：4 step:11908/14065 loss：0.034215
【train】 epoch：4 step:11909/14065 loss：0.061125
【train】 epoch：4 step:11910/14065 loss：0.004692
【train】 epoch：4 step:11911/14065 loss：0.061222
【train】 epoch：4 step:11912/14065 loss：0.044418
【train】 epoch：4 step:11913/14065 loss：0.083194
【train】 epoch：4 step:11914/14065 loss：0.035121
【train】 epoch：4 step:11915/14065 loss：0.053785
【train】 epoch：4 step:11916/14065 loss：0.019404
【train】 epoch：4 step:11917/14065 loss：0.030241
【train】 epoch：4 step:11918/14065 loss：0.152858
【train】 epoch：4 step:11919/14065 loss：0.082553
【train】 epoch：4 step:11920/14065 loss：0.045428
【train】 epoch：4 step:11921/14065 loss：0.050942
【train】 epoch：4 step:11922/14065 loss：0.046546
【train】 epoch：4 step:11923/14065 loss：0.069217
【train】 epoch：4 step:11924/14065 loss：0.020683
【train】 epoch：4 step:11925/14065 loss：0.021700
【train】 epoch：4 step:11926/14065 loss：0.039232
【train】 epoch：4 step:11927/14065 loss：0.018589
【train】 epoch：4 step:11928/14065 loss：0.018520
【train】 epoch：4 step:11929/14065 loss：0.011777
【train】 epoch：4 step:11930/14065 loss：0.010355
【train】 epoch：4 step:11931/14065 loss：0.039209
【train】 epoch：4 step:11932/14065 loss：0.004378
【train】 epoch：4 step:11933/14065 loss：0.033410
【train】 epoch：4 step:11934/14065 loss：0.020857
【train】 epoch：4 step:11935/14065 loss：0.001880
【train】 epoch：4 step:11936/14065 loss：0.024808
【train】 epoch：4 step:11937/14065 loss：0.011731
【train】 epoch：4 step:11938/14065 loss：0.007801
【train】 epoch：4 step:11939/14065 loss：0.028294
【train】 epoch：4 step:11940/14065 loss：0.030389
【train】 epoch：4 step:11941/14065 loss：0.052900
【train】 epoch：4 step:11942/14065 loss：0.105717
【train】 epoch：4 step:11943/14065 loss：0.013917
【train】 epoch：4 step:11944/14065 loss：0.070454
【train】 epoch：4 step:11945/14065 loss：0.022225
【train】 epoch：4 step:11946/14065 loss：0.091421
【train】 epoch：4 step:11947/14065 loss：0.034346
【train】 epoch：4 step:11948/14065 loss：0.008462
【train】 epoch：4 step:11949/14065 loss：0.006676
【train】 epoch：4 step:11950/14065 loss：0.123502
【train】 epoch：4 step:11951/14065 loss：0.021017
【train】 epoch：4 step:11952/14065 loss：0.004375
【train】 epoch：4 step:11953/14065 loss：0.129554
【train】 epoch：4 step:11954/14065 loss：0.016328
【train】 epoch：4 step:11955/14065 loss：0.062473
【train】 epoch：4 step:11956/14065 loss：0.015347
【train】 epoch：4 step:11957/14065 loss：0.008917
【train】 epoch：4 step:11958/14065 loss：0.057026
【train】 epoch：4 step:11959/14065 loss：0.051141
【train】 epoch：4 step:11960/14065 loss：0.015294
【train】 epoch：4 step:11961/14065 loss：0.009191
【train】 epoch：4 step:11962/14065 loss：0.060383
【train】 epoch：4 step:11963/14065 loss：0.003974
【train】 epoch：4 step:11964/14065 loss：0.036371
【train】 epoch：4 step:11965/14065 loss：0.015652
【train】 epoch：4 step:11966/14065 loss：0.061706
【train】 epoch：4 step:11967/14065 loss：0.007365
【train】 epoch：4 step:11968/14065 loss：0.052118
【train】 epoch：4 step:11969/14065 loss：0.055292
【train】 epoch：4 step:11970/14065 loss：0.013709
【train】 epoch：4 step:11971/14065 loss：0.024515
【train】 epoch：4 step:11972/14065 loss：0.018123
【train】 epoch：4 step:11973/14065 loss：0.078950
【train】 epoch：4 step:11974/14065 loss：0.036800
【train】 epoch：4 step:11975/14065 loss：0.046315
【train】 epoch：4 step:11976/14065 loss：0.007066
【train】 epoch：4 step:11977/14065 loss：0.068398
【train】 epoch：4 step:11978/14065 loss：0.136911
【train】 epoch：4 step:11979/14065 loss：0.016206
【train】 epoch：4 step:11980/14065 loss：0.003039
【train】 epoch：4 step:11981/14065 loss：0.147169
【train】 epoch：4 step:11982/14065 loss：0.053328
【train】 epoch：4 step:11983/14065 loss：0.063029
【train】 epoch：4 step:11984/14065 loss：0.007977
【train】 epoch：4 step:11985/14065 loss：0.007148
【train】 epoch：4 step:11986/14065 loss：0.080049
【train】 epoch：4 step:11987/14065 loss：0.058607
【train】 epoch：4 step:11988/14065 loss：0.006257
【train】 epoch：4 step:11989/14065 loss：0.019895
【train】 epoch：4 step:11990/14065 loss：0.012239
【train】 epoch：4 step:11991/14065 loss：0.045763
【train】 epoch：4 step:11992/14065 loss：0.059408
【train】 epoch：4 step:11993/14065 loss：0.007313
【train】 epoch：4 step:11994/14065 loss：0.036975
【train】 epoch：4 step:11995/14065 loss：0.019345
【train】 epoch：4 step:11996/14065 loss：0.002554
【train】 epoch：4 step:11997/14065 loss：0.023885
【train】 epoch：4 step:11998/14065 loss：0.018227
【train】 epoch：4 step:11999/14065 loss：0.052334
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：71.559980 accuracy：0.9921 precision：0.9921 recall：0.9921 f1：0.9921
------------>保存当前最好的模型
【train】 epoch：4 step:12000/14065 loss：0.006225
【train】 epoch：4 step:12001/14065 loss：0.037190
【train】 epoch：4 step:12002/14065 loss：0.027783
【train】 epoch：4 step:12003/14065 loss：0.003235
【train】 epoch：4 step:12004/14065 loss：0.003811
【train】 epoch：4 step:12005/14065 loss：0.033909
【train】 epoch：4 step:12006/14065 loss：0.040140
【train】 epoch：4 step:12007/14065 loss：0.051428
【train】 epoch：4 step:12008/14065 loss：0.025841
【train】 epoch：4 step:12009/14065 loss：0.014084
【train】 epoch：4 step:12010/14065 loss：0.006757
【train】 epoch：4 step:12011/14065 loss：0.007524
【train】 epoch：4 step:12012/14065 loss：0.010009
【train】 epoch：4 step:12013/14065 loss：0.009026
【train】 epoch：4 step:12014/14065 loss：0.137754
【train】 epoch：4 step:12015/14065 loss：0.093983
【train】 epoch：4 step:12016/14065 loss：0.083318
【train】 epoch：4 step:12017/14065 loss：0.021738
【train】 epoch：4 step:12018/14065 loss：0.047456
【train】 epoch：4 step:12019/14065 loss：0.002860
【train】 epoch：4 step:12020/14065 loss：0.095990
【train】 epoch：4 step:12021/14065 loss：0.005705
【train】 epoch：4 step:12022/14065 loss：0.022332
【train】 epoch：4 step:12023/14065 loss：0.115248
【train】 epoch：4 step:12024/14065 loss：0.012110
【train】 epoch：4 step:12025/14065 loss：0.035877
【train】 epoch：4 step:12026/14065 loss：0.079505
【train】 epoch：4 step:12027/14065 loss：0.113593
【train】 epoch：4 step:12028/14065 loss：0.088415
【train】 epoch：4 step:12029/14065 loss：0.004109
【train】 epoch：4 step:12030/14065 loss：0.027697
【train】 epoch：4 step:12031/14065 loss：0.086029
【train】 epoch：4 step:12032/14065 loss：0.030765
【train】 epoch：4 step:12033/14065 loss：0.054142
【train】 epoch：4 step:12034/14065 loss：0.014926
【train】 epoch：4 step:12035/14065 loss：0.025958
【train】 epoch：4 step:12036/14065 loss：0.019083
【train】 epoch：4 step:12037/14065 loss：0.058992
【train】 epoch：4 step:12038/14065 loss：0.005360
【train】 epoch：4 step:12039/14065 loss：0.135766
【train】 epoch：4 step:12040/14065 loss：0.019304
【train】 epoch：4 step:12041/14065 loss：0.089097
【train】 epoch：4 step:12042/14065 loss：0.057838
【train】 epoch：4 step:12043/14065 loss：0.018019
【train】 epoch：4 step:12044/14065 loss：0.092400
【train】 epoch：4 step:12045/14065 loss：0.009643
【train】 epoch：4 step:12046/14065 loss：0.032151
【train】 epoch：4 step:12047/14065 loss：0.095695
【train】 epoch：4 step:12048/14065 loss：0.012417
【train】 epoch：4 step:12049/14065 loss：0.007566
【train】 epoch：4 step:12050/14065 loss：0.063455
【train】 epoch：4 step:12051/14065 loss：0.082051
【train】 epoch：4 step:12052/14065 loss：0.008423
【train】 epoch：4 step:12053/14065 loss：0.023135
【train】 epoch：4 step:12054/14065 loss：0.007986
【train】 epoch：4 step:12055/14065 loss：0.040745
【train】 epoch：4 step:12056/14065 loss：0.034593
【train】 epoch：4 step:12057/14065 loss：0.012014
【train】 epoch：4 step:12058/14065 loss：0.050949
【train】 epoch：4 step:12059/14065 loss：0.061211
【train】 epoch：4 step:12060/14065 loss：0.098672
【train】 epoch：4 step:12061/14065 loss：0.008361
【train】 epoch：4 step:12062/14065 loss：0.054566
【train】 epoch：4 step:12063/14065 loss：0.045351
【train】 epoch：4 step:12064/14065 loss：0.015460
【train】 epoch：4 step:12065/14065 loss：0.075601
【train】 epoch：4 step:12066/14065 loss：0.001121
【train】 epoch：4 step:12067/14065 loss：0.032554
【train】 epoch：4 step:12068/14065 loss：0.013495
【train】 epoch：4 step:12069/14065 loss：0.010133
【train】 epoch：4 step:12070/14065 loss：0.139368
【train】 epoch：4 step:12071/14065 loss：0.011539
【train】 epoch：4 step:12072/14065 loss：0.012362
【train】 epoch：4 step:12073/14065 loss：0.036280
【train】 epoch：4 step:12074/14065 loss：0.053335
【train】 epoch：4 step:12075/14065 loss：0.116804
【train】 epoch：4 step:12076/14065 loss：0.006682
【train】 epoch：4 step:12077/14065 loss：0.017409
【train】 epoch：4 step:12078/14065 loss：0.005541
【train】 epoch：4 step:12079/14065 loss：0.007746
【train】 epoch：4 step:12080/14065 loss：0.006660
【train】 epoch：4 step:12081/14065 loss：0.111405
【train】 epoch：4 step:12082/14065 loss：0.006781
【train】 epoch：4 step:12083/14065 loss：0.022545
【train】 epoch：4 step:12084/14065 loss：0.115834
【train】 epoch：4 step:12085/14065 loss：0.013070
【train】 epoch：4 step:12086/14065 loss：0.027458
【train】 epoch：4 step:12087/14065 loss：0.011588
【train】 epoch：4 step:12088/14065 loss：0.061374
【train】 epoch：4 step:12089/14065 loss：0.002829
【train】 epoch：4 step:12090/14065 loss：0.024083
【train】 epoch：4 step:12091/14065 loss：0.019609
【train】 epoch：4 step:12092/14065 loss：0.015208
【train】 epoch：4 step:12093/14065 loss：0.071100
【train】 epoch：4 step:12094/14065 loss：0.043298
【train】 epoch：4 step:12095/14065 loss：0.111348
【train】 epoch：4 step:12096/14065 loss：0.019529
【train】 epoch：4 step:12097/14065 loss：0.033575
【train】 epoch：4 step:12098/14065 loss：0.114729
【train】 epoch：4 step:12099/14065 loss：0.070742
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：86.061576 accuracy：0.9899 precision：0.9899 recall：0.9899 f1：0.9899
【train】 epoch：4 step:12100/14065 loss：0.018306
【train】 epoch：4 step:12101/14065 loss：0.001190
【train】 epoch：4 step:12102/14065 loss：0.045860
【train】 epoch：4 step:12103/14065 loss：0.053740
【train】 epoch：4 step:12104/14065 loss：0.046488
【train】 epoch：4 step:12105/14065 loss：0.008648
【train】 epoch：4 step:12106/14065 loss：0.040648
【train】 epoch：4 step:12107/14065 loss：0.015817
【train】 epoch：4 step:12108/14065 loss：0.062491
【train】 epoch：4 step:12109/14065 loss：0.017676
【train】 epoch：4 step:12110/14065 loss：0.091311
【train】 epoch：4 step:12111/14065 loss：0.024196
【train】 epoch：4 step:12112/14065 loss：0.007968
【train】 epoch：4 step:12113/14065 loss：0.007113
【train】 epoch：4 step:12114/14065 loss：0.028076
【train】 epoch：4 step:12115/14065 loss：0.022177
【train】 epoch：4 step:12116/14065 loss：0.028522
【train】 epoch：4 step:12117/14065 loss：0.029032
【train】 epoch：4 step:12118/14065 loss：0.049526
【train】 epoch：4 step:12119/14065 loss：0.041029
【train】 epoch：4 step:12120/14065 loss：0.065909
【train】 epoch：4 step:12121/14065 loss：0.005833
【train】 epoch：4 step:12122/14065 loss：0.052622
【train】 epoch：4 step:12123/14065 loss：0.004977
【train】 epoch：4 step:12124/14065 loss：0.005315
【train】 epoch：4 step:12125/14065 loss：0.028894
【train】 epoch：4 step:12126/14065 loss：0.004413
【train】 epoch：4 step:12127/14065 loss：0.122283
【train】 epoch：4 step:12128/14065 loss：0.083856
【train】 epoch：4 step:12129/14065 loss：0.113230
【train】 epoch：4 step:12130/14065 loss：0.126080
【train】 epoch：4 step:12131/14065 loss：0.018671
【train】 epoch：4 step:12132/14065 loss：0.043120
【train】 epoch：4 step:12133/14065 loss：0.039135
【train】 epoch：4 step:12134/14065 loss：0.006434
【train】 epoch：4 step:12135/14065 loss：0.038331
【train】 epoch：4 step:12136/14065 loss：0.020342
【train】 epoch：4 step:12137/14065 loss：0.125354
【train】 epoch：4 step:12138/14065 loss：0.016641
【train】 epoch：4 step:12139/14065 loss：0.022138
【train】 epoch：4 step:12140/14065 loss：0.024730
【train】 epoch：4 step:12141/14065 loss：0.052862
【train】 epoch：4 step:12142/14065 loss：0.041518
【train】 epoch：4 step:12143/14065 loss：0.053798
【train】 epoch：4 step:12144/14065 loss：0.085559
【train】 epoch：4 step:12145/14065 loss：0.011615
【train】 epoch：4 step:12146/14065 loss：0.023943
【train】 epoch：4 step:12147/14065 loss：0.019041
【train】 epoch：4 step:12148/14065 loss：0.031070
【train】 epoch：4 step:12149/14065 loss：0.030824
【train】 epoch：4 step:12150/14065 loss：0.091902
【train】 epoch：4 step:12151/14065 loss：0.005928
【train】 epoch：4 step:12152/14065 loss：0.047879
【train】 epoch：4 step:12153/14065 loss：0.008660
【train】 epoch：4 step:12154/14065 loss：0.015521
【train】 epoch：4 step:12155/14065 loss：0.016198
【train】 epoch：4 step:12156/14065 loss：0.009528
【train】 epoch：4 step:12157/14065 loss：0.158021
【train】 epoch：4 step:12158/14065 loss：0.048645
【train】 epoch：4 step:12159/14065 loss：0.024110
【train】 epoch：4 step:12160/14065 loss：0.053250
【train】 epoch：4 step:12161/14065 loss：0.081262
【train】 epoch：4 step:12162/14065 loss：0.117966
【train】 epoch：4 step:12163/14065 loss：0.021692
【train】 epoch：4 step:12164/14065 loss：0.030827
【train】 epoch：4 step:12165/14065 loss：0.032504
【train】 epoch：4 step:12166/14065 loss：0.008015
【train】 epoch：4 step:12167/14065 loss：0.065045
【train】 epoch：4 step:12168/14065 loss：0.050512
【train】 epoch：4 step:12169/14065 loss：0.039745
【train】 epoch：4 step:12170/14065 loss：0.048257
【train】 epoch：4 step:12171/14065 loss：0.112029
【train】 epoch：4 step:12172/14065 loss：0.007708
【train】 epoch：4 step:12173/14065 loss：0.065129
【train】 epoch：4 step:12174/14065 loss：0.004492
【train】 epoch：4 step:12175/14065 loss：0.006944
【train】 epoch：4 step:12176/14065 loss：0.085846
【train】 epoch：4 step:12177/14065 loss：0.009942
【train】 epoch：4 step:12178/14065 loss：0.110633
【train】 epoch：4 step:12179/14065 loss：0.081915
【train】 epoch：4 step:12180/14065 loss：0.060429
【train】 epoch：4 step:12181/14065 loss：0.039566
【train】 epoch：4 step:12182/14065 loss：0.061860
【train】 epoch：4 step:12183/14065 loss：0.003147
【train】 epoch：4 step:12184/14065 loss：0.015274
【train】 epoch：4 step:12185/14065 loss：0.003409
【train】 epoch：4 step:12186/14065 loss：0.054700
【train】 epoch：4 step:12187/14065 loss：0.043912
【train】 epoch：4 step:12188/14065 loss：0.066218
【train】 epoch：4 step:12189/14065 loss：0.066768
【train】 epoch：4 step:12190/14065 loss：0.095817
【train】 epoch：4 step:12191/14065 loss：0.012723
【train】 epoch：4 step:12192/14065 loss：0.007691
【train】 epoch：4 step:12193/14065 loss：0.045100
【train】 epoch：4 step:12194/14065 loss：0.133464
【train】 epoch：4 step:12195/14065 loss：0.065171
【train】 epoch：4 step:12196/14065 loss：0.042931
【train】 epoch：4 step:12197/14065 loss：0.006263
【train】 epoch：4 step:12198/14065 loss：0.038388
【train】 epoch：4 step:12199/14065 loss：0.072642
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：75.506998 accuracy：0.9917 precision：0.9917 recall：0.9917 f1：0.9917
【train】 epoch：4 step:12200/14065 loss：0.027312
【train】 epoch：4 step:12201/14065 loss：0.065029
【train】 epoch：4 step:12202/14065 loss：0.017640
【train】 epoch：4 step:12203/14065 loss：0.159599
【train】 epoch：4 step:12204/14065 loss：0.015068
【train】 epoch：4 step:12205/14065 loss：0.010870
【train】 epoch：4 step:12206/14065 loss：0.119494
【train】 epoch：4 step:12207/14065 loss：0.037424
【train】 epoch：4 step:12208/14065 loss：0.180103
【train】 epoch：4 step:12209/14065 loss：0.083104
【train】 epoch：4 step:12210/14065 loss：0.004111
【train】 epoch：4 step:12211/14065 loss：0.054184
【train】 epoch：4 step:12212/14065 loss：0.094504
【train】 epoch：4 step:12213/14065 loss：0.022043
【train】 epoch：4 step:12214/14065 loss：0.060729
【train】 epoch：4 step:12215/14065 loss：0.126162
【train】 epoch：4 step:12216/14065 loss：0.013411
【train】 epoch：4 step:12217/14065 loss：0.007342
【train】 epoch：4 step:12218/14065 loss：0.045508
【train】 epoch：4 step:12219/14065 loss：0.071840
【train】 epoch：4 step:12220/14065 loss：0.055237
【train】 epoch：4 step:12221/14065 loss：0.026831
【train】 epoch：4 step:12222/14065 loss：0.017895
【train】 epoch：4 step:12223/14065 loss：0.093541
【train】 epoch：4 step:12224/14065 loss：0.037721
【train】 epoch：4 step:12225/14065 loss：0.063589
【train】 epoch：4 step:12226/14065 loss：0.026460
【train】 epoch：4 step:12227/14065 loss：0.088502
【train】 epoch：4 step:12228/14065 loss：0.021844
【train】 epoch：4 step:12229/14065 loss：0.010024
【train】 epoch：4 step:12230/14065 loss：0.005354
【train】 epoch：4 step:12231/14065 loss：0.109608
【train】 epoch：4 step:12232/14065 loss：0.172836
【train】 epoch：4 step:12233/14065 loss：0.018227
【train】 epoch：4 step:12234/14065 loss：0.088831
【train】 epoch：4 step:12235/14065 loss：0.006169
【train】 epoch：4 step:12236/14065 loss：0.044785
【train】 epoch：4 step:12237/14065 loss：0.053133
【train】 epoch：4 step:12238/14065 loss：0.080306
【train】 epoch：4 step:12239/14065 loss：0.021838
【train】 epoch：4 step:12240/14065 loss：0.021192
【train】 epoch：4 step:12241/14065 loss：0.054104
【train】 epoch：4 step:12242/14065 loss：0.035734
【train】 epoch：4 step:12243/14065 loss：0.080208
【train】 epoch：4 step:12244/14065 loss：0.029781
【train】 epoch：4 step:12245/14065 loss：0.123630
【train】 epoch：4 step:12246/14065 loss：0.076755
【train】 epoch：4 step:12247/14065 loss：0.024379
【train】 epoch：4 step:12248/14065 loss：0.108679
【train】 epoch：4 step:12249/14065 loss：0.042797
【train】 epoch：4 step:12250/14065 loss：0.141556
【train】 epoch：4 step:12251/14065 loss：0.109153
【train】 epoch：4 step:12252/14065 loss：0.008344
【train】 epoch：4 step:12253/14065 loss：0.036266
【train】 epoch：4 step:12254/14065 loss：0.142650
【train】 epoch：4 step:12255/14065 loss：0.040777
【train】 epoch：4 step:12256/14065 loss：0.027739
【train】 epoch：4 step:12257/14065 loss：0.016370
【train】 epoch：4 step:12258/14065 loss：0.020751
【train】 epoch：4 step:12259/14065 loss：0.004674
【train】 epoch：4 step:12260/14065 loss：0.010571
【train】 epoch：4 step:12261/14065 loss：0.086446
【train】 epoch：4 step:12262/14065 loss：0.035984
【train】 epoch：4 step:12263/14065 loss：0.047351
【train】 epoch：4 step:12264/14065 loss：0.007721
【train】 epoch：4 step:12265/14065 loss：0.001742
【train】 epoch：4 step:12266/14065 loss：0.010007
【train】 epoch：4 step:12267/14065 loss：0.048378
【train】 epoch：4 step:12268/14065 loss：0.082286
【train】 epoch：4 step:12269/14065 loss：0.054861
【train】 epoch：4 step:12270/14065 loss：0.012044
【train】 epoch：4 step:12271/14065 loss：0.017164
【train】 epoch：4 step:12272/14065 loss：0.086870
【train】 epoch：4 step:12273/14065 loss：0.048006
【train】 epoch：4 step:12274/14065 loss：0.046661
【train】 epoch：4 step:12275/14065 loss：0.029296
【train】 epoch：4 step:12276/14065 loss：0.118147
【train】 epoch：4 step:12277/14065 loss：0.036727
【train】 epoch：4 step:12278/14065 loss：0.019460
【train】 epoch：4 step:12279/14065 loss：0.045967
【train】 epoch：4 step:12280/14065 loss：0.089118
【train】 epoch：4 step:12281/14065 loss：0.146240
【train】 epoch：4 step:12282/14065 loss：0.013776
【train】 epoch：4 step:12283/14065 loss：0.031167
【train】 epoch：4 step:12284/14065 loss：0.023332
【train】 epoch：4 step:12285/14065 loss：0.039640
【train】 epoch：4 step:12286/14065 loss：0.019239
【train】 epoch：4 step:12287/14065 loss：0.050303
【train】 epoch：4 step:12288/14065 loss：0.010653
【train】 epoch：4 step:12289/14065 loss：0.009806
【train】 epoch：4 step:12290/14065 loss：0.158817
【train】 epoch：4 step:12291/14065 loss：0.027630
【train】 epoch：4 step:12292/14065 loss：0.028634
【train】 epoch：4 step:12293/14065 loss：0.075951
【train】 epoch：4 step:12294/14065 loss：0.128604
【train】 epoch：4 step:12295/14065 loss：0.073563
【train】 epoch：4 step:12296/14065 loss：0.066623
【train】 epoch：4 step:12297/14065 loss：0.060904
【train】 epoch：4 step:12298/14065 loss：0.094074
【train】 epoch：4 step:12299/14065 loss：0.056785
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：88.056293 accuracy：0.9896 precision：0.9896 recall：0.9896 f1：0.9896
【train】 epoch：4 step:12300/14065 loss：0.053049
【train】 epoch：4 step:12301/14065 loss：0.066611
【train】 epoch：4 step:12302/14065 loss：0.045678
【train】 epoch：4 step:12303/14065 loss：0.052360
【train】 epoch：4 step:12304/14065 loss：0.108182
【train】 epoch：4 step:12305/14065 loss：0.048245
【train】 epoch：4 step:12306/14065 loss：0.018944
【train】 epoch：4 step:12307/14065 loss：0.007342
【train】 epoch：4 step:12308/14065 loss：0.040702
【train】 epoch：4 step:12309/14065 loss：0.026918
【train】 epoch：4 step:12310/14065 loss：0.025653
【train】 epoch：4 step:12311/14065 loss：0.057407
【train】 epoch：4 step:12312/14065 loss：0.055847
【train】 epoch：4 step:12313/14065 loss：0.073626
【train】 epoch：4 step:12314/14065 loss：0.008839
【train】 epoch：4 step:12315/14065 loss：0.041386
【train】 epoch：4 step:12316/14065 loss：0.094127
【train】 epoch：4 step:12317/14065 loss：0.071283
【train】 epoch：4 step:12318/14065 loss：0.058134
【train】 epoch：4 step:12319/14065 loss：0.077566
【train】 epoch：4 step:12320/14065 loss：0.005913
【train】 epoch：4 step:12321/14065 loss：0.089700
【train】 epoch：4 step:12322/14065 loss：0.012063
【train】 epoch：4 step:12323/14065 loss：0.013542
【train】 epoch：4 step:12324/14065 loss：0.018783
【train】 epoch：4 step:12325/14065 loss：0.033690
【train】 epoch：4 step:12326/14065 loss：0.019692
【train】 epoch：4 step:12327/14065 loss：0.031214
【train】 epoch：4 step:12328/14065 loss：0.057368
【train】 epoch：4 step:12329/14065 loss：0.022714
【train】 epoch：4 step:12330/14065 loss：0.027658
【train】 epoch：4 step:12331/14065 loss：0.048733
【train】 epoch：4 step:12332/14065 loss：0.054530
【train】 epoch：4 step:12333/14065 loss：0.075458
【train】 epoch：4 step:12334/14065 loss：0.012080
【train】 epoch：4 step:12335/14065 loss：0.015160
【train】 epoch：4 step:12336/14065 loss：0.020341
【train】 epoch：4 step:12337/14065 loss：0.037820
【train】 epoch：4 step:12338/14065 loss：0.013807
【train】 epoch：4 step:12339/14065 loss：0.041989
【train】 epoch：4 step:12340/14065 loss：0.018247
【train】 epoch：4 step:12341/14065 loss：0.080140
【train】 epoch：4 step:12342/14065 loss：0.041565
【train】 epoch：4 step:12343/14065 loss：0.004331
【train】 epoch：4 step:12344/14065 loss：0.023232
【train】 epoch：4 step:12345/14065 loss：0.080482
【train】 epoch：4 step:12346/14065 loss：0.068469
【train】 epoch：4 step:12347/14065 loss：0.028174
【train】 epoch：4 step:12348/14065 loss：0.013510
【train】 epoch：4 step:12349/14065 loss：0.020418
【train】 epoch：4 step:12350/14065 loss：0.026628
【train】 epoch：4 step:12351/14065 loss：0.011221
【train】 epoch：4 step:12352/14065 loss：0.013130
【train】 epoch：4 step:12353/14065 loss：0.042371
【train】 epoch：4 step:12354/14065 loss：0.008368
【train】 epoch：4 step:12355/14065 loss：0.088429
【train】 epoch：4 step:12356/14065 loss：0.011164
【train】 epoch：4 step:12357/14065 loss：0.042577
【train】 epoch：4 step:12358/14065 loss：0.061142
【train】 epoch：4 step:12359/14065 loss：0.174573
【train】 epoch：4 step:12360/14065 loss：0.014781
【train】 epoch：4 step:12361/14065 loss：0.018846
【train】 epoch：4 step:12362/14065 loss：0.008958
【train】 epoch：4 step:12363/14065 loss：0.004894
【train】 epoch：4 step:12364/14065 loss：0.109865
【train】 epoch：4 step:12365/14065 loss：0.064012
【train】 epoch：4 step:12366/14065 loss：0.154330
【train】 epoch：4 step:12367/14065 loss：0.012151
【train】 epoch：4 step:12368/14065 loss：0.078873
【train】 epoch：4 step:12369/14065 loss：0.030942
【train】 epoch：4 step:12370/14065 loss：0.108826
【train】 epoch：4 step:12371/14065 loss：0.061631
【train】 epoch：4 step:12372/14065 loss：0.179398
【train】 epoch：4 step:12373/14065 loss：0.016412
【train】 epoch：4 step:12374/14065 loss：0.039969
【train】 epoch：4 step:12375/14065 loss：0.001479
【train】 epoch：4 step:12376/14065 loss：0.096734
【train】 epoch：4 step:12377/14065 loss：0.052991
【train】 epoch：4 step:12378/14065 loss：0.123786
【train】 epoch：4 step:12379/14065 loss：0.052043
【train】 epoch：4 step:12380/14065 loss：0.015661
【train】 epoch：4 step:12381/14065 loss：0.175551
【train】 epoch：4 step:12382/14065 loss：0.013220
【train】 epoch：4 step:12383/14065 loss：0.016153
【train】 epoch：4 step:12384/14065 loss：0.078818
【train】 epoch：4 step:12385/14065 loss：0.093732
【train】 epoch：4 step:12386/14065 loss：0.015527
【train】 epoch：4 step:12387/14065 loss：0.070229
【train】 epoch：4 step:12388/14065 loss：0.020091
【train】 epoch：4 step:12389/14065 loss：0.027490
【train】 epoch：4 step:12390/14065 loss：0.153712
【train】 epoch：4 step:12391/14065 loss：0.098876
【train】 epoch：4 step:12392/14065 loss：0.121110
【train】 epoch：4 step:12393/14065 loss：0.082581
【train】 epoch：4 step:12394/14065 loss：0.051793
【train】 epoch：4 step:12395/14065 loss：0.015774
【train】 epoch：4 step:12396/14065 loss：0.058761
【train】 epoch：4 step:12397/14065 loss：0.064574
【train】 epoch：4 step:12398/14065 loss：0.035076
【train】 epoch：4 step:12399/14065 loss：0.006803
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：82.366461 accuracy：0.9910 precision：0.9910 recall：0.9910 f1：0.9910
【train】 epoch：4 step:12400/14065 loss：0.027469
【train】 epoch：4 step:12401/14065 loss：0.063194
【train】 epoch：4 step:12402/14065 loss：0.017360
【train】 epoch：4 step:12403/14065 loss：0.026820
【train】 epoch：4 step:12404/14065 loss：0.044979
【train】 epoch：4 step:12405/14065 loss：0.031563
【train】 epoch：4 step:12406/14065 loss：0.038954
【train】 epoch：4 step:12407/14065 loss：0.077239
【train】 epoch：4 step:12408/14065 loss：0.018001
【train】 epoch：4 step:12409/14065 loss：0.047749
【train】 epoch：4 step:12410/14065 loss：0.025152
【train】 epoch：4 step:12411/14065 loss：0.030912
【train】 epoch：4 step:12412/14065 loss：0.065318
【train】 epoch：4 step:12413/14065 loss：0.100766
【train】 epoch：4 step:12414/14065 loss：0.043251
【train】 epoch：4 step:12415/14065 loss：0.016055
【train】 epoch：4 step:12416/14065 loss：0.022490
【train】 epoch：4 step:12417/14065 loss：0.108025
【train】 epoch：4 step:12418/14065 loss：0.027816
【train】 epoch：4 step:12419/14065 loss：0.010179
【train】 epoch：4 step:12420/14065 loss：0.030681
【train】 epoch：4 step:12421/14065 loss：0.075996
【train】 epoch：4 step:12422/14065 loss：0.023368
【train】 epoch：4 step:12423/14065 loss：0.015162
【train】 epoch：4 step:12424/14065 loss：0.042845
【train】 epoch：4 step:12425/14065 loss：0.026180
【train】 epoch：4 step:12426/14065 loss：0.013293
【train】 epoch：4 step:12427/14065 loss：0.074257
【train】 epoch：4 step:12428/14065 loss：0.109588
【train】 epoch：4 step:12429/14065 loss：0.041398
【train】 epoch：4 step:12430/14065 loss：0.023647
【train】 epoch：4 step:12431/14065 loss：0.033729
【train】 epoch：4 step:12432/14065 loss：0.043759
【train】 epoch：4 step:12433/14065 loss：0.023836
【train】 epoch：4 step:12434/14065 loss：0.076251
【train】 epoch：4 step:12435/14065 loss：0.093432
【train】 epoch：4 step:12436/14065 loss：0.114992
【train】 epoch：4 step:12437/14065 loss：0.139105
【train】 epoch：4 step:12438/14065 loss：0.073952
【train】 epoch：4 step:12439/14065 loss：0.037057
【train】 epoch：4 step:12440/14065 loss：0.070077
【train】 epoch：4 step:12441/14065 loss：0.029315
【train】 epoch：4 step:12442/14065 loss：0.004397
【train】 epoch：4 step:12443/14065 loss：0.031438
【train】 epoch：4 step:12444/14065 loss：0.018278
【train】 epoch：4 step:12445/14065 loss：0.029619
【train】 epoch：4 step:12446/14065 loss：0.022889
【train】 epoch：4 step:12447/14065 loss：0.176780
【train】 epoch：4 step:12448/14065 loss：0.055876
【train】 epoch：4 step:12449/14065 loss：0.057362
【train】 epoch：4 step:12450/14065 loss：0.065321
【train】 epoch：4 step:12451/14065 loss：0.017338
【train】 epoch：4 step:12452/14065 loss：0.007000
【train】 epoch：4 step:12453/14065 loss：0.108844
【train】 epoch：4 step:12454/14065 loss：0.006091
【train】 epoch：4 step:12455/14065 loss：0.074872
【train】 epoch：4 step:12456/14065 loss：0.015665
【train】 epoch：4 step:12457/14065 loss：0.048120
【train】 epoch：4 step:12458/14065 loss：0.024822
【train】 epoch：4 step:12459/14065 loss：0.024757
【train】 epoch：4 step:12460/14065 loss：0.022403
【train】 epoch：4 step:12461/14065 loss：0.030805
【train】 epoch：4 step:12462/14065 loss：0.024525
【train】 epoch：4 step:12463/14065 loss：0.058286
【train】 epoch：4 step:12464/14065 loss：0.027671
【train】 epoch：4 step:12465/14065 loss：0.173937
【train】 epoch：4 step:12466/14065 loss：0.035246
【train】 epoch：4 step:12467/14065 loss：0.055163
【train】 epoch：4 step:12468/14065 loss：0.007751
【train】 epoch：4 step:12469/14065 loss：0.022035
【train】 epoch：4 step:12470/14065 loss：0.057637
【train】 epoch：4 step:12471/14065 loss：0.099406
【train】 epoch：4 step:12472/14065 loss：0.033819
【train】 epoch：4 step:12473/14065 loss：0.039715
【train】 epoch：4 step:12474/14065 loss：0.018533
【train】 epoch：4 step:12475/14065 loss：0.019755
【train】 epoch：4 step:12476/14065 loss：0.070856
【train】 epoch：4 step:12477/14065 loss：0.111724
【train】 epoch：4 step:12478/14065 loss：0.029980
【train】 epoch：4 step:12479/14065 loss：0.047289
【train】 epoch：4 step:12480/14065 loss：0.007936
【train】 epoch：4 step:12481/14065 loss：0.011217
【train】 epoch：4 step:12482/14065 loss：0.058816
【train】 epoch：4 step:12483/14065 loss：0.038015
【train】 epoch：4 step:12484/14065 loss：0.039143
【train】 epoch：4 step:12485/14065 loss：0.215219
【train】 epoch：4 step:12486/14065 loss：0.021279
【train】 epoch：4 step:12487/14065 loss：0.014199
【train】 epoch：4 step:12488/14065 loss：0.100264
【train】 epoch：4 step:12489/14065 loss：0.096870
【train】 epoch：4 step:12490/14065 loss：0.061001
【train】 epoch：4 step:12491/14065 loss：0.085795
【train】 epoch：4 step:12492/14065 loss：0.096090
【train】 epoch：4 step:12493/14065 loss：0.007471
【train】 epoch：4 step:12494/14065 loss：0.039569
【train】 epoch：4 step:12495/14065 loss：0.011964
【train】 epoch：4 step:12496/14065 loss：0.061327
【train】 epoch：4 step:12497/14065 loss：0.025088
【train】 epoch：4 step:12498/14065 loss：0.022439
【train】 epoch：4 step:12499/14065 loss：0.257978
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：79.424769 accuracy：0.9910 precision：0.9910 recall：0.9910 f1：0.9910
【train】 epoch：4 step:12500/14065 loss：0.166326
【train】 epoch：4 step:12501/14065 loss：0.044266
【train】 epoch：4 step:12502/14065 loss：0.035434
【train】 epoch：4 step:12503/14065 loss：0.009589
【train】 epoch：4 step:12504/14065 loss：0.008555
【train】 epoch：4 step:12505/14065 loss：0.105829
【train】 epoch：4 step:12506/14065 loss：0.176653
【train】 epoch：4 step:12507/14065 loss：0.023507
【train】 epoch：4 step:12508/14065 loss：0.010841
【train】 epoch：4 step:12509/14065 loss：0.010825
【train】 epoch：4 step:12510/14065 loss：0.182024
【train】 epoch：4 step:12511/14065 loss：0.017622
【train】 epoch：4 step:12512/14065 loss：0.109886
【train】 epoch：4 step:12513/14065 loss：0.013651
【train】 epoch：4 step:12514/14065 loss：0.020529
【train】 epoch：4 step:12515/14065 loss：0.211424
【train】 epoch：4 step:12516/14065 loss：0.260689
【train】 epoch：4 step:12517/14065 loss：0.067406
【train】 epoch：4 step:12518/14065 loss：0.029716
【train】 epoch：4 step:12519/14065 loss：0.058057
【train】 epoch：4 step:12520/14065 loss：0.013538
【train】 epoch：4 step:12521/14065 loss：0.087835
【train】 epoch：4 step:12522/14065 loss：0.019537
【train】 epoch：4 step:12523/14065 loss：0.028083
【train】 epoch：4 step:12524/14065 loss：0.017408
【train】 epoch：4 step:12525/14065 loss：0.041923
【train】 epoch：4 step:12526/14065 loss：0.115728
【train】 epoch：4 step:12527/14065 loss：0.037281
【train】 epoch：4 step:12528/14065 loss：0.138860
【train】 epoch：4 step:12529/14065 loss：0.101373
【train】 epoch：4 step:12530/14065 loss：0.022886
【train】 epoch：4 step:12531/14065 loss：0.136759
【train】 epoch：4 step:12532/14065 loss：0.032665
【train】 epoch：4 step:12533/14065 loss：0.046900
【train】 epoch：4 step:12534/14065 loss：0.026776
【train】 epoch：4 step:12535/14065 loss：0.050163
【train】 epoch：4 step:12536/14065 loss：0.049369
【train】 epoch：4 step:12537/14065 loss：0.008412
【train】 epoch：4 step:12538/14065 loss：0.035093
【train】 epoch：4 step:12539/14065 loss：0.059075
【train】 epoch：4 step:12540/14065 loss：0.109052
【train】 epoch：4 step:12541/14065 loss：0.062717
【train】 epoch：4 step:12542/14065 loss：0.020279
【train】 epoch：4 step:12543/14065 loss：0.034890
【train】 epoch：4 step:12544/14065 loss：0.014916
【train】 epoch：4 step:12545/14065 loss：0.044514
【train】 epoch：4 step:12546/14065 loss：0.056709
【train】 epoch：4 step:12547/14065 loss：0.026211
【train】 epoch：4 step:12548/14065 loss：0.038321
【train】 epoch：4 step:12549/14065 loss：0.057958
【train】 epoch：4 step:12550/14065 loss：0.041355
【train】 epoch：4 step:12551/14065 loss：0.004111
【train】 epoch：4 step:12552/14065 loss：0.008912
【train】 epoch：4 step:12553/14065 loss：0.048794
【train】 epoch：4 step:12554/14065 loss：0.008771
【train】 epoch：4 step:12555/14065 loss：0.053273
【train】 epoch：4 step:12556/14065 loss：0.024439
【train】 epoch：4 step:12557/14065 loss：0.125454
【train】 epoch：4 step:12558/14065 loss：0.006380
【train】 epoch：4 step:12559/14065 loss：0.090940
【train】 epoch：4 step:12560/14065 loss：0.027164
【train】 epoch：4 step:12561/14065 loss：0.030838
【train】 epoch：4 step:12562/14065 loss：0.131783
【train】 epoch：4 step:12563/14065 loss：0.098695
【train】 epoch：4 step:12564/14065 loss：0.032595
【train】 epoch：4 step:12565/14065 loss：0.009563
【train】 epoch：4 step:12566/14065 loss：0.016475
【train】 epoch：4 step:12567/14065 loss：0.034176
【train】 epoch：4 step:12568/14065 loss：0.048557
【train】 epoch：4 step:12569/14065 loss：0.040884
【train】 epoch：4 step:12570/14065 loss：0.006248
【train】 epoch：4 step:12571/14065 loss：0.021782
【train】 epoch：4 step:12572/14065 loss：0.026493
【train】 epoch：4 step:12573/14065 loss：0.023686
【train】 epoch：4 step:12574/14065 loss：0.010944
【train】 epoch：4 step:12575/14065 loss：0.052857
【train】 epoch：4 step:12576/14065 loss：0.114094
【train】 epoch：4 step:12577/14065 loss：0.194022
【train】 epoch：4 step:12578/14065 loss：0.038935
【train】 epoch：4 step:12579/14065 loss：0.110325
【train】 epoch：4 step:12580/14065 loss：0.046789
【train】 epoch：4 step:12581/14065 loss：0.011346
【train】 epoch：4 step:12582/14065 loss：0.034463
【train】 epoch：4 step:12583/14065 loss：0.053604
【train】 epoch：4 step:12584/14065 loss：0.057711
【train】 epoch：4 step:12585/14065 loss：0.059282
【train】 epoch：4 step:12586/14065 loss：0.012431
【train】 epoch：4 step:12587/14065 loss：0.076680
【train】 epoch：4 step:12588/14065 loss：0.007688
【train】 epoch：4 step:12589/14065 loss：0.008692
【train】 epoch：4 step:12590/14065 loss：0.060527
【train】 epoch：4 step:12591/14065 loss：0.012904
【train】 epoch：4 step:12592/14065 loss：0.006980
【train】 epoch：4 step:12593/14065 loss：0.037382
【train】 epoch：4 step:12594/14065 loss：0.043364
【train】 epoch：4 step:12595/14065 loss：0.059417
【train】 epoch：4 step:12596/14065 loss：0.079502
【train】 epoch：4 step:12597/14065 loss：0.066019
【train】 epoch：4 step:12598/14065 loss：0.014556
【train】 epoch：4 step:12599/14065 loss：0.005685
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：110.899565 accuracy：0.9866 precision：0.9866 recall：0.9866 f1：0.9866
【train】 epoch：4 step:12600/14065 loss：0.011138
【train】 epoch：4 step:12601/14065 loss：0.099399
【train】 epoch：4 step:12602/14065 loss：0.035892
【train】 epoch：4 step:12603/14065 loss：0.127769
【train】 epoch：4 step:12604/14065 loss：0.054375
【train】 epoch：4 step:12605/14065 loss：0.047820
【train】 epoch：4 step:12606/14065 loss：0.104903
【train】 epoch：4 step:12607/14065 loss：0.080359
【train】 epoch：4 step:12608/14065 loss：0.121859
【train】 epoch：4 step:12609/14065 loss：0.058630
【train】 epoch：4 step:12610/14065 loss：0.005208
【train】 epoch：4 step:12611/14065 loss：0.016062
【train】 epoch：4 step:12612/14065 loss：0.030088
【train】 epoch：4 step:12613/14065 loss：0.040698
【train】 epoch：4 step:12614/14065 loss：0.085564
【train】 epoch：4 step:12615/14065 loss：0.053927
【train】 epoch：4 step:12616/14065 loss：0.015532
【train】 epoch：4 step:12617/14065 loss：0.022012
【train】 epoch：4 step:12618/14065 loss：0.060328
【train】 epoch：4 step:12619/14065 loss：0.107332
【train】 epoch：4 step:12620/14065 loss：0.096690
【train】 epoch：4 step:12621/14065 loss：0.036089
【train】 epoch：4 step:12622/14065 loss：0.007735
【train】 epoch：4 step:12623/14065 loss：0.110402
【train】 epoch：4 step:12624/14065 loss：0.017645
【train】 epoch：4 step:12625/14065 loss：0.168306
【train】 epoch：4 step:12626/14065 loss：0.047597
【train】 epoch：4 step:12627/14065 loss：0.046437
【train】 epoch：4 step:12628/14065 loss：0.120016
【train】 epoch：4 step:12629/14065 loss：0.008749
【train】 epoch：4 step:12630/14065 loss：0.022253
【train】 epoch：4 step:12631/14065 loss：0.023716
【train】 epoch：4 step:12632/14065 loss：0.043093
【train】 epoch：4 step:12633/14065 loss：0.050865
【train】 epoch：4 step:12634/14065 loss：0.186947
【train】 epoch：4 step:12635/14065 loss：0.028808
【train】 epoch：4 step:12636/14065 loss：0.007942
【train】 epoch：4 step:12637/14065 loss：0.193590
【train】 epoch：4 step:12638/14065 loss：0.033512
【train】 epoch：4 step:12639/14065 loss：0.092568
【train】 epoch：4 step:12640/14065 loss：0.016975
【train】 epoch：4 step:12641/14065 loss：0.021530
【train】 epoch：4 step:12642/14065 loss：0.092251
【train】 epoch：4 step:12643/14065 loss：0.122571
【train】 epoch：4 step:12644/14065 loss：0.066010
【train】 epoch：4 step:12645/14065 loss：0.042543
【train】 epoch：4 step:12646/14065 loss：0.066414
【train】 epoch：4 step:12647/14065 loss：0.022312
【train】 epoch：4 step:12648/14065 loss：0.053926
【train】 epoch：4 step:12649/14065 loss：0.066657
【train】 epoch：4 step:12650/14065 loss：0.049842
【train】 epoch：4 step:12651/14065 loss：0.039875
【train】 epoch：4 step:12652/14065 loss：0.105899
【train】 epoch：4 step:12653/14065 loss：0.049864
【train】 epoch：4 step:12654/14065 loss：0.012280
【train】 epoch：4 step:12655/14065 loss：0.013764
【train】 epoch：4 step:12656/14065 loss：0.095530
【train】 epoch：4 step:12657/14065 loss：0.017255
【train】 epoch：4 step:12658/14065 loss：0.093721
【train】 epoch：4 step:12659/14065 loss：0.098311
【train】 epoch：4 step:12660/14065 loss：0.093882
【train】 epoch：4 step:12661/14065 loss：0.197460
【train】 epoch：4 step:12662/14065 loss：0.045156
【train】 epoch：4 step:12663/14065 loss：0.008063
【train】 epoch：4 step:12664/14065 loss：0.038429
【train】 epoch：4 step:12665/14065 loss：0.018080
【train】 epoch：4 step:12666/14065 loss：0.011068
【train】 epoch：4 step:12667/14065 loss：0.144129
【train】 epoch：4 step:12668/14065 loss：0.048118
【train】 epoch：4 step:12669/14065 loss：0.036098
【train】 epoch：4 step:12670/14065 loss：0.061064
【train】 epoch：4 step:12671/14065 loss：0.030458
【train】 epoch：4 step:12672/14065 loss：0.046209
【train】 epoch：4 step:12673/14065 loss：0.009048
【train】 epoch：4 step:12674/14065 loss：0.053067
【train】 epoch：4 step:12675/14065 loss：0.074227
【train】 epoch：4 step:12676/14065 loss：0.009340
【train】 epoch：4 step:12677/14065 loss：0.021220
【train】 epoch：4 step:12678/14065 loss：0.062961
【train】 epoch：4 step:12679/14065 loss：0.009856
【train】 epoch：4 step:12680/14065 loss：0.057614
【train】 epoch：4 step:12681/14065 loss：0.004443
【train】 epoch：4 step:12682/14065 loss：0.031928
【train】 epoch：4 step:12683/14065 loss：0.029514
【train】 epoch：4 step:12684/14065 loss：0.085285
【train】 epoch：4 step:12685/14065 loss：0.001965
【train】 epoch：4 step:12686/14065 loss：0.017651
【train】 epoch：4 step:12687/14065 loss：0.053912
【train】 epoch：4 step:12688/14065 loss：0.043747
【train】 epoch：4 step:12689/14065 loss：0.181834
【train】 epoch：4 step:12690/14065 loss：0.103495
【train】 epoch：4 step:12691/14065 loss：0.005513
【train】 epoch：4 step:12692/14065 loss：0.028728
【train】 epoch：4 step:12693/14065 loss：0.066096
【train】 epoch：4 step:12694/14065 loss：0.009718
【train】 epoch：4 step:12695/14065 loss：0.010312
【train】 epoch：4 step:12696/14065 loss：0.094890
【train】 epoch：4 step:12697/14065 loss：0.022493
【train】 epoch：4 step:12698/14065 loss：0.194479
【train】 epoch：4 step:12699/14065 loss：0.010638
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：88.745137 accuracy：0.9898 precision：0.9898 recall：0.9898 f1：0.9898
【train】 epoch：4 step:12700/14065 loss：0.168896
【train】 epoch：4 step:12701/14065 loss：0.011656
【train】 epoch：4 step:12702/14065 loss：0.015738
【train】 epoch：4 step:12703/14065 loss：0.024946
【train】 epoch：4 step:12704/14065 loss：0.019025
【train】 epoch：4 step:12705/14065 loss：0.028580
【train】 epoch：4 step:12706/14065 loss：0.032513
【train】 epoch：4 step:12707/14065 loss：0.005796
【train】 epoch：4 step:12708/14065 loss：0.194320
【train】 epoch：4 step:12709/14065 loss：0.072645
【train】 epoch：4 step:12710/14065 loss：0.006972
【train】 epoch：4 step:12711/14065 loss：0.012412
【train】 epoch：4 step:12712/14065 loss：0.013436
【train】 epoch：4 step:12713/14065 loss：0.026734
【train】 epoch：4 step:12714/14065 loss：0.007443
【train】 epoch：4 step:12715/14065 loss：0.046473
【train】 epoch：4 step:12716/14065 loss：0.019826
【train】 epoch：4 step:12717/14065 loss：0.012356
【train】 epoch：4 step:12718/14065 loss：0.079723
【train】 epoch：4 step:12719/14065 loss：0.021709
【train】 epoch：4 step:12720/14065 loss：0.031594
【train】 epoch：4 step:12721/14065 loss：0.004271
【train】 epoch：4 step:12722/14065 loss：0.016442
【train】 epoch：4 step:12723/14065 loss：0.076880
【train】 epoch：4 step:12724/14065 loss：0.043416
【train】 epoch：4 step:12725/14065 loss：0.021318
【train】 epoch：4 step:12726/14065 loss：0.012817
【train】 epoch：4 step:12727/14065 loss：0.084843
【train】 epoch：4 step:12728/14065 loss：0.009442
【train】 epoch：4 step:12729/14065 loss：0.043457
【train】 epoch：4 step:12730/14065 loss：0.041737
【train】 epoch：4 step:12731/14065 loss：0.116246
【train】 epoch：4 step:12732/14065 loss：0.138796
【train】 epoch：4 step:12733/14065 loss：0.095036
【train】 epoch：4 step:12734/14065 loss：0.085819
【train】 epoch：4 step:12735/14065 loss：0.016024
【train】 epoch：4 step:12736/14065 loss：0.003537
【train】 epoch：4 step:12737/14065 loss：0.099004
【train】 epoch：4 step:12738/14065 loss：0.041389
【train】 epoch：4 step:12739/14065 loss：0.090928
【train】 epoch：4 step:12740/14065 loss：0.035504
【train】 epoch：4 step:12741/14065 loss：0.047089
【train】 epoch：4 step:12742/14065 loss：0.089577
【train】 epoch：4 step:12743/14065 loss：0.075957
【train】 epoch：4 step:12744/14065 loss：0.022433
【train】 epoch：4 step:12745/14065 loss：0.068473
【train】 epoch：4 step:12746/14065 loss：0.015978
【train】 epoch：4 step:12747/14065 loss：0.034697
【train】 epoch：4 step:12748/14065 loss：0.016720
【train】 epoch：4 step:12749/14065 loss：0.083278
【train】 epoch：4 step:12750/14065 loss：0.020801
【train】 epoch：4 step:12751/14065 loss：0.059886
【train】 epoch：4 step:12752/14065 loss：0.021426
【train】 epoch：4 step:12753/14065 loss：0.090314
【train】 epoch：4 step:12754/14065 loss：0.038339
【train】 epoch：4 step:12755/14065 loss：0.009935
【train】 epoch：4 step:12756/14065 loss：0.068392
【train】 epoch：4 step:12757/14065 loss：0.013664
【train】 epoch：4 step:12758/14065 loss：0.021980
【train】 epoch：4 step:12759/14065 loss：0.017537
【train】 epoch：4 step:12760/14065 loss：0.030335
【train】 epoch：4 step:12761/14065 loss：0.085219
【train】 epoch：4 step:12762/14065 loss：0.032693
【train】 epoch：4 step:12763/14065 loss：0.114909
【train】 epoch：4 step:12764/14065 loss：0.011604
【train】 epoch：4 step:12765/14065 loss：0.005825
【train】 epoch：4 step:12766/14065 loss：0.024925
【train】 epoch：4 step:12767/14065 loss：0.008425
【train】 epoch：4 step:12768/14065 loss：0.029669
【train】 epoch：4 step:12769/14065 loss：0.106390
【train】 epoch：4 step:12770/14065 loss：0.010561
【train】 epoch：4 step:12771/14065 loss：0.035352
【train】 epoch：4 step:12772/14065 loss：0.088392
【train】 epoch：4 step:12773/14065 loss：0.069830
【train】 epoch：4 step:12774/14065 loss：0.017997
【train】 epoch：4 step:12775/14065 loss：0.024076
【train】 epoch：4 step:12776/14065 loss：0.072348
【train】 epoch：4 step:12777/14065 loss：0.029736
【train】 epoch：4 step:12778/14065 loss：0.004428
【train】 epoch：4 step:12779/14065 loss：0.037600
【train】 epoch：4 step:12780/14065 loss：0.037114
【train】 epoch：4 step:12781/14065 loss：0.103596
【train】 epoch：4 step:12782/14065 loss：0.032246
【train】 epoch：4 step:12783/14065 loss：0.127579
【train】 epoch：4 step:12784/14065 loss：0.154006
【train】 epoch：4 step:12785/14065 loss：0.022108
【train】 epoch：4 step:12786/14065 loss：0.107331
【train】 epoch：4 step:12787/14065 loss：0.010032
【train】 epoch：4 step:12788/14065 loss：0.109621
【train】 epoch：4 step:12789/14065 loss：0.015035
【train】 epoch：4 step:12790/14065 loss：0.040366
【train】 epoch：4 step:12791/14065 loss：0.104308
【train】 epoch：4 step:12792/14065 loss：0.068267
【train】 epoch：4 step:12793/14065 loss：0.026447
【train】 epoch：4 step:12794/14065 loss：0.022112
【train】 epoch：4 step:12795/14065 loss：0.038432
【train】 epoch：4 step:12796/14065 loss：0.095998
【train】 epoch：4 step:12797/14065 loss：0.011993
【train】 epoch：4 step:12798/14065 loss：0.057954
【train】 epoch：4 step:12799/14065 loss：0.052383
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：76.682334 accuracy：0.9912 precision：0.9912 recall：0.9912 f1：0.9912
【train】 epoch：4 step:12800/14065 loss：0.035529
【train】 epoch：4 step:12801/14065 loss：0.056409
【train】 epoch：4 step:12802/14065 loss：0.033452
【train】 epoch：4 step:12803/14065 loss：0.065611
【train】 epoch：4 step:12804/14065 loss：0.071893
【train】 epoch：4 step:12805/14065 loss：0.061059
【train】 epoch：4 step:12806/14065 loss：0.046805
【train】 epoch：4 step:12807/14065 loss：0.010811
【train】 epoch：4 step:12808/14065 loss：0.063234
【train】 epoch：4 step:12809/14065 loss：0.030767
【train】 epoch：4 step:12810/14065 loss：0.211276
【train】 epoch：4 step:12811/14065 loss：0.010397
【train】 epoch：4 step:12812/14065 loss：0.039807
【train】 epoch：4 step:12813/14065 loss：0.095469
【train】 epoch：4 step:12814/14065 loss：0.224980
【train】 epoch：4 step:12815/14065 loss：0.019173
【train】 epoch：4 step:12816/14065 loss：0.103575
【train】 epoch：4 step:12817/14065 loss：0.066368
【train】 epoch：4 step:12818/14065 loss：0.176166
【train】 epoch：4 step:12819/14065 loss：0.146190
【train】 epoch：4 step:12820/14065 loss：0.019637
【train】 epoch：4 step:12821/14065 loss：0.145303
【train】 epoch：4 step:12822/14065 loss：0.025320
【train】 epoch：4 step:12823/14065 loss：0.082425
【train】 epoch：4 step:12824/14065 loss：0.064287
【train】 epoch：4 step:12825/14065 loss：0.039222
【train】 epoch：4 step:12826/14065 loss：0.010470
【train】 epoch：4 step:12827/14065 loss：0.091421
【train】 epoch：4 step:12828/14065 loss：0.028906
【train】 epoch：4 step:12829/14065 loss：0.005272
【train】 epoch：4 step:12830/14065 loss：0.046364
【train】 epoch：4 step:12831/14065 loss：0.026308
【train】 epoch：4 step:12832/14065 loss：0.043916
【train】 epoch：4 step:12833/14065 loss：0.140211
【train】 epoch：4 step:12834/14065 loss：0.019600
【train】 epoch：4 step:12835/14065 loss：0.072143
【train】 epoch：4 step:12836/14065 loss：0.018766
【train】 epoch：4 step:12837/14065 loss：0.008417
【train】 epoch：4 step:12838/14065 loss：0.023031
【train】 epoch：4 step:12839/14065 loss：0.141810
【train】 epoch：4 step:12840/14065 loss：0.022119
【train】 epoch：4 step:12841/14065 loss：0.053656
【train】 epoch：4 step:12842/14065 loss：0.160819
【train】 epoch：4 step:12843/14065 loss：0.016735
【train】 epoch：4 step:12844/14065 loss：0.093258
【train】 epoch：4 step:12845/14065 loss：0.212079
【train】 epoch：4 step:12846/14065 loss：0.041504
【train】 epoch：4 step:12847/14065 loss：0.039338
【train】 epoch：4 step:12848/14065 loss：0.027894
【train】 epoch：4 step:12849/14065 loss：0.099915
【train】 epoch：4 step:12850/14065 loss：0.014525
【train】 epoch：4 step:12851/14065 loss：0.055739
【train】 epoch：4 step:12852/14065 loss：0.054149
【train】 epoch：4 step:12853/14065 loss：0.035880
【train】 epoch：4 step:12854/14065 loss：0.072076
【train】 epoch：4 step:12855/14065 loss：0.025767
【train】 epoch：4 step:12856/14065 loss：0.040052
【train】 epoch：4 step:12857/14065 loss：0.034588
【train】 epoch：4 step:12858/14065 loss：0.046546
【train】 epoch：4 step:12859/14065 loss：0.060477
【train】 epoch：4 step:12860/14065 loss：0.131349
【train】 epoch：4 step:12861/14065 loss：0.006353
【train】 epoch：4 step:12862/14065 loss：0.076470
【train】 epoch：4 step:12863/14065 loss：0.079159
【train】 epoch：4 step:12864/14065 loss：0.050500
【train】 epoch：4 step:12865/14065 loss：0.035055
【train】 epoch：4 step:12866/14065 loss：0.165668
【train】 epoch：4 step:12867/14065 loss：0.022213
【train】 epoch：4 step:12868/14065 loss：0.070420
【train】 epoch：4 step:12869/14065 loss：0.053910
【train】 epoch：4 step:12870/14065 loss：0.018409
【train】 epoch：4 step:12871/14065 loss：0.019155
【train】 epoch：4 step:12872/14065 loss：0.060313
【train】 epoch：4 step:12873/14065 loss：0.046707
【train】 epoch：4 step:12874/14065 loss：0.015687
【train】 epoch：4 step:12875/14065 loss：0.011052
【train】 epoch：4 step:12876/14065 loss：0.069529
【train】 epoch：4 step:12877/14065 loss：0.021810
【train】 epoch：4 step:12878/14065 loss：0.073280
【train】 epoch：4 step:12879/14065 loss：0.067171
【train】 epoch：4 step:12880/14065 loss：0.010552
【train】 epoch：4 step:12881/14065 loss：0.067120
【train】 epoch：4 step:12882/14065 loss：0.036157
【train】 epoch：4 step:12883/14065 loss：0.125647
【train】 epoch：4 step:12884/14065 loss：0.020684
【train】 epoch：4 step:12885/14065 loss：0.009069
【train】 epoch：4 step:12886/14065 loss：0.018340
【train】 epoch：4 step:12887/14065 loss：0.042940
【train】 epoch：4 step:12888/14065 loss：0.031765
【train】 epoch：4 step:12889/14065 loss：0.022920
【train】 epoch：4 step:12890/14065 loss：0.035724
【train】 epoch：4 step:12891/14065 loss：0.039114
【train】 epoch：4 step:12892/14065 loss：0.065172
【train】 epoch：4 step:12893/14065 loss：0.007598
【train】 epoch：4 step:12894/14065 loss：0.045217
【train】 epoch：4 step:12895/14065 loss：0.037338
【train】 epoch：4 step:12896/14065 loss：0.018062
【train】 epoch：4 step:12897/14065 loss：0.078199
【train】 epoch：4 step:12898/14065 loss：0.113148
【train】 epoch：4 step:12899/14065 loss：0.055287
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：88.753794 accuracy：0.9903 precision：0.9903 recall：0.9903 f1：0.9903
【train】 epoch：4 step:12900/14065 loss：0.030156
【train】 epoch：4 step:12901/14065 loss：0.009326
【train】 epoch：4 step:12902/14065 loss：0.013666
【train】 epoch：4 step:12903/14065 loss：0.015596
【train】 epoch：4 step:12904/14065 loss：0.054899
【train】 epoch：4 step:12905/14065 loss：0.011037
【train】 epoch：4 step:12906/14065 loss：0.038293
【train】 epoch：4 step:12907/14065 loss：0.022850
【train】 epoch：4 step:12908/14065 loss：0.104009
【train】 epoch：4 step:12909/14065 loss：0.030818
【train】 epoch：4 step:12910/14065 loss：0.007939
【train】 epoch：4 step:12911/14065 loss：0.060902
【train】 epoch：4 step:12912/14065 loss：0.005488
【train】 epoch：4 step:12913/14065 loss：0.031606
【train】 epoch：4 step:12914/14065 loss：0.067831
【train】 epoch：4 step:12915/14065 loss：0.106667
【train】 epoch：4 step:12916/14065 loss：0.041119
【train】 epoch：4 step:12917/14065 loss：0.038955
【train】 epoch：4 step:12918/14065 loss：0.086627
【train】 epoch：4 step:12919/14065 loss：0.008274
【train】 epoch：4 step:12920/14065 loss：0.015973
【train】 epoch：4 step:12921/14065 loss：0.023936
【train】 epoch：4 step:12922/14065 loss：0.049536
【train】 epoch：4 step:12923/14065 loss：0.113753
【train】 epoch：4 step:12924/14065 loss：0.161829
【train】 epoch：4 step:12925/14065 loss：0.172505
【train】 epoch：4 step:12926/14065 loss：0.032762
【train】 epoch：4 step:12927/14065 loss：0.058362
【train】 epoch：4 step:12928/14065 loss：0.139039
【train】 epoch：4 step:12929/14065 loss：0.014577
【train】 epoch：4 step:12930/14065 loss：0.063606
【train】 epoch：4 step:12931/14065 loss：0.031236
【train】 epoch：4 step:12932/14065 loss：0.038104
【train】 epoch：4 step:12933/14065 loss：0.041778
【train】 epoch：4 step:12934/14065 loss：0.007205
【train】 epoch：4 step:12935/14065 loss：0.017654
【train】 epoch：4 step:12936/14065 loss：0.027732
【train】 epoch：4 step:12937/14065 loss：0.034880
【train】 epoch：4 step:12938/14065 loss：0.083974
【train】 epoch：4 step:12939/14065 loss：0.028512
【train】 epoch：4 step:12940/14065 loss：0.046572
【train】 epoch：4 step:12941/14065 loss：0.026621
【train】 epoch：4 step:12942/14065 loss：0.004987
【train】 epoch：4 step:12943/14065 loss：0.060150
【train】 epoch：4 step:12944/14065 loss：0.061852
【train】 epoch：4 step:12945/14065 loss：0.058782
【train】 epoch：4 step:12946/14065 loss：0.046430
【train】 epoch：4 step:12947/14065 loss：0.019482
【train】 epoch：4 step:12948/14065 loss：0.011092
【train】 epoch：4 step:12949/14065 loss：0.022905
【train】 epoch：4 step:12950/14065 loss：0.027093
【train】 epoch：4 step:12951/14065 loss：0.131607
【train】 epoch：4 step:12952/14065 loss：0.046200
【train】 epoch：4 step:12953/14065 loss：0.115660
【train】 epoch：4 step:12954/14065 loss：0.029813
【train】 epoch：4 step:12955/14065 loss：0.158007
【train】 epoch：4 step:12956/14065 loss：0.132312
【train】 epoch：4 step:12957/14065 loss：0.034177
【train】 epoch：4 step:12958/14065 loss：0.011075
【train】 epoch：4 step:12959/14065 loss：0.019612
【train】 epoch：4 step:12960/14065 loss：0.007919
【train】 epoch：4 step:12961/14065 loss：0.028528
【train】 epoch：4 step:12962/14065 loss：0.075105
【train】 epoch：4 step:12963/14065 loss：0.029336
【train】 epoch：4 step:12964/14065 loss：0.022657
【train】 epoch：4 step:12965/14065 loss：0.156942
【train】 epoch：4 step:12966/14065 loss：0.056934
【train】 epoch：4 step:12967/14065 loss：0.080271
【train】 epoch：4 step:12968/14065 loss：0.034820
【train】 epoch：4 step:12969/14065 loss：0.089543
【train】 epoch：4 step:12970/14065 loss：0.082878
【train】 epoch：4 step:12971/14065 loss：0.017071
【train】 epoch：4 step:12972/14065 loss：0.028321
【train】 epoch：4 step:12973/14065 loss：0.143128
【train】 epoch：4 step:12974/14065 loss：0.125061
【train】 epoch：4 step:12975/14065 loss：0.024080
【train】 epoch：4 step:12976/14065 loss：0.036027
【train】 epoch：4 step:12977/14065 loss：0.163679
【train】 epoch：4 step:12978/14065 loss：0.033650
【train】 epoch：4 step:12979/14065 loss：0.060603
【train】 epoch：4 step:12980/14065 loss：0.020571
【train】 epoch：4 step:12981/14065 loss：0.064351
【train】 epoch：4 step:12982/14065 loss：0.036465
【train】 epoch：4 step:12983/14065 loss：0.037260
【train】 epoch：4 step:12984/14065 loss：0.092091
【train】 epoch：4 step:12985/14065 loss：0.040682
【train】 epoch：4 step:12986/14065 loss：0.008746
【train】 epoch：4 step:12987/14065 loss：0.105560
【train】 epoch：4 step:12988/14065 loss：0.098164
【train】 epoch：4 step:12989/14065 loss：0.032452
【train】 epoch：4 step:12990/14065 loss：0.043319
【train】 epoch：4 step:12991/14065 loss：0.056617
【train】 epoch：4 step:12992/14065 loss：0.032093
【train】 epoch：4 step:12993/14065 loss：0.010264
【train】 epoch：4 step:12994/14065 loss：0.064943
【train】 epoch：4 step:12995/14065 loss：0.024770
【train】 epoch：4 step:12996/14065 loss：0.080419
【train】 epoch：4 step:12997/14065 loss：0.114319
【train】 epoch：4 step:12998/14065 loss：0.124784
【train】 epoch：4 step:12999/14065 loss：0.021869
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：67.737441 accuracy：0.9928 precision：0.9928 recall：0.9928 f1：0.9928
------------>保存当前最好的模型
【train】 epoch：4 step:13000/14065 loss：0.018605
【train】 epoch：4 step:13001/14065 loss：0.026548
【train】 epoch：4 step:13002/14065 loss：0.006066
【train】 epoch：4 step:13003/14065 loss：0.019374
【train】 epoch：4 step:13004/14065 loss：0.024489
【train】 epoch：4 step:13005/14065 loss：0.016356
【train】 epoch：4 step:13006/14065 loss：0.017130
【train】 epoch：4 step:13007/14065 loss：0.046821
【train】 epoch：4 step:13008/14065 loss：0.067275
【train】 epoch：4 step:13009/14065 loss：0.052705
【train】 epoch：4 step:13010/14065 loss：0.014922
【train】 epoch：4 step:13011/14065 loss：0.013985
【train】 epoch：4 step:13012/14065 loss：0.067500
【train】 epoch：4 step:13013/14065 loss：0.062220
【train】 epoch：4 step:13014/14065 loss：0.034423
【train】 epoch：4 step:13015/14065 loss：0.002940
【train】 epoch：4 step:13016/14065 loss：0.020447
【train】 epoch：4 step:13017/14065 loss：0.118709
【train】 epoch：4 step:13018/14065 loss：0.132376
【train】 epoch：4 step:13019/14065 loss：0.058439
【train】 epoch：4 step:13020/14065 loss：0.027348
【train】 epoch：4 step:13021/14065 loss：0.017578
【train】 epoch：4 step:13022/14065 loss：0.025868
【train】 epoch：4 step:13023/14065 loss：0.007868
【train】 epoch：4 step:13024/14065 loss：0.049397
【train】 epoch：4 step:13025/14065 loss：0.013410
【train】 epoch：4 step:13026/14065 loss：0.163613
【train】 epoch：4 step:13027/14065 loss：0.020909
【train】 epoch：4 step:13028/14065 loss：0.150116
【train】 epoch：4 step:13029/14065 loss：0.033861
【train】 epoch：4 step:13030/14065 loss：0.185149
【train】 epoch：4 step:13031/14065 loss：0.029818
【train】 epoch：4 step:13032/14065 loss：0.163508
【train】 epoch：4 step:13033/14065 loss：0.098220
【train】 epoch：4 step:13034/14065 loss：0.003824
【train】 epoch：4 step:13035/14065 loss：0.151449
【train】 epoch：4 step:13036/14065 loss：0.020315
【train】 epoch：4 step:13037/14065 loss：0.053427
【train】 epoch：4 step:13038/14065 loss：0.051738
【train】 epoch：4 step:13039/14065 loss：0.105892
【train】 epoch：4 step:13040/14065 loss：0.024228
【train】 epoch：4 step:13041/14065 loss：0.008925
【train】 epoch：4 step:13042/14065 loss：0.053042
【train】 epoch：4 step:13043/14065 loss：0.028877
【train】 epoch：4 step:13044/14065 loss：0.024501
【train】 epoch：4 step:13045/14065 loss：0.041593
【train】 epoch：4 step:13046/14065 loss：0.072330
【train】 epoch：4 step:13047/14065 loss：0.058514
【train】 epoch：4 step:13048/14065 loss：0.137181
【train】 epoch：4 step:13049/14065 loss：0.026108
【train】 epoch：4 step:13050/14065 loss：0.048821
【train】 epoch：4 step:13051/14065 loss：0.045474
【train】 epoch：4 step:13052/14065 loss：0.094785
【train】 epoch：4 step:13053/14065 loss：0.151415
【train】 epoch：4 step:13054/14065 loss：0.051289
【train】 epoch：4 step:13055/14065 loss：0.022641
【train】 epoch：4 step:13056/14065 loss：0.061475
【train】 epoch：4 step:13057/14065 loss：0.108594
【train】 epoch：4 step:13058/14065 loss：0.011847
【train】 epoch：4 step:13059/14065 loss：0.048454
【train】 epoch：4 step:13060/14065 loss：0.028648
【train】 epoch：4 step:13061/14065 loss：0.045867
【train】 epoch：4 step:13062/14065 loss：0.073723
【train】 epoch：4 step:13063/14065 loss：0.015184
【train】 epoch：4 step:13064/14065 loss：0.091956
【train】 epoch：4 step:13065/14065 loss：0.012281
【train】 epoch：4 step:13066/14065 loss：0.115666
【train】 epoch：4 step:13067/14065 loss：0.011779
【train】 epoch：4 step:13068/14065 loss：0.005927
【train】 epoch：4 step:13069/14065 loss：0.083705
【train】 epoch：4 step:13070/14065 loss：0.041536
【train】 epoch：4 step:13071/14065 loss：0.022323
【train】 epoch：4 step:13072/14065 loss：0.024740
【train】 epoch：4 step:13073/14065 loss：0.069797
【train】 epoch：4 step:13074/14065 loss：0.041577
【train】 epoch：4 step:13075/14065 loss：0.044421
【train】 epoch：4 step:13076/14065 loss：0.062886
【train】 epoch：4 step:13077/14065 loss：0.069863
【train】 epoch：4 step:13078/14065 loss：0.016804
【train】 epoch：4 step:13079/14065 loss：0.016033
【train】 epoch：4 step:13080/14065 loss：0.014487
【train】 epoch：4 step:13081/14065 loss：0.016623
【train】 epoch：4 step:13082/14065 loss：0.152434
【train】 epoch：4 step:13083/14065 loss：0.050764
【train】 epoch：4 step:13084/14065 loss：0.054161
【train】 epoch：4 step:13085/14065 loss：0.011445
【train】 epoch：4 step:13086/14065 loss：0.052598
【train】 epoch：4 step:13087/14065 loss：0.071654
【train】 epoch：4 step:13088/14065 loss：0.055656
【train】 epoch：4 step:13089/14065 loss：0.145263
【train】 epoch：4 step:13090/14065 loss：0.045368
【train】 epoch：4 step:13091/14065 loss：0.013091
【train】 epoch：4 step:13092/14065 loss：0.036992
【train】 epoch：4 step:13093/14065 loss：0.136147
【train】 epoch：4 step:13094/14065 loss：0.019144
【train】 epoch：4 step:13095/14065 loss：0.184570
【train】 epoch：4 step:13096/14065 loss：0.053002
【train】 epoch：4 step:13097/14065 loss：0.010493
【train】 epoch：4 step:13098/14065 loss：0.040579
【train】 epoch：4 step:13099/14065 loss：0.013280
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：80.266670 accuracy：0.9910 precision：0.9910 recall：0.9910 f1：0.9910
【train】 epoch：4 step:13100/14065 loss：0.037080
【train】 epoch：4 step:13101/14065 loss：0.061484
【train】 epoch：4 step:13102/14065 loss：0.175343
【train】 epoch：4 step:13103/14065 loss：0.129874
【train】 epoch：4 step:13104/14065 loss：0.008008
【train】 epoch：4 step:13105/14065 loss：0.013583
【train】 epoch：4 step:13106/14065 loss：0.106208
【train】 epoch：4 step:13107/14065 loss：0.115767
【train】 epoch：4 step:13108/14065 loss：0.023734
【train】 epoch：4 step:13109/14065 loss：0.043556
【train】 epoch：4 step:13110/14065 loss：0.084701
【train】 epoch：4 step:13111/14065 loss：0.007182
【train】 epoch：4 step:13112/14065 loss：0.064413
【train】 epoch：4 step:13113/14065 loss：0.018549
【train】 epoch：4 step:13114/14065 loss：0.112615
【train】 epoch：4 step:13115/14065 loss：0.002074
【train】 epoch：4 step:13116/14065 loss：0.043055
【train】 epoch：4 step:13117/14065 loss：0.044808
【train】 epoch：4 step:13118/14065 loss：0.034079
【train】 epoch：4 step:13119/14065 loss：0.012533
【train】 epoch：4 step:13120/14065 loss：0.145076
【train】 epoch：4 step:13121/14065 loss：0.008043
【train】 epoch：4 step:13122/14065 loss：0.045386
【train】 epoch：4 step:13123/14065 loss：0.062865
【train】 epoch：4 step:13124/14065 loss：0.136067
【train】 epoch：4 step:13125/14065 loss：0.017629
【train】 epoch：4 step:13126/14065 loss：0.017464
【train】 epoch：4 step:13127/14065 loss：0.060249
【train】 epoch：4 step:13128/14065 loss：0.141836
【train】 epoch：4 step:13129/14065 loss：0.011127
【train】 epoch：4 step:13130/14065 loss：0.030732
【train】 epoch：4 step:13131/14065 loss：0.014548
【train】 epoch：4 step:13132/14065 loss：0.069769
【train】 epoch：4 step:13133/14065 loss：0.017386
【train】 epoch：4 step:13134/14065 loss：0.010060
【train】 epoch：4 step:13135/14065 loss：0.098697
【train】 epoch：4 step:13136/14065 loss：0.170582
【train】 epoch：4 step:13137/14065 loss：0.035947
【train】 epoch：4 step:13138/14065 loss：0.044985
【train】 epoch：4 step:13139/14065 loss：0.018463
【train】 epoch：4 step:13140/14065 loss：0.080973
【train】 epoch：4 step:13141/14065 loss：0.029862
【train】 epoch：4 step:13142/14065 loss：0.003859
【train】 epoch：4 step:13143/14065 loss：0.012702
【train】 epoch：4 step:13144/14065 loss：0.094802
【train】 epoch：4 step:13145/14065 loss：0.048904
【train】 epoch：4 step:13146/14065 loss：0.150552
【train】 epoch：4 step:13147/14065 loss：0.033326
【train】 epoch：4 step:13148/14065 loss：0.065110
【train】 epoch：4 step:13149/14065 loss：0.058977
【train】 epoch：4 step:13150/14065 loss：0.023871
【train】 epoch：4 step:13151/14065 loss：0.025405
【train】 epoch：4 step:13152/14065 loss：0.145534
【train】 epoch：4 step:13153/14065 loss：0.020056
【train】 epoch：4 step:13154/14065 loss：0.015870
【train】 epoch：4 step:13155/14065 loss：0.028005
【train】 epoch：4 step:13156/14065 loss：0.027841
【train】 epoch：4 step:13157/14065 loss：0.051384
【train】 epoch：4 step:13158/14065 loss：0.009339
【train】 epoch：4 step:13159/14065 loss：0.065314
【train】 epoch：4 step:13160/14065 loss：0.043084
【train】 epoch：4 step:13161/14065 loss：0.013284
【train】 epoch：4 step:13162/14065 loss：0.022036
【train】 epoch：4 step:13163/14065 loss：0.007147
【train】 epoch：4 step:13164/14065 loss：0.022649
【train】 epoch：4 step:13165/14065 loss：0.005650
【train】 epoch：4 step:13166/14065 loss：0.012128
【train】 epoch：4 step:13167/14065 loss：0.037216
【train】 epoch：4 step:13168/14065 loss：0.028099
【train】 epoch：4 step:13169/14065 loss：0.024167
【train】 epoch：4 step:13170/14065 loss：0.037376
【train】 epoch：4 step:13171/14065 loss：0.024917
【train】 epoch：4 step:13172/14065 loss：0.043826
【train】 epoch：4 step:13173/14065 loss：0.043955
【train】 epoch：4 step:13174/14065 loss：0.007566
【train】 epoch：4 step:13175/14065 loss：0.008788
【train】 epoch：4 step:13176/14065 loss：0.092882
【train】 epoch：4 step:13177/14065 loss：0.017024
【train】 epoch：4 step:13178/14065 loss：0.018612
【train】 epoch：4 step:13179/14065 loss：0.116219
【train】 epoch：4 step:13180/14065 loss：0.014751
【train】 epoch：4 step:13181/14065 loss：0.105568
【train】 epoch：4 step:13182/14065 loss：0.023022
【train】 epoch：4 step:13183/14065 loss：0.099935
【train】 epoch：4 step:13184/14065 loss：0.102410
【train】 epoch：4 step:13185/14065 loss：0.012501
【train】 epoch：4 step:13186/14065 loss：0.046444
【train】 epoch：4 step:13187/14065 loss：0.021416
【train】 epoch：4 step:13188/14065 loss：0.046410
【train】 epoch：4 step:13189/14065 loss：0.021496
【train】 epoch：4 step:13190/14065 loss：0.058711
【train】 epoch：4 step:13191/14065 loss：0.024928
【train】 epoch：4 step:13192/14065 loss：0.018125
【train】 epoch：4 step:13193/14065 loss：0.011977
【train】 epoch：4 step:13194/14065 loss：0.021966
【train】 epoch：4 step:13195/14065 loss：0.103489
【train】 epoch：4 step:13196/14065 loss：0.248731
【train】 epoch：4 step:13197/14065 loss：0.061205
【train】 epoch：4 step:13198/14065 loss：0.029757
【train】 epoch：4 step:13199/14065 loss：0.005332
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：66.838899 accuracy：0.9926 precision：0.9926 recall：0.9926 f1：0.9926
【train】 epoch：4 step:13200/14065 loss：0.047363
【train】 epoch：4 step:13201/14065 loss：0.112401
【train】 epoch：4 step:13202/14065 loss：0.009519
【train】 epoch：4 step:13203/14065 loss：0.005355
【train】 epoch：4 step:13204/14065 loss：0.084459
【train】 epoch：4 step:13205/14065 loss：0.098533
【train】 epoch：4 step:13206/14065 loss：0.016225
【train】 epoch：4 step:13207/14065 loss：0.047307
【train】 epoch：4 step:13208/14065 loss：0.051606
【train】 epoch：4 step:13209/14065 loss：0.025059
【train】 epoch：4 step:13210/14065 loss：0.058940
【train】 epoch：4 step:13211/14065 loss：0.096678
【train】 epoch：4 step:13212/14065 loss：0.022244
【train】 epoch：4 step:13213/14065 loss：0.011258
【train】 epoch：4 step:13214/14065 loss：0.005198
【train】 epoch：4 step:13215/14065 loss：0.125543
【train】 epoch：4 step:13216/14065 loss：0.047284
【train】 epoch：4 step:13217/14065 loss：0.051237
【train】 epoch：4 step:13218/14065 loss：0.098307
【train】 epoch：4 step:13219/14065 loss：0.058995
【train】 epoch：4 step:13220/14065 loss：0.209735
【train】 epoch：4 step:13221/14065 loss：0.007693
【train】 epoch：4 step:13222/14065 loss：0.005813
【train】 epoch：4 step:13223/14065 loss：0.004547
【train】 epoch：4 step:13224/14065 loss：0.039964
【train】 epoch：4 step:13225/14065 loss：0.017162
【train】 epoch：4 step:13226/14065 loss：0.014329
【train】 epoch：4 step:13227/14065 loss：0.140626
【train】 epoch：4 step:13228/14065 loss：0.026723
【train】 epoch：4 step:13229/14065 loss：0.031107
【train】 epoch：4 step:13230/14065 loss：0.034872
【train】 epoch：4 step:13231/14065 loss：0.077537
【train】 epoch：4 step:13232/14065 loss：0.065905
【train】 epoch：4 step:13233/14065 loss：0.079500
【train】 epoch：4 step:13234/14065 loss：0.040892
【train】 epoch：4 step:13235/14065 loss：0.042785
【train】 epoch：4 step:13236/14065 loss：0.087874
【train】 epoch：4 step:13237/14065 loss：0.166125
【train】 epoch：4 step:13238/14065 loss：0.005857
【train】 epoch：4 step:13239/14065 loss：0.033726
【train】 epoch：4 step:13240/14065 loss：0.028007
【train】 epoch：4 step:13241/14065 loss：0.012770
【train】 epoch：4 step:13242/14065 loss：0.005442
【train】 epoch：4 step:13243/14065 loss：0.011593
【train】 epoch：4 step:13244/14065 loss：0.042462
【train】 epoch：4 step:13245/14065 loss：0.050902
【train】 epoch：4 step:13246/14065 loss：0.033529
【train】 epoch：4 step:13247/14065 loss：0.118054
【train】 epoch：4 step:13248/14065 loss：0.050820
【train】 epoch：4 step:13249/14065 loss：0.080561
【train】 epoch：4 step:13250/14065 loss：0.042908
【train】 epoch：4 step:13251/14065 loss：0.059634
【train】 epoch：4 step:13252/14065 loss：0.059897
【train】 epoch：4 step:13253/14065 loss：0.115441
【train】 epoch：4 step:13254/14065 loss：0.007830
【train】 epoch：4 step:13255/14065 loss：0.060539
【train】 epoch：4 step:13256/14065 loss：0.076063
【train】 epoch：4 step:13257/14065 loss：0.032935
【train】 epoch：4 step:13258/14065 loss：0.013469
【train】 epoch：4 step:13259/14065 loss：0.024577
【train】 epoch：4 step:13260/14065 loss：0.027032
【train】 epoch：4 step:13261/14065 loss：0.056755
【train】 epoch：4 step:13262/14065 loss：0.072025
【train】 epoch：4 step:13263/14065 loss：0.035337
【train】 epoch：4 step:13264/14065 loss：0.078279
【train】 epoch：4 step:13265/14065 loss：0.190092
【train】 epoch：4 step:13266/14065 loss：0.027088
【train】 epoch：4 step:13267/14065 loss：0.025640
【train】 epoch：4 step:13268/14065 loss：0.009472
【train】 epoch：4 step:13269/14065 loss：0.023118
【train】 epoch：4 step:13270/14065 loss：0.006675
【train】 epoch：4 step:13271/14065 loss：0.053358
【train】 epoch：4 step:13272/14065 loss：0.051327
【train】 epoch：4 step:13273/14065 loss：0.041240
【train】 epoch：4 step:13274/14065 loss：0.023803
【train】 epoch：4 step:13275/14065 loss：0.092366
【train】 epoch：4 step:13276/14065 loss：0.178137
【train】 epoch：4 step:13277/14065 loss：0.056754
【train】 epoch：4 step:13278/14065 loss：0.020761
【train】 epoch：4 step:13279/14065 loss：0.064831
【train】 epoch：4 step:13280/14065 loss：0.117872
【train】 epoch：4 step:13281/14065 loss：0.033937
【train】 epoch：4 step:13282/14065 loss：0.040482
【train】 epoch：4 step:13283/14065 loss：0.005233
【train】 epoch：4 step:13284/14065 loss：0.129471
【train】 epoch：4 step:13285/14065 loss：0.028862
【train】 epoch：4 step:13286/14065 loss：0.070003
【train】 epoch：4 step:13287/14065 loss：0.068851
【train】 epoch：4 step:13288/14065 loss：0.074781
【train】 epoch：4 step:13289/14065 loss：0.003489
【train】 epoch：4 step:13290/14065 loss：0.051540
【train】 epoch：4 step:13291/14065 loss：0.096750
【train】 epoch：4 step:13292/14065 loss：0.036001
【train】 epoch：4 step:13293/14065 loss：0.108004
【train】 epoch：4 step:13294/14065 loss：0.040760
【train】 epoch：4 step:13295/14065 loss：0.047346
【train】 epoch：4 step:13296/14065 loss：0.037477
【train】 epoch：4 step:13297/14065 loss：0.113526
【train】 epoch：4 step:13298/14065 loss：0.098874
【train】 epoch：4 step:13299/14065 loss：0.007914
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：61.817480 accuracy：0.9933 precision：0.9933 recall：0.9933 f1：0.9933
------------>保存当前最好的模型
【train】 epoch：4 step:13300/14065 loss：0.158136
【train】 epoch：4 step:13301/14065 loss：0.006102
【train】 epoch：4 step:13302/14065 loss：0.025070
【train】 epoch：4 step:13303/14065 loss：0.117271
【train】 epoch：4 step:13304/14065 loss：0.003899
【train】 epoch：4 step:13305/14065 loss：0.011816
【train】 epoch：4 step:13306/14065 loss：0.017681
【train】 epoch：4 step:13307/14065 loss：0.016276
【train】 epoch：4 step:13308/14065 loss：0.073478
【train】 epoch：4 step:13309/14065 loss：0.004601
【train】 epoch：4 step:13310/14065 loss：0.010402
【train】 epoch：4 step:13311/14065 loss：0.030939
【train】 epoch：4 step:13312/14065 loss：0.037710
【train】 epoch：4 step:13313/14065 loss：0.021036
【train】 epoch：4 step:13314/14065 loss：0.040284
【train】 epoch：4 step:13315/14065 loss：0.023768
【train】 epoch：4 step:13316/14065 loss：0.015642
【train】 epoch：4 step:13317/14065 loss：0.075063
【train】 epoch：4 step:13318/14065 loss：0.008111
【train】 epoch：4 step:13319/14065 loss：0.111071
【train】 epoch：4 step:13320/14065 loss：0.110527
【train】 epoch：4 step:13321/14065 loss：0.023294
【train】 epoch：4 step:13322/14065 loss：0.017216
【train】 epoch：4 step:13323/14065 loss：0.030405
【train】 epoch：4 step:13324/14065 loss：0.009061
【train】 epoch：4 step:13325/14065 loss：0.168190
【train】 epoch：4 step:13326/14065 loss：0.054753
【train】 epoch：4 step:13327/14065 loss：0.066762
【train】 epoch：4 step:13328/14065 loss：0.064539
【train】 epoch：4 step:13329/14065 loss：0.016736
【train】 epoch：4 step:13330/14065 loss：0.020156
【train】 epoch：4 step:13331/14065 loss：0.002835
【train】 epoch：4 step:13332/14065 loss：0.010618
【train】 epoch：4 step:13333/14065 loss：0.040885
【train】 epoch：4 step:13334/14065 loss：0.003674
【train】 epoch：4 step:13335/14065 loss：0.133710
【train】 epoch：4 step:13336/14065 loss：0.013337
【train】 epoch：4 step:13337/14065 loss：0.065784
【train】 epoch：4 step:13338/14065 loss：0.084311
【train】 epoch：4 step:13339/14065 loss：0.034074
【train】 epoch：4 step:13340/14065 loss：0.005240
【train】 epoch：4 step:13341/14065 loss：0.011128
【train】 epoch：4 step:13342/14065 loss：0.120141
【train】 epoch：4 step:13343/14065 loss：0.015656
【train】 epoch：4 step:13344/14065 loss：0.034676
【train】 epoch：4 step:13345/14065 loss：0.021900
【train】 epoch：4 step:13346/14065 loss：0.037327
【train】 epoch：4 step:13347/14065 loss：0.024825
【train】 epoch：4 step:13348/14065 loss：0.017134
【train】 epoch：4 step:13349/14065 loss：0.166046
【train】 epoch：4 step:13350/14065 loss：0.066321
【train】 epoch：4 step:13351/14065 loss：0.010623
【train】 epoch：4 step:13352/14065 loss：0.192077
【train】 epoch：4 step:13353/14065 loss：0.019844
【train】 epoch：4 step:13354/14065 loss：0.050397
【train】 epoch：4 step:13355/14065 loss：0.038543
【train】 epoch：4 step:13356/14065 loss：0.005062
【train】 epoch：4 step:13357/14065 loss：0.061219
【train】 epoch：4 step:13358/14065 loss：0.008307
【train】 epoch：4 step:13359/14065 loss：0.097249
【train】 epoch：4 step:13360/14065 loss：0.115325
【train】 epoch：4 step:13361/14065 loss：0.010159
【train】 epoch：4 step:13362/14065 loss：0.027338
【train】 epoch：4 step:13363/14065 loss：0.078140
【train】 epoch：4 step:13364/14065 loss：0.103789
【train】 epoch：4 step:13365/14065 loss：0.047656
【train】 epoch：4 step:13366/14065 loss：0.008332
【train】 epoch：4 step:13367/14065 loss：0.024559
【train】 epoch：4 step:13368/14065 loss：0.015130
【train】 epoch：4 step:13369/14065 loss：0.114717
【train】 epoch：4 step:13370/14065 loss：0.044288
【train】 epoch：4 step:13371/14065 loss：0.091122
【train】 epoch：4 step:13372/14065 loss：0.054936
【train】 epoch：4 step:13373/14065 loss：0.060904
【train】 epoch：4 step:13374/14065 loss：0.007099
【train】 epoch：4 step:13375/14065 loss：0.028388
【train】 epoch：4 step:13376/14065 loss：0.020547
【train】 epoch：4 step:13377/14065 loss：0.029051
【train】 epoch：4 step:13378/14065 loss：0.022011
【train】 epoch：4 step:13379/14065 loss：0.070536
【train】 epoch：4 step:13380/14065 loss：0.129514
【train】 epoch：4 step:13381/14065 loss：0.021880
【train】 epoch：4 step:13382/14065 loss：0.045511
【train】 epoch：4 step:13383/14065 loss：0.038695
【train】 epoch：4 step:13384/14065 loss：0.076154
【train】 epoch：4 step:13385/14065 loss：0.141329
【train】 epoch：4 step:13386/14065 loss：0.034169
【train】 epoch：4 step:13387/14065 loss：0.005206
【train】 epoch：4 step:13388/14065 loss：0.026626
【train】 epoch：4 step:13389/14065 loss：0.074919
【train】 epoch：4 step:13390/14065 loss：0.077173
【train】 epoch：4 step:13391/14065 loss：0.022550
【train】 epoch：4 step:13392/14065 loss：0.019422
【train】 epoch：4 step:13393/14065 loss：0.007289
【train】 epoch：4 step:13394/14065 loss：0.004096
【train】 epoch：4 step:13395/14065 loss：0.060728
【train】 epoch：4 step:13396/14065 loss：0.017845
【train】 epoch：4 step:13397/14065 loss：0.028518
【train】 epoch：4 step:13398/14065 loss：0.033460
【train】 epoch：4 step:13399/14065 loss：0.034425
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：72.110573 accuracy：0.9922 precision：0.9922 recall：0.9922 f1：0.9922
【train】 epoch：4 step:13400/14065 loss：0.033229
【train】 epoch：4 step:13401/14065 loss：0.032755
【train】 epoch：4 step:13402/14065 loss：0.064343
【train】 epoch：4 step:13403/14065 loss：0.172601
【train】 epoch：4 step:13404/14065 loss：0.034332
【train】 epoch：4 step:13405/14065 loss：0.091353
【train】 epoch：4 step:13406/14065 loss：0.124131
【train】 epoch：4 step:13407/14065 loss：0.006209
【train】 epoch：4 step:13408/14065 loss：0.092776
【train】 epoch：4 step:13409/14065 loss：0.048356
【train】 epoch：4 step:13410/14065 loss：0.065277
【train】 epoch：4 step:13411/14065 loss：0.005183
【train】 epoch：4 step:13412/14065 loss：0.086242
【train】 epoch：4 step:13413/14065 loss：0.057250
【train】 epoch：4 step:13414/14065 loss：0.075167
【train】 epoch：4 step:13415/14065 loss：0.131371
【train】 epoch：4 step:13416/14065 loss：0.027560
【train】 epoch：4 step:13417/14065 loss：0.056729
【train】 epoch：4 step:13418/14065 loss：0.085001
【train】 epoch：4 step:13419/14065 loss：0.060659
【train】 epoch：4 step:13420/14065 loss：0.072001
【train】 epoch：4 step:13421/14065 loss：0.040792
【train】 epoch：4 step:13422/14065 loss：0.052547
【train】 epoch：4 step:13423/14065 loss：0.010014
【train】 epoch：4 step:13424/14065 loss：0.178556
【train】 epoch：4 step:13425/14065 loss：0.025282
【train】 epoch：4 step:13426/14065 loss：0.019727
【train】 epoch：4 step:13427/14065 loss：0.025416
【train】 epoch：4 step:13428/14065 loss：0.129598
【train】 epoch：4 step:13429/14065 loss：0.047076
【train】 epoch：4 step:13430/14065 loss：0.012201
【train】 epoch：4 step:13431/14065 loss：0.031760
【train】 epoch：4 step:13432/14065 loss：0.020363
【train】 epoch：4 step:13433/14065 loss：0.053436
【train】 epoch：4 step:13434/14065 loss：0.106739
【train】 epoch：4 step:13435/14065 loss：0.010808
【train】 epoch：4 step:13436/14065 loss：0.038230
【train】 epoch：4 step:13437/14065 loss：0.054481
【train】 epoch：4 step:13438/14065 loss：0.083391
【train】 epoch：4 step:13439/14065 loss：0.061409
【train】 epoch：4 step:13440/14065 loss：0.081323
【train】 epoch：4 step:13441/14065 loss：0.077219
【train】 epoch：4 step:13442/14065 loss：0.008420
【train】 epoch：4 step:13443/14065 loss：0.130162
【train】 epoch：4 step:13444/14065 loss：0.048181
【train】 epoch：4 step:13445/14065 loss：0.161986
【train】 epoch：4 step:13446/14065 loss：0.029284
【train】 epoch：4 step:13447/14065 loss：0.105688
【train】 epoch：4 step:13448/14065 loss：0.044772
【train】 epoch：4 step:13449/14065 loss：0.021949
【train】 epoch：4 step:13450/14065 loss：0.108031
【train】 epoch：4 step:13451/14065 loss：0.003760
【train】 epoch：4 step:13452/14065 loss：0.022440
【train】 epoch：4 step:13453/14065 loss：0.056680
【train】 epoch：4 step:13454/14065 loss：0.119580
【train】 epoch：4 step:13455/14065 loss：0.009796
【train】 epoch：4 step:13456/14065 loss：0.164057
【train】 epoch：4 step:13457/14065 loss：0.017144
【train】 epoch：4 step:13458/14065 loss：0.081754
【train】 epoch：4 step:13459/14065 loss：0.037941
【train】 epoch：4 step:13460/14065 loss：0.038686
【train】 epoch：4 step:13461/14065 loss：0.175825
【train】 epoch：4 step:13462/14065 loss：0.020404
【train】 epoch：4 step:13463/14065 loss：0.027509
【train】 epoch：4 step:13464/14065 loss：0.075941
【train】 epoch：4 step:13465/14065 loss：0.032486
【train】 epoch：4 step:13466/14065 loss：0.148444
【train】 epoch：4 step:13467/14065 loss：0.067016
【train】 epoch：4 step:13468/14065 loss：0.024543
【train】 epoch：4 step:13469/14065 loss：0.035621
【train】 epoch：4 step:13470/14065 loss：0.080609
【train】 epoch：4 step:13471/14065 loss：0.009631
【train】 epoch：4 step:13472/14065 loss：0.074529
【train】 epoch：4 step:13473/14065 loss：0.013306
【train】 epoch：4 step:13474/14065 loss：0.069092
【train】 epoch：4 step:13475/14065 loss：0.051890
【train】 epoch：4 step:13476/14065 loss：0.032256
【train】 epoch：4 step:13477/14065 loss：0.088977
【train】 epoch：4 step:13478/14065 loss：0.068035
【train】 epoch：4 step:13479/14065 loss：0.061148
【train】 epoch：4 step:13480/14065 loss：0.087195
【train】 epoch：4 step:13481/14065 loss：0.011349
【train】 epoch：4 step:13482/14065 loss：0.080437
【train】 epoch：4 step:13483/14065 loss：0.003990
【train】 epoch：4 step:13484/14065 loss：0.005787
【train】 epoch：4 step:13485/14065 loss：0.049996
【train】 epoch：4 step:13486/14065 loss：0.026141
【train】 epoch：4 step:13487/14065 loss：0.036792
【train】 epoch：4 step:13488/14065 loss：0.078570
【train】 epoch：4 step:13489/14065 loss：0.067717
【train】 epoch：4 step:13490/14065 loss：0.018199
【train】 epoch：4 step:13491/14065 loss：0.158763
【train】 epoch：4 step:13492/14065 loss：0.012041
【train】 epoch：4 step:13493/14065 loss：0.019650
【train】 epoch：4 step:13494/14065 loss：0.057953
【train】 epoch：4 step:13495/14065 loss：0.226261
【train】 epoch：4 step:13496/14065 loss：0.021360
【train】 epoch：4 step:13497/14065 loss：0.040580
【train】 epoch：4 step:13498/14065 loss：0.012499
【train】 epoch：4 step:13499/14065 loss：0.066846
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：70.464838 accuracy：0.9920 precision：0.9920 recall：0.9920 f1：0.9920
【train】 epoch：4 step:13500/14065 loss：0.003444
【train】 epoch：4 step:13501/14065 loss：0.013785
【train】 epoch：4 step:13502/14065 loss：0.128765
【train】 epoch：4 step:13503/14065 loss：0.078122
【train】 epoch：4 step:13504/14065 loss：0.027588
【train】 epoch：4 step:13505/14065 loss：0.108277
【train】 epoch：4 step:13506/14065 loss：0.114250
【train】 epoch：4 step:13507/14065 loss：0.070831
【train】 epoch：4 step:13508/14065 loss：0.045557
【train】 epoch：4 step:13509/14065 loss：0.017568
【train】 epoch：4 step:13510/14065 loss：0.079205
【train】 epoch：4 step:13511/14065 loss：0.028504
【train】 epoch：4 step:13512/14065 loss：0.039968
【train】 epoch：4 step:13513/14065 loss：0.016815
【train】 epoch：4 step:13514/14065 loss：0.126715
【train】 epoch：4 step:13515/14065 loss：0.021845
【train】 epoch：4 step:13516/14065 loss：0.033234
【train】 epoch：4 step:13517/14065 loss：0.153835
【train】 epoch：4 step:13518/14065 loss：0.043586
【train】 epoch：4 step:13519/14065 loss：0.051199
【train】 epoch：4 step:13520/14065 loss：0.139278
【train】 epoch：4 step:13521/14065 loss：0.075665
【train】 epoch：4 step:13522/14065 loss：0.024924
【train】 epoch：4 step:13523/14065 loss：0.016045
【train】 epoch：4 step:13524/14065 loss：0.019014
【train】 epoch：4 step:13525/14065 loss：0.011950
【train】 epoch：4 step:13526/14065 loss：0.071059
【train】 epoch：4 step:13527/14065 loss：0.156438
【train】 epoch：4 step:13528/14065 loss：0.116799
【train】 epoch：4 step:13529/14065 loss：0.010516
【train】 epoch：4 step:13530/14065 loss：0.049094
【train】 epoch：4 step:13531/14065 loss：0.078863
【train】 epoch：4 step:13532/14065 loss：0.013856
【train】 epoch：4 step:13533/14065 loss：0.032688
【train】 epoch：4 step:13534/14065 loss：0.010216
【train】 epoch：4 step:13535/14065 loss：0.020660
【train】 epoch：4 step:13536/14065 loss：0.063480
【train】 epoch：4 step:13537/14065 loss：0.057237
【train】 epoch：4 step:13538/14065 loss：0.032081
【train】 epoch：4 step:13539/14065 loss：0.012356
【train】 epoch：4 step:13540/14065 loss：0.149161
【train】 epoch：4 step:13541/14065 loss：0.034827
【train】 epoch：4 step:13542/14065 loss：0.104272
【train】 epoch：4 step:13543/14065 loss：0.067967
【train】 epoch：4 step:13544/14065 loss：0.031251
【train】 epoch：4 step:13545/14065 loss：0.070387
【train】 epoch：4 step:13546/14065 loss：0.035863
【train】 epoch：4 step:13547/14065 loss：0.014928
【train】 epoch：4 step:13548/14065 loss：0.009838
【train】 epoch：4 step:13549/14065 loss：0.047504
【train】 epoch：4 step:13550/14065 loss：0.007758
【train】 epoch：4 step:13551/14065 loss：0.148582
【train】 epoch：4 step:13552/14065 loss：0.136295
【train】 epoch：4 step:13553/14065 loss：0.090672
【train】 epoch：4 step:13554/14065 loss：0.064593
【train】 epoch：4 step:13555/14065 loss：0.051208
【train】 epoch：4 step:13556/14065 loss：0.135551
【train】 epoch：4 step:13557/14065 loss：0.034221
【train】 epoch：4 step:13558/14065 loss：0.033838
【train】 epoch：4 step:13559/14065 loss：0.011362
【train】 epoch：4 step:13560/14065 loss：0.092809
【train】 epoch：4 step:13561/14065 loss：0.105815
【train】 epoch：4 step:13562/14065 loss：0.041495
【train】 epoch：4 step:13563/14065 loss：0.126776
【train】 epoch：4 step:13564/14065 loss：0.025682
【train】 epoch：4 step:13565/14065 loss：0.027725
【train】 epoch：4 step:13566/14065 loss：0.021453
【train】 epoch：4 step:13567/14065 loss：0.062253
【train】 epoch：4 step:13568/14065 loss：0.069727
【train】 epoch：4 step:13569/14065 loss：0.137488
【train】 epoch：4 step:13570/14065 loss：0.093075
【train】 epoch：4 step:13571/14065 loss：0.024519
【train】 epoch：4 step:13572/14065 loss：0.215202
【train】 epoch：4 step:13573/14065 loss：0.033548
【train】 epoch：4 step:13574/14065 loss：0.119824
【train】 epoch：4 step:13575/14065 loss：0.066235
【train】 epoch：4 step:13576/14065 loss：0.111853
【train】 epoch：4 step:13577/14065 loss：0.140218
【train】 epoch：4 step:13578/14065 loss：0.022331
【train】 epoch：4 step:13579/14065 loss：0.055096
【train】 epoch：4 step:13580/14065 loss：0.016264
【train】 epoch：4 step:13581/14065 loss：0.189400
【train】 epoch：4 step:13582/14065 loss：0.067187
【train】 epoch：4 step:13583/14065 loss：0.050952
【train】 epoch：4 step:13584/14065 loss：0.130728
【train】 epoch：4 step:13585/14065 loss：0.092242
【train】 epoch：4 step:13586/14065 loss：0.045821
【train】 epoch：4 step:13587/14065 loss：0.083890
【train】 epoch：4 step:13588/14065 loss：0.101274
【train】 epoch：4 step:13589/14065 loss：0.046653
【train】 epoch：4 step:13590/14065 loss：0.093217
【train】 epoch：4 step:13591/14065 loss：0.008140
【train】 epoch：4 step:13592/14065 loss：0.029406
【train】 epoch：4 step:13593/14065 loss：0.136780
【train】 epoch：4 step:13594/14065 loss：0.042205
【train】 epoch：4 step:13595/14065 loss：0.047118
【train】 epoch：4 step:13596/14065 loss：0.009387
【train】 epoch：4 step:13597/14065 loss：0.086328
【train】 epoch：4 step:13598/14065 loss：0.089524
【train】 epoch：4 step:13599/14065 loss：0.045723
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：69.147208 accuracy：0.9927 precision：0.9927 recall：0.9927 f1：0.9927
【train】 epoch：4 step:13600/14065 loss：0.140732
【train】 epoch：4 step:13601/14065 loss：0.004486
【train】 epoch：4 step:13602/14065 loss：0.062408
【train】 epoch：4 step:13603/14065 loss：0.011594
【train】 epoch：4 step:13604/14065 loss：0.008530
【train】 epoch：4 step:13605/14065 loss：0.073022
【train】 epoch：4 step:13606/14065 loss：0.014911
【train】 epoch：4 step:13607/14065 loss：0.052910
【train】 epoch：4 step:13608/14065 loss：0.165588
【train】 epoch：4 step:13609/14065 loss：0.089871
【train】 epoch：4 step:13610/14065 loss：0.026290
【train】 epoch：4 step:13611/14065 loss：0.070603
【train】 epoch：4 step:13612/14065 loss：0.025135
【train】 epoch：4 step:13613/14065 loss：0.044166
【train】 epoch：4 step:13614/14065 loss：0.035493
【train】 epoch：4 step:13615/14065 loss：0.021383
【train】 epoch：4 step:13616/14065 loss：0.100123
【train】 epoch：4 step:13617/14065 loss：0.009257
【train】 epoch：4 step:13618/14065 loss：0.019037
【train】 epoch：4 step:13619/14065 loss：0.022789
【train】 epoch：4 step:13620/14065 loss：0.096240
【train】 epoch：4 step:13621/14065 loss：0.024435
【train】 epoch：4 step:13622/14065 loss：0.073634
【train】 epoch：4 step:13623/14065 loss：0.073313
【train】 epoch：4 step:13624/14065 loss：0.047906
【train】 epoch：4 step:13625/14065 loss：0.076788
【train】 epoch：4 step:13626/14065 loss：0.033799
【train】 epoch：4 step:13627/14065 loss：0.018438
【train】 epoch：4 step:13628/14065 loss：0.076422
【train】 epoch：4 step:13629/14065 loss：0.134056
【train】 epoch：4 step:13630/14065 loss：0.023942
【train】 epoch：4 step:13631/14065 loss：0.156212
【train】 epoch：4 step:13632/14065 loss：0.050802
【train】 epoch：4 step:13633/14065 loss：0.049693
【train】 epoch：4 step:13634/14065 loss：0.074740
【train】 epoch：4 step:13635/14065 loss：0.064905
【train】 epoch：4 step:13636/14065 loss：0.035521
【train】 epoch：4 step:13637/14065 loss：0.046133
【train】 epoch：4 step:13638/14065 loss：0.014544
【train】 epoch：4 step:13639/14065 loss：0.053103
【train】 epoch：4 step:13640/14065 loss：0.031056
【train】 epoch：4 step:13641/14065 loss：0.016375
【train】 epoch：4 step:13642/14065 loss：0.009915
【train】 epoch：4 step:13643/14065 loss：0.119341
【train】 epoch：4 step:13644/14065 loss：0.015966
【train】 epoch：4 step:13645/14065 loss：0.062393
【train】 epoch：4 step:13646/14065 loss：0.090552
【train】 epoch：4 step:13647/14065 loss：0.041218
【train】 epoch：4 step:13648/14065 loss：0.013842
【train】 epoch：4 step:13649/14065 loss：0.037511
【train】 epoch：4 step:13650/14065 loss：0.048222
【train】 epoch：4 step:13651/14065 loss：0.022826
【train】 epoch：4 step:13652/14065 loss：0.116923
【train】 epoch：4 step:13653/14065 loss：0.068673
【train】 epoch：4 step:13654/14065 loss：0.082287
【train】 epoch：4 step:13655/14065 loss：0.030912
【train】 epoch：4 step:13656/14065 loss：0.040040
【train】 epoch：4 step:13657/14065 loss：0.121867
【train】 epoch：4 step:13658/14065 loss：0.013312
【train】 epoch：4 step:13659/14065 loss：0.124240
【train】 epoch：4 step:13660/14065 loss：0.092163
【train】 epoch：4 step:13661/14065 loss：0.075368
【train】 epoch：4 step:13662/14065 loss：0.058878
【train】 epoch：4 step:13663/14065 loss：0.005571
【train】 epoch：4 step:13664/14065 loss：0.164788
【train】 epoch：4 step:13665/14065 loss：0.050562
【train】 epoch：4 step:13666/14065 loss：0.108158
【train】 epoch：4 step:13667/14065 loss：0.023756
【train】 epoch：4 step:13668/14065 loss：0.005511
【train】 epoch：4 step:13669/14065 loss：0.122753
【train】 epoch：4 step:13670/14065 loss：0.125611
【train】 epoch：4 step:13671/14065 loss：0.096159
【train】 epoch：4 step:13672/14065 loss：0.045201
【train】 epoch：4 step:13673/14065 loss：0.107935
【train】 epoch：4 step:13674/14065 loss：0.033920
【train】 epoch：4 step:13675/14065 loss：0.087461
【train】 epoch：4 step:13676/14065 loss：0.034893
【train】 epoch：4 step:13677/14065 loss：0.053697
【train】 epoch：4 step:13678/14065 loss：0.062599
【train】 epoch：4 step:13679/14065 loss：0.057463
【train】 epoch：4 step:13680/14065 loss：0.034873
【train】 epoch：4 step:13681/14065 loss：0.065651
【train】 epoch：4 step:13682/14065 loss：0.021177
【train】 epoch：4 step:13683/14065 loss：0.045313
【train】 epoch：4 step:13684/14065 loss：0.029323
【train】 epoch：4 step:13685/14065 loss：0.004987
【train】 epoch：4 step:13686/14065 loss：0.051778
【train】 epoch：4 step:13687/14065 loss：0.039589
【train】 epoch：4 step:13688/14065 loss：0.050508
【train】 epoch：4 step:13689/14065 loss：0.051557
【train】 epoch：4 step:13690/14065 loss：0.053829
【train】 epoch：4 step:13691/14065 loss：0.073099
【train】 epoch：4 step:13692/14065 loss：0.098912
【train】 epoch：4 step:13693/14065 loss：0.035592
【train】 epoch：4 step:13694/14065 loss：0.122065
【train】 epoch：4 step:13695/14065 loss：0.031878
【train】 epoch：4 step:13696/14065 loss：0.066219
【train】 epoch：4 step:13697/14065 loss：0.066153
【train】 epoch：4 step:13698/14065 loss：0.029690
【train】 epoch：4 step:13699/14065 loss：0.024059
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：89.243016 accuracy：0.9899 precision：0.9899 recall：0.9899 f1：0.9899
【train】 epoch：4 step:13700/14065 loss：0.071154
【train】 epoch：4 step:13701/14065 loss：0.033235
【train】 epoch：4 step:13702/14065 loss：0.014809
【train】 epoch：4 step:13703/14065 loss：0.034878
【train】 epoch：4 step:13704/14065 loss：0.064610
【train】 epoch：4 step:13705/14065 loss：0.100944
【train】 epoch：4 step:13706/14065 loss：0.146674
【train】 epoch：4 step:13707/14065 loss：0.165265
【train】 epoch：4 step:13708/14065 loss：0.073830
【train】 epoch：4 step:13709/14065 loss：0.049770
【train】 epoch：4 step:13710/14065 loss：0.125806
【train】 epoch：4 step:13711/14065 loss：0.012738
【train】 epoch：4 step:13712/14065 loss：0.090870
【train】 epoch：4 step:13713/14065 loss：0.036306
【train】 epoch：4 step:13714/14065 loss：0.017039
【train】 epoch：4 step:13715/14065 loss：0.109802
【train】 epoch：4 step:13716/14065 loss：0.014513
【train】 epoch：4 step:13717/14065 loss：0.064369
【train】 epoch：4 step:13718/14065 loss：0.012032
【train】 epoch：4 step:13719/14065 loss：0.090302
【train】 epoch：4 step:13720/14065 loss：0.082491
【train】 epoch：4 step:13721/14065 loss：0.012955
【train】 epoch：4 step:13722/14065 loss：0.141601
【train】 epoch：4 step:13723/14065 loss：0.030798
【train】 epoch：4 step:13724/14065 loss：0.014053
【train】 epoch：4 step:13725/14065 loss：0.068178
【train】 epoch：4 step:13726/14065 loss：0.074361
【train】 epoch：4 step:13727/14065 loss：0.043958
【train】 epoch：4 step:13728/14065 loss：0.276381
【train】 epoch：4 step:13729/14065 loss：0.081407
【train】 epoch：4 step:13730/14065 loss：0.028831
【train】 epoch：4 step:13731/14065 loss：0.068051
【train】 epoch：4 step:13732/14065 loss：0.042883
【train】 epoch：4 step:13733/14065 loss：0.039112
【train】 epoch：4 step:13734/14065 loss：0.039903
【train】 epoch：4 step:13735/14065 loss：0.063848
【train】 epoch：4 step:13736/14065 loss：0.040649
【train】 epoch：4 step:13737/14065 loss：0.149457
【train】 epoch：4 step:13738/14065 loss：0.018048
【train】 epoch：4 step:13739/14065 loss：0.072062
【train】 epoch：4 step:13740/14065 loss：0.187639
【train】 epoch：4 step:13741/14065 loss：0.086725
【train】 epoch：4 step:13742/14065 loss：0.038892
【train】 epoch：4 step:13743/14065 loss：0.118355
【train】 epoch：4 step:13744/14065 loss：0.110041
【train】 epoch：4 step:13745/14065 loss：0.031598
【train】 epoch：4 step:13746/14065 loss：0.029846
【train】 epoch：4 step:13747/14065 loss：0.119263
【train】 epoch：4 step:13748/14065 loss：0.024714
【train】 epoch：4 step:13749/14065 loss：0.078607
【train】 epoch：4 step:13750/14065 loss：0.099017
【train】 epoch：4 step:13751/14065 loss：0.110193
【train】 epoch：4 step:13752/14065 loss：0.052401
【train】 epoch：4 step:13753/14065 loss：0.078925
【train】 epoch：4 step:13754/14065 loss：0.058852
【train】 epoch：4 step:13755/14065 loss：0.030279
【train】 epoch：4 step:13756/14065 loss：0.016374
【train】 epoch：4 step:13757/14065 loss：0.012826
【train】 epoch：4 step:13758/14065 loss：0.061756
【train】 epoch：4 step:13759/14065 loss：0.012023
【train】 epoch：4 step:13760/14065 loss：0.070396
【train】 epoch：4 step:13761/14065 loss：0.137154
【train】 epoch：4 step:13762/14065 loss：0.098828
【train】 epoch：4 step:13763/14065 loss：0.007992
【train】 epoch：4 step:13764/14065 loss：0.009945
【train】 epoch：4 step:13765/14065 loss：0.027165
【train】 epoch：4 step:13766/14065 loss：0.003658
【train】 epoch：4 step:13767/14065 loss：0.052321
【train】 epoch：4 step:13768/14065 loss：0.045673
【train】 epoch：4 step:13769/14065 loss：0.074134
【train】 epoch：4 step:13770/14065 loss：0.044671
【train】 epoch：4 step:13771/14065 loss：0.074259
【train】 epoch：4 step:13772/14065 loss：0.027713
【train】 epoch：4 step:13773/14065 loss：0.007257
【train】 epoch：4 step:13774/14065 loss：0.049208
【train】 epoch：4 step:13775/14065 loss：0.044354
【train】 epoch：4 step:13776/14065 loss：0.091604
【train】 epoch：4 step:13777/14065 loss：0.015514
【train】 epoch：4 step:13778/14065 loss：0.126563
【train】 epoch：4 step:13779/14065 loss：0.041524
【train】 epoch：4 step:13780/14065 loss：0.020787
【train】 epoch：4 step:13781/14065 loss：0.154903
【train】 epoch：4 step:13782/14065 loss：0.078240
【train】 epoch：4 step:13783/14065 loss：0.068817
【train】 epoch：4 step:13784/14065 loss：0.067111
【train】 epoch：4 step:13785/14065 loss：0.016322
【train】 epoch：4 step:13786/14065 loss：0.034006
【train】 epoch：4 step:13787/14065 loss：0.047345
【train】 epoch：4 step:13788/14065 loss：0.056490
【train】 epoch：4 step:13789/14065 loss：0.030242
【train】 epoch：4 step:13790/14065 loss：0.074648
【train】 epoch：4 step:13791/14065 loss：0.109707
【train】 epoch：4 step:13792/14065 loss：0.041693
【train】 epoch：4 step:13793/14065 loss：0.018985
【train】 epoch：4 step:13794/14065 loss：0.032454
【train】 epoch：4 step:13795/14065 loss：0.040403
【train】 epoch：4 step:13796/14065 loss：0.120197
【train】 epoch：4 step:13797/14065 loss：0.099061
【train】 epoch：4 step:13798/14065 loss：0.136678
【train】 epoch：4 step:13799/14065 loss：0.092435
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：73.845703 accuracy：0.9922 precision：0.9922 recall：0.9922 f1：0.9922
【train】 epoch：4 step:13800/14065 loss：0.052800
【train】 epoch：4 step:13801/14065 loss：0.079608
【train】 epoch：4 step:13802/14065 loss：0.035393
【train】 epoch：4 step:13803/14065 loss：0.066180
【train】 epoch：4 step:13804/14065 loss：0.043438
【train】 epoch：4 step:13805/14065 loss：0.023075
【train】 epoch：4 step:13806/14065 loss：0.085589
【train】 epoch：4 step:13807/14065 loss：0.044647
【train】 epoch：4 step:13808/14065 loss：0.008364
【train】 epoch：4 step:13809/14065 loss：0.081393
【train】 epoch：4 step:13810/14065 loss：0.209789
【train】 epoch：4 step:13811/14065 loss：0.089092
【train】 epoch：4 step:13812/14065 loss：0.134240
【train】 epoch：4 step:13813/14065 loss：0.048877
【train】 epoch：4 step:13814/14065 loss：0.063822
【train】 epoch：4 step:13815/14065 loss：0.010946
【train】 epoch：4 step:13816/14065 loss：0.018862
【train】 epoch：4 step:13817/14065 loss：0.049562
【train】 epoch：4 step:13818/14065 loss：0.118110
【train】 epoch：4 step:13819/14065 loss：0.114725
【train】 epoch：4 step:13820/14065 loss：0.119130
【train】 epoch：4 step:13821/14065 loss：0.078731
【train】 epoch：4 step:13822/14065 loss：0.071638
【train】 epoch：4 step:13823/14065 loss：0.006293
【train】 epoch：4 step:13824/14065 loss：0.012148
【train】 epoch：4 step:13825/14065 loss：0.108744
【train】 epoch：4 step:13826/14065 loss：0.006279
【train】 epoch：4 step:13827/14065 loss：0.080612
【train】 epoch：4 step:13828/14065 loss：0.103507
【train】 epoch：4 step:13829/14065 loss：0.018191
【train】 epoch：4 step:13830/14065 loss：0.035892
【train】 epoch：4 step:13831/14065 loss：0.086919
【train】 epoch：4 step:13832/14065 loss：0.035970
【train】 epoch：4 step:13833/14065 loss：0.034284
【train】 epoch：4 step:13834/14065 loss：0.028383
【train】 epoch：4 step:13835/14065 loss：0.014147
【train】 epoch：4 step:13836/14065 loss：0.011910
【train】 epoch：4 step:13837/14065 loss：0.027238
【train】 epoch：4 step:13838/14065 loss：0.020762
【train】 epoch：4 step:13839/14065 loss：0.057660
【train】 epoch：4 step:13840/14065 loss：0.011262
【train】 epoch：4 step:13841/14065 loss：0.030938
【train】 epoch：4 step:13842/14065 loss：0.053766
【train】 epoch：4 step:13843/14065 loss：0.078599
【train】 epoch：4 step:13844/14065 loss：0.010833
【train】 epoch：4 step:13845/14065 loss：0.035892
【train】 epoch：4 step:13846/14065 loss：0.035044
【train】 epoch：4 step:13847/14065 loss：0.063386
【train】 epoch：4 step:13848/14065 loss：0.063893
【train】 epoch：4 step:13849/14065 loss：0.126995
【train】 epoch：4 step:13850/14065 loss：0.210042
【train】 epoch：4 step:13851/14065 loss：0.120450
【train】 epoch：4 step:13852/14065 loss：0.025396
【train】 epoch：4 step:13853/14065 loss：0.042326
【train】 epoch：4 step:13854/14065 loss：0.072930
【train】 epoch：4 step:13855/14065 loss：0.037759
【train】 epoch：4 step:13856/14065 loss：0.024741
【train】 epoch：4 step:13857/14065 loss：0.083302
【train】 epoch：4 step:13858/14065 loss：0.056243
【train】 epoch：4 step:13859/14065 loss：0.071280
【train】 epoch：4 step:13860/14065 loss：0.089315
【train】 epoch：4 step:13861/14065 loss：0.013376
【train】 epoch：4 step:13862/14065 loss：0.053339
【train】 epoch：4 step:13863/14065 loss：0.012090
【train】 epoch：4 step:13864/14065 loss：0.047204
【train】 epoch：4 step:13865/14065 loss：0.007211
【train】 epoch：4 step:13866/14065 loss：0.041028
【train】 epoch：4 step:13867/14065 loss：0.054036
【train】 epoch：4 step:13868/14065 loss：0.047050
【train】 epoch：4 step:13869/14065 loss：0.165032
【train】 epoch：4 step:13870/14065 loss：0.081468
【train】 epoch：4 step:13871/14065 loss：0.091890
【train】 epoch：4 step:13872/14065 loss：0.021100
【train】 epoch：4 step:13873/14065 loss：0.045896
【train】 epoch：4 step:13874/14065 loss：0.011715
【train】 epoch：4 step:13875/14065 loss：0.018307
【train】 epoch：4 step:13876/14065 loss：0.074850
【train】 epoch：4 step:13877/14065 loss：0.093191
【train】 epoch：4 step:13878/14065 loss：0.037727
【train】 epoch：4 step:13879/14065 loss：0.010934
【train】 epoch：4 step:13880/14065 loss：0.136718
【train】 epoch：4 step:13881/14065 loss：0.080123
【train】 epoch：4 step:13882/14065 loss：0.010039
【train】 epoch：4 step:13883/14065 loss：0.220606
【train】 epoch：4 step:13884/14065 loss：0.065199
【train】 epoch：4 step:13885/14065 loss：0.034516
【train】 epoch：4 step:13886/14065 loss：0.065171
【train】 epoch：4 step:13887/14065 loss：0.086697
【train】 epoch：4 step:13888/14065 loss：0.064040
【train】 epoch：4 step:13889/14065 loss：0.007611
【train】 epoch：4 step:13890/14065 loss：0.004442
【train】 epoch：4 step:13891/14065 loss：0.023539
【train】 epoch：4 step:13892/14065 loss：0.048239
【train】 epoch：4 step:13893/14065 loss：0.081490
【train】 epoch：4 step:13894/14065 loss：0.011222
【train】 epoch：4 step:13895/14065 loss：0.081737
【train】 epoch：4 step:13896/14065 loss：0.030839
【train】 epoch：4 step:13897/14065 loss：0.022447
【train】 epoch：4 step:13898/14065 loss：0.072615
【train】 epoch：4 step:13899/14065 loss：0.002783
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：67.985488 accuracy：0.9930 precision：0.9930 recall：0.9930 f1：0.9930
【train】 epoch：4 step:13900/14065 loss：0.080649
【train】 epoch：4 step:13901/14065 loss：0.035059
【train】 epoch：4 step:13902/14065 loss：0.011184
【train】 epoch：4 step:13903/14065 loss：0.164982
【train】 epoch：4 step:13904/14065 loss：0.215222
【train】 epoch：4 step:13905/14065 loss：0.142100
【train】 epoch：4 step:13906/14065 loss：0.138483
【train】 epoch：4 step:13907/14065 loss：0.004643
【train】 epoch：4 step:13908/14065 loss：0.042960
【train】 epoch：4 step:13909/14065 loss：0.041804
【train】 epoch：4 step:13910/14065 loss：0.105811
【train】 epoch：4 step:13911/14065 loss：0.083797
【train】 epoch：4 step:13912/14065 loss：0.019665
【train】 epoch：4 step:13913/14065 loss：0.055430
【train】 epoch：4 step:13914/14065 loss：0.027182
【train】 epoch：4 step:13915/14065 loss：0.073342
【train】 epoch：4 step:13916/14065 loss：0.093965
【train】 epoch：4 step:13917/14065 loss：0.032432
【train】 epoch：4 step:13918/14065 loss：0.068007
【train】 epoch：4 step:13919/14065 loss：0.078871
【train】 epoch：4 step:13920/14065 loss：0.110622
【train】 epoch：4 step:13921/14065 loss：0.018652
【train】 epoch：4 step:13922/14065 loss：0.027258
【train】 epoch：4 step:13923/14065 loss：0.010584
【train】 epoch：4 step:13924/14065 loss：0.186412
【train】 epoch：4 step:13925/14065 loss：0.110715
【train】 epoch：4 step:13926/14065 loss：0.047007
【train】 epoch：4 step:13927/14065 loss：0.044677
【train】 epoch：4 step:13928/14065 loss：0.012065
【train】 epoch：4 step:13929/14065 loss：0.073224
【train】 epoch：4 step:13930/14065 loss：0.093807
【train】 epoch：4 step:13931/14065 loss：0.078851
【train】 epoch：4 step:13932/14065 loss：0.029672
【train】 epoch：4 step:13933/14065 loss：0.004381
【train】 epoch：4 step:13934/14065 loss：0.011757
【train】 epoch：4 step:13935/14065 loss：0.036668
【train】 epoch：4 step:13936/14065 loss：0.037755
【train】 epoch：4 step:13937/14065 loss：0.072782
【train】 epoch：4 step:13938/14065 loss：0.035176
【train】 epoch：4 step:13939/14065 loss：0.030960
【train】 epoch：4 step:13940/14065 loss：0.023558
【train】 epoch：4 step:13941/14065 loss：0.095292
【train】 epoch：4 step:13942/14065 loss：0.042680
【train】 epoch：4 step:13943/14065 loss：0.056380
【train】 epoch：4 step:13944/14065 loss：0.004903
【train】 epoch：4 step:13945/14065 loss：0.007485
【train】 epoch：4 step:13946/14065 loss：0.027384
【train】 epoch：4 step:13947/14065 loss：0.032458
【train】 epoch：4 step:13948/14065 loss：0.012254
【train】 epoch：4 step:13949/14065 loss：0.008208
【train】 epoch：4 step:13950/14065 loss：0.075942
【train】 epoch：4 step:13951/14065 loss：0.174986
【train】 epoch：4 step:13952/14065 loss：0.023981
【train】 epoch：4 step:13953/14065 loss：0.049732
【train】 epoch：4 step:13954/14065 loss：0.004477
【train】 epoch：4 step:13955/14065 loss：0.010550
【train】 epoch：4 step:13956/14065 loss：0.042521
【train】 epoch：4 step:13957/14065 loss：0.006414
【train】 epoch：4 step:13958/14065 loss：0.020167
【train】 epoch：4 step:13959/14065 loss：0.041790
【train】 epoch：4 step:13960/14065 loss：0.043543
【train】 epoch：4 step:13961/14065 loss：0.032695
【train】 epoch：4 step:13962/14065 loss：0.026617
【train】 epoch：4 step:13963/14065 loss：0.003329
【train】 epoch：4 step:13964/14065 loss：0.006084
【train】 epoch：4 step:13965/14065 loss：0.017451
【train】 epoch：4 step:13966/14065 loss：0.017181
【train】 epoch：4 step:13967/14065 loss：0.033141
【train】 epoch：4 step:13968/14065 loss：0.111097
【train】 epoch：4 step:13969/14065 loss：0.059011
【train】 epoch：4 step:13970/14065 loss：0.057324
【train】 epoch：4 step:13971/14065 loss：0.115973
【train】 epoch：4 step:13972/14065 loss：0.042626
【train】 epoch：4 step:13973/14065 loss：0.025106
【train】 epoch：4 step:13974/14065 loss：0.014786
【train】 epoch：4 step:13975/14065 loss：0.022811
【train】 epoch：4 step:13976/14065 loss：0.060429
【train】 epoch：4 step:13977/14065 loss：0.006454
【train】 epoch：4 step:13978/14065 loss：0.124276
【train】 epoch：4 step:13979/14065 loss：0.055049
【train】 epoch：4 step:13980/14065 loss：0.002306
【train】 epoch：4 step:13981/14065 loss：0.051720
【train】 epoch：4 step:13982/14065 loss：0.004753
【train】 epoch：4 step:13983/14065 loss：0.050363
【train】 epoch：4 step:13984/14065 loss：0.090115
【train】 epoch：4 step:13985/14065 loss：0.012788
【train】 epoch：4 step:13986/14065 loss：0.015737
【train】 epoch：4 step:13987/14065 loss：0.023427
【train】 epoch：4 step:13988/14065 loss：0.002761
【train】 epoch：4 step:13989/14065 loss：0.102297
【train】 epoch：4 step:13990/14065 loss：0.004576
【train】 epoch：4 step:13991/14065 loss：0.034946
【train】 epoch：4 step:13992/14065 loss：0.019377
【train】 epoch：4 step:13993/14065 loss：0.088686
【train】 epoch：4 step:13994/14065 loss：0.094466
【train】 epoch：4 step:13995/14065 loss：0.113328
【train】 epoch：4 step:13996/14065 loss：0.041207
【train】 epoch：4 step:13997/14065 loss：0.082816
【train】 epoch：4 step:13998/14065 loss：0.039750
【train】 epoch：4 step:13999/14065 loss：0.072499
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
【dev】 loss：77.508338 accuracy：0.9908 precision：0.9908 recall：0.9908 f1：0.9908
【train】 epoch：4 step:14000/14065 loss：0.135404
【train】 epoch：4 step:14001/14065 loss：0.078720
【train】 epoch：4 step:14002/14065 loss：0.016231
【train】 epoch：4 step:14003/14065 loss：0.046669
【train】 epoch：4 step:14004/14065 loss：0.099773
【train】 epoch：4 step:14005/14065 loss：0.013631
【train】 epoch：4 step:14006/14065 loss：0.018895
【train】 epoch：4 step:14007/14065 loss：0.082387
【train】 epoch：4 step:14008/14065 loss：0.149652
【train】 epoch：4 step:14009/14065 loss：0.163392
【train】 epoch：4 step:14010/14065 loss：0.071206
【train】 epoch：4 step:14011/14065 loss：0.023745
【train】 epoch：4 step:14012/14065 loss：0.053250
【train】 epoch：4 step:14013/14065 loss：0.174989
【train】 epoch：4 step:14014/14065 loss：0.017759
【train】 epoch：4 step:14015/14065 loss：0.068270
【train】 epoch：4 step:14016/14065 loss：0.105450
【train】 epoch：4 step:14017/14065 loss：0.115564
【train】 epoch：4 step:14018/14065 loss：0.095223
【train】 epoch：4 step:14019/14065 loss：0.006283
【train】 epoch：4 step:14020/14065 loss：0.044405
【train】 epoch：4 step:14021/14065 loss：0.099222
【train】 epoch：4 step:14022/14065 loss：0.008459
【train】 epoch：4 step:14023/14065 loss：0.093180
【train】 epoch：4 step:14024/14065 loss：0.142743
【train】 epoch：4 step:14025/14065 loss：0.007006
【train】 epoch：4 step:14026/14065 loss：0.062707
【train】 epoch：4 step:14027/14065 loss：0.015760
【train】 epoch：4 step:14028/14065 loss：0.068899
【train】 epoch：4 step:14029/14065 loss：0.149145
【train】 epoch：4 step:14030/14065 loss：0.016850
【train】 epoch：4 step:14031/14065 loss：0.023486
【train】 epoch：4 step:14032/14065 loss：0.008140
【train】 epoch：4 step:14033/14065 loss：0.063310
【train】 epoch：4 step:14034/14065 loss：0.110970
【train】 epoch：4 step:14035/14065 loss：0.084951
【train】 epoch：4 step:14036/14065 loss：0.035475
【train】 epoch：4 step:14037/14065 loss：0.016309
【train】 epoch：4 step:14038/14065 loss：0.012744
【train】 epoch：4 step:14039/14065 loss：0.015200
【train】 epoch：4 step:14040/14065 loss：0.007462
【train】 epoch：4 step:14041/14065 loss：0.037593
【train】 epoch：4 step:14042/14065 loss：0.057389
【train】 epoch：4 step:14043/14065 loss：0.141527
【train】 epoch：4 step:14044/14065 loss：0.008469
【train】 epoch：4 step:14045/14065 loss：0.067591
【train】 epoch：4 step:14046/14065 loss：0.048340
【train】 epoch：4 step:14047/14065 loss：0.058563
【train】 epoch：4 step:14048/14065 loss：0.064886
【train】 epoch：4 step:14049/14065 loss：0.036386
【train】 epoch：4 step:14050/14065 loss：0.009001
【train】 epoch：4 step:14051/14065 loss：0.169435
【train】 epoch：4 step:14052/14065 loss：0.024994
【train】 epoch：4 step:14053/14065 loss：0.028000
【train】 epoch：4 step:14054/14065 loss：0.046693
【train】 epoch：4 step:14055/14065 loss：0.101629
【train】 epoch：4 step:14056/14065 loss：0.011602
【train】 epoch：4 step:14057/14065 loss：0.017802
【train】 epoch：4 step:14058/14065 loss：0.064092
【train】 epoch：4 step:14059/14065 loss：0.019336
【train】 epoch：4 step:14060/14065 loss：0.094820
【train】 epoch：4 step:14061/14065 loss：0.072103
【train】 epoch：4 step:14062/14065 loss：0.040998
【train】 epoch：4 step:14063/14065 loss：0.011044
【train】 epoch：4 step:14064/14065 loss：0.133621
